{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8c2ac08b",
      "metadata": {
        "id": "8c2ac08b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.models import load_model\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import plotly.graph_objects as go\n",
        "from math import sqrt\n",
        "import warnings\n",
        "from scipy import stats\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "00f841db",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "00f841db",
        "outputId": "7ce9066c-30cd-4020-fda6-99f3883bf89e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       NEWRACE2_White  NEWRACE2_Black  NEWRACE2_Others  \\\n",
              "0                True           False            False   \n",
              "1                True           False            False   \n",
              "2               False           False             True   \n",
              "3                True           False            False   \n",
              "4                True           False            False   \n",
              "...               ...             ...              ...   \n",
              "32888            True           False            False   \n",
              "32889            True           False            False   \n",
              "32890           False           False             True   \n",
              "32891            True           False            False   \n",
              "32892            True           False            False   \n",
              "\n",
              "       INCOME_1 - Less than $20,000  ADDPREV_1 - Yes  ADDPREV_2 - No  \\\n",
              "0                             False            False            True   \n",
              "1                             False            False            True   \n",
              "2                             False             True           False   \n",
              "3                             False            False            True   \n",
              "4                             False            False           False   \n",
              "...                             ...              ...             ...   \n",
              "32888                         False             True           False   \n",
              "32889                         False             True           False   \n",
              "32890                         False            False           False   \n",
              "32891                         False             True           False   \n",
              "32892                         False             True           False   \n",
              "\n",
              "       OXCOPDAPYU_1 - Yes  OXYMPDAPYU_1 - Yes  HYDCPDAPYU_1 - Yes  \\\n",
              "0                   False               False               False   \n",
              "1                   False               False                True   \n",
              "2                   False               False                True   \n",
              "3                   False               False               False   \n",
              "4                   False               False               False   \n",
              "...                   ...                 ...                 ...   \n",
              "32888               False               False               False   \n",
              "32889               False               False               False   \n",
              "32890               False               False               False   \n",
              "32891               False               False               False   \n",
              "32892               False               False                True   \n",
              "\n",
              "       HYDMPDAPYU_1 - Yes  ...  CANCEREVR_1 - Yes  CANCEREVR_2 - No  \\\n",
              "0                   False  ...              False              True   \n",
              "1                   False  ...              False             False   \n",
              "2                   False  ...              False             False   \n",
              "3                   False  ...              False              True   \n",
              "4                   False  ...              False              True   \n",
              "...                   ...  ...                ...               ...   \n",
              "32888               False  ...              False              True   \n",
              "32889               False  ...              False              True   \n",
              "32890               False  ...              False             False   \n",
              "32891               False  ...              False             False   \n",
              "32892               False  ...              False              True   \n",
              "\n",
              "       IRSEX_1 - Male  IRMARIT_1 - Married  IRMARIT_2 - Widowed  \\\n",
              "0                True                False                False   \n",
              "1                True                False                False   \n",
              "2               False                False                False   \n",
              "3                True                 True                False   \n",
              "4                True                False                False   \n",
              "...               ...                  ...                  ...   \n",
              "32888            True                False                False   \n",
              "32889            True                 True                False   \n",
              "32890           False                False                False   \n",
              "32891           False                False                False   \n",
              "32892           False                False                False   \n",
              "\n",
              "       IRMARIT_3 - Divorced or Separated  IRMARIT_4 - Never Been Married  \\\n",
              "0                                   True                           False   \n",
              "1                                  False                            True   \n",
              "2                                  False                            True   \n",
              "3                                  False                           False   \n",
              "4                                  False                           False   \n",
              "...                                  ...                             ...   \n",
              "32888                              False                            True   \n",
              "32889                              False                           False   \n",
              "32890                              False                           False   \n",
              "32891                              False                            True   \n",
              "32892                              False                            True   \n",
              "\n",
              "       WRK35WKUS_1 - Yes  WRK35WKUS_2 - No  UDPYOPI_1 - Yes  \n",
              "0                   True             False            False  \n",
              "1                   True             False            False  \n",
              "2                   True             False            False  \n",
              "3                   True             False            False  \n",
              "4                  False             False            False  \n",
              "...                  ...               ...              ...  \n",
              "32888              False             False            False  \n",
              "32889               True             False            False  \n",
              "32890              False             False            False  \n",
              "32891               True             False            False  \n",
              "32892              False             False            False  \n",
              "\n",
              "[32893 rows x 44 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5268d869-c607-4ca2-bc38-68482e6efda9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NEWRACE2_White</th>\n",
              "      <th>NEWRACE2_Black</th>\n",
              "      <th>NEWRACE2_Others</th>\n",
              "      <th>INCOME_1 - Less than $20,000</th>\n",
              "      <th>ADDPREV_1 - Yes</th>\n",
              "      <th>ADDPREV_2 - No</th>\n",
              "      <th>OXCOPDAPYU_1 - Yes</th>\n",
              "      <th>OXYMPDAPYU_1 - Yes</th>\n",
              "      <th>HYDCPDAPYU_1 - Yes</th>\n",
              "      <th>HYDMPDAPYU_1 - Yes</th>\n",
              "      <th>...</th>\n",
              "      <th>CANCEREVR_1 - Yes</th>\n",
              "      <th>CANCEREVR_2 - No</th>\n",
              "      <th>IRSEX_1 - Male</th>\n",
              "      <th>IRMARIT_1 - Married</th>\n",
              "      <th>IRMARIT_2 - Widowed</th>\n",
              "      <th>IRMARIT_3 - Divorced or Separated</th>\n",
              "      <th>IRMARIT_4 - Never Been Married</th>\n",
              "      <th>WRK35WKUS_1 - Yes</th>\n",
              "      <th>WRK35WKUS_2 - No</th>\n",
              "      <th>UDPYOPI_1 - Yes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32888</th>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32889</th>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32890</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32891</th>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32892</th>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>32893 rows Ã— 44 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5268d869-c607-4ca2-bc38-68482e6efda9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5268d869-c607-4ca2-bc38-68482e6efda9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5268d869-c607-4ca2-bc38-68482e6efda9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e710d425-63b3-4d4d-9803-7e1f96b9f50b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e710d425-63b3-4d4d-9803-7e1f96b9f50b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e710d425-63b3-4d4d-9803-7e1f96b9f50b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_564ffd6b-8664-4750-83fe-d740fc60daae\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_564ffd6b-8664-4750-83fe-d740fc60daae button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "df=pd.read_stata('NSDUH_2020.dta')\n",
        "df['BMI2']=pd.to_numeric(df['BMI2'], errors='coerce')\n",
        "\n",
        "df['NEWRACE2'] = df['NEWRACE2'].replace('1 - NonHisp White','White')\n",
        "df['NEWRACE2'] = df['NEWRACE2'].replace('2 - NonHisp Black/Afr Am','Black')\n",
        "df['NEWRACE2'] = df['NEWRACE2'].replace('3 - NonHisp Native Am/AK Native','Others')\n",
        "df['NEWRACE2'] = df['NEWRACE2'].replace('4 - NonHisp Native HI/Other Pac Isl','Others')\n",
        "df['NEWRACE2'] = df['NEWRACE2'].replace('5 - NonHisp Asian','Others')\n",
        "df['NEWRACE2'] = df['NEWRACE2'].replace('6 - NonHisp more than one race','Others')\n",
        "df['NEWRACE2'] = df['NEWRACE2'].replace('7 - Hispanic','Others')\n",
        "\n",
        "data=df[['NEWRACE2', 'INCOME' ,'ADDPREV','OXCOPDAPYU', 'OXYMPDAPYU', 'HYDCPDAPYU', 'HYDMPDAPYU', 'FENTPDAPYU',\n",
        "         'MORPPDAPYU', 'CODEPDAPYU', 'MTDNPDAPYU', 'TRAMPDAPYU', 'BUPRPDAPYU',\n",
        "         'HEREVER','TXEVRRCVD','DIABETEVR', 'COPDEVER', 'CIRROSEVR', 'HEPBCEVER',\n",
        "         'KIDNYDSEV', 'ASTHMAEVR', 'HIVAIDSEV', 'CANCEREVR','IRSEX', 'IRMARIT', 'WRK35WKUS', 'UDPYOPI']]\n",
        "\n",
        "data=pd.get_dummies(data)\n",
        "\n",
        "data=data.drop(['INCOME_2 - $20,000 - $49,999', 'INCOME_3 - $50,000 - $74,999',  'INCOME_4 - $75,000 or More', 'ADDPREV_85 - BAD DATA Logically assigned', 'ADDPREV_94 - DON T KNOW', 'ADDPREV_97 - REFUSED', 'ADDPREV_98 - BLANK',\n",
        "                'ADDPREV_99 - LEGITIMATE SKIP', 'IRSEX_2 - Female',\n",
        "                'OXCOPDAPYU_0 - No/Unknown', 'OXYMPDAPYU_0 - No/Unknown', 'HYDCPDAPYU_0 - No/Unknown', 'HYDMPDAPYU_0 - No/Unknown',\n",
        "               'FENTPDAPYU_0 - No/Unknown', 'MORPPDAPYU_0 - No/Unknown', 'CODEPDAPYU_0 - No/Unknown', 'MTDNPDAPYU_0 - No/Unknown',\n",
        "               'TRAMPDAPYU_0 - No/Unknown', 'BUPRPDAPYU_0 - No/Unknown', 'HEREVER_94 - DON T KNOW',\n",
        "'HEREVER_97 - REFUSED', 'TXEVRRCVD_85 - BAD DATA Logically assigned',\n",
        "'TXEVRRCVD_91 - NEVER USED ALCOHOL OR DRUGS','TXEVRRCVD_94 - DON T KNOW','TXEVRRCVD_97 - REFUSED','TXEVRRCVD_98 - BLANK',\n",
        "                'DIABETEVR_85 - BAD DATA Logically assigned'\n",
        ",'DIABETEVR_94 - DON T KNOW','DIABETEVR_97 - REFUSED','DIABETEVR_98 - BLANK','DIABETEVR_99 - LEGITIMATE SKIP',\n",
        "                'COPDEVER_85 - BAD DATA Logically assigned','COPDEVER_94 - DON T KNOW','COPDEVER_97 - REFUSED'\n",
        ",'COPDEVER_98 - BLANK','COPDEVER_99 - LEGITIMATE SKIP', 'CIRROSEVR_85 - BAD DATA Logically assigned'\n",
        ",'CIRROSEVR_94 - DON T KNOW','CIRROSEVR_97 - REFUSED','CIRROSEVR_98 - BLANK','CIRROSEVR_99 - LEGITIMATE SKIP',\n",
        "                'HEPBCEVER_85 - BAD DATA Logically assigned','HEPBCEVER_94 - DON T KNOW','HEPBCEVER_97 - REFUSED'\n",
        ",'HEPBCEVER_98 - BLANK','HEPBCEVER_99 - LEGITIMATE SKIP'\n",
        ",'KIDNYDSEV_85 - BAD DATA Logically assigned','KIDNYDSEV_94 - DON T KNOW','KIDNYDSEV_97 - REFUSED','KIDNYDSEV_98 - BLANK'\n",
        ",'KIDNYDSEV_99 - LEGITIMATE SKIP','ASTHMAEVR_85 - BAD DATA Logically assigned','ASTHMAEVR_94 - DON T KNOW','ASTHMAEVR_97 - REFUSED',\n",
        "'ASTHMAEVR_98 - BLANK','ASTHMAEVR_99 - LEGITIMATE SKIP', 'HIVAIDSEV_85 - BAD DATA Logically assigned'\n",
        ",'HIVAIDSEV_94 - DON T KNOW','HIVAIDSEV_97 - REFUSED','HIVAIDSEV_98 - BLANK','HIVAIDSEV_99 - LEGITIMATE SKIP',\n",
        "              'CANCEREVR_85 - BAD DATA Logically assigned','CANCEREVR_94 - DON T KNOW','CANCEREVR_97 - REFUSED'\n",
        ",'CANCEREVR_98 - BLANK','CANCEREVR_99 - LEGITIMATE SKIP'\n",
        ",'WRK35WKUS_85 - BAD DATA Logically assigned','WRK35WKUS_94 - DON T KNOW','WRK35WKUS_97 - REFUSED','WRK35WKUS_98 - BLANK'\n",
        ",'WRK35WKUS_99 - LEGITIMATE SKIP', 'UDPYOPI_0 - No', 'IRMARIT_99 - LEGITIMATE SKIP Respondent is <= 14 years old'\n",
        "               ], axis=1)\n",
        "\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "9feae128",
      "metadata": {
        "id": "9feae128"
      },
      "outputs": [],
      "source": [
        "d_pos=data[data['UDPYOPI_1 - Yes'].isin([1])]\n",
        "d_neg=data[data['UDPYOPI_1 - Yes'].isin([0])]\n",
        "data=pd.concat([d_pos, d_neg])\n",
        "\n",
        "X=data.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "y=data['UDPYOPI_1 - Yes']\n",
        "X=X.astype(float)\n",
        "y=y.astype(float)\n",
        "df1=df[['BMI2']]\n",
        "df1=df1.astype(float)\n",
        "X=pd.concat([X, df1], axis=1)\n",
        "\n",
        "X=X.fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.concat([X, y], axis=1)\n",
        "data=data.dropna()"
      ],
      "metadata": {
        "id": "ZYkZV9LMaJbN"
      },
      "id": "ZYkZV9LMaJbN",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "VQOWHIgSaR7S",
        "outputId": "df45261e-b3c3-4df9-9254-aae457bcde02"
      },
      "id": "VQOWHIgSaR7S",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       NEWRACE2_White  NEWRACE2_Black  NEWRACE2_Others  \\\n",
              "193               1.0             0.0              0.0   \n",
              "258               1.0             0.0              0.0   \n",
              "430               0.0             0.0              1.0   \n",
              "776               1.0             0.0              0.0   \n",
              "887               1.0             0.0              0.0   \n",
              "...               ...             ...              ...   \n",
              "32888             1.0             0.0              0.0   \n",
              "32889             1.0             0.0              0.0   \n",
              "32890             0.0             0.0              1.0   \n",
              "32891             1.0             0.0              0.0   \n",
              "32892             1.0             0.0              0.0   \n",
              "\n",
              "       INCOME_1 - Less than $20,000  ADDPREV_1 - Yes  ADDPREV_2 - No  \\\n",
              "193                             0.0              0.0             0.0   \n",
              "258                             0.0              1.0             0.0   \n",
              "430                             0.0              0.0             0.0   \n",
              "776                             0.0              1.0             0.0   \n",
              "887                             0.0              1.0             0.0   \n",
              "...                             ...              ...             ...   \n",
              "32888                           0.0              1.0             0.0   \n",
              "32889                           0.0              1.0             0.0   \n",
              "32890                           0.0              0.0             0.0   \n",
              "32891                           0.0              1.0             0.0   \n",
              "32892                           0.0              1.0             0.0   \n",
              "\n",
              "       OXCOPDAPYU_1 - Yes  OXYMPDAPYU_1 - Yes  HYDCPDAPYU_1 - Yes  \\\n",
              "193                   1.0                 0.0                 1.0   \n",
              "258                   1.0                 0.0                 1.0   \n",
              "430                   1.0                 0.0                 1.0   \n",
              "776                   0.0                 0.0                 0.0   \n",
              "887                   0.0                 0.0                 0.0   \n",
              "...                   ...                 ...                 ...   \n",
              "32888                 0.0                 0.0                 0.0   \n",
              "32889                 0.0                 0.0                 0.0   \n",
              "32890                 0.0                 0.0                 0.0   \n",
              "32891                 0.0                 0.0                 0.0   \n",
              "32892                 0.0                 0.0                 1.0   \n",
              "\n",
              "       HYDMPDAPYU_1 - Yes  ...  CANCEREVR_2 - No  IRSEX_1 - Male  \\\n",
              "193                   0.0  ...               0.0             0.0   \n",
              "258                   0.0  ...               1.0             1.0   \n",
              "430                   0.0  ...               0.0             1.0   \n",
              "776                   0.0  ...               1.0             0.0   \n",
              "887                   0.0  ...               0.0             1.0   \n",
              "...                   ...  ...               ...             ...   \n",
              "32888                 0.0  ...               1.0             1.0   \n",
              "32889                 0.0  ...               1.0             1.0   \n",
              "32890                 0.0  ...               0.0             0.0   \n",
              "32891                 0.0  ...               0.0             0.0   \n",
              "32892                 0.0  ...               1.0             0.0   \n",
              "\n",
              "       IRMARIT_1 - Married  IRMARIT_2 - Widowed  \\\n",
              "193                    0.0                  0.0   \n",
              "258                    1.0                  0.0   \n",
              "430                    0.0                  0.0   \n",
              "776                    0.0                  0.0   \n",
              "887                    0.0                  0.0   \n",
              "...                    ...                  ...   \n",
              "32888                  0.0                  0.0   \n",
              "32889                  1.0                  0.0   \n",
              "32890                  0.0                  0.0   \n",
              "32891                  0.0                  0.0   \n",
              "32892                  0.0                  0.0   \n",
              "\n",
              "       IRMARIT_3 - Divorced or Separated  IRMARIT_4 - Never Been Married  \\\n",
              "193                                  0.0                             1.0   \n",
              "258                                  0.0                             0.0   \n",
              "430                                  0.0                             1.0   \n",
              "776                                  1.0                             0.0   \n",
              "887                                  0.0                             1.0   \n",
              "...                                  ...                             ...   \n",
              "32888                                0.0                             1.0   \n",
              "32889                                0.0                             0.0   \n",
              "32890                                0.0                             0.0   \n",
              "32891                                0.0                             1.0   \n",
              "32892                                0.0                             1.0   \n",
              "\n",
              "       WRK35WKUS_1 - Yes  WRK35WKUS_2 - No       BMI2  UDPYOPI_1 - Yes  \n",
              "193                  0.0               1.0  23.025951              1.0  \n",
              "258                  0.0               0.0  27.546122              1.0  \n",
              "430                  0.0               0.0  20.500099              1.0  \n",
              "776                  1.0               0.0  25.151424              1.0  \n",
              "887                  0.0               0.0  23.108108              1.0  \n",
              "...                  ...               ...        ...              ...  \n",
              "32888                0.0               0.0  38.391094              0.0  \n",
              "32889                1.0               0.0  36.868444              0.0  \n",
              "32890                0.0               0.0  16.812819              0.0  \n",
              "32891                1.0               0.0  21.726686              0.0  \n",
              "32892                0.0               0.0  30.724246              0.0  \n",
              "\n",
              "[32893 rows x 45 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de16e7d3-0c37-475b-afd0-e0e70b60594d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NEWRACE2_White</th>\n",
              "      <th>NEWRACE2_Black</th>\n",
              "      <th>NEWRACE2_Others</th>\n",
              "      <th>INCOME_1 - Less than $20,000</th>\n",
              "      <th>ADDPREV_1 - Yes</th>\n",
              "      <th>ADDPREV_2 - No</th>\n",
              "      <th>OXCOPDAPYU_1 - Yes</th>\n",
              "      <th>OXYMPDAPYU_1 - Yes</th>\n",
              "      <th>HYDCPDAPYU_1 - Yes</th>\n",
              "      <th>HYDMPDAPYU_1 - Yes</th>\n",
              "      <th>...</th>\n",
              "      <th>CANCEREVR_2 - No</th>\n",
              "      <th>IRSEX_1 - Male</th>\n",
              "      <th>IRMARIT_1 - Married</th>\n",
              "      <th>IRMARIT_2 - Widowed</th>\n",
              "      <th>IRMARIT_3 - Divorced or Separated</th>\n",
              "      <th>IRMARIT_4 - Never Been Married</th>\n",
              "      <th>WRK35WKUS_1 - Yes</th>\n",
              "      <th>WRK35WKUS_2 - No</th>\n",
              "      <th>BMI2</th>\n",
              "      <th>UDPYOPI_1 - Yes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>23.025951</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27.546122</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>430</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.500099</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>776</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.151424</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.108108</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32888</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>38.391094</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32889</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>36.868444</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32890</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.812819</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32891</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.726686</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32892</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30.724246</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>32893 rows Ã— 45 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de16e7d3-0c37-475b-afd0-e0e70b60594d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-de16e7d3-0c37-475b-afd0-e0e70b60594d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-de16e7d3-0c37-475b-afd0-e0e70b60594d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9cc302b2-6f8c-499a-8c48-17a681738cf7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9cc302b2-6f8c-499a-8c48-17a681738cf7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9cc302b2-6f8c-499a-8c48-17a681738cf7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_eb67809a-861d-4d7b-bfb3-31688c907559\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_eb67809a-861d-4d7b-bfb3-31688c907559 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "features = ['NEWRACE2_White', 'NEWRACE2_Black', 'NEWRACE2_Others',\n",
        "            'INCOME_1 - Less than $20,000', 'IRSEX_1 - Male', 'IRMARIT_1 - Married',\n",
        "            'IRMARIT_2 - Widowed', 'IRMARIT_3 - Divorced or Separated',\n",
        "            'IRMARIT_4 - Never Been Married', 'WRK35WKUS_1 - Yes',\n",
        "            'WRK35WKUS_2 - No', 'BMI2']\n",
        "\n",
        "X_control = data[features]\n",
        "model = LogisticRegression()\n",
        "model.fit(X_control, y)\n",
        "data['propensity_score'] = model.predict_proba(X_control)[:, 1]\n",
        "\n",
        "treated = data[data['UDPYOPI_1 - Yes'] == 1]\n",
        "control = data[data['UDPYOPI_1 - Yes'] == 0]\n",
        "\n",
        "nn = NearestNeighbors(n_neighbors=158)\n",
        "nn.fit(control[['propensity_score']])\n",
        "distances, indices = nn.kneighbors(treated[['propensity_score']])\n",
        "\n",
        "matched_indices = indices.flatten()\n",
        "matched_control = control.iloc[matched_indices]\n",
        "matched_data = pd.concat([treated, matched_control])\n",
        "\n",
        "counts = matched_data['UDPYOPI_1 - Yes'].value_counts()\n",
        "number_of_OUD_cases = counts.get(1, 0)\n",
        "number_of_non_OUD_cases = counts.get(0, 0)\n",
        "\n",
        "print(f\"Number of OUD (treatment) cases after matching: {number_of_OUD_cases}\")\n",
        "print(f\"Number of non-OUD (control) cases after matching: {number_of_non_OUD_cases}\")\n",
        "\n",
        "if number_of_non_OUD_cases > number_of_OUD_cases:\n",
        "    print(\"Class 0 (non-OUD) is the control group, and there are more control cases than treatment cases after matching.\")\n",
        "else:\n",
        "    print(\"Class 1 (OUD) is the treatment group, and the matching has resulted in more treatment cases.\")"
      ],
      "metadata": {
        "id": "AnFt51kAGLSU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "593a66ad-b7de-42a5-c1fd-2b0203a1a475"
      },
      "id": "AnFt51kAGLSU",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of OUD (treatment) cases after matching: 207\n",
            "Number of non-OUD (control) cases after matching: 32706\n",
            "Class 0 (non-OUD) is the control group, and there are more control cases than treatment cases after matching.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matched_data_full = data.loc[matched_data.index]\n",
        "\n",
        "matched_data_full\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "TVQLpA49JICU",
        "outputId": "8fff09f1-ac18-49d9-d69b-87c6c2f9e72c"
      },
      "id": "TVQLpA49JICU",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       NEWRACE2_White  NEWRACE2_Black  NEWRACE2_Others  \\\n",
              "193               1.0             0.0              0.0   \n",
              "258               1.0             0.0              0.0   \n",
              "430               0.0             0.0              1.0   \n",
              "776               1.0             0.0              0.0   \n",
              "887               1.0             0.0              0.0   \n",
              "...               ...             ...              ...   \n",
              "17296             1.0             0.0              0.0   \n",
              "23435             1.0             0.0              0.0   \n",
              "21424             1.0             0.0              0.0   \n",
              "18179             1.0             0.0              0.0   \n",
              "31203             1.0             0.0              0.0   \n",
              "\n",
              "       INCOME_1 - Less than $20,000  ADDPREV_1 - Yes  ADDPREV_2 - No  \\\n",
              "193                             0.0              0.0             0.0   \n",
              "258                             0.0              1.0             0.0   \n",
              "430                             0.0              0.0             0.0   \n",
              "776                             0.0              1.0             0.0   \n",
              "887                             0.0              1.0             0.0   \n",
              "...                             ...              ...             ...   \n",
              "17296                           0.0              0.0             0.0   \n",
              "23435                           1.0              1.0             0.0   \n",
              "21424                           1.0              0.0             1.0   \n",
              "18179                           1.0              0.0             1.0   \n",
              "31203                           0.0              0.0             0.0   \n",
              "\n",
              "       OXCOPDAPYU_1 - Yes  OXYMPDAPYU_1 - Yes  HYDCPDAPYU_1 - Yes  \\\n",
              "193                   1.0                 0.0                 1.0   \n",
              "258                   1.0                 0.0                 1.0   \n",
              "430                   1.0                 0.0                 1.0   \n",
              "776                   0.0                 0.0                 0.0   \n",
              "887                   0.0                 0.0                 0.0   \n",
              "...                   ...                 ...                 ...   \n",
              "17296                 0.0                 0.0                 0.0   \n",
              "23435                 0.0                 0.0                 0.0   \n",
              "21424                 0.0                 0.0                 0.0   \n",
              "18179                 0.0                 0.0                 0.0   \n",
              "31203                 0.0                 0.0                 0.0   \n",
              "\n",
              "       HYDMPDAPYU_1 - Yes  ...  IRSEX_1 - Male  IRMARIT_1 - Married  \\\n",
              "193                   0.0  ...             0.0                  0.0   \n",
              "258                   0.0  ...             1.0                  1.0   \n",
              "430                   0.0  ...             1.0                  0.0   \n",
              "776                   0.0  ...             0.0                  0.0   \n",
              "887                   0.0  ...             1.0                  0.0   \n",
              "...                   ...  ...             ...                  ...   \n",
              "17296                 0.0  ...             0.0                  0.0   \n",
              "23435                 0.0  ...             0.0                  0.0   \n",
              "21424                 0.0  ...             0.0                  0.0   \n",
              "18179                 0.0  ...             0.0                  0.0   \n",
              "31203                 0.0  ...             0.0                  0.0   \n",
              "\n",
              "       IRMARIT_2 - Widowed  IRMARIT_3 - Divorced or Separated  \\\n",
              "193                    0.0                                0.0   \n",
              "258                    0.0                                0.0   \n",
              "430                    0.0                                0.0   \n",
              "776                    0.0                                1.0   \n",
              "887                    0.0                                0.0   \n",
              "...                    ...                                ...   \n",
              "17296                  0.0                                0.0   \n",
              "23435                  0.0                                0.0   \n",
              "21424                  0.0                                0.0   \n",
              "18179                  0.0                                0.0   \n",
              "31203                  0.0                                0.0   \n",
              "\n",
              "       IRMARIT_4 - Never Been Married  WRK35WKUS_1 - Yes  WRK35WKUS_2 - No  \\\n",
              "193                               1.0                0.0               1.0   \n",
              "258                               0.0                0.0               0.0   \n",
              "430                               1.0                0.0               0.0   \n",
              "776                               0.0                1.0               0.0   \n",
              "887                               1.0                0.0               0.0   \n",
              "...                               ...                ...               ...   \n",
              "17296                             1.0                0.0               0.0   \n",
              "23435                             1.0                1.0               0.0   \n",
              "21424                             1.0                1.0               0.0   \n",
              "18179                             1.0                1.0               0.0   \n",
              "31203                             1.0                0.0               0.0   \n",
              "\n",
              "            BMI2  UDPYOPI_1 - Yes  propensity_score  \n",
              "193    23.025951              1.0          0.005049  \n",
              "258    27.546122              1.0          0.006936  \n",
              "430    20.500099              1.0          0.006709  \n",
              "776    25.151424              1.0          0.009169  \n",
              "887    23.108108              1.0          0.011472  \n",
              "...          ...              ...               ...  \n",
              "17296  33.084252              0.0          0.008294  \n",
              "23435  19.737549              0.0          0.008408  \n",
              "21424  23.294675              0.0          0.008293  \n",
              "18179  23.294675              0.0          0.008293  \n",
              "31203  29.531611              0.0          0.008409  \n",
              "\n",
              "[32913 rows x 46 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc9b9c0c-8acd-4886-ae99-1a3a531c9738\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NEWRACE2_White</th>\n",
              "      <th>NEWRACE2_Black</th>\n",
              "      <th>NEWRACE2_Others</th>\n",
              "      <th>INCOME_1 - Less than $20,000</th>\n",
              "      <th>ADDPREV_1 - Yes</th>\n",
              "      <th>ADDPREV_2 - No</th>\n",
              "      <th>OXCOPDAPYU_1 - Yes</th>\n",
              "      <th>OXYMPDAPYU_1 - Yes</th>\n",
              "      <th>HYDCPDAPYU_1 - Yes</th>\n",
              "      <th>HYDMPDAPYU_1 - Yes</th>\n",
              "      <th>...</th>\n",
              "      <th>IRSEX_1 - Male</th>\n",
              "      <th>IRMARIT_1 - Married</th>\n",
              "      <th>IRMARIT_2 - Widowed</th>\n",
              "      <th>IRMARIT_3 - Divorced or Separated</th>\n",
              "      <th>IRMARIT_4 - Never Been Married</th>\n",
              "      <th>WRK35WKUS_1 - Yes</th>\n",
              "      <th>WRK35WKUS_2 - No</th>\n",
              "      <th>BMI2</th>\n",
              "      <th>UDPYOPI_1 - Yes</th>\n",
              "      <th>propensity_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>23.025951</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.005049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27.546122</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.006936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>430</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.500099</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.006709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>776</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.151424</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.009169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.108108</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.011472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17296</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>33.084252</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23435</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.737549</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21424</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.294675</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18179</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.294675</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31203</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.531611</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008409</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>32913 rows Ã— 46 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc9b9c0c-8acd-4886-ae99-1a3a531c9738')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dc9b9c0c-8acd-4886-ae99-1a3a531c9738 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dc9b9c0c-8acd-4886-ae99-1a3a531c9738');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9923c1b2-8c0c-4b27-b1b3-7b17862f8396\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9923c1b2-8c0c-4b27-b1b3-7b17862f8396')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9923c1b2-8c0c-4b27-b1b3-7b17862f8396 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_1df88fcf-cfc3-4cd2-a03c-3ca22c0f37e6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('matched_data_full')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1df88fcf-cfc3-4cd2-a03c-3ca22c0f37e6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('matched_data_full');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "matched_data_full"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d_pos=matched_data_full[matched_data_full['UDPYOPI_1 - Yes'].isin([1])]\n",
        "d_neg=matched_data_full[matched_data_full['UDPYOPI_1 - Yes'].isin([0])]\n",
        "matched_data_full=pd.concat([d_pos, d_neg])\n",
        "\n",
        "X=matched_data_full.drop(['UDPYOPI_1 - Yes', 'propensity_score'], axis=1)\n",
        "y=matched_data_full['UDPYOPI_1 - Yes']\n"
      ],
      "metadata": {
        "id": "MkBP8HBJcgGt"
      },
      "id": "MkBP8HBJcgGt",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "44c42e30",
      "metadata": {
        "id": "44c42e30"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=43, stratify=y) # Use stratify to have the same proportion of each class"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights_sample = compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(y_train),\n",
        "                                        y = y_train\n",
        "                                    )\n",
        "sklearn_weights = dict(enumerate(class_weights_sample))"
      ],
      "metadata": {
        "id": "VIkAiTfRx1Of"
      },
      "id": "VIkAiTfRx1Of",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sklearn_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6s6xuUC2gjkJ",
        "outputId": "7fa9d0d9-5897-43a2-a199-0ef09331042c"
      },
      "id": "6s6xuUC2gjkJ",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.5031722978137899, 1: 79.30722891566265}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tK5QAaljHe-O",
        "outputId": "aa1963a6-fd08-42f5-d7fe-972e42e0e25b"
      },
      "id": "tK5QAaljHe-O",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['NEWRACE2_White', 'NEWRACE2_Black', 'NEWRACE2_Others',\n",
              "       'INCOME_1 - Less than $20,000', 'ADDPREV_1 - Yes', 'ADDPREV_2 - No',\n",
              "       'OXCOPDAPYU_1 - Yes', 'OXYMPDAPYU_1 - Yes', 'HYDCPDAPYU_1 - Yes',\n",
              "       'HYDMPDAPYU_1 - Yes', 'FENTPDAPYU_1 - Yes', 'MORPPDAPYU_1 - Yes',\n",
              "       'CODEPDAPYU_1 - Yes', 'MTDNPDAPYU_1 - Yes', 'TRAMPDAPYU_1 - Yes',\n",
              "       'BUPRPDAPYU_1 - Yes', 'HEREVER_1 - Yes', 'HEREVER_2 - No',\n",
              "       'TXEVRRCVD_1 - Yes', 'TXEVRRCVD_2 - No', 'DIABETEVR_1 - Yes',\n",
              "       'DIABETEVR_2 - No', 'COPDEVER_1 - Yes', 'COPDEVER_2 - No',\n",
              "       'CIRROSEVR_1 - Yes', 'CIRROSEVR_2 - No', 'HEPBCEVER_1 - Yes',\n",
              "       'HEPBCEVER_2 - No', 'KIDNYDSEV_1 - Yes', 'KIDNYDSEV_2 - No',\n",
              "       'ASTHMAEVR_1 - Yes', 'ASTHMAEVR_2 - No', 'HIVAIDSEV_1 - Yes',\n",
              "       'HIVAIDSEV_2 - No', 'CANCEREVR_1 - Yes', 'CANCEREVR_2 - No',\n",
              "       'IRSEX_1 - Male', 'IRMARIT_1 - Married', 'IRMARIT_2 - Widowed',\n",
              "       'IRMARIT_3 - Divorced or Separated', 'IRMARIT_4 - Never Been Married',\n",
              "       'WRK35WKUS_1 - Yes', 'WRK35WKUS_2 - No', 'BMI2'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3de6a67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3de6a67",
        "outputId": "a4f6738b-07d7-42a9-bbfa-258ceee802fa",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "410/412 [============================>.] - ETA: 0s - loss: 0.7395 - accuracy: 0.5524\n",
            "Epoch 1: val_accuracy improved from -inf to 0.20188, saving model to best_model_sgd.h5\n",
            "412/412 [==============================] - 10s 23ms/step - loss: 0.7435 - accuracy: 0.5529 - val_loss: 0.7653 - val_accuracy: 0.2019\n",
            "Epoch 2/20\n",
            "412/412 [==============================] - ETA: 0s - loss: 0.6350 - accuracy: 0.6469\n",
            "Epoch 2: val_accuracy improved from 0.20188 to 0.95823, saving model to best_model_sgd.h5\n",
            "412/412 [==============================] - 6s 14ms/step - loss: 0.6350 - accuracy: 0.6469 - val_loss: 0.4185 - val_accuracy: 0.9582\n",
            "Epoch 3/20\n",
            "412/412 [==============================] - ETA: 0s - loss: 0.6023 - accuracy: 0.6945\n",
            "Epoch 3: val_accuracy did not improve from 0.95823\n",
            "412/412 [==============================] - 7s 18ms/step - loss: 0.6023 - accuracy: 0.6945 - val_loss: 0.7629 - val_accuracy: 0.4673\n",
            "Epoch 4/20\n",
            "409/412 [============================>.] - ETA: 0s - loss: 0.5577 - accuracy: 0.7252\n",
            "Epoch 4: val_accuracy did not improve from 0.95823\n",
            "412/412 [==============================] - 6s 14ms/step - loss: 0.5628 - accuracy: 0.7263 - val_loss: 2.7978 - val_accuracy: 0.0769\n",
            "Epoch 5/20\n",
            "408/412 [============================>.] - ETA: 0s - loss: 0.5351 - accuracy: 0.7505\n",
            "Epoch 5: val_accuracy improved from 0.95823 to 0.97114, saving model to best_model_sgd.h5\n",
            "412/412 [==============================] - 7s 18ms/step - loss: 0.5384 - accuracy: 0.7495 - val_loss: 0.2120 - val_accuracy: 0.9711\n",
            "Epoch 6/20\n",
            "411/412 [============================>.] - ETA: 0s - loss: 0.5241 - accuracy: 0.7716\n",
            "Epoch 6: val_accuracy did not improve from 0.97114\n",
            "412/412 [==============================] - 6s 14ms/step - loss: 0.5260 - accuracy: 0.7717 - val_loss: 3.9586 - val_accuracy: 0.0767\n",
            "Epoch 7/20\n",
            "411/412 [============================>.] - ETA: 0s - loss: 0.5073 - accuracy: 0.7764\n",
            "Epoch 7: val_accuracy did not improve from 0.97114\n",
            "412/412 [==============================] - 10s 24ms/step - loss: 0.5073 - accuracy: 0.7758 - val_loss: 0.6635 - val_accuracy: 0.6927\n",
            "Epoch 8/20\n",
            "411/412 [============================>.] - ETA: 0s - loss: 0.5188 - accuracy: 0.7815\n",
            "Epoch 8: val_accuracy did not improve from 0.97114\n",
            "412/412 [==============================] - 14s 34ms/step - loss: 0.5185 - accuracy: 0.7816 - val_loss: 0.3303 - val_accuracy: 0.9446\n",
            "Epoch 9/20\n",
            "412/412 [==============================] - ETA: 0s - loss: 0.4673 - accuracy: 0.8059\n",
            "Epoch 9: val_accuracy did not improve from 0.97114\n",
            "412/412 [==============================] - 11s 27ms/step - loss: 0.4673 - accuracy: 0.8059 - val_loss: 1.2042 - val_accuracy: 0.2198\n",
            "Epoch 10/20\n",
            "411/412 [============================>.] - ETA: 0s - loss: 0.4546 - accuracy: 0.8068\n",
            "Epoch 10: val_accuracy did not improve from 0.97114\n",
            "412/412 [==============================] - 13s 31ms/step - loss: 0.4543 - accuracy: 0.8068 - val_loss: 0.1986 - val_accuracy: 0.9420\n",
            "Epoch 11/20\n",
            "410/412 [============================>.] - ETA: 0s - loss: 0.4805 - accuracy: 0.7954\n",
            "Epoch 11: val_accuracy did not improve from 0.97114\n",
            "412/412 [==============================] - 13s 30ms/step - loss: 0.4797 - accuracy: 0.7961 - val_loss: 0.2686 - val_accuracy: 0.9566\n",
            "Epoch 12/20\n",
            "412/412 [==============================] - ETA: 0s - loss: 0.4400 - accuracy: 0.8246\n",
            "Epoch 12: val_accuracy did not improve from 0.97114\n",
            "412/412 [==============================] - 11s 27ms/step - loss: 0.4400 - accuracy: 0.8246 - val_loss: 0.2044 - val_accuracy: 0.9521\n",
            "Epoch 13/20\n",
            "412/412 [==============================] - ETA: 0s - loss: 0.4525 - accuracy: 0.8244\n",
            "Epoch 13: val_accuracy did not improve from 0.97114\n",
            "412/412 [==============================] - 13s 31ms/step - loss: 0.4525 - accuracy: 0.8244 - val_loss: 0.2977 - val_accuracy: 0.9210\n",
            "Epoch 14/20\n",
            "410/412 [============================>.] - ETA: 0s - loss: 0.4341 - accuracy: 0.8224\n",
            "Epoch 14: val_accuracy did not improve from 0.97114\n",
            "412/412 [==============================] - 11s 26ms/step - loss: 0.4332 - accuracy: 0.8229 - val_loss: 0.2306 - val_accuracy: 0.9297\n",
            "Epoch 15/20\n",
            "410/412 [============================>.] - ETA: 0s - loss: 0.4246 - accuracy: 0.8311\n",
            "Epoch 15: val_accuracy improved from 0.97114 to 0.97463, saving model to best_model_sgd.h5\n",
            "412/412 [==============================] - 10s 25ms/step - loss: 0.4233 - accuracy: 0.8316 - val_loss: 0.1165 - val_accuracy: 0.9746\n",
            "Epoch 16/20\n",
            "412/412 [==============================] - ETA: 0s - loss: 0.4351 - accuracy: 0.8343\n",
            "Epoch 16: val_accuracy did not improve from 0.97463\n",
            "412/412 [==============================] - 11s 28ms/step - loss: 0.4351 - accuracy: 0.8343 - val_loss: 0.2422 - val_accuracy: 0.9673\n",
            "Epoch 17/20\n",
            "411/412 [============================>.] - ETA: 0s - loss: 0.4033 - accuracy: 0.8306\n",
            "Epoch 17: val_accuracy did not improve from 0.97463\n",
            "412/412 [==============================] - 11s 27ms/step - loss: 0.4034 - accuracy: 0.8307 - val_loss: 0.2052 - val_accuracy: 0.9269\n",
            "Epoch 18/20\n",
            "410/412 [============================>.] - ETA: 0s - loss: 0.4151 - accuracy: 0.8276\n",
            "Epoch 18: val_accuracy did not improve from 0.97463\n",
            "412/412 [==============================] - 8s 18ms/step - loss: 0.4139 - accuracy: 0.8280 - val_loss: 0.1446 - val_accuracy: 0.9661\n",
            "Epoch 19/20\n",
            "411/412 [============================>.] - ETA: 0s - loss: 0.4053 - accuracy: 0.8363\n",
            "Epoch 19: val_accuracy did not improve from 0.97463\n",
            "412/412 [==============================] - 8s 20ms/step - loss: 0.4050 - accuracy: 0.8364 - val_loss: 0.2802 - val_accuracy: 0.9400\n",
            "Epoch 20/20\n",
            "412/412 [==============================] - ETA: 0s - loss: 0.4004 - accuracy: 0.8397\n",
            "Epoch 20: val_accuracy did not improve from 0.97463\n",
            "412/412 [==============================] - 11s 27ms/step - loss: 0.4004 - accuracy: 0.8397 - val_loss: 0.1851 - val_accuracy: 0.9600\n"
          ]
        }
      ],
      "source": [
        "def algorithm():\n",
        "    tf.keras.utils.set_random_seed(43)  # sets seeds for base-python, numpy and tf\n",
        "    tf.config.experimental.enable_op_determinism()\n",
        "\n",
        "algorithm()\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath='best_model_sgd.h5',\n",
        "                               monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "algorithm()\n",
        "callbacks = [checkpoint]\n",
        "number_of_features=44\n",
        "algorithm()\n",
        "network = models.Sequential()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=1000, activation=\"relu\", input_shape=(\n",
        "number_of_features,)))\n",
        "algorithm()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=1000, activation=\"relu\"))\n",
        "algorithm()\n",
        "# Add fully connected layer with a sigmoid activation function\n",
        "network.add(layers.Dense(units=1, activation=\"sigmoid\")) # No activation for regression\n",
        "# Compile neural network\n",
        "algorithm()\n",
        "network.compile(loss=\"binary_crossentropy\", # Cross-entropy # \"mse\" for regression\n",
        "optimizer=\"sgd\", # Root Mean Square Propagation\n",
        "metrics=[\"accuracy\"]) # Accuracy performance metric\n",
        "history = network.fit(X_train, # Features\n",
        "y_train, # Target vector\n",
        "epochs=20,\n",
        "verbose=1,\n",
        "callbacks=callbacks, # Print description after each epoch\n",
        "batch_size=64,\n",
        "class_weight=sklearn_weights,\n",
        "validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jgD0sEY0Oq_T",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "jgD0sEY0Oq_T",
        "outputId": "c80cb431-e65e-43fa-d2cf-5a8d3a1d53cf",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB0j0lEQVR4nO3deXhTVfoH8G+SJmmabhToBm1ZZQdZpeAIKLLIILggOjiAqDMq/AZ0xBl0XAZG666MMCCKoqO4oIKOqAhoUVlkVzZBEEqBLhTolrRJmtzfH6c3aUv33OQm4ft5njy5SZPTU23p2/e857waSZIkEBEREYUIrdoTICIiIlISgxsiIiIKKQxuiIiIKKQwuCEiIqKQwuCGiIiIQgqDGyIiIgopDG6IiIgopISpPQF/c7lcOHPmDKKioqDRaNSeDhERETWCJEkoKSlBcnIytNr6czOXXHBz5swZpKSkqD0NIiIiaobs7Gy0bdu23tdccsFNVFQUAPEfJzo6WuXZEBFdeiwWC5KTkwGIPzjNZrPKM6JgUFxcjJSUFPfv8fpccsGNvBQVHR3N4IaISAU6nc59HR0dzeCGmqQxJSUsKCYiIqKQwuCGiIiIQsoltyxFRETqCgsLw7Rp09zXRErjdxUREfmV0WjEihUr1J6GzzidTjgcDrWnEZQMBkOD27wbg8ENERGRAiRJQm5uLgoLC9WeStDSarVo3749DAaDV+MwuCEiIr+SJAlWqxUAEBERETIHqsqBTXx8fEh9Xf4iH7Kbk5OD1NRUr/77MbghIiK/slqtiIyMBACUlpaGxFZwp9PpDmxatmyp9nSCVuvWrXHmzBlUVFRAr9c3e5yA2S319NNPQ6PRYM6cOfW+btWqVejatSvCw8PRq1cvfPHFF/6ZIBERUR3kGpuIiAiVZxLc5OUop9Pp1TgBEdzs2LEDr776Knr37l3v67Zs2YLbbrsNd955J/bs2YOJEydi4sSJ2L9/v59mSkREVDcuRXlHqf9+qgc3paWlmDJlCl577TW0aNGi3tcuXLgQY8aMwdy5c9GtWzcsWLAA/fr1w6JFi+p8j81mQ3FxcbUbERERhS7Vg5uZM2di3LhxGDlyZIOv3bp160WvGz16NLZu3VrnezIyMhATE+O+sWkmERFRaFM1uHn//fexe/duZGRkNOr1ubm5SEhIqPZcQkICcnNz63zPvHnzUFRU5L5lZ2d7NWciIiKqXbt27fDyyy+rPQ31dktlZ2dj9uzZWL9+PcLDw332eYxGI4xGo8/Gp0uE3QoYWChIRKFn+PDhuPzyyxUJSnbs2BEQu99UC2527dqF/Px89OvXz/2c0+nEd999h0WLFsFms1XrHAsAiYmJyMvLq/ZcXl4eEhMT/TJnukTtfQ/49D7gpteBnjepPRuioKfT6XDzzTe7rymwSZIEp9PZqFYZrVu39sOMGqbastQ111yDffv2Ye/eve7bgAEDMGXKFOzdu7fWb/j09HRs3Lix2nPr169Henq6v6ZNl6KTWwDJBWTVXdtFRI0XHh6OVatWYdWqVT7N3KtJkiRY7RWq3CRJavQ8p0+fjk2bNmHhwoXQaDTQaDRYsWIFNBoNvvzyS/Tv3x9GoxE//PADjh07hgkTJiAhIQGRkZEYOHAgNmzYUG28mstSGo0Gr7/+Om644QZERESgc+fO+Oyzz5T6z1wn1TI3UVFR6NmzZ7XnzGYzWrZs6X5+6tSpaNOmjbsmZ/bs2Rg2bBheeOEFjBs3Du+//z527tyJZcuW+X3+dAkpuyDurQXqzoOIgkaZw4nuj61T5XMfnD8aEYbG/XpfuHAhjhw5gp49e2L+/PkAgAMHDgAA/v73v+P5559Hhw4d0KJFC2RnZ+O6667Dk08+CaPRiLfffhvjx4/H4cOHkZqaWufn+Oc//4lnn30Wzz33HF555RVMmTIFWVlZiIuL8/6LrYPqu6Xqc/LkSeTk5LgfDxkyBCtXrsSyZcvQp08ffPTRR1izZs1FQRKRoqyVwY2FwQ0RhZaYmBgYDAZEREQgMTERiYmJ7pWT+fPn49prr0XHjh0RFxeHPn364M9//jN69uyJzp07Y8GCBejYsWODmZjp06fjtttuQ6dOnfDUU0+htLQU27dv9+nXFVDtFzIzM+t9DACTJk3CpEmT/DMhIqBK5uacuvMgChEWiyXk2i/UZNLrcHD+aNU+txIGDBhQ7XFpaSmeeOIJrF27Fjk5OaioqEBZWRlOnjxZ7zhVD+g1m82Ijo5Gfn6+InOsS0AFN0QBqey8uGfmhogaSaPRNHppKFDVDDoffPBBrF+/Hs8//zw6deoEk8mEm2++GXa7vd5xavaI0mg0cLlcis+3quD+L0/ka5IEWCuDG+s5wOUCtAG9mktE1CQGg6FRvZw2b96M6dOn44YbbgAgMjknTpzw8eyah/9KE9XHUQY4beJacgLlhapOh4hIae3atcOPP/6IEydOoKCgoM6sSufOnfHJJ59g7969+Omnn/CHP/zB5xmY5mJwQ1QfeUlKxqUpIgoxDz74IHQ6Hbp3747WrVvXWUPz4osvokWLFhgyZAjGjx+P0aNHVzurLpBwWYqoPnIxscxaAOAyVaZCROQLl1122UU9GqdPn37R69q1a4dvvvmm2nMzZ86s9rjmMlVtZ+4UFhY2a55NwcwNUX2szNwQEQUbZm6I6lNr5oaIvKHT6XDddde5r4mUxuCGqD4X1dzwrBsib4WHh2Pt2rVqT4NCGJeliOrDzA0RUdBhcENUH7nmRlt5CBVrboiIAh6DG6L6lBWK+5YdxT0zN0Res1gsMJvNMJvNsFgsak+HQhCDG6L6yDU3LTuJe9bcECnCarXCarWqPQ0KUQxuiOojL0u1qjzbhpkbIqKAx+CGqD5yQXGrzuLeUiD6TREREQBxuN/LL7+s9jSqYXBDVB/3slRlcONyALZi9eZDREQNYnBDVBdJ8mRuopMBvVlcc8cUEVFAY3BDVBdbCeCqENemFoC5pbhmcENEIWLZsmVITk6+qLv3hAkTMGPGDBw7dgwTJkxAQkICIiMjMXDgQGzYsEGl2TYegxuiushZm7BwwBABRLQSj1lUTOQVrVaLYcOGYdiwYdBqQ/TXkCQBdos6tybUBU6aNAnnzp3Dt99+637u/Pnz+OqrrzBlyhSUlpbiuuuuw8aNG7Fnzx6MGTMG48ePr7NzeKBg+wWiusj1NqY4cW+uDG6YuSHyislkQmZmptrT8C2HFXgqWZ3P/fAZwGBu1EtbtGiBsWPHYuXKlbjmmmsAAB999BFatWqFESNGQKvVok+fPu7XL1iwAKtXr8Znn32GWbNm+WT6SgjRkJlIAXLmxtRC3Jtbi3tmbogohEyZMgUff/wxbDYbAODdd9/FrbfeCq1Wi9LSUjz44IPo1q0bYmNjERkZiUOHDjFzQxS05DNuIiozNxFyzQ0P8iOiBugjRAZFrc/dBOPHj4ckSVi7di0GDhyI77//Hi+99BIA4MEHH8T69evx/PPPo1OnTjCZTLj55ptht9t9MXPFMLghqos7cxMr7s2suSFSgsViQbt27QAAJ06cgNncuCWUoKLRNHppSG3h4eG48cYb8e677+Lo0aPo0qUL+vXrBwDYvHkzpk+fjhtuuAEAUFpaihMnTqg428ZhcENUF3dwI2duWHNDpJSCAv4cBZIpU6bg97//PQ4cOIDbb7/d/Xznzp3xySefYPz48dBoNHj00Ucv2lkViFhzQ1QXeVnKXXPDzA0Rhaarr74acXFxOHz4MP7whz+4n3/xxRfRokULDBkyBOPHj8fo0aPdWZ1AxswNUV3kzE1EzcwNa26IKLRotVqcOXNxjVC7du3wzTffVHtu5syZ1R4H4jIVMzdEdSmrmbmpLCi2sr8UEVEgY3BDVJe6am4qysVBWUREFJAY3BDVpWbNjcEsTisGWHdDRBTAWHNDVJeaNTcajcjeFJ8SO6ZatFNtakTBTKvVYsCAAe5rIqUxuCGqjcsFlBeKa3lZChB1N3JwQ0TNYjKZsGPHDrWn4RMS6/G8otR/P4bMRLWxFQFS5VkO8rIUwOaZRFQrvV4PALBarSrPJLjJJx/rdDqvxmHmhqg2cr2NIRIIM3ieZ/NMIqqFTqdDbGws8vPzAQARERHQaDQqzyq4uFwunD17FhEREQgL8y48UTW4WbJkCZYsWeLeI9+jRw889thjGDt2bK2vX7FiBe64445qzxmNRpSXl/t6qnSpKSsU91WzNgCbZxIpwGq1onv37gCAgwcPIiKiab2QAlViYiIAuAMcajqtVovU1FSvA0NVg5u2bdvi6aefRufOnSFJEt566y1MmDABe/bsQY8ePWp9T3R0NA4fPux+zMiYfKLmGTcyNs8k8pokScjKynJfhwqNRoOkpCTEx8fD4XCoPZ2gZDAYFCkyVzW4GT9+fLXHTz75JJYsWYJt27bVGdxoNBp3dEzkM+4zbmpmblhzQ0T10+l0XteMkHcCpqDY6XTi/fffh8ViQXp6ep2vKy0tRVpaGlJSUjBhwgQcOHCg3nFtNhuKi4ur3YgaJNfcRMRVf57NM4mIAp7qwc2+ffsQGRkJo9GIe+65B6tXr3avxdbUpUsXvPHGG/j000/xzjvvwOVyYciQITh16lSd42dkZCAmJsZ9S0lJ8dWXQqGkrmUpZm6IiAKe6sFNly5dsHfvXvz444+49957MW3aNBw8eLDW16anp2Pq1Km4/PLLMWzYMHzyySdo3bo1Xn311TrHnzdvHoqKity37OxsX30pFEpqtl6QseaGiCjgqb4V3GAwoFOnTgCA/v37Y8eOHVi4cGG9AYtMr9ejb9++OHr0aJ2vMRqNMBqNis2XLhE1Wy/I5MyNwwI4ygC9yb/zIiKiBqmeuanJ5XLBZrM16rVOpxP79u1DUlKSj2dFl5yarRdkxmhAKw7rYt0NUfNoNBp0794d3bt3545X8glVMzfz5s3D2LFjkZqaipKSEqxcuRKZmZlYt24dAGDq1Klo06YNMjIyAADz58/H4MGD0alTJxQWFuK5555DVlYW7rrrLjW/DApF7pqbGsGNRiOyNyU5gOUsEMsaLqKmioiIaHAzCJE3VA1u8vPzMXXqVOTk5CAmJga9e/fGunXrcO211wIATp48WW2/+4ULF3D33XcjNzcXLVq0QP/+/bFly5Y6C5CJmq2ureCA2DFVkgNYWXdDRBSIVA1uli9fXu/HMzMzqz1+6aWX8NJLL/lwRkSVrHUsSwGieSbAZSkiogAVcDU3RKpzVojGmUDdmRuA28GJmslqtaJHjx7o0aMHG02ST6i+W4oo4JQXeq7DYy/+uNxfipkbomaRJMl95EcotV+gwMHMDVFNcr2NMQbQ1RL/y8tSzNwQEQUkBjdENblbL9SyJAVUacHAgmIiokDE4IaoprpaL8jYgoGIKKAxuCGqqa7WCzI2zyQiCmgMbohqqqv1gsydueGyFBFRIOJuKaKa6mq9IJObZ9qKgQobEMbeZURNodFokJaW5r4mUhqDG6Ka6mq9IAuPBTQ6QHKK7E10st+mRhQKIiIicOLECbWnQSGMy1JENdXXegEAtFpP9sZy1j9zIiKiRmNwQ1STeyt4HZkbwFN3w6JiIqKAw+CGqKaGMjeAJ3PDomKiJisrK8PAgQMxcOBAlJWVqT0dCkGsuSGqqaGt4AAzN0RecLlc2Llzp/uaSGnM3BDV5A5uYut+jdxfigf5EREFHAY3RFVV2AF7qbiur+aGB/kREQUsBjdEVclZG41WNM6si5k1N0REgYrBDVFV8hk34bFiy3ddmLkhIgpYDG6Iqmqo9YKMzTOJiAIWd0sRVdVQ6wUZMzdEXmnVqpXaU6AQxuCGqKqGWi/I5MxNeSHgdAA6vU+nRRRKzGYzzp7l6d7kO1yWIqqqMQf4uT9e2fBPXsoiIqKAwOCGqKrGtF4AAK3O8xrW3RARBRQGN0RVNTZzA1Spu2F6nagpysrKMHz4cAwfPpztF8gnWHNDVFVZI3dLAaLupuAwi4qJmsjlcmHTpk3uayKlMXNDVFVZobhvVOaGB/kREQUiBjdEVTW25gZg80wiogDF4IaoqqbU3LB5JhFRQGJwQ1RVY8+5AXiQHxFRgGJwQySzW4GKcnHdqMwNa26IiAIRd0sRyeQlKW0YYIxq+PXM3BA1W0REhNpToBDG4IZIVnVJSqNp+PVsnknULGazGRaLRe1pUAjjshSRrCnFxIAnc2M9D7icvpkTERE1GYMbIllTtoFXe53kCYyIiEh1qgY3S5YsQe/evREdHY3o6Gikp6fjyy+/rPc9q1atQteuXREeHo5evXrhiy++8NNsKeQ1NXOj0wPhseKadTdEjVZeXo5x48Zh3LhxKC8vV3s6FIJUDW7atm2Lp59+Grt27cLOnTtx9dVXY8KECThw4ECtr9+yZQtuu+023HnnndizZw8mTpyIiRMnYv/+/X6eOYWkpmwDl5nZX4qoqZxOJ7744gt88cUXcDq5pEvKUzW4GT9+PK677jp07twZl112GZ588klERkZi27Zttb5+4cKFGDNmDObOnYtu3bphwYIF6NevHxYtWuTnmVNIcmduYhv/nggWFRMRBZqAqblxOp14//33YbFYkJ6eXutrtm7dipEjR1Z7bvTo0di6dWud49psNhQXF1e7EdXKWhncNLbmBmALBiKiAKR6cLNv3z5ERkbCaDTinnvuwerVq9G9e/daX5ubm4uEhIRqzyUkJCA3N7fO8TMyMhATE+O+paSkKDp/CiFNrbkB2DyTiCgAqR7cdOnSBXv37sWPP/6Ie++9F9OmTcPBgwcVG3/evHkoKipy37KzsxUbm0JMs2puKvtLMXNDRBQwVD/Ez2AwoFOnTgCA/v37Y8eOHVi4cCFeffXVi16bmJiIvLy8as/l5eUhMTGxzvGNRiOMRqOyk6bQJG8Fb0rmhgf5EREFHNUzNzW5XC7YbLZaP5aeno6NGzdWe279+vV11ugQNUlZM2pu2IKBiCjgqJq5mTdvHsaOHYvU1FSUlJRg5cqVyMzMxLp16wAAU6dORZs2bZCRkQEAmD17NoYNG4YXXngB48aNw/vvv4+dO3di2bJlan4ZFAokqZnLUqy5IWoqs9kMSZLUngaFMFWDm/z8fEydOhU5OTmIiYlB7969sW7dOlx77bUAgJMnT0Kr9SSXhgwZgpUrV+If//gHHn74YXTu3Blr1qxBz5491foSKFTYSwFXhbhuUkExMzdERIFGI11i4XNxcTFiYmJQVFSE6OhotadDgeJCFrCwNxAWDvwjr+HXy4rPAC92AzQ64NECQBtwK71ERCGhKb+/+S8xEdC8beCAZyu45ATKCxWdElGoKi8vx6RJkzBp0iS2XyCfYHBDBDSv3gYAwoyAsfIvCNbdEDWK0+nERx99hI8++ojtF8gnGNwQAc3P3ACe7A37SxERBQQGN0SA54ybiGYEN2zBQEQUUBjcEAFAWaG4b1bmhgf5EREFEgY3REDza24Az1k3FtbcEBEFAgY3RIB3NTdyfylmboiIAgKDGyKgSs1NMzI3PMiPiCigqN44kygglDWjaaaMzTOJmiQiIgKlpaXuayKlMbgh/9j3EeC0A5f/Qe2Z1M69LOVN5oY1N0SNodFoYDab1Z4GhTAGN+R7dguw+s+A5AK6jG1edsTXvFmWcjfPZOaGiCgQsOaGfO/CCdGUUnKJXkyBxuXytE7wZiu4pUB0FyeietlsNkyfPh3Tp0+HzWZTezoUghjckO9dOOG5Ls5RbRp1shWJwAvwrubG5QBsxcrNiyhEVVRU4K233sJbb72FiooKtadDIYjBDfle1eCmJAAzN3K9jd4sekU1ld4k3gtwxxQRUQBgcEO+F+iZG2tlcNOcehuZu+6GRcVERGpjcEO+FyyZG1Ns88dw192weSYRkdoY3JDvBXrmxpvWCzI2zyQiChgMbsi3XC7gQpbncUBnbrzYos7mmUREAYPBDflWSQ7grLLVMxAzN96ccSNj80wiooDBQ/zIt+QlqfAYoLxIZDYq7ECYQdVpVeNN6wUZm2cSNVpERATy8/Pd10RKY+aGfEsObpL7ArrKgKY0V7Xp1Mqb1gsyNs8kajSNRoPWrVujdevW0Gg0ak+HQhCDG/ItObiJ6wBEJYrrQFuaUmRZijU3RESBgsEN+ZYc3LRoB0Qli+tAKypWsqCYNTdEDbLZbJg5cyZmzpzJ9gvkEwxuyLeqBTcBmrlRZCt4leaZ7C9FVK+Kigr85z//wX/+8x+2XyCfYHBDvlU1uIm+BDI3FeWiCzoREamGwQ35jq0UsIgdESJzkySuAylz46wQu7gA72puDGYgLFxcs+6GiEhVDG7IdworD+8ztRBbwd2ZmwDaLSUHNgAQHtv8cTQa1t0QEQUIBjfkO1WXpABP5iaQlqXkehtjDKDz8tgn90F+7C9FRKQmBjfkOzWDm+gqy1KBUnSrRNNMGVswEBEFBAY35Dvu4Ka9uJczNxVlQHmhGjO6mBJn3MjYPJOIKCCw/QL5Ts3Mjd4k6m/KLojsjTe7k5SixE4pGTM3RI1iMplw/Phx9zWR0hjckO/UDG4Akb0puyDqbhK6qzGr6pQ440ZmZkExUWNotVq0a9dO7WlQCOOyFPmGywVcqNwtVTO4AQJnO7gvlqWYuSEiUpWqwU1GRgYGDhyIqKgoxMfHY+LEiTh8+HC971mxYgU0Gk21W3h4uJ9mTI1WkgM4bYA2DIhu43leLiouCZDgxhfLUqy5IaqX3W7H3LlzMXfuXNjtdrWnQyFI1eBm06ZNmDlzJrZt24b169fD4XBg1KhRsFjqP+E1OjoaOTk57ltWVpafZkyNJi9JxaRU32Lt7i8VKMGND5almLkhqpfD4cDzzz+P559/Hg6HQ+3pUAhStebmq6++qvZ4xYoViI+Px65du3DVVVfV+T6NRoPExMRGfQ6bzVatMVtxcXHzJktNU1u9DVB9O3ggUDRzI59zw5obIiI1BVTNTVGROC02Lq7+v6JLS0uRlpaGlJQUTJgwAQcOHKjztRkZGYiJiXHfUlJSFJ0z1UEObuLaV38+0DqD+6LmxmEBHGXej0dERM0SMMGNy+XCnDlzMHToUPTs2bPO13Xp0gVvvPEGPv30U7zzzjtwuVwYMmQITp06Vevr582bh6KiIvctOzvbV18CVRU0mZtCca9E5sYYDWj14pp1N0REqgmYreAzZ87E/v378cMPP9T7uvT0dKSnp7sfDxkyBN26dcOrr76KBQsWXPR6o9EIo9Go+HypAXUFN/JuKctZwOkAdHp/zupi7pobBYIbjUZkb0pyRN1NLLOERERqCIjMzaxZs/D555/j22+/Rdu2bZv0Xr1ej759++Lo0aM+mh01ywVxQNdFwU1Eq8rshqR+A80KO2AvFddKHSjIHVNERKpTNbiRJAmzZs3C6tWr8c0336B9+/YNv6kGp9OJffv2ISkpyQczpGaxlXqaR9YMbrRaIKqyGFztHVNyMTE03nUEr8rdPJPBDRGRWlRdlpo5cyZWrlyJTz/9FFFRUcjNFX/Jx8TEuI/knjp1Ktq0aYOMjAwAwPz58zF48GB06tQJhYWFeO6555CVlYW77rpLta+Daiis3JpvagGEx1z88agkoCgbKFa5qLhq00ytQnE+WzAQNchkMmH//v3uayKlqRrcLFmyBAAwfPjwas+/+eabmD59OgDg5MmT0Fb5xXPhwgXcfffdyM3NRYsWLdC/f39s2bIF3bsHwFH+JNRVbyNzH+Sn8rKUkmfcyNg8k6hBWq0WPXr0UHsaFMJUDW4kSWrwNZmZmdUev/TSS3jppZd8NCNSRM1u4DUFynZwJbeBy3iQHxGR6gJmtxSFkMZmbtTeDq7kAX6yCDbPJGqI3W7HU089BQB4+OGHYTAYVJ4RhRoGN6S8hoKbQGnB4MtlKWZuiOrkcDjwz3/+EwAwd+5cBjekuIDYCk4h5nwd28Bl8m6pgCko9kXmhsENEZFaGNyQslwuz26pOpelqmRuGlF35TM+rbnhshQRkVoY3JCySnIApx3QhgHRbWp/jXxKscMKlBf5b241+SRzU3nOja0YqLDV/1oiIvIJBjekLLneJiYF0NVR0mWI8Jx/o+Z2cF8EN+GxgEYnrpm9ISJSBYMbUlZDxcSyQNgO7ovgRqv1ZG9Yd0NEpAoGN6QsObiJa6CVRiBsB/dFzQ3AHVNERCrjVnBS1qWeuQGYuSFqQHh4OLZv3+6+JlIagxtSVl3dwGtSO3PjKAMqysS1kufcAGzBQNQAnU6HgQMHqj0NCmFcliJlNTpzo3JncHlJShsGGKOUHZvNM4mIVMXMDSnHVgpYzorrxi5LqXWQX9UlKY1G2bGZuSGql91ux8KFCwEAs2fP5gnFpDgGN6Qc+fA+UwvPVu+6uDuDq5S58UXrBRkP8iOql8PhwEMPPQQAuO+++xjckOK4LEXKaeySFODJ3JTmA84KX82obr4qJgbYgoGISGUMbkg57uCmgW3gAGBuLepdIAGleb6cVe18tQ0c4FZwIiKVMbgh5TQlc6PVApEqFhUzc0NEFLIY3JByGuoGXpN7O7gKRcXumhsfBDdy5qa8EHA6lB+fiIjqxeCGlNOUzA2g7nZwX2ZuTC0AVO7Akpe/iIjIbxjckDJcLs9uqUYHNypuB7dWBje+qLnR6jzjsu6GiMjvuBWclFGSAzjtokg4uk3j3qPmdnBfZm4AUXdjPce6G6JahIeH49tvv3VfEymNwQ0pQ16SikkBdI38tnL3l1IjuPHhOTeAqLspOOw51JCI3HQ6HYYPH672NCiEcVmKlNHYbuBVqdlfqsyHy1KAp3kmD/IjIvK7ZgU32dnZOHXqlPvx9u3bMWfOHCxbtkyxiVGQaWoxMaBe5kaSPIW+vlqWYgsGojo5HA4sXrwYixcvhsPBHYWkvGYFN3/4wx/c66W5ubm49tprsX37djzyyCOYP3++ohOkINHYbuBVyZkbeylQXqz4lOpkLwVclf+g+mpZis0ziepkt9sxa9YszJo1C3a7Xe3pUAhqVnCzf/9+DBo0CADw4YcfomfPntiyZQveffddrFixQsn5UbBoTubGYAaMlT2o/Jm9kZekdEZAb/LN5zC3FvfM3BAR+V2zghuHwwGj0QgA2LBhA66//noAQNeuXZGTo1IjRFJXc4IbwHPWjT+3g1dtvaB0R3CZmTU3RERqaVZw06NHDyxduhTff/891q9fjzFjxgAAzpw5g5YtWyo6QQoCtlLPrqCmBjdqbAf39TZwgC0YiIhU1Kzg5plnnsGrr76K4cOH47bbbkOfPn0AAJ999pl7uYouIfLhfaYWQHhM096rxkF+vt4GDrB5JhGRipp1zs3w4cNRUFCA4uJitGjh+ev3T3/6EyIiIhSbHAWJpnQDr8mduclVbDoNcmduYn33OdwFxecBl1OcWkxERH7RrMxNWVkZbDabO7DJysrCyy+/jMOHDyM+Pl7RCVIQaG69DQBEqbAs5cvWCzL32JInmCIiIr9oVuZmwoQJuPHGG3HPPfegsLAQV1xxBfR6PQoKCvDiiy/i3nvvVXqeFMia2g28qmg1lqX8UHOj0wPhsaIzuKXAs0xFRDAajfj888/d10RKa1bmZvfu3fjd734HAPjoo4+QkJCArKwsvP322/j3v/+t6AQpCARb5sYfNTcA626I6hAWFoZx48Zh3LhxCAtjFyBSXrOCG6vViqioKADA119/jRtvvBFarRaDBw9GVlaWohOkIKBEcFOaBzgrlJpR/XzdekHm3jHF/lJERP7UrOCmU6dOWLNmDbKzs7Fu3TqMGjUKAJCfn4/o6OhGj5ORkYGBAwciKioK8fHxmDhxIg4fPtzg+1atWoWuXbsiPDwcvXr1whdffNGcL4OU4HJ5dks1J7iJjAc0OkByAZZ8RadWJ1+3XpCxBQNRrRwOB1asWIEVK1aw/QL5RLOCm8ceewwPPvgg2rVrh0GDBiE9PR2AyOL07du30eNs2rQJM2fOxLZt27B+/Xo4HA6MGjUKFoulzvds2bIFt912G+68807s2bMHEydOxMSJE7F///7mfCnkrZIcwGkHtGFAdJumv1+rAyITxLW/Gmj6a1mKzTOJamW323HHHXfgjjvuYPsF8olmLXbefPPNuPLKK5GTk+M+4wYArrnmGtxwww2NHuerr76q9njFihWIj4/Hrl27cNVVV9X6noULF2LMmDGYO3cuAGDBggVYv349Fi1ahKVLl170epvNBpvN5n5cXOzHHkaXAnlJKiYF0DVz7Tw6CSg5I27or9TM6uaPgmKAmRsiIpU0K3MDAImJiejbty/OnDnj7hA+aNAgdO3atdmTKSoqAgDExdX9F/XWrVsxcuTIas+NHj0aW7durfX1GRkZiImJcd9SUlKaPT+qhRzcxDXjjBtZlB/PunG5/FdzI/eXYkExEZFfNSu4cblcmD9/PmJiYpCWloa0tDTExsZiwYIFcLlczZqIy+XCnDlzMHToUPTs2bPO1+Xm5iIhIaHacwkJCcjNrf0X47x581BUVOS+ZWdnN2t+VIfmdAOvyZ/bwW3For4H8H3mhi0YiIhU0ax1hEceeQTLly/H008/jaFDhwIAfvjhBzzxxBMoLy/Hk08+2eQxZ86cif379+OHH35ozpTqZDQaeY6CL3mzU0rmz+3gcr2N3gyE+fj7gs0ziYhU0azg5q233sLrr7/u7gYOAL1790abNm1w3333NTm4mTVrFj7//HN89913aNu2bb2vTUxMRF5eXrXn8vLykJiY2KTPSQpRIrjxZ+bGX/U2ADM3REQqaday1Pnz52utrenatSvOnz/f6HEkScKsWbOwevVqfPPNN2jfvuG6jfT0dGzcuLHac+vXr3fv2CI/UyRzUxmY+iNz42694Ifgxn2I3zlR60NERH7RrOCmT58+WLRo0UXPL1q0CL179270ODNnzsQ777yDlStXIioqCrm5ucjNzUVZWZn7NVOnTsW8efPcj2fPno2vvvoKL7zwAn755Rc88cQT2LlzJ2bNmtWcL4W8YSv1HFDnVXAjZ278sSzlz8xN5bKU5BRtGIgIgCgX+PDDD/Hhhx+ybIB8olnLUs8++yzGjRuHDRs2uDMmW7duRXZ2dpMO1FuyZAkA0WW8qjfffBPTp08HAJw8eRJarScGGzJkCFauXIl//OMfePjhh9G5c2esWbOm3iJk8hH58D5TCyA8pvnjyJ3B7SWArQQwRnk/t7r464wbQNT0GKNFEbP1nO93ZxEFibCwMEyaNEntaVAIa1ZwM2zYMBw5cgSLFy/GL7/8AgC48cYb8ac//Qn/+te/3H2nGiJJUoOvyczMvOi5SZMm8QcjELiXpLzYBg6IYMYQJYKbklwfBzd+2gYui2gpghtLAdCqs38+JxHRJa7ZHcuSk5MvKhz+6aefsHz5cixbtszriVEQ8KYbeE3RSUBBiSgq9mUQ4K/WCzJzK7FdnmfdELlVVFRg9erVAIAbbriBzTNJcfyOouZTophYFpUEFBzxfVGxu+bGX5kbNs8kqslms+GWW24BAJSWljK4IcU1+4RiIkWDG39tBy/zd+amsqjYwrNuiIj8hcENNZ/SmRvA95kbeVnKbzU38nZwLksREflLk3KBN954Y70fLyws9GYuFExcLs9uKSWDG59nbvy4FRzw9JfiQX5ERH7TpOAmJqb+7b4xMTGYOnWqVxOiIFGSAzjtgDYMiG7j/XjRfsrc+HMrOFDlID8GN0RE/tKk4ObNN9/01Two2MhLUrGpgE6BYkB/HOTncgLlovO83zI37oJi1twQEfkLa26oeZToBl6VnLkpzRNBiC+UFXqu/V1QzMwNEZHfcP8dNY+SxcQAYI4HNFrRqsBy1tNvSklyvY0xWplsU2NUbZ4pSYBG45/PSxTADAaDeyXAYDCoPBsKRQxuqHmUDm50YUBkgqi5KT7jo+DGz9vAAU/NjcshTir2pk0FUYjQ6/XuFjtEvsBlKWoepYMbwPfbwf29UwoA9CZAbxbX3DFFROQXDG6oeXwZ3PhqO7i/z7iRuetuWFRMBIj2C2vXrsXatWtRUVGh9nQoBHFZiprOVuppJ6BkcOPr7eD+br0gi2gFFJ5k5oaoks1mw+9//3sAbL9AvsHMDTWdfHifKU7ZGhJ35sZXwY0KNTeAp+6G/aWIiPyCwQ01nZLdwKuS+0uVhNiyFFswEBH5FYMbajpf1NsAVQqKc5UdV6ZGQTHA5plERH7G4IaazlfBTbSPTyn2d+sFGTM3RER+xeCGms7XmRtbEWC3KDs2oGLmhs0ziYj8icENNZ2vgpvwaMAQKa59kb2xVgY3ft8KzswNEZE/cf8dNY3L5dktpXRwA4iTic8dFUXFrTopO7ZamRs2zySqxmAwYNGiRe5rIqUxuKGmKckBnHZAGwZEt1F+/KgkEdwonbmpsAP2EnGtVkGxlf2liADRfmHmzJlqT4NCGJelqGnkbuCxqb5pPumr7eDlhZUXGv/3d5IzNxXlvqklIiKiahjcUNP4qt5G5qvt4PIZN6ZYQKtTduyGGMxAWHjlPFh3Q+R0OpGZmYnMzEw4nU61p0MhiMtS1DS+Dm7c28EVztyo1XoBEMtQEa2A4lOi7sZX/+2IgkR5eTlGjBgBQLRfMJvNKs+IQg0zN9Q0fsvcKFxzo1brBVnVuhsiIvIpBjfUNH7L3Cgc3KjVekEWwf5SRET+wuCGmsbnmZtEcV+aK7adK0WtbeAyd/NMZm6IiHyNwQ01nq3Uk3nwVXATmQBAA7gqlM1yqNV6QcYWDEREfsPghhpPztqY4ny3nVqnByLjxbWS28FVz9yweSYRkb8wuKHG8/WSlEwuKlay7kbtmhu5vxQzN0REPset4NR4/gpuopOBnL3K7phSO3MTwZobIpler8ezzz7rviZSGoMbajx/Z25CKbhh80wiN4PBgLlz56o9DQphqi5Lfffddxg/fjySk5Oh0WiwZs2ael+fmZkJjUZz0S03V+HTbKl2fsvc+GBZSu3gJoI1N0RE/qJqcGOxWNCnTx8sXry4Se87fPgwcnJy3Lf4+HgfzZCq8Vvmxgf9pVSvuanM3DgsgKNMnTkQBQin04kdO3Zgx44dbL9APqHqstTYsWMxduzYJr8vPj4esbGxyk+I6uZyAYVZ4trnwU3lWTdKZW4cZUBFZUCh1lZwYzSg1QMuh6i7iU1RZx5EAaC8vByDBg0CwPYL5BtBuVvq8ssvR1JSEq699lps3ry53tfabDYUFxdXu1EzlJwBnHZAGwbEtPXt51K6M7i8JKUNA4xRyozZVBoN626IiPwkqIKbpKQkLF26FB9//DE+/vhjpKSkYPjw4di9e3ed78nIyEBMTIz7lpLCv5ibRV6Sik31fVdtuaC4vAiwW70fr2q9jUbj/XjN5d4xxbobIiJfCqrdUl26dEGXLl3cj4cMGYJjx47hpZdewn//+99a3zNv3jw88MAD7sfFxcUMcJrDX/U2gDggUB8BOKxix1TLjt6NZ1W5aaaMzTOJiPwiqDI3tRk0aBCOHj1a58eNRiOio6Or3agZ/BncaDTKbgdXu/WCjM0ziYj8IuiDm7179yIpKUntaYQ+fwY3gLLdwdXeBi5j80wiIr9QdVmqtLS0Wtbl+PHj2Lt3L+Li4pCamop58+bh9OnTePvttwEAL7/8Mtq3b48ePXqgvLwcr7/+Or755ht8/fXXan0Jlw5/BzfuzI0CRcVqbwOXsXkmEZFfqBrc7Ny5EyNGjHA/lmtjpk2bhhUrViAnJwcnT550f9xut+Ovf/0rTp8+jYiICPTu3RsbNmyoNgb5iN8zNwoe5BdwmRsWFNOlTa/X4/HHH3dfEylN1eBm+PDhkCSpzo+vWLGi2uOHHnoIDz30kI9nRRexlXrqRIIxc1MWKAXFzNwQAaL9whNPPKH2NCiEBX3NDfmBnLUxxYmdTP6gZGfwskJxr3Zww+aZRER+EVRbwUkl/l6SAqoc5KdAcBMoNTfuzA2XpejS5nK5cOjQIQBAt27doNXy72xSFoMbapgawY17WSpXtH7w5h8/d82N2gXFlefc2IqBChsQZlR3PkQqKSsrQ8+ePQGw/QL5BsNlapgqwU0iAI3oxeRtpiNQam7CYwFN5enOzN4QEfkMgxtqmBrBjU4PmFuLa2+KiiXJk7lRe1lKq/Vkb1h3Q0TkMwxuqGFqBDeAMtvB7RbR8BNQP3MDcMcUEZEfMLih+rlcQGGWuPZ3cKPEdnB5SUpnFP2q1ObO3HBZiojIVxjcUP1KzojMhzYMiGnr38+txHbwQOkILjOzvxQRka8xuKH6yUtSsamAVuffz+3eDu5F5iZQtoHL2IKBiMjnuBWc6qdWvQ2gfOYmELB5JhH0ej0efPBB9zWR0hjcUP3UDG6iq5x101yBsg1cJtfccCs4XcIMBgOee+45tadBIYzLUlQ/VTM3CixLBVzmpnJ7OzM3REQ+w+CG6hcImZuyC4CjrHljWAPkjBsZt4ITweVy4cSJEzhx4gRcLpfa06EQxOCG6qdmcBMeC4SZxHVze0wFSusFGZtnEqGsrAzt27dH+/btUVbWzD9ciOrB4IbqZivxbFlWI7jRaCrbMKD5RcWBVnMjZ27KCwGnQ9WpEBGFKgY3VLcLlYf3meKA8Bh15uBtd/BAab0gM7UAUHnejrxNnYiIFMXghuqm5pKUzL0dvJlFxdYAy9xodZ5Ai3U3REQ+weCG6hYIwY17O3iI1NwAoVd3U3gSqLCpPQsiIjcGN1S3QAhuorxYlqraETxQMjdAaO2Y+m0T8HJv4MuH1J4JEZEbgxuqWyAEN950Bi8vAiSnuA6k4MbdPDMEgpu9KwFIwIHVgMup9myIiADwhGKqTyAEN94c5CdnbfQRgD5cuTl5K1RaMDgrgCNfievyIuDMHqDtAHXnREEhLCwM9913n/uaSGn8rqLauZxAYeVuqbj26s1D3gpekiuWmZrS2du9DTyA6m2A0GmeeXKL2NIuO/YtgxtqFKPRiMWLF6s9DQphXJai2pXkAE47oA0DotuoNw95t5TT3vR+TIFYbwOETubmly/EvTFa3P/2rXpzISKqgsEN1U5ekopNFduX1RJm8GQ6mrod3N16IUCDm2BunilJwC9rxfWwv4n77O2ArVS9OVHQkCQJZ8+exdmzZyFJktrToRDE4IZqFwj1NrLmbgcPxG3gQGhsBc/bDxSdFO0xBswQ3ycuB5C1We2ZURCwWq2Ij49HfHw8rFar2tOhEMTghmoXSMFNc7eDB1rrBVkobAWXszYdrwYMEUCHEeLxMS5NEZH6GNxQ7QIpuGnudvBAa70gcxcUnw/e7dNycNP1OnHfUQ5uvlFnPkREVTC4odoFUnDT3O3ggdZ6QeYOtqocMhhMCk8CuT8DGi1w2RjxXPurxOOCw0DRaXXnR0SXPAY3VLvzx8V9CxW3gcu8zdwEWs2NTg+Ex4rrYKy7OfyluE8Z7FliM7UAkvuK698yVZkWEZGMwQ1dzFbiqQdpkabuXADPdvBQqbkBgrvu5pfPxX3XcdWfl+tuuCWciFTG4IYudqHy8D5THBAeo+5cgOZ3BpeXpQKt5gYI3h1TZReAE5U7ouR6G5lcd/NbJuBy+XVaRERV8YRiulgg1dsAQHRlzU3ZecBR3vhWCoF6iB8QvJmbI1+Lfl3x3YG4DtU/1nYQoDcDlrNA/gEgsZc6c6SAFxYWhmnTprmviZTG7yq6WKAFN6YWgM4IOG1iaaox7SBcTtHvCAi8mhsgeJtnHq7cJdXluos/FmYA2g0Ffv1abAlncEN1MBqNWLFihdrToBCm6rLUd999h/HjxyM5ORkajQZr1qxp8D2ZmZno168fjEYjOnXqxB8QXwi04EajqXKQX27j3lNeBKDy5FNTrC9m5Z1gbMHgKAd+3SCua9bbyFh3Q0QBQNXgxmKxoE+fPo1uoHb8+HGMGzcOI0aMwN69ezFnzhzcddddWLdunY9neokJtOAGaPp2cLnexhgtdicFmmBsnnn8O8BhEf8v5J1RNcl1N1lbRDBEVAtJkmCxWGCxWNh+gXxC1WWpsWPHYuzYsY1+/dKlS9G+fXu88MILAIBu3brhhx9+wEsvvYTRo0f7apqXngvyNvB2qk6jmqZuBw/kehsAMLcW98GUuXHvkrqu7u7srbuKAvCSHCB7G9BhuN+mR8HDarUiMjISAFBaWgqz2azyjCjUBNVuqa1bt2LkyJHVnhs9ejS2bt1a53tsNhuKi4ur3ageLqc4pA1oXG2LvzR1O3ggbwMHAHNlzU2wNM90uTzn29RWbyPTaNiKgYhUF1TBTW5uLhISEqo9l5CQgOLiYpSVldX6noyMDMTExLhvKSkp/phq8CrJAZx2QBsGRLdRezYeTd0OHqitF2TBthX89E7Aki+W+dr9rv7XdmTdDRGpK6iCm+aYN28eioqK3Lfs7Gy1pxTY5Hqb2FRAq1N1KtU0tTN4oLZekLm3gp8LjjNh5F5Sna8Vu6LqIy9F5fwUPMEbEYWUoApuEhMTkZeXV+25vLw8REdHw2Qy1foeo9GI6OjoajeqRyAWEwOeguKmZm4CcRs44NkKLjmB8kJVp9Io7kaZdeySqioyHkjoKa7ZioGIVBBUwU16ejo2btxY7bn169cjPT1dpRmFoEANbqpuBW/M7opAr7kJM4olHiDw627OHgHO/Qpo9UCnaxv3Hjl7w6UpIlKBqsFNaWkp9u7di7179wIQW7337t2LkydFQeu8efMwdepU9+vvuece/Pbbb3jooYfwyy+/4D//+Q8+/PBD3H///WpMPzQFanAj19w4bY3rpB3oNTdA8BzkJx/c1/4qILyRmU+57uZYZuOCUSIiBam6FXznzp0YMWKE+/EDDzwAAJg2bRpWrFiBnJwcd6ADAO3bt8fatWtx//33Y+HChWjbti1ef/11bgNX0vkA3AYOiExHREuR5Sg+03DQEug1N4Cou7lwPPDPuvnlC3Ffs5dUfVKHADoDUHwKOHcUaNXZN3OjoKTT6XDzzTe7r4mUpmpwM3z48HoPcKrt9OHhw4djz549PpzVJc6duQmgbeCyqGQR3JTkAIk963+te1kqkDM3QbBjqiQPOLVDXNe3BbwmQwSQOlgc/HfsWwY3VE14eDhWrVql9jQohAVVzQ35mK3Ek0VokabuXGoTlSjuG1NUHOiH+AGes24CObg58iUACUju52lg2lhsxUBEKmFwQx4XssS9KQ4Ij1F3LrVpynZwazDU3ARBC4am7JKqSa67Of494HQoNyciogYwuCGPQC0mljV2O7jTAdhLxHVAZ24CfFnKVgL8tklcNye4SewjAmV7CXB6l7Jzo6BmsVig0Wig0WhgsVjUng6FIAY35BHowU1jMzfu3VSawMxAyQI9c3N0o9idFtdB9IxqKq3WsyWcrRiIyI8Y3JBHoAc37s7gjQxuTLGBdcpyTe7mmQF6zs3hyl1SXepplNkQtmIgIhUwuCGPQOwGXlVjO4MHwzZwoErzzADM3DgdwJGvxHXX3zd/HLmo+NROoLzI+3kRETUCgxvykDM3gdQNvCo5c2MtACpsdb8u0FsvyKpuBQ+0g+6ytohgJKIVkDKo+ePEpgAtO4k2E8e/V25+RET1YHBDgssJFFYemBiomZuIOHEwHCDaMNQl0FsvyOSCYpcDsBWrO5ea5F1SXcZ4v7THLeFE5GcMbkgoyQGcdkAbBkS3UXs2tdNoPGfd1Fd3EwytFwBAbwL0ZnEdSDumJKlKvU0zdknV5G7FwOCGiPxD1ROKKYDIS1KxqYFdhBuVLDJM9W0HD5aaG0DU3RRaxMnLLTuqPRsh92egKBvQR3gCE2+0uxLQ6IDzx8T/u9hU78ekoKbT6XDddde5r4mUxswNCYG+U0rWmO3gwdB6QRaILRjkXlIdrxbZJW+FxwBtB4hrZm8Iov3C2rVrsXbtWoSHh6s9HQpBDG6UVF4MOMrVnkXzBEtw05iD/IKh9YLMHIBn3XhzKnFdWHdDRH7E4EYp+b8Ar10NfPGg2jNpnkDtBl6TO3NTT0GxvCwV6DU3QJXMzVl15yG7kAXk7QM0WqDzaOXGdZ93swlwuZQbl4ioFgxulFKaC+n8MWDPf4FdK9SeTdPkHfAUkDbnJFp/imrMslShuDfF+no23nM3zwyQg/zk74PUIZ65KaFNf8AQJZYMc39SblwKShaLBWazGWazme0XyCcY3CjkbOt0PO+4BQDgXPsgbFk7VJ5RI5UVAh/cDjis4qj8TiPVnlH9ohuzLBWENTeBsizlXpK6TtlxdXqg/e/ENetuCIDVaoXValV7GhSiGNwoZOeJ81jquh7rnAOgczlw/s3JePaTzTiSV6L21OrmcgGr/wyc/w2ISQVueiOwd0oB1beC13XwXbBsBQcCq3mm9bw4vA8QLReU1vFqcc+6GyLyMQY3ChnbKwlb/34NTl71PE5qkpGEc0jf8xDGvJSJm5Zswce7TqHc4VR7mtV995w4Yl9nBCb/V9llCF+Rl6Uqyqs0yKzCUS6yUECQFBRX9pcKhMzNr1+Lk4Tje/jmlGq5qPjkNsDOv9iJyHcY3CgoPjocd1/bF23//DGcOhN+p9uPB/WrsCvrAv666icMenIDnvjsQGBkc458DWRmiOvfvwQkX67qdBpNb/IELbXV3cgBj0YHGKP9N6/mchcUB0DNzS+fi3sld0lV1bIjEJMiDouUM0RERD7A4MYHtIndoZu4CABwn+5T/Kf/GbRtYUJxeQVWbDmBUS99h5vVzOac/w345C4AEjDgTqDvFP/PwRvu7eC1BTdVDvBrbidrf6raPFPN/lKOMuDoN+Ja6XobmUYj6roALk0RkU8xuPGVXjcDg+8DAFx3dD6+m5GCt2YMwpgeidBpNdipVjbHbgHev100RWw7EBjztH8+r5Lc28FrKSoOpnobwJO5qSgX/2/U8tsmwGERrTeSLvfd52ErBiLyA7Zf8KVr5wNn9gInt0D74R8x7K4NGHZZf+QXl2PVrlN4b/tJnLpQhhVbTmDFlhMYkNYCtw1KxbjeSQjX+6CwV5KA/80G8g+IWo9b3gbCDMp/Hl+Lquesm2BqvQAABjMQFi6CG2sBYIxUZx6H5UaZ1/k249V+OACN+B4syQOiEnz3uShgabVaDBs2zH1NpDR+V/mSTg9MWgFEJgJnDwGf/R8gSYiPDsfMEZ3w3dwReGvGIIzukeCfbM6PrwL7Vol6lElvebZVB5v6toMH0zZwQAQScvamMFudObicwOEvxbWv6m1k5pZAUm9x/Vumbz8XBSyTyYTMzExkZmbCZFKgxQdRDQxufC0qAbjlLdFt+8AnwI9L3R/SajUYdllrvPrHAdj696vx4KjL0CbWR7U5JzYDXz8irkc/CbQb6t14aqrvIL9gar0ga9NX3H9+v1gu9LdTO8UJycYY0eTS19iKgYh8jMGNP6QOBkY/Ja6//ketO0Xio8Mx6+rO+P6h+rM5q/ecwvbj53G6sAwVzkYeY1+cA6yaDrgqgF6TgCvuUe5rU4Mc3NSWuQmm1guycS+KWpdzvwIf3y0yKf4k75K6bJTINvpa1bobNYuoiShksebGXwb9CTi1QywLrZoO/Pk7z4F0VcjZnGGXtUZ+cTk+3JmN97Zn43ShqM2pSqfVIDE6HG1iTWjTwuS+T46tvI41waR1Ah9OBSz54vyS8QuDYxdRferrDO7O3MT6bTpei4wHbn0XeGMM8Os64JsFwMgn/PO5JclzKrEvDu6rTcpgUWdUmguc/QWI7+afz0sBw2KxoF27dgCAEydOwGw2qzshCjkMbvxFoxGBRd4BIP8g8OE0YPrn9f6lLGdz7hveCd8fLcAXP+fg5HkrTheWIaeoDA6nhNOFZThdWAacqH2MZ01v4RZpOyzaSLwZ/wQitud7AqFYE2Ij9NAEW7AjbwW3nAUq7NWLot3BTRBlbgAguS9w/SKxRf+Hl4CEnmLHna8VHAHOHwN0Bv+13tCHA2lDgGPfiOwNg5tLUkFBABxcSSGLwY0/GczA5HeAZcOB7G1iiWrsMw2+rWo2R+ZySThbasOpCyK4OX2hDKcLrTh9oQxnCstxurAMYyo24hZpHQBgVvm9+HanA8DBamNHGHTujE/bFia0a2lG+1ZmtGtlRkqLCBjCAnDlMqIloNUDLof46z821fOxYNsKXlXvSaIj9+aFwKezgJadfH+4opy1aX8VEO7HQw87Xi2Cm9++BdLv89/nJaJLAoMbf2vZEbjhVeD920RxcZsB4pdaE2m1GiREhyMhOhz90y4unpXO7AGWrwCcwNHu/4dhbaagU2HVQKgMBaV2WO1O/Jpfil/zSy8aQ6fVoE2sCe1bVQY8LSPQvnUk2rc0o00LE3RalTI+Wq2ouyk6KbaDVw1ugm0reE3XPA7kHQSOrgfe/wPwp0yxbOUr7kaZPt4lVZNcVHziB6DCBoQZ/fv5iSikMbhRQ9frgN89CHz/PPC/vwAJ3YGEHsqNbz0PzQdTAacNuGwMOt08H51qOUui3OHEmSoBT/YFK04UWPFbgQUnCiwoczhx8rwVJ89bsenI2Wrv1es0SImLQIdWZrRrKTI9chCUGB0Ora8Dn+jK4KZmUXGwLkvJtDrgpteB10eKAuMP/ghM+59vziMqyQVO7xTXl41Vfvz6JPQAzPGiFix7u6djOBGRAhjcqGXEw8CZ3SI1/8HtwN3fKlME63ICH80Qv/hbtBdZojoOyQrX69ChdSQ6tL744DhJkpBfYsPxAguOVwY7xwssOHHOghPnrLBXuPDbWQt+O3vxqbrGMG215a32rSLQrqUZbeMi0CrSAGOYAgcU1rYdXJKqt18IVqZY4Lb3gNeuFsuXXzzom0Lww1+I+zYDPEXa/iK3Ytj3oViaYnBDRApicKMWrQ64aTnw6jDR62n1PcCtK+sMRBrtm3+JXxb6CFHf08yASaPxLHsN7lC9W7jLJeFMURlOFFhx/JwFx89WBj0FFpw8b4WtwoXDeSU4XMchhFHhYWgdaUSrSCNaRRnEvftmQKsoo/vjJkMdgVBtB/k5rKIpIxCcNTdVteosvj9W3gLsfkscfDfwLmU/xy+VwY2vekk1pOMIEdwc+xa45jF15kBEIYnBjZoi4sQBf2+MAY58CfzwInDVg80f79D/xBgAcP0rQGJPZeZZg1arQdsWEWjbIgJXdm5V7WMVThdOXSjD8XOebI+c8cktKofDKaGkvAIl5RX4raDhXkpmgw6toqoEPpVBz1UXjOgP4FxuFkoKLGgVZYS57Bw0gNj5o4/wydfuV5eNElvCNzwOfPk3oHVX5Q7Zs5UAxzeJ666/V2bMppKbaJ7ZI2qlgj0gpUbTarUYMGCA+5pIaQxu1NamHzDuedGa4Zt/iS3Bna5p+jhnjwCr7xXXg+/zzzbiWoTptGhXuRyFLtU/JkkSisocKCi14WyJHQWlNs+t2mM7zpbaYK9wwWJ3wnLOiqxz1mpjHdfa0d8A/Hr0CG59PhMA0EN7AmsNwFmnGZOez0SEIQxmow4mQxjMBh0iDGGIMOgQYdTBLF/Lr9HrYDZ6nosweB4bw7TqbZcfOhvI2y/OR/pwqli+bJHm/bhHN4gsV1xHoNVl3o/XHNHJImA7+wtw/Dugx0R15kF+ZzKZsGPHDrWnQSEsIIKbxYsX47nnnkNubi769OmDV155BYMGDar1tStWrMAdd9xR7Tmj0Yjy8nJ/TNU3+k0VR+Dvfgv4+E7gT5ua9gvMVgJ8MAWwlwBpQ0XDzgCk0WgQG2FAbIQBnRrYACRJEkpsFSgoEcGOJwiy4WypHXFnc4EcoI2uECa9DmUOJ2Igdnydd5lxokYw5A2tBjAbwhBt0iM2ovJmMngem/SIqbyOMRkq78Vjk17nXWCk0YgsXMERIOcnsYPqzq/FsQI1OF0SrPYKlDmcKLM7UeZwwmp3otzuRLRJj84JkZ56p6q7pNQ856jDCBHc/PYtgxsiUozqwc0HH3yABx54AEuXLsUVV1yBl19+GaNHj8bhw4cRH1/7b8Do6GgcPnzY/TjoDqGrzdhngdyfRYr+w6nAjHXisLOGSBKw5j7xyy8qSTTq9McR+j6m0WgQHa5HdLgeHVrX8oJzEcArQIquEIceGw2L3YmKn0uBtUDb5DZYNSYdFlsFrHZn5a0CFpsTZfYKWCofW+1OWGyea/drHE5YbBWwVYj2Fi4JKLFVoMRWIQ5MbAKDTosYOdipDHiiTSI4kgOlGJMexjAdbBVirnJgUlY59zJHBYwRj+B+3Z8Rk7cfW1+4Bf+K+BvKHC53AFNmd8LeQDuOMK0GneIj0SvJjH/9+iWMAErbj4ZKfciFjiOAH5eIuhsiIoWoHty8+OKLuPvuu93ZmKVLl2Lt2rV444038Pe//73W92g0GiQmXty6oDY2mw02m839uLi42PtJ+4I+HLjlbVFgnLNX7JCZsKjh921eCBz6TBxqd8t/fXsmSiCRC4oryoDyIphNsUBl5sYc2xoD23lfvyFnQqx2J0ptFSgqc4ib1YFCqx2FVR9XXhda7ZX3DlS4JNidLpwtseFsia3hT9iAfZq/4D3Dv5Bu+wEjSpOwyHlDra/TaIAIvQ4mg7iFh+mQX2JDUZkDv+SWoGX+FhgNpTgrReOK5ReQ3OIbdE+KRo/kGHRPjkb35Ggkx4T754+GtKHie7cwSxTWx3Xw/eck1VmtVnTv3h0AcPDgQUREhECNHAUUVYMbu92OXbt2Yd68ee7ntFotRo4cia1bt9b5vtLSUqSlpcHlcqFfv3546qmn0KNH7efEZGRk4J///Kfic/eJ2FTg5jeAd24E9vwXaDsQ6D+t7tf/lglsrPzaxj4DpAz0yzQDgt4EhMcC5YViO7gpVvFt4DqtBlHhekSF65HQxPdKkgSr3YnCKgFP9SDIgaIye+W9A+UOpwhG9GEwGXTVghPPdU/sP6NFv58ex4P6Vbh+1EjYOo4VrzGIuiFTHTVCkiThTFE5DpwuQvwPa4AcYFvYILhsWpy6UIZTF8rw9cE89+tjI/TonhQtbski8OnQ2gy9TuHiT2MkkDIIyNossjcMbi4JkiQhKyvLfU2kNFWDm4KCAjidTiQkVP/VkZCQgF9++aXW93Tp0gVvvPEGevfujaKiIjz//PMYMmQIDhw4gLZt2170+nnz5uGBBx5wPy4uLkZKSoqyX4iSOo4Arv4HsHG+yN4k9gTa9L/4dYUngVV3AJILuPx2YMAM/89VbdHJIrgpPiP6E5UViucDYNeNRqOB2RgGszEMbWJNCo48BzCeBrYvw2Wb/wp069Oo3kwajThtuk1MOLBOdKUff8vduCrlGhzMKcaBM0U4mFOMg2eKcTS/FIVWB7YcO4ctx865xzCEadElIQo9KrM73ZOi0S0pGmajl/+MdBwhgpvfvgUG3undWFW4XBIuWEVxupw9k28FpTb3806XVONcJj8eRklEPqH6slRTpaenIz093f14yJAh6NatG1599VUsWLDgotcbjUYYjUF2tPvQ+4FTu4DDa0WDzT9tAsxVzppxlIuTa8vOA0mXi91WoVB31FRRiaIJqXyQX7C3Xmis0U8B+YeAE98D790G3P1N4wO6nJ+A4lNiq3yHYYjR65HesSXSO3q+v8odThzNL8XBM56g51BOCUptFdh3ugj7The5X6vRAGlxEWgdZXTvPDMbwtw7zczGyp1qxjCxQ82oQ6T8scrH0alXIRwAfvsOcFYAurr/WZIkCRa7s0awUl49gCmVAxg7nK7GZQWO1XIYZbheHEYpn8DdoTL4adcqAq0jjaFR60cUolQNblq1agWdToe8vLxqz+fl5TW6pkav16Nv3744evSoL6aoDq0WuGEJsGyE6Nj88Qzg9k/EwX+SBKz9q6jLMcUBk/8rlmguRXJ38OLK4CbYWy80lk4PTHoLeG04cOE48NEdwJSP6w0K3ORdUp2uqfP7JlyvQ882MejZJgaAyHK6XBKyL1hx4IzI7sjZnrxiG06cs3q1O00LF3YbzYi1FWHGU8tw3NTdHfyYjTqE6bQ4b7G7g5cyh7NJ48eZDWgdaUTrqCq3Ko8lCe5zmeSzmU6et6Lc4cIvuSX4JffiwygjjWFo1yoC7VtFon3LiGoZn9gI71pluFySKGq3V8BqE/dldqcohLeJgni5ML7M7oTZqBO7EE36yt2I1QvViS5FqgY3BoMB/fv3x8aNGzFx4kQAgMvlwsaNGzFr1qxGjeF0OrFv3z5cd51Kp6z6SniMOGH49WtEbc23T4pTXHe9Cex9B9BogZuXV28aeamRWwaUVJ5SHAqtFxrL3BK49T1g+Sjx/bH+MWDMUw2/T2650KVpjTK1Wg3SWpqR1tKM63p5WjUUlNpwJLcERWUOcSaRraLaL2VL5S9j+ZeyvCNN3slmsVfAJWmxxdUD1+m2o0f5LnxjafgYBLNBV2ewIh6Ho3WUES0jDY2qE2rsYZTHCyw4XViGUlsF9p8uxv7TF29QiI3Qi0CnMuNj0uvEf5PK/z5llV+3/PiiHX1NDN7qE2HQ1RL0GNCiypEGMRF6tJA/btIjJoJBEQU/1ZelHnjgAUybNg0DBgzAoEGD8PLLL8Nisbh3T02dOhVt2rRBRkYGAGD+/PkYPHgwOnXqhMLCQjz33HPIysrCXXcpfDR9IEjoLs44+fhO4PsXxK6S718QH7vmMaDj1erOT21yf6mamZsAqLnxi8SeIsP34VRg22Lx+PI/1P36CyfEgYAaHXDZaEWm0CrSiFadmr/sK0kiS+HcfhrYsB33pJzEsDHpKLV5fvnbKlxoaTa4A5dWkUbv63waUN9hlLYKJ7LPW/FbZdsRT/81K3KLy1FodWDPyULsOVno1Rw0lecryct74qBJz8GTEYYwGMO0sNqduGD1FKfLBewuCe7A6UxR084Bk4OiaJMe4XpRrB6u17qvjTUey9fuW5hW7NTTi9161T+uhavKsQX2ChcqrA5YHRXuYw2s9qpHNIhMlfva4flYzddWfVzucCEqPAzJsSYkx4YjOdaENrGmysfiuVZmI+uqQpTqwc3kyZNx9uxZPPbYY8jNzcXll1+Or776yl1kfPLkyWrHc1+4cAF33303cnNz0aJFC/Tv3x9btmxxbysMOb1uFgf8/bgE2PS0eK7beGDoHFWnFRDk7eBy5uZSqbmpqvsEYNjfgE3PAP+bLU4bbjug9tfKvaTShgRMAKjRaBBhCAO6XwtsAMz5uzEgSQ8YA2N+tTGG6dApPgqd4qMu+pjVXiF6rhV4Ah+nS6p24nXVk7EjDKIWyWTQueuV5I+H65t/MrbLJdqcFFbuyLtQ5YiCmoHQBQWDokbPz1EOfSuRde4z/2toG3OmVzOcs9hxzmKvVidWlUGnRVJsOJJjTNWCIBEIiesIg39+TUqSODqi3C7Or3I4XTDqtTCGiR2Qqp6UHoQ00iW2D6+4uBgxMTEoKipCdHS02tNpHKcDeGs8cHKr+OV110YgPEjm7ktn9gLLhgGRCcBfDwPzWwKSE3jgF/93uVaTywV8+Efgl8+ByETgT5m1f/1vjgOyfgDGPA0Mvtfv02zQwj4iu3TbB0CXMWrP5pJUMyiSjykor3Ch3O5EeYUT5Q4nyuwu93W5w1V5X/mxi56r/tq6hGk1IsirDPDcRxwYwhCh17lbp0QYRBYrourHqwSN8ntNeh0KrQ6cKSzDmaIynCksF9eVt9zicjSm3jw2Qu8OftpUCX4SosPhdEnur1k+fLPqf4eyykClvMrHaz6uet3QfIxhIgNmDNPCqNciPEznDoDCa9xXe22YFkZ99ecMYVqEabXQaTXQ6zTQaTUI02oRptMgTKtBmE6LMK2myse1lc9XPqfVQqervNeK9/g6C9aU39+qZ26oEXR60TH85w+B7tczsJHJmZvSfLEkJVXWKlxKmRugsgB9KfD6tcDZQ6IVx/Qvqp9wbT0PnBRbwNElQOvTOowQNWW/fcvgRiVarUacqB2hR1rLhl/fVJIkwVbhcv/yB4CIyrOdDGHKN9BMjjWhe3Lt/15WOF3IK7G5g53T7sCn3P24pLwChVaR8TqY478DYOVgw1bhQtX0g63C5T45PRBpNXAHSH1TY/HuXYNVmwuDm2AREQcMvkftWQSWiFaANgxwVYit0YDY4uyjFHdAM0YBt70HvDYCOL0L+HwOMHGJ54iAI1+JM5ESeinTeNMXOlYGN2zFELI0Go279iZW5bmE6bTi7Kd6zqEqLncgp0qwc6ZKAJRfUg69zlNbZKpSf1TzuWqPDfLrPNcmvQ7hBq37ebkIXpIkVFRmh+Sg0Fbhgq0yG1b13lblvlx+XOU9Nd/rcLpQ4RTjV7gkVDhdcFa5FvfisdNV9bUuOJy1p5hcEmB3umB3ArZ6snT+wOCGgpdWK5Zhik8BeQfEc5da1qaquPait9h/bwR+eg9I7AWkzxQfczfKDNCsDQC0v0rsAiw4DBSdBmLaqD0j8hGr1YqBA8WJ6jt27AjY9gvR4XpEJ+rRJfHi+ip/0GjEkpBep4U6M6ibyyXB4RIBkcMpVQZGIghyuiToVC7UVj4PSORPcm1JvhzcBG4hql90GC4O+QOAr/8BHN0IOMqAY9+I57o2bQu4X5laAMl9xfVvmapOhXxLkiQcPHgQBw8eZPuFIKXVamAME3VOMSY94swGxEeJmqSUuAgkK3oyezPmp+pnJ/KWvB1cztxEXMKZG9kVfxYtOSSXOOBv5xuAwwrEpACJvdWeXf06jBD3v3Fpioiaj8ENBTe5qFiuubmUl6VkGg3w+xdF49XyImDdw+L5LtcFfpsO+eymY9+KXWBERM3A4IaCm5y5sZeK+0t9WUoWZhQnXEdV2RIeyPU2srYDAb0ZsBaIAweJiJqBwQ0FNzlzI2PmxiMqEbj1XSDMBES3BdKGqj2jhoUZgHZXimsuTRFRMzG4oeAWVeOwugA5eTdgtOkP/N8ucbCfTq/2bBqnY2XdDbeEE1EzcSs4BTdmbhoWbFuq5aLik1sBR/mleW5RfSpsYhfc/o+B45uA2DSg3VAg7UogdXBQHPKp0WiQlpbmviZSGoMbCm5RidUfs+Ym+LXuIjJyJTkiwJEzOZcyZ4UIZPZ/Ahz6H2Cr0ivJchY4vRPYvFCcE5TURyxBtvudCHZMsapNuy4RERE4ceKE2tO4NLlcwPFM8YdDxxGAXt0t277C4IaCm8EMGGM8/9gzcxP8NBqRvflppai78VVwU14sgqfyItFstEX7wNpN5nKJ+e3/GDi4BrCe83wsKgnocSPQZSxQdAo48YPoG3bhBHBmj7htXQRAIw5zbHeluKWmc+n2UuVyAYfXApnPAHn7xHOGKKDb70WD5vbDAV3ohASh85XQpSs6CThbGdzwH+7Q0LEyuDn2LXCtQmM6yoDsH4Hj34nb6d2efmSAOO06dbDomp46GEjoCWh1Cn3yRpIkMa/9HwMHPhHZK1lES6D7RKDnTSJI0VYpmbz8NnFfdAo4sVkEOic2A+ePAbk/i9u2/wDQAAk9RKCTNlTczD5oIkWBo66gJjxGnO7+03viFtEK6HED0GsSkDIosAL9ZmBXcAp+b0/07Kx58FcgMl7V6ZACSvOB5zuL67nHAHOrpo/hdIg+W3Iwk/0j4LRXf02L9iJoyPkJcDmqf8wQJf6RT0sXwUSb/r5J4UuS2Pa+/2Ox7FSY5fmYMQboNh7oeSPQfljT/7IuzgGyNldmdjYDBUcufk1898plrMq6ncjW3n09jVBWVoarrroKAPDdd9/BZPLBf1e7BYAGMARmawefqyuoueLPoi1LeCxwajuwbxVwYHX1zGBsqgiie00SwXCAaMrvbwY3FPzW3AfsfVdcP1oQPLuCqH5Lhopf+jctF2nzhricIkMhBzNZWwGHpfpropJEkND+KqD978Q/4oDI6pzeJZaBsrYC2dsBe0n192r1oj2EHOykXOFdprDg18qA5uPqQYc+Qhy42PMmoNM14swipZTkiSAna7PI7Jw9dPFrWnWpDHQq63aiEpT7/JUsFgsiIyMBAKWlpTCbzcoNnv8LsOXfwM8fioA1MlH0XWvR/uL7iLigz1BcpKGgprbvWacD+G2TCHR++dxzbhgggt9eN4vvxxbt/PIl1IXBTT0Y3ISgjQuA758HjNHAvGy1Z0NKWfeIqBvpezswYfHFH5ck4OzhymBmk8hOlBdWf01ES/ELuv1VIqhp2bFxv8xcThFYndwGZG0RQU9p3sWva92tMtipXMqKTal/3AtZYrlp/8dA7j7P8zoj0Pla8QvkstGilswfLAWeQCdrcy0HJ2qAzqOAQX8Sp0drlTk9xCfBzcltwA8vA0e+bPx7jNHiF3Zce3FfNfCJaev/ZUlvNCeoqY3dChz5SnyP/vp19Wxn20Eim9PjBr9k+GpicFMPBjchaMfrwNq/ir/C5+xr+PUUHI5uBN65URxAeH/lL90LJzyZmePfAZb86u8xRouMQ/urxC2+uzK/kCUJuHC8erBz7ujFr4tJEUFOamV2p3VXERQdXCN+WZza4XmtNkwUTve8SZweHR7j/Ty9ZT0vvj55KSv3Z8/H4joAA+8CLv+D14X7igU3Lpf4Rbz5ZbHsCADQiCLZIbNFMHv+uPh/d+E4cP5E5f1xoORM/WNr9eLflFqzPu0CZ5eRUkFNbcouiN15+1YBx78HUBkuaHRAh2Ei0On6e78dP8Dgph4MbkLQr+uBd28Wf1XctV7t2ZBSHGXA02mA0yb+Ujy1Cyg6Wf01YSYRTMiZmaQ+/tvxUXpWBDkntwEntwA5P1cvUAYqd/IVw/1LARpRzNvzJqDb9YFfzFtwFNi5HNjzrmdHoj4C6H0LMPBuILFns4b1OripsAP7PgQ2/xsoOCye0xmAPrcCQ/4CtOrc8BiOMpFJk4OdCyc814VZF9dn1RSVJJYp2w4UtVnJ/fxb3+PLoKY2xTmiNmffKuDMbs/zOiPQZQzQ82aR5fPhuVQMburB4CYEOSuAH14COgwHUgaqPRtS0lvXiyUnmTZM/DKRMzNtBypbk+INW6nIzMjBzqmdohs7IOpzet4EdJ9w8dlMwcBuETUs218D8g94nk8dAgy6WxQ9N6HWrdnBTXkxsGsFsG2JJ/NijAYGzAAG36vcf1uXEyg+UyXwqXp/ovo5QzKNTmy7Txkk/tBKGSgOWFS6psffQU1tzh0TmcifPwTO/ep53hgtgvZeN4ufT4WX9Rjc1IPBDVEQObkN+P4FIL6b+McyNd1/9SjecjqA/IPiYMmGanGChSSJZavty8RyhZypikwEBtwB9J/eqACjycFNSR7w41Jgx3JPYBGZCKTfB/S/w/+nMlvPi4LwUzvEjqPsHbUvc5njRbAjBzzJlzd/OSsQgpqaJEksXe77SAQ7xac9H4vrCMzaqVidFsDgpl4MboiIFFB8RmRRdq3wFFtrw8Rf7oP+JJYL68haWCwWtGvXDgBw4sSJuoObc8fEzqe974nlSQBo2RkYOlssjQVK1g4QZwxlbxe3U9vFMmXN4wW0ek92Rw54YtrWn90JxKCmNvKhk/tWiRqzzqOBG19V9FMwuKkHgxsiIgVV2IFDn4klq+xtnucTeoklq16Tml6LcnqX2Pl06H9w1yu1HQgMnSO2ySuYDfAZR5k4Pyn7x8qAZ0ftO+6ikjx1OylXiLqxMGPwBDW1qbCLWrPmnE9VDwY39WBwQ0TkIzk/AzteA35eBVSUiefCY4C+fxR1MS071v1eSRI75Da/DJz43vP8ZWNEpiY1PbjPpJEkoPCkCHKyt4ugJ3ffxUXoOoMIcOxWT31TsAQ1Psbgph4MboiIfKzsgthhteM1sQsJAKABOo0US1adRnqyL84KcfbP5oWec3a0YSLjM+QvQEJ3Nb4C/7BbRR8wuW4n+0fAWuD5OIOaahjc1IPBDRGRn7hcwNENogD5qOeYhjJzKsa+Vw5Agy8n62EqOyU+oDeLouT0+0QtyqVGPk8pe4dY1ul5E4OaKpry+5uNM4mIyDe0WuCyUeJ27hiw8w1gz3/hupCFTXtEewvXmCggtjUw+B5gwJ2X9i9zjUYclhjXQe2ZBD1mboiIyH/sVli2v4PI3/0ZAFC6aRHM6TMC58RfClhN+f0dBCXnREQUMgwRQN8pnsf9pzOwIcUxuCEiIqKQwuCGiIiIQgqDGyIiIgop3C1FRER+FxHhxw7adMkJiMzN4sWL0a5dO4SHh+OKK67A9u3b6339qlWr0LVrV4SHh6NXr1744osv/DRTIiLyltlshsVigcViaXxHcKImUD24+eCDD/DAAw/g8ccfx+7du9GnTx+MHj0a+fn5tb5+y5YtuO2223DnnXdiz549mDhxIiZOnIj9+/f7eeZEREQUiFQ/5+aKK67AwIEDsWjRIgCAy+VCSkoK/u///g9///vfL3r95MmTYbFY8Pnnn7ufGzx4MC6//HIsXbq0wc/Hc26IiIiCT9Ccc2O327Fr1y6MHDnS/ZxWq8XIkSOxdevWWt+zdevWaq8HgNGjR9f5epvNhuLi4mo3IiJST3l5OcaNG4dx48ahvLxc7elQCFK1oLigoABOpxMJCQnVnk9ISMAvv/xS63tyc3NrfX1ubm6tr8/IyMA///lPZSZMREReczqd7lpJp9PZwKuJmk71mhtfmzdvHoqKity37OxstadEREREPqRq5qZVq1bQ6XTIy8ur9nxeXh4SExNrfU9iYmKTXm80GmE0GpWZMBEREQU8VTM3BoMB/fv3x8aNG93PuVwubNy4Eenp6bW+Jz09vdrrAWD9+vV1vp6IiIguLaof4vfAAw9g2rRpGDBgAAYNGoSXX34ZFosFd9xxBwBg6tSpaNOmDTIyMgAAs2fPxrBhw/DCCy9g3LhxeP/997Fz504sW7ZMzS+DiIiIAoTqwc3kyZNx9uxZPPbYY8jNzcXll1+Or776yl00fPLkSWi1ngTTkCFDsHLlSvzjH//Aww8/jM6dO2PNmjXo2bOnWl8CERERBRDVz7nxt6KiIsTGxiI7O5vn3BARqcBisSA5ORkAcObMGZ5STI1SXFyMlJQUFBYWIiYmpt7Xqp658beSkhIAQEpKisozISIiOcghaqySkpIGg5tLLnPjcrlw5swZREVFQaPRKDq2HFX6Kivky/GDee6+Hj+Y5x7s4wfz3IN9/GCee7CPH8xz9+X4kiShpKQEycnJ1cpVanPJZW60Wi3atm3r088RHR3t0yUvX44fzHP39fjBPPdgHz+Y5x7s4wfz3IN9/GCeu6/GbyhjIwv5Q/yIiIjo0sLghoiIiEIKgxsFGY1GPP744z47EdmX4wfz3H09fjDPPdjHD+a5B/v4wTz3YB8/mOfuj/Eb45IrKCYiIqLQxswNERERhRQGN0RERBRSGNwQERFRSGFwQ0RERCGFwY1CFi9ejHbt2iE8PBxXXHEFtm/frtjY3333HcaPH4/k5GRoNBqsWbNGsbEzMjIwcOBAREVFIT4+HhMnTsThw4cVG3/JkiXo3bu3+zCn9PR0fPnll4qNX9XTTz8NjUaDOXPmKDLeE088AY1GU+3WtWtXRcaWnT59GrfffjtatmwJk8mEXr16YefOnYqM3a5du4vmr9FoMHPmTK/HdjqdePTRR9G+fXuYTCZ07NgRCxYsgJL7E0pKSjBnzhykpaXBZDJhyJAh2LFjR7PGauhnSJIkPPbYY0hKSoLJZMLIkSPx66+/Kjb+J598glGjRqFly5bQaDTYu3evImM7HA787W9/Q69evWA2m5GcnIypU6fizJkzis39iSeeQNeuXWE2m9GiRQuMHDkSP/74o2LjV3XPPfdAo9Hg5ZdfVmz86dOnX/QzMGbMGMXmfujQIVx//fWIiYmB2WzGwIEDcfLkSUXGr+3nV6PR4LnnnlNk/NLSUsyaNQtt27aFyWRC9+7dsXTpUkXGzsvLw/Tp05GcnIyIiAiMGTOmST9T3mJwo4APPvgADzzwAB5//HHs3r0bffr0wejRo5Gfn6/I+BaLBX369MHixYsVGa+qTZs2YebMmdi2bRvWr18Ph8OBUaNGwWKxKDJ+27Zt8fTTT2PXrl3YuXMnrr76akyYMAEHDhxQZHzZjh078Oqrr6J3796KjtujRw/k5OS4bz/88INiY1+4cAFDhw6FXq/Hl19+iYMHD+KFF15AixYtFBl/x44d1ea+fv16AMCkSZO8HvuZZ57BkiVLsGjRIhw6dAjPPPMMnn32Wbzyyitejy276667sH79evz3v//Fvn37MGrUKIwcORKnT59u8lgN/Qw9++yz+Pe//42lS5fixx9/hNlsxujRo1FeXq7I+BaLBVdeeSWeeeYZRedutVqxe/duPProo9i9ezc++eQTHD58GNdff70i4wPAZZddhkWLFmHfvn344Ycf0K5dO4waNQpnz55VZHzZ6tWrsW3btib3mmrM+GPGjKn2s/Dee+8pMvaxY8dw5ZVXomvXrsjMzMTPP/+MRx99FOHh4YqMX3XOOTk5eOONN6DRaHDTTTcpMv4DDzyAr776Cu+88w4OHTqEOXPmYNasWfjss8+8GluSJEycOBG//fYbPv30U+zZswdpaWkYOXKkYr9bGiSR1wYNGiTNnDnT/djpdErJyclSRkaG4p8LgLR69WrFx5Xl5+dLAKRNmzb57HO0aNFCev311xUbr6SkROrcubO0fv16adiwYdLs2bMVGffxxx+X+vTpo8hYtfnb3/4mXXnllT4bv6bZs2dLHTt2lFwul9djjRs3TpoxY0a152688UZpypQpXo8tSZJktVolnU4nff7559We79evn/TII494NXbNnyGXyyUlJiZKzz33nPu5wsJCyWg0Su+9957X41d1/PhxCYC0Z8+eJo/b0Niy7du3SwCkrKwsn4xfVFQkAZA2bNig2PinTp2S2rRpI+3fv19KS0uTXnrppSaPXdf406ZNkyZMmNCs8Roae/LkydLtt9/u9dh1jV/ThAkTpKuvvlqx8Xv06CHNnz+/2nPN+RmrOfbhw4clANL+/fvdzzmdTql169bSa6+91uS5NwczN16y2+3YtWsXRo4c6X5Oq9Vi5MiR2Lp1q4oza56ioiIAQFxcnOJjO51OvP/++7BYLEhPT1ds3JkzZ2LcuHHV/h8o5ddff0VycjI6dOiAKVOmNDrd3BifffYZBgwYgEmTJiE+Ph59+/bFa6+9ptj4VdntdrzzzjuYMWOGIg1jhwwZgo0bN+LIkSMAgJ9++gk//PADxo4d6/XYAFBRUQGn03nRX8Amk0nR7BkAHD9+HLm5udW+f2JiYnDFFVcE7c+wRqNBbGys4mPb7XYsW7YMMTEx6NOnjyJjulwu/PGPf8TcuXPRo0cPRcasKTMzE/Hx8ejSpQvuvfdenDt3zusxXS4X1q5di8suuwyjR49GfHw8rrjiCkXLBqrKy8vD2rVrceeddyo25pAhQ/DZZ5/h9OnTkCQJ3377LY4cOYJRo0Z5Na7NZgOAaj+/Wq0WRqNR8Z/fujC48VJBQQGcTicSEhKqPZ+QkIDc3FyVZtU8LpcLc+bMwdChQ9GzZ0/Fxt23bx8iIyNhNBpxzz33YPXq1ejevbsiY7///vvYvXs3MjIyFBmvqiuuuAIrVqzAV199hSVLluD48eP43e9+h5KSEkXG/+2337BkyRJ07twZ69atw7333ou//OUveOuttxQZv6o1a9agsLAQ06dPV2S8v//977j11lvRtWtX6PV69O3bF3PmzMGUKVMUGT8qKgrp6elYsGABzpw5A6fTiXfeeQdbt25FTk6OIp9DJv+chsLPcHl5Of72t7/htttuU7Rh4eeff47IyEiEh4fjpZdewvr169GqVStFxn7mmWcQFhaGv/zlL4qMV9OYMWPw9ttvY+PGjXjmmWewadMmjB07Fk6n06tx8/PzUVpaiqeffhpjxozB119/jRtuuAE33ngjNm3apNDsPd566y1ERUXhxhtvVGzMV155Bd27d0fbtm1hMBgwZswYLF68GFdddZVX43bt2hWpqamYN28eLly4ALvdjmeeeQanTp1S/Oe3LpdcV3Cq28yZM7F//37FI+suXbpg7969KCoqwkcffYRp06Zh06ZNXgc42dnZmD17NtavX9/oNe6mqJqF6N27N6644gqkpaXhww8/VOSvJ5fLhQEDBuCpp54CAPTt2xf79+/H0qVLMW3aNK/Hr2r58uUYO3Zsk+sZ6vLhhx/i3XffxcqVK9GjRw/s3bsXc+bMQXJysmJz/+9//4sZM2agTZs20Ol06NevH2677Tbs2rVLkfFDjcPhwC233AJJkrBkyRJFxx4xYgT27t2LgoICvPbaa7jlllvw448/Ij4+3qtxd+3ahYULF2L37t2KZBRrc+utt7qve/Xqhd69e6Njx47IzMzENddc0+xxXS4XAGDChAm4//77AQCXX345tmzZgqVLl2LYsGHeTbyGN954A1OmTFH037pXXnkF27Ztw2effYa0tDR89913mDlzJpKTk73KhOv1enzyySe48847ERcXB51Oh5EjR2Ls2LGKbjqoDzM3XmrVqhV0Oh3y8vKqPZ+Xl4fExESVZtV0s2bNwueff45vv/0Wbdu2VXRsg8GATp06oX///sjIyECfPn2wcOFCr8fdtWsX8vPz0a9fP4SFhSEsLAybNm3Cv//9b4SFhXn9l1lNsbGxuOyyy3D06FFFxktKSroowOvWrZuiS18AkJWVhQ0bNuCuu+5SbMy5c+e6sze9evXCH//4R9x///2KZtA6duyITZs2obS0FNnZ2di+fTscDgc6dOig2OcA4P45DeafYTmwycrKwvr16xXN2gCA2WxGp06dMHjwYCxfvhxhYWFYvny51+N+//33yM/PR2pqqvtnOCsrC3/961/Rrl077ydeiw4dOqBVq1Ze/xy3atUKYWFhfvkZ/v7773H48GFFf4bLysrw8MMP48UXX8T48ePRu3dvzJo1C5MnT8bzzz/v9fj9+/fH3r17UVhYiJycHHz11Vc4d+6c4j+/dWFw4yWDwYD+/ftj48aN7udcLhc2btyoaF2Jr0iShFmzZmH16tX45ptv0L59e59/TpfL5V6T9cY111yDffv2Ye/eve7bgAEDMGXKFOzduxc6nU6B2XqUlpbi2LFjSEpKUmS8oUOHXrTt/siRI0hLS1NkfNmbb76J+Ph4jBs3TrExrVYrtNrq/3zodDr3X7NKMpvNSEpKwoULF7Bu3TpMmDBB0fHbt2+PxMTEaj/DxcXF+PHHH4PiZ1gObH799Vds2LABLVu29PnnVOpn+I9//CN+/vnnaj/DycnJmDt3LtatW6fATC926tQpnDt3zuufY4PBgIEDB/rlZ3j58uXo37+/YnVOgPi+cTgcPv85jomJQevWrfHrr79i586div/81oXLUgp44IEHMG3aNAwYMACDBg3Cyy+/DIvFgjvuuEOR8UtLS6v9lXH8+HHs3bsXcXFxSE1N9WrsmTNnYuXKlfj0008RFRXlrjGIiYmByWTyamwAmDdvHsaOHYvU1FSUlJRg5cqVyMzMVOQfrqioqItqg8xmM1q2bKlIzdCDDz6I8ePHIy0tDWfOnMHjjz8OnU6H2267zeuxAeD+++/HkCFD8NRTT+GWW27B9u3bsWzZMixbtkyR8QHxS+jNN9/EtGnTEBam3I/7+PHj8eSTTyI1NRU9evTAnj178OKLL2LGjBmKfY5169ZBkiR06dIFR48exdy5c9G1a9dm/Vw19DM0Z84c/Otf/0Lnzp3Rvn17PProo0hOTsbEiRMVGf/8+fM4efKk+/wZ+RdiYmJig9mh+sZOSkrCzTffjN27d+Pzzz+H0+l0/wzHxcXBYDB4NfeWLVviySefxPXXX4+kpCQUFBRg8eLFOH36dKOPFGjov03NYEyv1yMxMRFdunTxevy4uDj885//xE033YTExEQcO3YMDz30EDp16oTRo0d7Pfe5c+di8uTJuOqqqzBixAh89dVX+N///ofMzEyv5y7/215cXIxVq1bhhRdeaNSYTRl/2LBhmDt3LkwmE9LS0rBp0ya8/fbbePHFF70ee9WqVWjdujVSU1Oxb98+zJ49GxMnTvS6WLnR/LIn6xLwyiuvSKmpqZLBYJAGDRokbdu2TbGxv/32WwnARbdp06Z5PXZt4wKQ3nzzTa/HliRJmjFjhpSWliYZDAapdevW0jXXXCN9/fXXioxdGyW3gk+ePFlKSkqSDAaD1KZNG2ny5MnS0aNHFRlb9r///U/q2bOnZDQapa5du0rLli1TdPx169ZJAKTDhw8rOm5xcbE0e/ZsKTU1VQoPD5c6dOggPfLII5LNZlPsc3zwwQdShw4dJIPBICUmJkozZ86UCgsLmzVWQz9DLpdLevTRR6WEhATJaDRK11xzTZP+mzU0/ptvvlnrxx9//HGvxpa3ltd2+/bbb72ee1lZmXTDDTdIycnJksFgkJKSkqTrr79e2r59u2L/bWpq6lbw+sa3Wq3SqFGjpNatW0t6vV5KS0uT7r77bik3N1exuS9fvlzq1KmTFB4eLvXp00das2aNInOXvfrqq5LJZGrW935D4+fk5EjTp0+XkpOTpfDwcKlLly7SCy+80KjjIhoae+HChVLbtm0lvV4vpaamSv/4xz8U/fehIRpJ8lN1DxEREZEfsOaGiIiIQgqDGyIiIgopDG6IiIgopDC4ISIiopDC4IaIiIhCCoMbIiIiCikMboiIiCikMLghIiKikMLghogueZmZmdBoNCgsLFR7KkSkAAY3REREFFIY3BAREVFIYXBDRKpzuVzIyMhA+/btYTKZ0KdPH3z00UcAPEtGa9euRe/evREeHo7Bgwdj//791cb4+OOP0aNHDxiNRrRr1+6iLso2mw1/+9vfkJKSAqPRiE6dOmH58uXVXrNr1y4MGDAAERERGDJkiLt7NxEFFwY3RKS6jIwMvP3221i6dCkOHDiA+++/H7fffjs2bdrkfs3cuXPxwgsvYMeOHWjdujXGjx8Ph8MBQAQlt9xyC2699Vbs27cPTzzxBB599FGsWLHC/f6pU6fivffew7///W8cOnQIr776KiIjI6vN45FHHsELL7yAnTt3IiwsDDNmzPDL109EymJXcCJSlc1mQ1xcHDZs2ID09HT383fddResViv+9Kc/YcSIEXj//fcxefJkAMD58+fRtm1brFixArfccgumTJmCs2fP4uuvv3a//6GHHsLatWtx4MABHDlyBF26dMH69esxcuTIi+aQmZmJESNGYMOGDbjmmmsAAF988QXGjRuHsrIyhIeH+/i/AhEpiZkbIlLV0aNHYbVace211yIyMtJ9e/vtt3Hs2DH366oGPnFxcejSpQsOHToEADh06BCGDh1abdyhQ4fi119/hdPpxN69e6HT6TBs2LB659K7d2/3dVJSEgAgPz/f66+RiPwrTO0JENGlrbS0FACwdu1atGnTptrHjEZjtQCnuUwmU6Nep9fr3dcajQaAqAciouDCzA0Rqap79+4wGo04efIkOnXqVO2WkpLift22bdvc1xcuXMCRI0fQrVs3AEC3bt2wefPmauNu3rwZl112GXQ6HXr16gWXy1WthoeIQhczN0SkqqioKDz44IO4//774XK5cOWVV6KoqAibN29GdHQ00tLSAADz589Hy5YtkZCQgEceeQStWrXCxIkTAQB//etfMXDgQCxYsACTJ0/G1q1bsWjRIvznP/8BALRr1w7Tpk3DjBkz8O9//xt9+vRBVlYW8vPzccstt6j1pRORjzC4ISLVLViwAK1bt0ZGRgZ+++03xMbGol+/fnj44Yfdy0JPP/00Zs+ejV9//RWXX345/ve//8FgMAAA+vXrhw8//BCPPfYYFixYgKSkJMyfPx/Tp093f44lS5bg4Ycfxn333Ydz584hNTUVDz/8sBpfLhH5GHdLEVFAk3cyXbhwAbGxsWpPh4iCAGtuiIiIKKQwuCEiIqKQwmUpIiIiCinM3BAREVFIYXBDREREIYXBDREREYUUBjdEREQUUhjcEBERUUhhcENEREQhhcENERERhRQGN0RERBRS/h+PMdDleyd8IwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.xticks(np.arange(0, 20, 1))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "a=history.history['val_accuracy']\n",
        "plt.axvline(x=a.index(max(a)), color='black', ls='--')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "17177ead",
      "metadata": {
        "id": "17177ead",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "0893b216-01a9-4849-b590-fff962ad0444"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "206/206 [==============================] - 1s 3ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "network = load_model('best_model_sgd.h5')\n",
        "\n",
        "a=network.predict(X_test)\n",
        "pred=[]\n",
        "for i in range(len(a)):\n",
        "    if a[i]>=0.5:\n",
        "        pred.append(1)\n",
        "    else:\n",
        "        pred.append(0)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, pred)\n",
        "fig, ax = plot_confusion_matrix(conf_mat=conf_matrix, figsize=(3, 3), cmap=plt.cm.Blues)\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.ylabel('True Label', fontsize=12)\n",
        "accuracy=(conf_matrix[0,0]+conf_matrix[1,1])/(conf_matrix[0,0]+conf_matrix[1,1]+conf_matrix[0,1]+conf_matrix[1,0])\n",
        "sensitivity=conf_matrix[1,1]/(conf_matrix[1,0]+conf_matrix[1,1])\n",
        "precision=conf_matrix[1,1]/(conf_matrix[0,1]+conf_matrix[1,1])\n",
        "f1_score=2*precision*sensitivity/(precision+sensitivity)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "3993ad35",
      "metadata": {
        "id": "3993ad35"
      },
      "outputs": [],
      "source": [
        "def plot_roc_curve(true_y, y_prob, positive=1):\n",
        "    c_fill      = 'rgba(52, 152, 219, 0.2)'\n",
        "    c_line      = 'rgba(52, 152, 219, 0.5)'\n",
        "    c_line_main = 'rgba(200, 50, 50, 1.0)'\n",
        "    c_grid      = 'rgba(189, 195, 199, 0.5)'\n",
        "    c_annot     = 'rgba(149, 165, 166, 0.5)'\n",
        "    c_i = 'rgba(255, 255, 255, 0)'\n",
        "    c_highlight = 'rgba(192, 57, 43, 1.0)'\n",
        "    AUC = roc_auc_score(true_y, y_prob)\n",
        "    N1 = sum(true_y == positive)\n",
        "    N2 = sum(true_y != positive)\n",
        "    Q1 = AUC / (2 - AUC)\n",
        "    Q2 = 2*AUC**2 / (1 + AUC)\n",
        "    SE_AUC = sqrt((AUC*(1 - AUC) + (N1 - 1)*(Q1 - AUC**2) + (N2 - 1)*(Q2 - AUC**2)) / (N1*N2))\n",
        "    lower = AUC - 1.96*SE_AUC\n",
        "    upper = AUC + 1.96*SE_AUC\n",
        "    if lower < 0:\n",
        "        lower = 0\n",
        "    if upper > 1:\n",
        "        upper = 1\n",
        "    auc=roc_auc_score(true_y, y_prob)\n",
        "    fpr, tpr, thresholds = roc_curve(true_y, y_prob)\n",
        "    fig = go.Figure([\n",
        "\n",
        "    go.Scatter(\n",
        "        x          = fpr,\n",
        "        y          = tpr,\n",
        "        line       = dict(color=c_line_main, width=3),\n",
        "        hoverinfo  = \"skip\",\n",
        "        showlegend = True,\n",
        "        name       = f'AUC: {auc:.4f}'),\n",
        "    go.Scatter(\n",
        "        x          = fpr,\n",
        "        y          = tpr,\n",
        "        line       = dict(color=c_i, width=0),\n",
        "        hoverinfo  = \"skip\",\n",
        "        showlegend = True,\n",
        "        name       = f'(95% CI '+f'{lower:.4f}-{upper:.4f})')\n",
        "    ])\n",
        "    fig.add_shape(\n",
        "        type ='line',\n",
        "        line =dict(dash='dash'),\n",
        "        x0=0, x1=1, y0=0, y1=1\n",
        "    )\n",
        "    fig.update_layout(\n",
        "        template    = 'plotly_white',\n",
        "        title_x     = 0.5,\n",
        "        xaxis_title = \"1 - Specificity\",\n",
        "        yaxis_title = \"Recall\",\n",
        "        width       = 600,\n",
        "        height      = 600,\n",
        "        legend      = dict(\n",
        "            yanchor=\"bottom\",\n",
        "            xanchor=\"right\",\n",
        "            x=0.95,\n",
        "            y=0.01,\n",
        "        )\n",
        "    )\n",
        "    fig.update_yaxes(\n",
        "        range       = [0, 1],\n",
        "        gridcolor   = c_grid,\n",
        "        scaleanchor = \"x\",\n",
        "        scaleratio  = 1,\n",
        "        linecolor   = 'black')\n",
        "    fig.update_xaxes(\n",
        "        range       = [0, 1],\n",
        "        gridcolor   = c_grid,\n",
        "        constrain   = 'domain',\n",
        "        linecolor   = 'black')\n",
        "    return fig\n",
        "\n",
        "\n",
        "c_fill      = 'rgba(52, 152, 219, 0.2)'\n",
        "c_line      = 'rgba(52, 152, 219, 0.5)'\n",
        "c_line_main1 = 'rgba(250, 50, 50, 1.0)'\n",
        "c_line_main2 = 'rgba(50, 50, 250, 1.0)'\n",
        "c_grid      = 'rgba(5, 5, 5, 0.5)'\n",
        "c_annot     = 'rgba(149, 165, 166, 0.5)'\n",
        "c_i = 'rgba(255, 255, 255, 0)'\n",
        "c_highlight = 'rgba(192, 57, 43, 1.0)'\n",
        "\n",
        "def plot_roc_curve2(true_y1, y_prob1, true_y2, y_prob2, name1, name2, positive=1):\n",
        "    c_fill      = 'rgba(52, 152, 219, 0.2)'\n",
        "    c_line      = 'rgba(52, 152, 219, 0.5)'\n",
        "    c_line_main1 = 'rgba(250, 50, 50, 1.0)'\n",
        "    c_line_main2 = 'rgba(50, 50, 250, 1.0)'\n",
        "    c_grid      = 'rgba(5, 5, 5, 0.5)'\n",
        "    c_annot     = 'rgba(149, 165, 166, 0.5)'\n",
        "    c_i = 'rgba(255, 255, 255, 0)'\n",
        "    c_highlight = 'rgba(192, 57, 43, 1.0)'\n",
        "    AUC1 = roc_auc_score(true_y1, y_prob1)\n",
        "    N1 = sum(true_y1 == positive)\n",
        "    N2 = sum(true_y1 != positive)\n",
        "    Q1 = AUC1 / (2 - AUC1)\n",
        "    Q2 = 2*AUC1**2 / (1 + AUC1)\n",
        "    SE_AUC1 = sqrt((AUC1*(1 - AUC1) + (N1 - 1)*(Q1 - AUC1**2) + (N2 - 1)*(Q2 - AUC1**2)) / (N1*N2))\n",
        "    lower1 = AUC1 - 1.96*SE_AUC1\n",
        "    upper1 = AUC1 + 1.96*SE_AUC1\n",
        "    if lower1 < 0:\n",
        "        lower1 = 0\n",
        "    if upper1 > 1:\n",
        "        upper1 = 1\n",
        "    auc1=roc_auc_score(true_y1, y_prob1)\n",
        "    fpr1, tpr1, thresholds1 = roc_curve(true_y1, y_prob1)\n",
        "\n",
        "\n",
        "    AUC2 = roc_auc_score(true_y2, y_prob2)\n",
        "    N1 = sum(true_y2 == positive)\n",
        "    N2 = sum(true_y2 != positive)\n",
        "    Q1 = AUC2 / (2 - AUC2)\n",
        "    Q2 = 2*AUC2**2 / (1 + AUC2)\n",
        "    SE_AUC2 = sqrt((AUC2*(1 - AUC2) + (N1 - 1)*(Q1 - AUC2**2) + (N2 - 1)*(Q2 - AUC2**2)) / (N1*N2))\n",
        "    lower2 = AUC2 - 1.96*SE_AUC2\n",
        "    upper2 = AUC2 + 1.96*SE_AUC2\n",
        "    if lower2 < 0:\n",
        "        lower2 = 0\n",
        "    if upper2 > 1:\n",
        "        upper2 = 1\n",
        "    auc2=roc_auc_score(true_y2, y_prob2)\n",
        "    fpr2, tpr2, thresholds2 = roc_curve(true_y2, y_prob2)\n",
        "\n",
        "    fig = go.Figure([\n",
        "    go.Scatter(\n",
        "        x          = fpr1,\n",
        "        y          = tpr1,\n",
        "        line       = dict(color=c_line_main1, width=5),\n",
        "        hoverinfo  = \"skip\",\n",
        "        showlegend = True,\n",
        "        name       = '<b>'+name1+'</b>'),\n",
        "    go.Scatter(\n",
        "        x          = fpr1,\n",
        "        y          = tpr1,\n",
        "        line       = dict(color=c_i, width=5),\n",
        "        hoverinfo  = \"skip\",\n",
        "        showlegend = True,\n",
        "        name       = f'AUC: {auc1:.4f}'),\n",
        "    go.Scatter(\n",
        "        x          = fpr1,\n",
        "        y          = tpr1,\n",
        "        line       = dict(color=c_i, width=0),\n",
        "        hoverinfo  = \"skip\",\n",
        "        showlegend = True,\n",
        "        name       = f'(95% CI: '+f'{lower1:.4f}-{upper1:.4f})'),\n",
        "    go.Scatter(\n",
        "        x          = fpr2,\n",
        "        y          = tpr2,\n",
        "        line       = dict(color=c_line_main2, width=5),\n",
        "        hoverinfo  = \"skip\",\n",
        "        showlegend = True,\n",
        "        name       = '<b>'+name2+'</b>'),\n",
        "    go.Scatter(\n",
        "        x          = fpr2,\n",
        "        y          = tpr2,\n",
        "        line       = dict(color=c_i, width=5),\n",
        "        hoverinfo  = \"skip\",\n",
        "        showlegend = True,\n",
        "        name       = f'AUC: {auc2:.4f}'),\n",
        "    go.Scatter(\n",
        "        x          = fpr2,\n",
        "        y          = tpr2,\n",
        "        line       = dict(color=c_i, width=0),\n",
        "        hoverinfo  = \"skip\",\n",
        "        showlegend = True,\n",
        "        name       = f'(95% CI: '+f'{lower2:.4f}-{upper2:.4f})')\n",
        "    ])\n",
        "    fig.add_shape(\n",
        "        type ='line',\n",
        "        line =dict(dash='dash'),\n",
        "        x0=0, x1=1, y0=0, y1=1\n",
        "    )\n",
        "    fig.update_layout(\n",
        "        template    = 'plotly_white',\n",
        "        title_x     = 1,\n",
        "        xaxis_title = '<b>1-Specificity</b>',\n",
        "        yaxis_title = \"<b>Recall</b>\",\n",
        "        width       = 600,\n",
        "        height      = 600,\n",
        "        legend      = dict(\n",
        "            yanchor=\"bottom\",\n",
        "            xanchor=\"right\",\n",
        "            x=0.95,\n",
        "            y=0.01,\n",
        "        )\n",
        "    )\n",
        "    fig.update_layout(\n",
        "        font=dict(\n",
        "            family=\"Times New Roman\",\n",
        "            size=22,  # Set the font size here\n",
        "            color=\"Black\"\n",
        "        )\n",
        "    )\n",
        "    fig.update_yaxes(\n",
        "        range       = [0, 1],\n",
        "        gridcolor   = c_grid,\n",
        "        scaleanchor = \"x\",\n",
        "        scaleratio  = 1,\n",
        "        linecolor   = 'black')\n",
        "    fig.update_xaxes(\n",
        "        range       = [0, 1],\n",
        "        gridcolor   = c_grid,\n",
        "        constrain   = 'domain',\n",
        "        linecolor   = 'black')\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "5f347548",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "id": "5f347548",
        "outputId": "5dae8b8a-b6e3-4a8e-aeb1-7b7046c38195"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "206/206 [==============================] - 1s 6ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"3532f4ac-4eff-45a5-b84d-20d24864133b\" class=\"plotly-graph-div\" style=\"height:600px; width:600px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3532f4ac-4eff-45a5-b84d-20d24864133b\")) {                    Plotly.newPlot(                        \"3532f4ac-4eff-45a5-b84d-20d24864133b\",                        [{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(200, 50, 50, 1.0)\",\"width\":3},\"name\":\"AUC: 0.9495\",\"showlegend\":true,\"x\":[0.0,0.0001528584530724549,0.0004585753592173647,0.0004585753592173647,0.0007642922653622745,0.0007642922653622745,0.0010700091715071843,0.0013757260776520942,0.0019871598899419136,0.0019871598899419136,0.0021400183430143687,0.0021400183430143687,0.0027514521553041885,0.003362885967594008,0.003362885967594008,0.0038214613268113726,0.005044328951391012,0.005350045857535922,0.006267196575970651,0.006267196575970651,0.0064200550290431065,0.006725771935188016,0.007031488841332926,0.007031488841332926,0.0077957811066952,0.00810149801284011,0.009171507184347295,0.009782940996637114,0.009935799449709569,0.009935799449709569,0.010547233261999389,0.010852950168144299,0.011311525527361662,0.011311525527361662,0.011922959339651483,0.012075817792723938,0.012075817792723938,0.012534393151941303,0.012992968511158666,0.013145826964231121,0.013145826964231121,0.013298685417303576,0.013604402323448487,0.014062977682665852,0.01467441149495567,0.014827269948028125,0.014827269948028125,0.01498012840110058,0.01498012840110058,0.017273005197187403,0.017578722103332313,0.01803729746254968,0.0186487312748395,0.019565881993274227,0.019871598899419137,0.02063589116478141,0.02063589116478141,0.02094160807092632,0.021400183430143688,0.021705900336288598,0.02216447569550596,0.02247019260165087,0.02461021094466524,0.025068786303882606,0.02522164475695506,0.02522164475695506,0.02583307856924488,0.02613879547538979,0.026291653928462243,0.026291653928462243,0.0264445123815347,0.02675022928767961,0.02736166309996943,0.02736166309996943,0.027514521553041883,0.027514521553041883,0.028125955365331703,0.028737389177621524,0.029043106083766434,0.029195964536838887,0.029501681442983797,0.0311831244267808,0.03148884133292571,0.03179455823907062,0.03210027514521553,0.03271170895750535,0.03317028431672271,0.033476001222867625,0.03378171812901253,0.03546316111280954,0.035921736472026906,0.03622745337817181,0.03653317028431672,0.037908896361968814,0.03836747172118618,0.03943748089269337,0.039743197798838274,0.040354631611128094,0.04081320697034546,0.04127178232956282,0.04142464078263528,0.0420360745949251,0.042188933047997555,0.04264750840721492,0.043258942219504735,0.043258942219504735,0.04432895139101192,0.044634668297156836,0.045093243656374196,0.04631611128095384,0.04662182818709874,0.0481504127178233,0.0481504127178233,0.04830327117089575,0.04891470498318557,0.04998471415469275,0.05044328951391012,0.05181901559156221,0.052124732497707126,0.052124732497707126,0.05227759095077958,0.052583307856924486,0.05350045857535922,0.053806175481504126,0.05426475084072149,0.0545704677468664,0.05472332619993886,0.055029043106083766,0.05518190155915622,0.05548761846530113,0.05594619382451849,0.056099052277590954,0.056099052277590954,0.059003362885967595,0.0593090797921125,0.05976765515132987,0.060226230510547235,0.06114338122898196,0.06175481504127178,0.061907673494344236,0.06221339040048915,0.06328339957199633,0.06358911647814124,0.06481198410272088,0.0651177010088658,0.0654234179150107,0.0654234179150107,0.06649342708651788,0.06679914399266279,0.06741057780495262,0.06771629471109752,0.06786915316416998,0.06817487007031489,0.06832772852338734,0.06863344542953226,0.06924487924182207,0.06955059614796698,0.0698563130541119,0.07031488841332925,0.07062060531947417,0.07184347294405381,0.07184347294405381,0.07291348211556099,0.0735249159278508,0.07428920819321308,0.074594925099358,0.07902782023845918,0.07963925405074901,0.07979211250382146,0.08009782940996638,0.08055640476918374,0.08086212167532865,0.08132069703454602,0.08177927239376337,0.08208498929990829,0.0826964231121981,0.08590645062671966,0.08636502598593702,0.0871293182512993,0.0874350351574442,0.08758789361051666,0.08819932742280648,0.08850504432895138,0.08942219504738612,0.08972791195353103,0.09003362885967595,0.09033934576582085,0.09064506267196576,0.0921736472026903,0.09278508101498013,0.09370223173341485,0.09416080709263222,0.09446652399877713,0.0949250993579945,0.0952308162641394,0.09553653317028432,0.09568939162335677,0.0966065423417915,0.09737083460715378,0.09767655151329868,0.09859370223173342,0.09935799449709569,0.10180372974625497,0.10379088963619688,0.10409660654234179,0.10470804035463162,0.10516661571384897,0.10531947416692143,0.10593090797921124,0.1060837664322837,0.10837664322837053,0.10883521858758789,0.1108223784775298,0.11112809538367471,0.11128095383674717,0.11158667074289208,0.11173952919596454,0.11204524610210945,0.11235096300825435,0.11265667991439926,0.11433812289819627,0.11464383980434117,0.11510241516355854,0.115255273616631,0.11556099052277591,0.11617242433506574,0.11663099969428309,0.11708957505350046,0.11754815041271782,0.1183124426780801,0.118618159584225,0.11907673494344237,0.11938245184958728,0.1199938856618771,0.1199938856618771,0.12029960256802201,0.12060531947416692,0.12091103638031184,0.12259247936410883,0.12350963008254356,0.12412106389483338,0.1244267808009783,0.12519107306634056,0.12564964842555792,0.1261082237847753,0.12702537450321003,0.12733109140935495,0.12977682665851423,0.1302354020177316,0.1305411189238765,0.13099969428309385,0.13130541118923877,0.13145826964231122,0.1319168450015286,0.13206970345460103,0.13206970345460103,0.13237542036074595,0.13268113726689085,0.13298685417303577,0.13298685417303577,0.13313971262610821,0.13344542953225313,0.1339040048914705,0.13512687251605013,0.1352797309691226,0.1355854478752675,0.13573830632833997,0.13665545704677468,0.1369611739529196,0.13787832467135433,0.13955976765515132,0.14108835218587587,0.14185264445123816,0.14215836135738305,0.14231121981045552,0.14292265362274534,0.1433812289819627,0.14368694588810763,0.14414552124732496,0.14414552124732496,0.14429837970039744,0.14460409660654233,0.1450626719657597,0.14536838887190462,0.14552124732497707,0.14582696423112199,0.14659125649648425,0.1470498318557016,0.14796698257413635,0.14857841638642616,0.14873127483949863,0.15071843472944055,0.15117701008865791,0.15163558544787525,0.15194130235402017,0.1522470192601651,0.15239987771323754,0.15270559461938246,0.15362274533781717,0.1539284622439621,0.15438703760317946,0.15499847141546927,0.1553041883216142,0.15576276368083156,0.15606848058697645,0.1566799143992663,0.157597065117701,0.15790278202384592,0.15881993274228065,0.1595842250076429,0.16019565881993275,0.16050137572607764,0.160959951085295,0.16157138489758482,0.16187710180372974,0.1623356771629471,0.16248853561601956,0.16355854478752674,0.1640171201467441,0.16432283705288903,0.16493427086517884,0.16523998777132376,0.16661571384897586,0.16799143992662793,0.1698257413634974,0.17028431672271477,0.17074289208193213,0.17211861815958424,0.17334148578416386,0.17410577804952615,0.17441149495567104,0.1748700703148884,0.17502292876796086,0.1756343625802507,0.17670437175175788,0.17808009782940998,0.17823295628248242,0.17853867318862734,0.1809844084377866,0.18281870987465607,0.183124426780801,0.18343014368694588,0.18480586976459798,0.1851115866707429,0.1854173035768878,0.1857230204830327,0.18587587893610516,0.18618159584225008,0.18648731274839497,0.1867930296545399,0.18709874656068481,0.18755732191990218,0.18786303882604707,0.18923876490369917,0.1895444818098441,0.19000305716906146,0.19092020788749617,0.1918373586059309,0.19214307551207582,0.19229593396514827,0.193213084683583,0.19336594313665545,0.19367166004280037,0.19672882910424946,0.19703454601039438,0.1976459798226842,0.1979516967288291,0.19841027208804646,0.1996331397126261,0.20024457352491593,0.2010088657902782,0.2013145826964231,0.20238459186793029,0.20238459186793029,0.20284316722714765,0.20314888413329257,0.20421889330479975,0.20452461021094467,0.20483032711708957,0.20528890247630693,0.20590033628859675,0.20590033628859675,0.20620605319474167,0.2101803729746255,0.21048608988077042,0.21063894833384286,0.21063894833384286,0.21125038214613268,0.21170895750535004,0.2118618159584225,0.2121675328645674,0.2129318251299297,0.2132375420360746,0.21339040048914704,0.21369611739529196,0.21400183430143688,0.21430755120758177,0.21553041883216142,0.21583613573830632,0.2159889941913788,0.21629471109752368,0.21644756955059616,0.21690614490981353,0.21721186181595842,0.22011617242433507,0.22042188933048,0.22439620911036381,0.2247019260165087,0.22485478446958118,0.22516050137572607,0.22531335982879852,0.22561907673494344,0.22623051054723325,0.22653622745337818,0.22760623662488536,0.22791195353103028,0.22821767043717517,0.2285233873433201,0.2291348211556099,0.2298991134209722,0.23020483032711708,0.2308162641394069,0.23127483949862426,0.232191990217059,0.23265056557627636,0.2328034240293488,0.23310914093549373,0.23402629165392846,0.23448486701314583,0.2349434423723632,0.235554876184653,0.23586059309079793,0.23616630999694282,0.2363191684500153,0.2366248853561602,0.2369306022623051,0.23723631916845,0.23754203607459493,0.23784775298073985,0.23891776215224703,0.2393763375114644,0.24182207276062367,0.24212778966676857,0.24319779883827575,0.24365637419749311,0.2438092326505656,0.24411494955671048,0.2444206664628554,0.2447263833690003,0.24564353408743503,0.24594925099357995,0.24640782635279732,0.24686640171201468,0.24701926016508713,0.2474778355243045,0.24793641088352186,0.24839498624273923,0.2494649954142464,0.24977071232039133,0.2503821461326811,0.25068786303882606,0.2508407214918985,0.2511464383980434,0.2516050137572608,0.2519107306634057,0.2528278813818404,0.25328645674105776,0.2535921736472027,0.25405074900642005,0.25481504127178234,0.25512075817792723,0.2552736166309997,0.2555793335371446,0.2557321919902171,0.2561907673494344,0.25741363497401404,0.25787221033323143,0.2580250687863039,0.2586365025985937,0.25955365331702845,0.25985937022317335,0.2603179455823907,0.26062366248853563,0.2609293793946805,0.2619993885661877,0.2623051054723326,0.2624579639254051,0.26276368083155,0.2638336900030572,0.26413940690920207,0.2642922653622745,0.2642922653622745,0.26490369917456436,0.26520941608070925,0.2653622745337817,0.26566799143992664,0.2664322837052889,0.2667380006114338,0.26719657597065116,0.2675022928767961,0.26964231121981047,0.26994802812595536,0.2705594619382452,0.2708651788443901,0.271170895750535,0.27147661265667994,0.27269948028125957,0.27376948945276675,0.27407520635891164,0.27453378171812903,0.2766738000611434,0.2769795169672883,0.2774380923265057,0.2777438092326506,0.277896667685723,0.2782023845918679,0.27835524304494036,0.2786609599510853,0.2794252522164476,0.2797309691225925,0.2817181290125344,0.2823295628248242,0.2827881381840416,0.2833995719963314,0.28492815652705594,0.2855395903393458,0.2858453072454907,0.2864567410577805,0.2867624579639254,0.2870681748700703,0.28767960868236014,0.28798532558850504,0.28844390094772243,0.28966676857230206,0.29241822072760626,0.29272393763375115,0.2928767960868236,0.2931825129929685,0.2945582390706206,0.29501681442983796,0.29608682360134514,0.29654539896056253,0.3006725771935188,0.3009782940996637,0.3020483032711709,0.30235402017731583,0.3025068786303883,0.30311831244267806,0.3054111892387649,0.3057169061449098,0.30663405686334455,0.30724549067563434,0.3087740752063589,0.30923265056557625,0.3106083766432284,0.31091409354937327,0.3145826964231122,0.3148884133292571,0.315194130235402,0.31549984714154694,0.31626413940690923,0.3165698563130541,0.31809844084377864,0.31855701620299604,0.31886273310914093,0.3191684500152858,0.32023845918679306,0.32054417609293795,0.3210027514521553,0.32161418526444513,0.32222561907673497,0.32253133598287986,0.32696423112198103,0.327269948028126,0.3287985325588505,0.3291042494649954,0.3295628248242128,0.3298685417303577,0.33521858758789363,0.3355243044940385,0.33644145521247326,0.33674717211861815,0.33751146438398044,0.33781718129012533,0.33827575664934273,0.3385814735554876,0.33949862427392236,0.34011005808621214,0.340721491898502,0.3410272088046469,0.3413329257107918,0.3416386426169367,0.34255579333537145,0.34286151024151634,0.3430143686945888,0.34332008560073374,0.3434729440538062,0.3437786609599511,0.34423723631916847,0.34484867013145826,0.34591867930296544,0.34637725466218283,0.3466829715683277,0.3501987159889942,0.3505044328951391,0.3515744420666463,0.3518801589727912,0.352491592785081,0.35310302659737086,0.3538673188627331,0.35417303576887804,0.35447875267502293,0.3547844695811678,0.3549373280342403,0.3552430449403852,0.3569244879241822,0.3573830632833996,0.35799449709568937,0.3583002140018343,0.360898807704066,0.3616630999694283,0.36181595842250075,0.36227453378171814,0.3624273922347906,0.3627331091409355,0.36487312748394984,0.3651788443900948,0.36563741974931213,0.365943136655457,0.366248853561602,0.36655457046774687,0.3671660042800367,0.3697645979822684,0.37007031488841335,0.3702231733414858,0.3705288902476307,0.371293182512993,0.3715988994191379,0.37190461632528277,0.3725160501375726,0.37297462549678995,0.3732803424029349,0.3738917762152247,0.37419749312136963,0.37511464383980436,0.37542036074594926,0.3766432283705289,0.3769489452766738,0.3771018037297463,0.37740752063589117,0.37847752980739835,0.37878324671354324,0.3793946805258331,0.379700397431978,0.38153469886884744,0.38184041577499234,0.38199327422806484,0.38229899113420973,0.3836747172118618,0.38398043411800675,0.3852033017425864,0.3856618771018037,0.38581473555487616,0.3861204524610211,0.38657902782023845,0.38688474472638335,0.3891776215224702,0.3894833384286151,0.39131763986548457,0.39162335677162946,0.39208193213084686,0.39238764903699175,0.39269336594313664,0.3933047997554265,0.3936105166615714,0.39391623356771627,0.39544481809844084,0.39575053500458574,0.3959033934576582,0.39620911036380313,0.3980434118006726,0.3983491287068175,0.4018648731274839,0.40247630693977376,0.40278202384591866,0.4033934576582085,0.40385203301742584,0.40400489147049834,0.40431060837664323,0.40782635279730967,0.4084377866095995,0.41057780495261387,0.4108835218587588,0.41103638031183126,0.41134209721797615,0.41241210638948334,0.41271782329562823,0.41287068174870073,0.4131763986548456,0.41363497401406296,0.4139406909202079,0.41439926627942525,0.41470498318557014,0.41608070926322227,0.4165392846224396,0.41822072760623663,0.4185264445123815,0.41883216141852647,0.4192907367777438,0.4195964536838887,0.4200550290431061,0.420360745949251,0.42097217976154083,0.42143075512075817,0.4226536227453378,0.42295933965148275,0.4234179150107001,0.4240293488229899,0.42479364108835216,0.4250993579944971,0.4266279425252216,0.4269336594313666,0.4289208193213085,0.4295322531335983,0.43167227147661263,0.4319779883827576,0.4365637419749312,0.43686945888107614,0.4370223173341486,0.4376337511464384,0.43870376031794556,0.43916233567716295,0.43992662794252524,0.44023234484867013,0.440538061754815,0.44084377866096,0.44114949556710487,0.44145521247324976,0.4420666462855396,0.44252522164475694,0.44298379700397433,0.4432895139101192,0.44497095689391625,0.44527667380006114,0.44558239070620603,0.445888107612351,0.4460409660654234,0.4463466829715683,0.44695811678385816,0.4474166921430755,0.4481809844084378,0.4484867013145827,0.4486395597676551,0.4489452766738001,0.45032100275145215,0.45062671965759704,0.45077957811066954,0.45139101192295933,0.45337817181290124,0.45368388871904614,0.45383674717211864,0.45414246407826353,0.4567410577804953,0.4570467746866402,0.4585753592173647,0.45888107612350965,0.4599510852950168,0.4602568022011617,0.4605625191073066,0.461021094466524,0.4616325282788138,0.46193824518495874,0.4630082543564659,0.46346682971568326,0.4637725466218282,0.4640782635279731,0.46423112198104555,0.4648425557933354,0.4657597065117701,0.466065423417915,0.46851115866707427,0.4688168755732192,0.47003974319779884,0.47034546010394374,0.4709568939162336,0.47126261082237847,0.47202690308774076,0.47233261999388565,0.4729440538061755,0.4732497707123204,0.4764597982268419,0.4767655151329869,0.47737694894527666,0.4776826658514216,0.4779883827575665,0.4782940996637114,0.4790583919290737,0.47936410883521857,0.479516967288291,0.47982268419443597,0.48012840110058086,0.48043411800672575,0.48058697645979825,0.48089269336594315,0.4810455518190156,0.4813512687251605,0.48287985325588506,0.4833384286151024,0.4853255885050443,0.48563130541118926,0.4874656068480587,0.4877713237542036,0.4880770406603485,0.4883827575664934,0.48975848364414554,0.4902170590033629,0.49281565270559463,0.4931213696117395,0.4934270865178844,0.49373280342402937,0.4941913787832467,0.4944970956893916,0.49633139712626106,0.4969428309385509,0.49785998165698564,0.49816569856313053,0.5004585753592173,0.5007642922653622,0.5012228676245797,0.5015285845307246,0.5024457352491593,0.5027514521553041,0.5032100275145216,0.5035157444206665,0.505350045857536,0.5056557627636808,0.5058086212167533,0.5061143381228982,0.5077957811066952,0.5082543564659125,0.5094772240904922,0.510088657902782,0.5108529501681442,0.5113115255273617,0.5116172424335066,0.5119229593396515,0.5125343931519413,0.5128401100580862,0.5129929685111587,0.5132986854173036,0.5140629776826658,0.5143686945888107,0.5162029960256802,0.5165087129318251,0.517120146744115,0.5175787221033323,0.5178844390094772,0.5180372974625497,0.5183430143686946,0.5188015897279119,0.5192601650871294,0.5194130235402018,0.5197187404463467,0.5198715988994191,0.5204830327117089,0.5207887496178538,0.5210944665239988,0.5215530418832162,0.521858758789361,0.5233873433200856,0.5236930602262305,0.5241516355854479,0.5247630693977376,0.5249159278508102,0.5252216447569551,0.5293488229899114,0.5298073983491287,0.5331702843167228,0.5336288596759401,0.5343931519413023,0.5346988688474472,0.5362274533781718,0.5368388871904616,0.5371446040966066,0.538978905533476,0.5394374808926934,0.5397431977988383,0.5403546316111281,0.540966065423418,0.5412717823295629,0.5420360745949251,0.54234179150107,0.5450932436563742,0.5453989605625191,0.547386120452461,0.5476918373586059,0.5489147049831856,0.5492204218893305,0.5515132986854173,0.5519718740446347,0.5522775909507796,0.5525833078569244,0.5528890247630694,0.5535004585753592,0.5538061754815041,0.5542647508407215,0.5545704677468664,0.5559461938245185,0.5564047691837358,0.5565576276368083,0.5571690614490982,0.5573219199021706,0.5576276368083155,0.557780495261388,0.5580862121675328,0.5583919290736777,0.5588505044328952,0.561143381228982,0.5614490981351269,0.5619076734943442,0.562519107306634,0.5638948333842861,0.564200550290431,0.5649648425557934,0.5652705594619383,0.5654234179150107,0.5657291348211556,0.5686334454295322,0.5689391623356772,0.5690920207887497,0.569550596147967,0.5698563130541119,0.5700091715071843,0.5703148884133292,0.5706206053194741,0.5709263222256191,0.5723020483032711,0.5727606236624886,0.5736777743809233,0.5739834912870682,0.574594925099358,0.574900642005503,0.5753592173647203,0.5756649342708652,0.5765820849892999,0.5768878018954449,0.5774992357077346,0.5785692448792418,0.5788749617853868,0.5791806786915317,0.5794863955976766,0.5807092632222562,0.5810149801284011,0.5811678385814736,0.5817792723937634,0.5833078569244879,0.5836135738306328,0.5845307245490675,0.5848364414552125,0.5851421583613574,0.5854478752675023,0.586365025985937,0.5868236013451544,0.5871293182512993,0.5888107612350963,0.5891164781412412,0.5892693365943137,0.5895750535004586,0.5920207887496178,0.5923265056557627,0.5926322225619077,0.5929379394680526,0.5932436563741975,0.5935493732803424,0.5943136655457046,0.5946193824518495,0.5947722409049221,0.595077957811067,0.5975236930602262,0.5978294099663711,0.5982879853255885,0.5988994191378784,0.5995108529501681,0.6001222867624579,0.6004280036686028,0.6036380311831244,0.6042494649954142,0.605166615713849,0.6054723326199939,0.6056251910730663,0.6059309079792112,0.6063894833384286,0.6071537756037909,0.6092937939468053,0.61021094466524,0.6108223784775298,0.6111280953836747,0.6129623968205442,0.613573830632834,0.6138795475389789,0.6141852644451238,0.6144909813512687,0.6147966982574137,0.6149495567104861,0.6154081320697035,0.6157138489758484,0.6160195658819932,0.6163252827881381,0.6170895750535005,0.6177010088657903,0.6180067257719352,0.6181595842250076,0.6184653011311525,0.6186181595842251,0.6192295933965148,0.620299602568022,0.620605319474167,0.6209110363803119,0.6215224701926017,0.6224396209110363,0.6228981962702538,0.6230510547233262,0.6235096300825436,0.623662488535616,0.6239682054417609,0.6247324977071232,0.6251910730663406,0.6258025068786304,0.6261082237847753,0.6265667991439927,0.6268725160501376,0.629012534393152,0.6296239682054418,0.6299296851115866,0.6302354020177315,0.6308468358300214,0.6311525527361663,0.6313054111892388,0.6316111280953837,0.6325282788138185,0.6328339957199633,0.6340568633445429,0.6343625802506878,0.6355854478752675,0.6360440232344848,0.637419749312137,0.6380311831244267,0.6387954753897891,0.6392540507490064,0.6395597676551513,0.6397126261082238,0.6400183430143687,0.6403240599205136,0.6406297768266586,0.640782635279731,0.6410883521858759,0.6418526444512381,0.642158361357383,0.6423112198104555,0.6426169367166005,0.6430755120758178,0.6435340874350352,0.6436869458881076,0.6444512381534699,0.6447569550596148,0.6450626719657597,0.6455212473249771,0.645826964231122,0.6464383980434119,0.6467441149495567,0.647508407214919,0.6479669825741363,0.6482726994802812,0.6485784163864262,0.6487312748394987,0.6494955671048609,0.6501070009171507,0.6505655762763681,0.650871293182513,0.6513298685417304,0.6514827269948028,0.6517884439009477,0.6520941608070926,0.65255273616631,0.6531641699785998,0.6536227453378172,0.6556099052277591,0.655915622133904,0.6562213390400489,0.6565270559461939,0.6566799143992663,0.6571384897584837,0.6582084989299908,0.6585142158361358,0.6614185264445124,0.6617242433506573,0.6624885356160196,0.6627942525221645,0.6647814124121064,0.6650871293182513,0.6678385814735555,0.6681442983797004,0.6689085906450627,0.6692143075512076,0.6704371751757873,0.6707428920819322,0.6721186181595842,0.6724243350657292,0.6728829104249465,0.6731886273310914,0.6739529195964536,0.6742586365025985,0.6753286456741058,0.6756343625802507,0.676398654845613,0.6767043717517579,0.6768572302048304,0.6771629471109752,0.6780800978294099,0.6785386731886274,0.6796086823601345,0.6800672577193518,0.6802201161724243,0.6811372668908591,0.6872516050137573,0.6877101803729746,0.6906144909813513,0.6909202078874962,0.6913787832467135,0.6935188015897279,0.6938245184958728,0.6939773769489452,0.6942830938550902,0.6953531030265974,0.6956588199327423,0.6959645368388871,0.6964231121981046,0.6970345460103944,0.6973402629165393,0.6977988382757566,0.6984102720880465,0.6987159889941914,0.6991745643534087,0.6994802812595536,0.6996331397126261,0.7000917150718434,0.7013145826964231,0.7019260165087129,0.7042188933047998,0.7046774686640171,0.704983185570162,0.7055946193824518,0.7062060531947417,0.7071232039131764,0.7074289208193213,0.7078874961785386,0.7081932130846836,0.7092632222561908,0.7095689391623357,0.7097217976154081,0.7106389483338429,0.7107918067869153,0.7114032405992051,0.7115560990522776,0.7118618159584225,0.7121675328645675,0.7124732497707124,0.7130846835830021,0.713390400489147,0.7141546927545094,0.7144604096606543,0.7150718434729441,0.715377560379089,0.7158361357383063,0.7161418526444513,0.7166004280036686,0.7172118618159584,0.7173647202690309,0.7176704371751758,0.7188933047997554,0.7193518801589728,0.7195047386120452,0.7198104555181901,0.7199633139712626,0.7202690308774076,0.7205747477835525,0.7210333231427698,0.7213390400489147,0.7214918985019871,0.721797615408132,0.7219504738612045,0.7222561907673495,0.7227147661265668,0.7231733414857842,0.7251605013757261,0.7257719351880159,0.7269948028125955,0.7274533781718129,0.7295933965148272,0.7302048303271171,0.7306634056863345,0.7315805564047692,0.732191990217059,0.732497707123204,0.7328034240293488,0.7332619993885662,0.7335677162947111,0.7340262916539284,0.7343320085600734,0.7344848670131459,0.7350963008254356,0.7357077346377254,0.7360134515438703,0.7363191684500153,0.7366248853561602,0.7369306022623051,0.73723631916845,0.7384591867930297,0.7387649036991746,0.740599205136044,0.7409049220421889,0.7421277896667686,0.7424335065729135,0.742586365025986,0.7428920819321309,0.7431977988382757,0.7435035157444206,0.7438092326505655,0.7441149495567105,0.7445735249159279,0.7448792418220728,0.7454906756343626,0.7457963925405074,0.7461021094466525,0.7464078263527973,0.7465606848058698,0.7468664017120147,0.7482421277896668,0.7485478446958117,0.7496178538673188,0.7502292876796087,0.7520635891164782,0.7523693060226231,0.752675022928768,0.7529807398349129,0.7538978905533475,0.7542036074594926,0.755732191990217,0.7563436258025069,0.7577193518801589,0.7580250687863039,0.7586365025985937,0.7592479364108835,0.7615408132069703,0.7618465301131152,0.7638336900030571,0.7641394069092021,0.7652094160807092,0.7655151329868541,0.7667380006114338,0.7670437175175787,0.7673494344237236,0.767808009782941,0.7679608682360135,0.7682665851421584,0.7684194435952308,0.7687251605013757,0.7690308774075206,0.7693365943136655,0.7731580556404769,0.7734637725466218,0.7740752063589117,0.7743809232650566,0.7757566493427086,0.7766738000611434,0.7768266585142158,0.7771323754203607,0.7785081014980129,0.7788138184041578,0.7803424029348823,0.7808009782940997,0.781259553653317,0.7815652705594619,0.7821767043717518,0.7824824212778967,0.7833995719963314,0.7837052889024763,0.7844695811678386,0.7850810149801284,0.7852338734332008,0.7855395903393457,0.786609599510853,0.7869153164169979,0.7876796086823601,0.78829104249465,0.7885967594007949,0.7889024763069398,0.7908896361968817,0.791348211556099,0.7915010700091715,0.7921125038214614,0.7934882298991134,0.7939468052583308,0.7944053806175482,0.7947110975236931,0.7948639559767655,0.7953225313359829,0.796698257413635,0.7970039743197799,0.7971568327728523,0.7974625496789972,0.7980739834912871,0.798379700397432,0.7994497095689391,0.799755426475084,0.8002140018343015,0.8005197187404464,0.8008254356465913,0.8011311525527361,0.8022011617242434,0.8025068786303883,0.803424029348823,0.8038826047080404,0.8063283399571997,0.8066340568633446,0.8069397737694894,0.8072454906756343,0.808468358300214,0.8087740752063589,0.8103026597370835,0.8106083766432284,0.8107612350963008,0.8110669520024457,0.8129012534393152,0.8133598287985325,0.813512687251605,0.81381840415775,0.8148884133292571,0.8153469886884744,0.8158055640476919,0.8162641394069092,0.8164169978599817,0.8167227147661266,0.8173341485784164,0.8176398654845612,0.8180984408437787,0.818557016202996,0.8194741669214307,0.8206970345460104,0.8210027514521553,0.8214613268113726,0.8217670437175176,0.8223784775298074,0.8229899113420972,0.8245184958728218,0.8251299296851116,0.8263527973096912,0.8266585142158361,0.8283399571996332,0.828645674105778,0.8294099663711403,0.8297156832772853,0.8307856924487924,0.8310914093549373,0.8313971262610822,0.8317028431672272,0.832314276979517,0.8326199938856619,0.8338428615102416,0.8344542953225313,0.8346071537756038,0.8349128706817487,0.8365943136655457,0.837052889024763,0.8375114643839804,0.8379700397431978,0.8417915010700092,0.8422500764292266,0.844084377866096,0.8445429532253134,0.8446958116783858,0.8451543870376031,0.845460103943748,0.845765820849893,0.8468358300214002,0.8472944053806175,0.8476001222867624,0.8498929990828493,0.8503515744420667,0.8505044328951391,0.8509630082543564,0.8512687251605013,0.8538673188627331,0.8547844695811678,0.8555487618465301,0.8558544787526751,0.8560073372057475,0.8563130541118924,0.8569244879241822,0.8573830632833995,0.8583002140018343,0.8587587893610517,0.8589116478141241,0.8595230816264139,0.8622745337817181,0.862580250687863,0.8628859675940079,0.8631916845001528,0.8636502598593703,0.8642616936716601,0.8651788443900947,0.8657902782023846,0.8674717211861815,0.8677774380923265,0.870987465606848,0.8712931825129929,0.8723631916845002,0.87297462549679,0.8732803424029348,0.8737389177621523,0.8751146438398043,0.8754203607459492,0.8760317945582391,0.876337511464384,0.8771018037297462,0.8774075206358911,0.8787832467135432,0.8790889636196881,0.8798532558850505,0.8801589727911954,0.8803118312442678,0.8806175481504127,0.8812289819627025,0.8815346988688475,0.8835218587587894,0.8838275756649343,0.8839804341180068,0.8842861510241516,0.8867318862733109,0.8870376031794558,0.8899419137878325,0.8902476306939774,0.8905533476001223,0.8908590645062672,0.8910119229593396,0.8913176398654845,0.8920819321308469,0.8923876490369917,0.8925405074900642,0.8929990828492815,0.8940690920207888,0.8949862427392234,0.900183430143687,0.9007948639559767,0.9012534393151941,0.9015591562213391,0.901864873127484,0.9021705900336289,0.9036991745643534,0.9043106083766432,0.904922042188933,0.9055334760012229,0.9067563436258025,0.9070620605319474,0.9073677774380923,0.9076734943442373,0.9101192295933965,0.9104249464995414,0.9105778049526139,0.9108835218587588,0.9114949556710487,0.9118006725771935,0.9127178232956282,0.9131763986548456,0.913329257107918,0.913634974014063,0.9140935493732804,0.9143992662794252,0.9147049831855701,0.9157749923570774,0.9162335677162947,0.9165392846224396,0.9168450015285845,0.916997859981657,0.9174564353408744,0.9182207276062366,0.918679302965454,0.9195964536838888,0.9200550290431061,0.9215836135738307,0.922042188933048,0.9221950473861205,0.9225007642922654,0.9238764903699175,0.9241822072760624,0.9243350657291348,0.9246407826352797,0.927392234790584,0.9276979516967289,0.9284622439620911,0.9290736777743809,0.9292265362274533,0.9295322531335983,0.9301436869458881,0.9306022623051055,0.9335065729134822,0.933812289819627,0.9367166004280036,0.9373280342402935,0.9376337511464384,0.9377866095995109,0.9380923265056558,0.9390094772240904,0.9393151941302355,0.9397737694894528,0.9400794863955977,0.9402323448486701,0.940538061754815,0.9417609293793947,0.9420666462855396,0.9432895139101193,0.9437480892693366,0.9451238153469886,0.9454295322531336,0.9464995414246408,0.9469581167838581,0.9507795781106695,0.9510852950168144,0.9550596147966982,0.9553653317028432,0.955976765515133,0.9562824824212779,0.9564353408743503,0.9567410577804952,0.9587282176704371,0.9591867930296546,0.9601039437480893,0.9605625191073066,0.9607153775603791,0.961021094466524,0.9611739529195965,0.9614796698257414,0.9633139712626109,0.9636196881687558,0.9649954142464078,0.9656068480586977,0.9659125649648426,0.9665239987771324,0.9675940079486396,0.9678997248547845,0.971415469275451,0.9720269030877408,0.9724854784469581,0.972791195353103,0.9734026291653929,0.9737083460715378,0.9750840721491898,0.9753897890553348,0.977835524304494,0.978141241210639,0.9787526750229287,0.9790583919290736,0.9792112503821462,0.9795169672882911,0.9805869764597982,0.9810455518190155,0.9811984102720881,0.981504127178233,0.9839498624273922,0.9842555793335371,0.9870070314888413,0.9873127483949863,0.988229899113421,0.9885356160195659,0.9909813512687251,0.9914399266279426,0.9931213696117396,0.9934270865178845,0.9961785386731886,0.9964842555793335,1.0],\"y\":[0.0,0.0,0.0,0.07317073170731707,0.07317073170731707,0.17073170731707318,0.17073170731707318,0.17073170731707318,0.17073170731707318,0.1951219512195122,0.1951219512195122,0.24390243902439024,0.24390243902439024,0.24390243902439024,0.2682926829268293,0.2682926829268293,0.2682926829268293,0.2682926829268293,0.2682926829268293,0.2926829268292683,0.2926829268292683,0.2926829268292683,0.2926829268292683,0.3170731707317073,0.3170731707317073,0.3170731707317073,0.3170731707317073,0.3170731707317073,0.3170731707317073,0.34146341463414637,0.34146341463414637,0.34146341463414637,0.34146341463414637,0.36585365853658536,0.36585365853658536,0.36585365853658536,0.3902439024390244,0.3902439024390244,0.3902439024390244,0.3902439024390244,0.4146341463414634,0.4146341463414634,0.4146341463414634,0.4146341463414634,0.4146341463414634,0.4146341463414634,0.4634146341463415,0.4634146341463415,0.4878048780487805,0.4878048780487805,0.4878048780487805,0.4878048780487805,0.4878048780487805,0.4878048780487805,0.4878048780487805,0.4878048780487805,0.5121951219512195,0.5121951219512195,0.5121951219512195,0.5121951219512195,0.5121951219512195,0.5121951219512195,0.5121951219512195,0.5121951219512195,0.5121951219512195,0.5365853658536586,0.5365853658536586,0.5365853658536586,0.5365853658536586,0.5609756097560976,0.5609756097560976,0.5609756097560976,0.5609756097560976,0.6097560975609756,0.6097560975609756,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6585365853658537,0.6585365853658537,0.6585365853658537,0.6585365853658537,0.6585365853658537,0.6585365853658537,0.6585365853658537,0.7073170731707317,0.7073170731707317,0.7073170731707317,0.7073170731707317,0.7073170731707317,0.7073170731707317,0.7073170731707317,0.7317073170731707,0.7317073170731707,0.7317073170731707,0.7317073170731707,0.7317073170731707,0.7317073170731707,0.7317073170731707,0.7317073170731707,0.7317073170731707,0.7317073170731707,0.7317073170731707,0.7317073170731707,0.7317073170731707,0.7560975609756098,0.7560975609756098,0.7560975609756098,0.7560975609756098,0.7560975609756098,0.7560975609756098,0.7560975609756098,0.7560975609756098,0.7560975609756098,0.7560975609756098,0.7560975609756098,0.7560975609756098,0.7560975609756098,0.7560975609756098,0.7804878048780488,0.7804878048780488,0.7804878048780488,0.7804878048780488,0.7804878048780488,0.7804878048780488,0.7804878048780488,0.7804878048780488,0.7804878048780488,0.7804878048780488,0.7804878048780488,0.7804878048780488,0.7804878048780488,0.7804878048780488,0.7804878048780488,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8536585365853658,0.8536585365853658,0.8536585365853658,0.8536585365853658,0.8780487804878049,0.8780487804878049,0.8780487804878049,0.8780487804878049,0.8780487804878049,0.8780487804878049,0.8780487804878049,0.8780487804878049,0.8780487804878049,0.8780487804878049,0.8780487804878049,0.8780487804878049,0.8780487804878049,0.8780487804878049,0.8780487804878049,0.8780487804878049,0.8780487804878049,0.8780487804878049,0.8780487804878049,0.8780487804878049,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.926829268292683,0.926829268292683,0.926829268292683,0.926829268292683,0.926829268292683,0.926829268292683,0.926829268292683,0.926829268292683,0.9512195121951219,0.9512195121951219,0.9512195121951219,0.9512195121951219,0.9512195121951219,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"type\":\"scatter\"},{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(255, 255, 255, 0)\",\"width\":0},\"name\":\"(95% CI 0.9027-0.9963)\",\"showlegend\":true,\"x\":[0.0,0.0001528584530724549,0.0004585753592173647,0.0004585753592173647,0.0007642922653622745,0.0007642922653622745,0.0010700091715071843,0.0013757260776520942,0.0019871598899419136,0.0019871598899419136,0.0021400183430143687,0.0021400183430143687,0.0027514521553041885,0.003362885967594008,0.003362885967594008,0.0038214613268113726,0.005044328951391012,0.005350045857535922,0.006267196575970651,0.006267196575970651,0.0064200550290431065,0.006725771935188016,0.007031488841332926,0.007031488841332926,0.0077957811066952,0.00810149801284011,0.009171507184347295,0.009782940996637114,0.009935799449709569,0.009935799449709569,0.010547233261999389,0.010852950168144299,0.011311525527361662,0.011311525527361662,0.011922959339651483,0.012075817792723938,0.012075817792723938,0.012534393151941303,0.012992968511158666,0.013145826964231121,0.013145826964231121,0.013298685417303576,0.013604402323448487,0.014062977682665852,0.01467441149495567,0.014827269948028125,0.014827269948028125,0.01498012840110058,0.01498012840110058,0.017273005197187403,0.017578722103332313,0.01803729746254968,0.0186487312748395,0.019565881993274227,0.019871598899419137,0.02063589116478141,0.02063589116478141,0.02094160807092632,0.021400183430143688,0.021705900336288598,0.02216447569550596,0.02247019260165087,0.02461021094466524,0.025068786303882606,0.02522164475695506,0.02522164475695506,0.02583307856924488,0.02613879547538979,0.026291653928462243,0.026291653928462243,0.0264445123815347,0.02675022928767961,0.02736166309996943,0.02736166309996943,0.027514521553041883,0.027514521553041883,0.028125955365331703,0.028737389177621524,0.029043106083766434,0.029195964536838887,0.029501681442983797,0.0311831244267808,0.03148884133292571,0.03179455823907062,0.03210027514521553,0.03271170895750535,0.03317028431672271,0.033476001222867625,0.03378171812901253,0.03546316111280954,0.035921736472026906,0.03622745337817181,0.03653317028431672,0.037908896361968814,0.03836747172118618,0.03943748089269337,0.039743197798838274,0.040354631611128094,0.04081320697034546,0.04127178232956282,0.04142464078263528,0.0420360745949251,0.042188933047997555,0.04264750840721492,0.043258942219504735,0.043258942219504735,0.04432895139101192,0.044634668297156836,0.045093243656374196,0.04631611128095384,0.04662182818709874,0.0481504127178233,0.0481504127178233,0.04830327117089575,0.04891470498318557,0.04998471415469275,0.05044328951391012,0.05181901559156221,0.052124732497707126,0.052124732497707126,0.05227759095077958,0.052583307856924486,0.05350045857535922,0.053806175481504126,0.05426475084072149,0.0545704677468664,0.05472332619993886,0.055029043106083766,0.05518190155915622,0.05548761846530113,0.05594619382451849,0.056099052277590954,0.056099052277590954,0.059003362885967595,0.0593090797921125,0.05976765515132987,0.060226230510547235,0.06114338122898196,0.06175481504127178,0.061907673494344236,0.06221339040048915,0.06328339957199633,0.06358911647814124,0.06481198410272088,0.0651177010088658,0.0654234179150107,0.0654234179150107,0.06649342708651788,0.06679914399266279,0.06741057780495262,0.06771629471109752,0.06786915316416998,0.06817487007031489,0.06832772852338734,0.06863344542953226,0.06924487924182207,0.06955059614796698,0.0698563130541119,0.07031488841332925,0.07062060531947417,0.07184347294405381,0.07184347294405381,0.07291348211556099,0.0735249159278508,0.07428920819321308,0.074594925099358,0.07902782023845918,0.07963925405074901,0.07979211250382146,0.08009782940996638,0.08055640476918374,0.08086212167532865,0.08132069703454602,0.08177927239376337,0.08208498929990829,0.0826964231121981,0.08590645062671966,0.08636502598593702,0.0871293182512993,0.0874350351574442,0.08758789361051666,0.08819932742280648,0.08850504432895138,0.08942219504738612,0.08972791195353103,0.09003362885967595,0.09033934576582085,0.09064506267196576,0.0921736472026903,0.09278508101498013,0.09370223173341485,0.09416080709263222,0.09446652399877713,0.0949250993579945,0.0952308162641394,0.09553653317028432,0.09568939162335677,0.0966065423417915,0.09737083460715378,0.09767655151329868,0.09859370223173342,0.09935799449709569,0.10180372974625497,0.10379088963619688,0.10409660654234179,0.10470804035463162,0.10516661571384897,0.10531947416692143,0.10593090797921124,0.1060837664322837,0.10837664322837053,0.10883521858758789,0.1108223784775298,0.11112809538367471,0.11128095383674717,0.11158667074289208,0.11173952919596454,0.11204524610210945,0.11235096300825435,0.11265667991439926,0.11433812289819627,0.11464383980434117,0.11510241516355854,0.115255273616631,0.11556099052277591,0.11617242433506574,0.11663099969428309,0.11708957505350046,0.11754815041271782,0.1183124426780801,0.118618159584225,0.11907673494344237,0.11938245184958728,0.1199938856618771,0.1199938856618771,0.12029960256802201,0.12060531947416692,0.12091103638031184,0.12259247936410883,0.12350963008254356,0.12412106389483338,0.1244267808009783,0.12519107306634056,0.12564964842555792,0.1261082237847753,0.12702537450321003,0.12733109140935495,0.12977682665851423,0.1302354020177316,0.1305411189238765,0.13099969428309385,0.13130541118923877,0.13145826964231122,0.1319168450015286,0.13206970345460103,0.13206970345460103,0.13237542036074595,0.13268113726689085,0.13298685417303577,0.13298685417303577,0.13313971262610821,0.13344542953225313,0.1339040048914705,0.13512687251605013,0.1352797309691226,0.1355854478752675,0.13573830632833997,0.13665545704677468,0.1369611739529196,0.13787832467135433,0.13955976765515132,0.14108835218587587,0.14185264445123816,0.14215836135738305,0.14231121981045552,0.14292265362274534,0.1433812289819627,0.14368694588810763,0.14414552124732496,0.14414552124732496,0.14429837970039744,0.14460409660654233,0.1450626719657597,0.14536838887190462,0.14552124732497707,0.14582696423112199,0.14659125649648425,0.1470498318557016,0.14796698257413635,0.14857841638642616,0.14873127483949863,0.15071843472944055,0.15117701008865791,0.15163558544787525,0.15194130235402017,0.1522470192601651,0.15239987771323754,0.15270559461938246,0.15362274533781717,0.1539284622439621,0.15438703760317946,0.15499847141546927,0.1553041883216142,0.15576276368083156,0.15606848058697645,0.1566799143992663,0.157597065117701,0.15790278202384592,0.15881993274228065,0.1595842250076429,0.16019565881993275,0.16050137572607764,0.160959951085295,0.16157138489758482,0.16187710180372974,0.1623356771629471,0.16248853561601956,0.16355854478752674,0.1640171201467441,0.16432283705288903,0.16493427086517884,0.16523998777132376,0.16661571384897586,0.16799143992662793,0.1698257413634974,0.17028431672271477,0.17074289208193213,0.17211861815958424,0.17334148578416386,0.17410577804952615,0.17441149495567104,0.1748700703148884,0.17502292876796086,0.1756343625802507,0.17670437175175788,0.17808009782940998,0.17823295628248242,0.17853867318862734,0.1809844084377866,0.18281870987465607,0.183124426780801,0.18343014368694588,0.18480586976459798,0.1851115866707429,0.1854173035768878,0.1857230204830327,0.18587587893610516,0.18618159584225008,0.18648731274839497,0.1867930296545399,0.18709874656068481,0.18755732191990218,0.18786303882604707,0.18923876490369917,0.1895444818098441,0.19000305716906146,0.19092020788749617,0.1918373586059309,0.19214307551207582,0.19229593396514827,0.193213084683583,0.19336594313665545,0.19367166004280037,0.19672882910424946,0.19703454601039438,0.1976459798226842,0.1979516967288291,0.19841027208804646,0.1996331397126261,0.20024457352491593,0.2010088657902782,0.2013145826964231,0.20238459186793029,0.20238459186793029,0.20284316722714765,0.20314888413329257,0.20421889330479975,0.20452461021094467,0.20483032711708957,0.20528890247630693,0.20590033628859675,0.20590033628859675,0.20620605319474167,0.2101803729746255,0.21048608988077042,0.21063894833384286,0.21063894833384286,0.21125038214613268,0.21170895750535004,0.2118618159584225,0.2121675328645674,0.2129318251299297,0.2132375420360746,0.21339040048914704,0.21369611739529196,0.21400183430143688,0.21430755120758177,0.21553041883216142,0.21583613573830632,0.2159889941913788,0.21629471109752368,0.21644756955059616,0.21690614490981353,0.21721186181595842,0.22011617242433507,0.22042188933048,0.22439620911036381,0.2247019260165087,0.22485478446958118,0.22516050137572607,0.22531335982879852,0.22561907673494344,0.22623051054723325,0.22653622745337818,0.22760623662488536,0.22791195353103028,0.22821767043717517,0.2285233873433201,0.2291348211556099,0.2298991134209722,0.23020483032711708,0.2308162641394069,0.23127483949862426,0.232191990217059,0.23265056557627636,0.2328034240293488,0.23310914093549373,0.23402629165392846,0.23448486701314583,0.2349434423723632,0.235554876184653,0.23586059309079793,0.23616630999694282,0.2363191684500153,0.2366248853561602,0.2369306022623051,0.23723631916845,0.23754203607459493,0.23784775298073985,0.23891776215224703,0.2393763375114644,0.24182207276062367,0.24212778966676857,0.24319779883827575,0.24365637419749311,0.2438092326505656,0.24411494955671048,0.2444206664628554,0.2447263833690003,0.24564353408743503,0.24594925099357995,0.24640782635279732,0.24686640171201468,0.24701926016508713,0.2474778355243045,0.24793641088352186,0.24839498624273923,0.2494649954142464,0.24977071232039133,0.2503821461326811,0.25068786303882606,0.2508407214918985,0.2511464383980434,0.2516050137572608,0.2519107306634057,0.2528278813818404,0.25328645674105776,0.2535921736472027,0.25405074900642005,0.25481504127178234,0.25512075817792723,0.2552736166309997,0.2555793335371446,0.2557321919902171,0.2561907673494344,0.25741363497401404,0.25787221033323143,0.2580250687863039,0.2586365025985937,0.25955365331702845,0.25985937022317335,0.2603179455823907,0.26062366248853563,0.2609293793946805,0.2619993885661877,0.2623051054723326,0.2624579639254051,0.26276368083155,0.2638336900030572,0.26413940690920207,0.2642922653622745,0.2642922653622745,0.26490369917456436,0.26520941608070925,0.2653622745337817,0.26566799143992664,0.2664322837052889,0.2667380006114338,0.26719657597065116,0.2675022928767961,0.26964231121981047,0.26994802812595536,0.2705594619382452,0.2708651788443901,0.271170895750535,0.27147661265667994,0.27269948028125957,0.27376948945276675,0.27407520635891164,0.27453378171812903,0.2766738000611434,0.2769795169672883,0.2774380923265057,0.2777438092326506,0.277896667685723,0.2782023845918679,0.27835524304494036,0.2786609599510853,0.2794252522164476,0.2797309691225925,0.2817181290125344,0.2823295628248242,0.2827881381840416,0.2833995719963314,0.28492815652705594,0.2855395903393458,0.2858453072454907,0.2864567410577805,0.2867624579639254,0.2870681748700703,0.28767960868236014,0.28798532558850504,0.28844390094772243,0.28966676857230206,0.29241822072760626,0.29272393763375115,0.2928767960868236,0.2931825129929685,0.2945582390706206,0.29501681442983796,0.29608682360134514,0.29654539896056253,0.3006725771935188,0.3009782940996637,0.3020483032711709,0.30235402017731583,0.3025068786303883,0.30311831244267806,0.3054111892387649,0.3057169061449098,0.30663405686334455,0.30724549067563434,0.3087740752063589,0.30923265056557625,0.3106083766432284,0.31091409354937327,0.3145826964231122,0.3148884133292571,0.315194130235402,0.31549984714154694,0.31626413940690923,0.3165698563130541,0.31809844084377864,0.31855701620299604,0.31886273310914093,0.3191684500152858,0.32023845918679306,0.32054417609293795,0.3210027514521553,0.32161418526444513,0.32222561907673497,0.32253133598287986,0.32696423112198103,0.327269948028126,0.3287985325588505,0.3291042494649954,0.3295628248242128,0.3298685417303577,0.33521858758789363,0.3355243044940385,0.33644145521247326,0.33674717211861815,0.33751146438398044,0.33781718129012533,0.33827575664934273,0.3385814735554876,0.33949862427392236,0.34011005808621214,0.340721491898502,0.3410272088046469,0.3413329257107918,0.3416386426169367,0.34255579333537145,0.34286151024151634,0.3430143686945888,0.34332008560073374,0.3434729440538062,0.3437786609599511,0.34423723631916847,0.34484867013145826,0.34591867930296544,0.34637725466218283,0.3466829715683277,0.3501987159889942,0.3505044328951391,0.3515744420666463,0.3518801589727912,0.352491592785081,0.35310302659737086,0.3538673188627331,0.35417303576887804,0.35447875267502293,0.3547844695811678,0.3549373280342403,0.3552430449403852,0.3569244879241822,0.3573830632833996,0.35799449709568937,0.3583002140018343,0.360898807704066,0.3616630999694283,0.36181595842250075,0.36227453378171814,0.3624273922347906,0.3627331091409355,0.36487312748394984,0.3651788443900948,0.36563741974931213,0.365943136655457,0.366248853561602,0.36655457046774687,0.3671660042800367,0.3697645979822684,0.37007031488841335,0.3702231733414858,0.3705288902476307,0.371293182512993,0.3715988994191379,0.37190461632528277,0.3725160501375726,0.37297462549678995,0.3732803424029349,0.3738917762152247,0.37419749312136963,0.37511464383980436,0.37542036074594926,0.3766432283705289,0.3769489452766738,0.3771018037297463,0.37740752063589117,0.37847752980739835,0.37878324671354324,0.3793946805258331,0.379700397431978,0.38153469886884744,0.38184041577499234,0.38199327422806484,0.38229899113420973,0.3836747172118618,0.38398043411800675,0.3852033017425864,0.3856618771018037,0.38581473555487616,0.3861204524610211,0.38657902782023845,0.38688474472638335,0.3891776215224702,0.3894833384286151,0.39131763986548457,0.39162335677162946,0.39208193213084686,0.39238764903699175,0.39269336594313664,0.3933047997554265,0.3936105166615714,0.39391623356771627,0.39544481809844084,0.39575053500458574,0.3959033934576582,0.39620911036380313,0.3980434118006726,0.3983491287068175,0.4018648731274839,0.40247630693977376,0.40278202384591866,0.4033934576582085,0.40385203301742584,0.40400489147049834,0.40431060837664323,0.40782635279730967,0.4084377866095995,0.41057780495261387,0.4108835218587588,0.41103638031183126,0.41134209721797615,0.41241210638948334,0.41271782329562823,0.41287068174870073,0.4131763986548456,0.41363497401406296,0.4139406909202079,0.41439926627942525,0.41470498318557014,0.41608070926322227,0.4165392846224396,0.41822072760623663,0.4185264445123815,0.41883216141852647,0.4192907367777438,0.4195964536838887,0.4200550290431061,0.420360745949251,0.42097217976154083,0.42143075512075817,0.4226536227453378,0.42295933965148275,0.4234179150107001,0.4240293488229899,0.42479364108835216,0.4250993579944971,0.4266279425252216,0.4269336594313666,0.4289208193213085,0.4295322531335983,0.43167227147661263,0.4319779883827576,0.4365637419749312,0.43686945888107614,0.4370223173341486,0.4376337511464384,0.43870376031794556,0.43916233567716295,0.43992662794252524,0.44023234484867013,0.440538061754815,0.44084377866096,0.44114949556710487,0.44145521247324976,0.4420666462855396,0.44252522164475694,0.44298379700397433,0.4432895139101192,0.44497095689391625,0.44527667380006114,0.44558239070620603,0.445888107612351,0.4460409660654234,0.4463466829715683,0.44695811678385816,0.4474166921430755,0.4481809844084378,0.4484867013145827,0.4486395597676551,0.4489452766738001,0.45032100275145215,0.45062671965759704,0.45077957811066954,0.45139101192295933,0.45337817181290124,0.45368388871904614,0.45383674717211864,0.45414246407826353,0.4567410577804953,0.4570467746866402,0.4585753592173647,0.45888107612350965,0.4599510852950168,0.4602568022011617,0.4605625191073066,0.461021094466524,0.4616325282788138,0.46193824518495874,0.4630082543564659,0.46346682971568326,0.4637725466218282,0.4640782635279731,0.46423112198104555,0.4648425557933354,0.4657597065117701,0.466065423417915,0.46851115866707427,0.4688168755732192,0.47003974319779884,0.47034546010394374,0.4709568939162336,0.47126261082237847,0.47202690308774076,0.47233261999388565,0.4729440538061755,0.4732497707123204,0.4764597982268419,0.4767655151329869,0.47737694894527666,0.4776826658514216,0.4779883827575665,0.4782940996637114,0.4790583919290737,0.47936410883521857,0.479516967288291,0.47982268419443597,0.48012840110058086,0.48043411800672575,0.48058697645979825,0.48089269336594315,0.4810455518190156,0.4813512687251605,0.48287985325588506,0.4833384286151024,0.4853255885050443,0.48563130541118926,0.4874656068480587,0.4877713237542036,0.4880770406603485,0.4883827575664934,0.48975848364414554,0.4902170590033629,0.49281565270559463,0.4931213696117395,0.4934270865178844,0.49373280342402937,0.4941913787832467,0.4944970956893916,0.49633139712626106,0.4969428309385509,0.49785998165698564,0.49816569856313053,0.5004585753592173,0.5007642922653622,0.5012228676245797,0.5015285845307246,0.5024457352491593,0.5027514521553041,0.5032100275145216,0.5035157444206665,0.505350045857536,0.5056557627636808,0.5058086212167533,0.5061143381228982,0.5077957811066952,0.5082543564659125,0.5094772240904922,0.510088657902782,0.5108529501681442,0.5113115255273617,0.5116172424335066,0.5119229593396515,0.5125343931519413,0.5128401100580862,0.5129929685111587,0.5132986854173036,0.5140629776826658,0.5143686945888107,0.5162029960256802,0.5165087129318251,0.517120146744115,0.5175787221033323,0.5178844390094772,0.5180372974625497,0.5183430143686946,0.5188015897279119,0.5192601650871294,0.5194130235402018,0.5197187404463467,0.5198715988994191,0.5204830327117089,0.5207887496178538,0.5210944665239988,0.5215530418832162,0.521858758789361,0.5233873433200856,0.5236930602262305,0.5241516355854479,0.5247630693977376,0.5249159278508102,0.5252216447569551,0.5293488229899114,0.5298073983491287,0.5331702843167228,0.5336288596759401,0.5343931519413023,0.5346988688474472,0.5362274533781718,0.5368388871904616,0.5371446040966066,0.538978905533476,0.5394374808926934,0.5397431977988383,0.5403546316111281,0.540966065423418,0.5412717823295629,0.5420360745949251,0.54234179150107,0.5450932436563742,0.5453989605625191,0.547386120452461,0.5476918373586059,0.5489147049831856,0.5492204218893305,0.5515132986854173,0.5519718740446347,0.5522775909507796,0.5525833078569244,0.5528890247630694,0.5535004585753592,0.5538061754815041,0.5542647508407215,0.5545704677468664,0.5559461938245185,0.5564047691837358,0.5565576276368083,0.5571690614490982,0.5573219199021706,0.5576276368083155,0.557780495261388,0.5580862121675328,0.5583919290736777,0.5588505044328952,0.561143381228982,0.5614490981351269,0.5619076734943442,0.562519107306634,0.5638948333842861,0.564200550290431,0.5649648425557934,0.5652705594619383,0.5654234179150107,0.5657291348211556,0.5686334454295322,0.5689391623356772,0.5690920207887497,0.569550596147967,0.5698563130541119,0.5700091715071843,0.5703148884133292,0.5706206053194741,0.5709263222256191,0.5723020483032711,0.5727606236624886,0.5736777743809233,0.5739834912870682,0.574594925099358,0.574900642005503,0.5753592173647203,0.5756649342708652,0.5765820849892999,0.5768878018954449,0.5774992357077346,0.5785692448792418,0.5788749617853868,0.5791806786915317,0.5794863955976766,0.5807092632222562,0.5810149801284011,0.5811678385814736,0.5817792723937634,0.5833078569244879,0.5836135738306328,0.5845307245490675,0.5848364414552125,0.5851421583613574,0.5854478752675023,0.586365025985937,0.5868236013451544,0.5871293182512993,0.5888107612350963,0.5891164781412412,0.5892693365943137,0.5895750535004586,0.5920207887496178,0.5923265056557627,0.5926322225619077,0.5929379394680526,0.5932436563741975,0.5935493732803424,0.5943136655457046,0.5946193824518495,0.5947722409049221,0.595077957811067,0.5975236930602262,0.5978294099663711,0.5982879853255885,0.5988994191378784,0.5995108529501681,0.6001222867624579,0.6004280036686028,0.6036380311831244,0.6042494649954142,0.605166615713849,0.6054723326199939,0.6056251910730663,0.6059309079792112,0.6063894833384286,0.6071537756037909,0.6092937939468053,0.61021094466524,0.6108223784775298,0.6111280953836747,0.6129623968205442,0.613573830632834,0.6138795475389789,0.6141852644451238,0.6144909813512687,0.6147966982574137,0.6149495567104861,0.6154081320697035,0.6157138489758484,0.6160195658819932,0.6163252827881381,0.6170895750535005,0.6177010088657903,0.6180067257719352,0.6181595842250076,0.6184653011311525,0.6186181595842251,0.6192295933965148,0.620299602568022,0.620605319474167,0.6209110363803119,0.6215224701926017,0.6224396209110363,0.6228981962702538,0.6230510547233262,0.6235096300825436,0.623662488535616,0.6239682054417609,0.6247324977071232,0.6251910730663406,0.6258025068786304,0.6261082237847753,0.6265667991439927,0.6268725160501376,0.629012534393152,0.6296239682054418,0.6299296851115866,0.6302354020177315,0.6308468358300214,0.6311525527361663,0.6313054111892388,0.6316111280953837,0.6325282788138185,0.6328339957199633,0.6340568633445429,0.6343625802506878,0.6355854478752675,0.6360440232344848,0.637419749312137,0.6380311831244267,0.6387954753897891,0.6392540507490064,0.6395597676551513,0.6397126261082238,0.6400183430143687,0.6403240599205136,0.6406297768266586,0.640782635279731,0.6410883521858759,0.6418526444512381,0.642158361357383,0.6423112198104555,0.6426169367166005,0.6430755120758178,0.6435340874350352,0.6436869458881076,0.6444512381534699,0.6447569550596148,0.6450626719657597,0.6455212473249771,0.645826964231122,0.6464383980434119,0.6467441149495567,0.647508407214919,0.6479669825741363,0.6482726994802812,0.6485784163864262,0.6487312748394987,0.6494955671048609,0.6501070009171507,0.6505655762763681,0.650871293182513,0.6513298685417304,0.6514827269948028,0.6517884439009477,0.6520941608070926,0.65255273616631,0.6531641699785998,0.6536227453378172,0.6556099052277591,0.655915622133904,0.6562213390400489,0.6565270559461939,0.6566799143992663,0.6571384897584837,0.6582084989299908,0.6585142158361358,0.6614185264445124,0.6617242433506573,0.6624885356160196,0.6627942525221645,0.6647814124121064,0.6650871293182513,0.6678385814735555,0.6681442983797004,0.6689085906450627,0.6692143075512076,0.6704371751757873,0.6707428920819322,0.6721186181595842,0.6724243350657292,0.6728829104249465,0.6731886273310914,0.6739529195964536,0.6742586365025985,0.6753286456741058,0.6756343625802507,0.676398654845613,0.6767043717517579,0.6768572302048304,0.6771629471109752,0.6780800978294099,0.6785386731886274,0.6796086823601345,0.6800672577193518,0.6802201161724243,0.6811372668908591,0.6872516050137573,0.6877101803729746,0.6906144909813513,0.6909202078874962,0.6913787832467135,0.6935188015897279,0.6938245184958728,0.6939773769489452,0.6942830938550902,0.6953531030265974,0.6956588199327423,0.6959645368388871,0.6964231121981046,0.6970345460103944,0.6973402629165393,0.6977988382757566,0.6984102720880465,0.6987159889941914,0.6991745643534087,0.6994802812595536,0.6996331397126261,0.7000917150718434,0.7013145826964231,0.7019260165087129,0.7042188933047998,0.7046774686640171,0.704983185570162,0.7055946193824518,0.7062060531947417,0.7071232039131764,0.7074289208193213,0.7078874961785386,0.7081932130846836,0.7092632222561908,0.7095689391623357,0.7097217976154081,0.7106389483338429,0.7107918067869153,0.7114032405992051,0.7115560990522776,0.7118618159584225,0.7121675328645675,0.7124732497707124,0.7130846835830021,0.713390400489147,0.7141546927545094,0.7144604096606543,0.7150718434729441,0.715377560379089,0.7158361357383063,0.7161418526444513,0.7166004280036686,0.7172118618159584,0.7173647202690309,0.7176704371751758,0.7188933047997554,0.7193518801589728,0.7195047386120452,0.7198104555181901,0.7199633139712626,0.7202690308774076,0.7205747477835525,0.7210333231427698,0.7213390400489147,0.7214918985019871,0.721797615408132,0.7219504738612045,0.7222561907673495,0.7227147661265668,0.7231733414857842,0.7251605013757261,0.7257719351880159,0.7269948028125955,0.7274533781718129,0.7295933965148272,0.7302048303271171,0.7306634056863345,0.7315805564047692,0.732191990217059,0.732497707123204,0.7328034240293488,0.7332619993885662,0.7335677162947111,0.7340262916539284,0.7343320085600734,0.7344848670131459,0.7350963008254356,0.7357077346377254,0.7360134515438703,0.7363191684500153,0.7366248853561602,0.7369306022623051,0.73723631916845,0.7384591867930297,0.7387649036991746,0.740599205136044,0.7409049220421889,0.7421277896667686,0.7424335065729135,0.742586365025986,0.7428920819321309,0.7431977988382757,0.7435035157444206,0.7438092326505655,0.7441149495567105,0.7445735249159279,0.7448792418220728,0.7454906756343626,0.7457963925405074,0.7461021094466525,0.7464078263527973,0.7465606848058698,0.7468664017120147,0.7482421277896668,0.7485478446958117,0.7496178538673188,0.7502292876796087,0.7520635891164782,0.7523693060226231,0.752675022928768,0.7529807398349129,0.7538978905533475,0.7542036074594926,0.755732191990217,0.7563436258025069,0.7577193518801589,0.7580250687863039,0.7586365025985937,0.7592479364108835,0.7615408132069703,0.7618465301131152,0.7638336900030571,0.7641394069092021,0.7652094160807092,0.7655151329868541,0.7667380006114338,0.7670437175175787,0.7673494344237236,0.767808009782941,0.7679608682360135,0.7682665851421584,0.7684194435952308,0.7687251605013757,0.7690308774075206,0.7693365943136655,0.7731580556404769,0.7734637725466218,0.7740752063589117,0.7743809232650566,0.7757566493427086,0.7766738000611434,0.7768266585142158,0.7771323754203607,0.7785081014980129,0.7788138184041578,0.7803424029348823,0.7808009782940997,0.781259553653317,0.7815652705594619,0.7821767043717518,0.7824824212778967,0.7833995719963314,0.7837052889024763,0.7844695811678386,0.7850810149801284,0.7852338734332008,0.7855395903393457,0.786609599510853,0.7869153164169979,0.7876796086823601,0.78829104249465,0.7885967594007949,0.7889024763069398,0.7908896361968817,0.791348211556099,0.7915010700091715,0.7921125038214614,0.7934882298991134,0.7939468052583308,0.7944053806175482,0.7947110975236931,0.7948639559767655,0.7953225313359829,0.796698257413635,0.7970039743197799,0.7971568327728523,0.7974625496789972,0.7980739834912871,0.798379700397432,0.7994497095689391,0.799755426475084,0.8002140018343015,0.8005197187404464,0.8008254356465913,0.8011311525527361,0.8022011617242434,0.8025068786303883,0.803424029348823,0.8038826047080404,0.8063283399571997,0.8066340568633446,0.8069397737694894,0.8072454906756343,0.808468358300214,0.8087740752063589,0.8103026597370835,0.8106083766432284,0.8107612350963008,0.8110669520024457,0.8129012534393152,0.8133598287985325,0.813512687251605,0.81381840415775,0.8148884133292571,0.8153469886884744,0.8158055640476919,0.8162641394069092,0.8164169978599817,0.8167227147661266,0.8173341485784164,0.8176398654845612,0.8180984408437787,0.818557016202996,0.8194741669214307,0.8206970345460104,0.8210027514521553,0.8214613268113726,0.8217670437175176,0.8223784775298074,0.8229899113420972,0.8245184958728218,0.8251299296851116,0.8263527973096912,0.8266585142158361,0.8283399571996332,0.828645674105778,0.8294099663711403,0.8297156832772853,0.8307856924487924,0.8310914093549373,0.8313971262610822,0.8317028431672272,0.832314276979517,0.8326199938856619,0.8338428615102416,0.8344542953225313,0.8346071537756038,0.8349128706817487,0.8365943136655457,0.837052889024763,0.8375114643839804,0.8379700397431978,0.8417915010700092,0.8422500764292266,0.844084377866096,0.8445429532253134,0.8446958116783858,0.8451543870376031,0.845460103943748,0.845765820849893,0.8468358300214002,0.8472944053806175,0.8476001222867624,0.8498929990828493,0.8503515744420667,0.8505044328951391,0.8509630082543564,0.8512687251605013,0.8538673188627331,0.8547844695811678,0.8555487618465301,0.8558544787526751,0.8560073372057475,0.8563130541118924,0.8569244879241822,0.8573830632833995,0.8583002140018343,0.8587587893610517,0.8589116478141241,0.8595230816264139,0.8622745337817181,0.862580250687863,0.8628859675940079,0.8631916845001528,0.8636502598593703,0.8642616936716601,0.8651788443900947,0.8657902782023846,0.8674717211861815,0.8677774380923265,0.870987465606848,0.8712931825129929,0.8723631916845002,0.87297462549679,0.8732803424029348,0.8737389177621523,0.8751146438398043,0.8754203607459492,0.8760317945582391,0.876337511464384,0.8771018037297462,0.8774075206358911,0.8787832467135432,0.8790889636196881,0.8798532558850505,0.8801589727911954,0.8803118312442678,0.8806175481504127,0.8812289819627025,0.8815346988688475,0.8835218587587894,0.8838275756649343,0.8839804341180068,0.8842861510241516,0.8867318862733109,0.8870376031794558,0.8899419137878325,0.8902476306939774,0.8905533476001223,0.8908590645062672,0.8910119229593396,0.8913176398654845,0.8920819321308469,0.8923876490369917,0.8925405074900642,0.8929990828492815,0.8940690920207888,0.8949862427392234,0.900183430143687,0.9007948639559767,0.9012534393151941,0.9015591562213391,0.901864873127484,0.9021705900336289,0.9036991745643534,0.9043106083766432,0.904922042188933,0.9055334760012229,0.9067563436258025,0.9070620605319474,0.9073677774380923,0.9076734943442373,0.9101192295933965,0.9104249464995414,0.9105778049526139,0.9108835218587588,0.9114949556710487,0.9118006725771935,0.9127178232956282,0.9131763986548456,0.913329257107918,0.913634974014063,0.9140935493732804,0.9143992662794252,0.9147049831855701,0.9157749923570774,0.9162335677162947,0.9165392846224396,0.9168450015285845,0.916997859981657,0.9174564353408744,0.9182207276062366,0.918679302965454,0.9195964536838888,0.9200550290431061,0.9215836135738307,0.922042188933048,0.9221950473861205,0.9225007642922654,0.9238764903699175,0.9241822072760624,0.9243350657291348,0.9246407826352797,0.927392234790584,0.9276979516967289,0.9284622439620911,0.9290736777743809,0.9292265362274533,0.9295322531335983,0.9301436869458881,0.9306022623051055,0.9335065729134822,0.933812289819627,0.9367166004280036,0.9373280342402935,0.9376337511464384,0.9377866095995109,0.9380923265056558,0.9390094772240904,0.9393151941302355,0.9397737694894528,0.9400794863955977,0.9402323448486701,0.940538061754815,0.9417609293793947,0.9420666462855396,0.9432895139101193,0.9437480892693366,0.9451238153469886,0.9454295322531336,0.9464995414246408,0.9469581167838581,0.9507795781106695,0.9510852950168144,0.9550596147966982,0.9553653317028432,0.955976765515133,0.9562824824212779,0.9564353408743503,0.9567410577804952,0.9587282176704371,0.9591867930296546,0.9601039437480893,0.9605625191073066,0.9607153775603791,0.961021094466524,0.9611739529195965,0.9614796698257414,0.9633139712626109,0.9636196881687558,0.9649954142464078,0.9656068480586977,0.9659125649648426,0.9665239987771324,0.9675940079486396,0.9678997248547845,0.971415469275451,0.9720269030877408,0.9724854784469581,0.972791195353103,0.9734026291653929,0.9737083460715378,0.9750840721491898,0.9753897890553348,0.977835524304494,0.978141241210639,0.9787526750229287,0.9790583919290736,0.9792112503821462,0.9795169672882911,0.9805869764597982,0.9810455518190155,0.9811984102720881,0.981504127178233,0.9839498624273922,0.9842555793335371,0.9870070314888413,0.9873127483949863,0.988229899113421,0.9885356160195659,0.9909813512687251,0.9914399266279426,0.9931213696117396,0.9934270865178845,0.9961785386731886,0.9964842555793335,1.0],\"y\":[0.0,0.0,0.0,0.07317073170731707,0.07317073170731707,0.17073170731707318,0.17073170731707318,0.17073170731707318,0.17073170731707318,0.1951219512195122,0.1951219512195122,0.24390243902439024,0.24390243902439024,0.24390243902439024,0.2682926829268293,0.2682926829268293,0.2682926829268293,0.2682926829268293,0.2682926829268293,0.2926829268292683,0.2926829268292683,0.2926829268292683,0.2926829268292683,0.3170731707317073,0.3170731707317073,0.3170731707317073,0.3170731707317073,0.3170731707317073,0.3170731707317073,0.34146341463414637,0.34146341463414637,0.34146341463414637,0.34146341463414637,0.36585365853658536,0.36585365853658536,0.36585365853658536,0.3902439024390244,0.3902439024390244,0.3902439024390244,0.3902439024390244,0.4146341463414634,0.4146341463414634,0.4146341463414634,0.4146341463414634,0.4146341463414634,0.4146341463414634,0.4634146341463415,0.4634146341463415,0.4878048780487805,0.4878048780487805,0.4878048780487805,0.4878048780487805,0.4878048780487805,0.4878048780487805,0.4878048780487805,0.4878048780487805,0.5121951219512195,0.5121951219512195,0.5121951219512195,0.5121951219512195,0.5121951219512195,0.5121951219512195,0.5121951219512195,0.5121951219512195,0.5121951219512195,0.5365853658536586,0.5365853658536586,0.5365853658536586,0.5365853658536586,0.5609756097560976,0.5609756097560976,0.5609756097560976,0.5609756097560976,0.6097560975609756,0.6097560975609756,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6341463414634146,0.6585365853658537,0.6585365853658537,0.6585365853658537,0.6585365853658537,0.6585365853658537,0.6585365853658537,0.6585365853658537,0.7073170731707317,0.7073170731707317,0.7073170731707317,0.7073170731707317,0.7073170731707317,0.7073170731707317,0.7073170731707317,0.7317073170731707,0.7317073170731707,0.7317073170731707,0.7317073170731707,0.7317073170731707,0.7317073170731707,0.7317073170731707,0.7317073170731707,0.7317073170731707,0.7317073170731707,0.7317073170731707,0.7317073170731707,0.7317073170731707,0.7560975609756098,0.7560975609756098,0.7560975609756098,0.7560975609756098,0.7560975609756098,0.7560975609756098,0.7560975609756098,0.7560975609756098,0.7560975609756098,0.7560975609756098,0.7560975609756098,0.7560975609756098,0.7560975609756098,0.7560975609756098,0.7804878048780488,0.7804878048780488,0.7804878048780488,0.7804878048780488,0.7804878048780488,0.7804878048780488,0.7804878048780488,0.7804878048780488,0.7804878048780488,0.7804878048780488,0.7804878048780488,0.7804878048780488,0.7804878048780488,0.7804878048780488,0.7804878048780488,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8048780487804879,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8292682926829268,0.8536585365853658,0.8536585365853658,0.8536585365853658,0.8536585365853658,0.8780487804878049,0.8780487804878049,0.8780487804878049,0.8780487804878049,0.8780487804878049,0.8780487804878049,0.8780487804878049,0.8780487804878049,0.8780487804878049,0.8780487804878049,0.8780487804878049,0.8780487804878049,0.8780487804878049,0.8780487804878049,0.8780487804878049,0.8780487804878049,0.8780487804878049,0.8780487804878049,0.8780487804878049,0.8780487804878049,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.9024390243902439,0.926829268292683,0.926829268292683,0.926829268292683,0.926829268292683,0.926829268292683,0.926829268292683,0.926829268292683,0.926829268292683,0.9512195121951219,0.9512195121951219,0.9512195121951219,0.9512195121951219,0.9512195121951219,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,0.975609756097561,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"title\":{\"x\":0.5},\"legend\":{\"yanchor\":\"bottom\",\"xanchor\":\"right\",\"x\":0.95,\"y\":0.01},\"xaxis\":{\"title\":{\"text\":\"1 - Specificity\"},\"range\":[0,1],\"gridcolor\":\"rgba(189, 195, 199, 0.5)\",\"constrain\":\"domain\",\"linecolor\":\"black\"},\"yaxis\":{\"title\":{\"text\":\"Recall\"},\"range\":[0,1],\"gridcolor\":\"rgba(189, 195, 199, 0.5)\",\"scaleanchor\":\"x\",\"scaleratio\":1,\"linecolor\":\"black\"},\"width\":600,\"height\":600},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('3532f4ac-4eff-45a5-b84d-20d24864133b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "prob=network.predict(X_test)\n",
        "plot_roc_curve(y_test, prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "e9903af2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "id": "e9903af2",
        "outputId": "2d0c08e6-faf8-44cc-c12a-c5ccc5e97285"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "105/105 [==============================] - 0s 4ms/step\n",
            "101/101 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"07e35f26-9733-47ef-882e-9a12f7c78218\" class=\"plotly-graph-div\" style=\"height:600px; width:600px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"07e35f26-9733-47ef-882e-9a12f7c78218\")) {                    Plotly.newPlot(                        \"07e35f26-9733-47ef-882e-9a12f7c78218\",                        [{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(250, 50, 50, 1.0)\",\"width\":5},\"name\":\"\\u003cb\\u003eMale\\u003c\\u002fb\\u003e\",\"showlegend\":true,\"x\":[0.0,0.0002992220227408737,0.0002992220227408737,0.0008976660682226212,0.0008976660682226212,0.0017953321364452424,0.0017953321364452424,0.0023937761819269898,0.003590664272890485,0.004488330341113106,0.005385996409335727,0.005984440454817474,0.007779772591262717,0.008378216636744464,0.009575104727707959,0.010173548773189706,0.011669658886894075,0.01286654697785757,0.01286654697785757,0.013464991023339317,0.014063435068821066,0.01436265709156194,0.014961101137043686,0.01526032315978456,0.016457211250748054,0.016457211250748054,0.018252543387193298,0.018850987432675045,0.02154398563734291,0.02154398563734291,0.022142429682824656,0.022740873728306403,0.02333931777378815,0.026929982046678635,0.02752842609216038,0.028126870137642132,0.02872531418312388,0.03201675643327349,0.032615200478755234,0.033512866546977854,0.03441053261520048,0.03500897666068223,0.035607420706163975,0.036505086774386596,0.03710353081986834,0.03919808497905446,0.039796529024536204,0.04039497307001795,0.0409934171154997,0.041891083183722325,0.0466786355475763,0.0466786355475763,0.04697785757031717,0.04757630161579892,0.05475763016157989,0.05535607420706164,0.056253740275284264,0.05685218432076601,0.057151406343506884,0.05774985038898863,0.05864751645721125,0.059245960502693,0.06044284859365649,0.06104129263913824,0.06253740275284261,0.06313584679832436,0.06373429084380611,0.0649311789347696,0.06552962298025135,0.0661280670257331,0.06642728904847396,0.06702573309395571,0.06822262118491922,0.06822262118491922,0.07001795332136446,0.0706163973668462,0.07570317175344106,0.0763016157989228,0.07719928186714542,0.07779772591262717,0.07899461400359066,0.07959305804907241,0.08228605625374028,0.08288450029922202,0.08348294434470377,0.08408138839018552,0.0843806104129264,0.08497905445840814,0.08677438659485338,0.08737283064033513,0.08797127468581688,0.08916816277678037,0.09036505086774387,0.09096349491322561,0.09365649311789348,0.09425493716337523,0.09485338120885697,0.09575104727707959,0.09605026929982047,0.09664871334530221,0.09694793536804308,0.09784560143626571,0.09874326750448834,0.09934171154997008,0.10113704368641532,0.10173548773189707,0.10293237582286056,0.10383004189108318,0.1047277079593058,0.10532615200478755,0.1059245960502693,0.10652304009575105,0.10712148414123279,0.11041292639138241,0.11190903650508677,0.11310592459605028,0.11400359066427289,0.11579892280071813,0.11609814482345901,0.12088569718731298,0.12178336325553561,0.12238180730101736,0.1229802513464991,0.1229802513464991,0.12327947336923997,0.12387791741472172,0.1241771394374626,0.12477558348294435,0.12567324955116696,0.12627169359664872,0.12716935966487133,0.1277678037103531,0.1298623578695392,0.13046080191502094,0.13076002393776182,0.13135846798324358,0.13165769000598443,0.13165769000598443,0.1319569120287253,0.13255535607420707,0.13464991023339318,0.13853979652902454,0.13973668461998803,0.14033512866546977,0.14093357271095153,0.14153201675643326,0.14183123877917414,0.14302812687013763,0.14332734889287851,0.14422501496110113,0.14542190305206462,0.14721723518850988,0.14871334530221425,0.14961101137043686,0.15020945541591862,0.15110712148414124,0.15170556552962297,0.1538001196888091,0.1558946738479952,0.15858767205266308,0.16247755834829444,0.16337522441651706,0.16576900059844404,0.1687612208258528,0.16935966487133453,0.17025733093955714,0.1708557749850389,0.17115499700777978,0.1717534410532615,0.17923399162178336,0.17983243566726512,0.18043087971274685,0.18162776780371034,0.18252543387193298,0.18312387791741472,0.1843207660083782,0.1843207660083782,0.18611609814482347,0.18701376421304608,0.18761220825852784,0.18761220825852784,0.19269898264512267,0.19269898264512267,0.19299820466786355,0.19389587073608616,0.19509275882704968,0.19569120287253142,0.1959904248952723,0.19658886894075403,0.19778575703171752,0.19838420107719928,0.20766008378216635,0.20825852782764812,0.21005385996409337,0.2106523040095751,0.2118491921005386,0.2127468581687612,0.2130460801915021,0.2139437462597247,0.21543985637342908,0.21663674446439257,0.21693596648713345,0.2175344105326152,0.2187312986235787,0.21962896469180132,0.2220227408737283,0.22292040694195092,0.2256134051466188,0.2265110712148414,0.2277079593058049,0.22830640335128666,0.2289048473967684,0.22950329144225015,0.23070017953321365,0.23159784560143626,0.23279473369239975,0.2333931777378815,0.23399162178336325,0.2348892878515859,0.23668461998803111,0.2378815080789946,0.23877917414721722,0.23937761819269898,0.2402752842609216,0.24087372830640336,0.2414721723518851,0.24207061639736685,0.24236983842010773,0.24296828246558946,0.24745661280670259,0.24805505685218432,0.2492519449431478,0.24985038898862957,0.2504488330341113,0.25254338719329744,0.2546379413524835,0.2552363853979653,0.25822860562537403,0.2588270496708558,0.260622381807301,0.2612208258527828,0.26181926989826454,0.26241771394374624,0.26361460203470977,0.2642130460801915,0.2645122681029324,0.26690604428485937,0.26929982046678635,0.2698982645122681,0.27019748653500897,0.27079593058049073,0.2731897067624177,0.27408737283064033,0.27857570317175345,0.2791741472172352,0.27947336923997607,0.28067025733093953,0.2836624775583483,0.2848593656493118,0.2863554757630162,0.2872531418312388,0.29204069419509276,0.2926391382405745,0.30131657690005986,0.30191502094554157,0.30430879712746856,0.3049072411729503,0.31119090365050867,0.3117893476959904,0.3123877917414722,0.3129862357869539,0.3132854578096948,0.31388390185517656,0.31448234590065827,0.3156792339916218,0.3165769000598444,0.31717534410532616,0.3177737881508079,0.31837223219628963,0.31867145421903054,0.31926989826451224,0.3201675643327349,0.3213644524236984,0.3234590065828845,0.32375822860562536,0.3243566726511071,0.3279473369239976,0.32854578096947934,0.32974266906044286,0.3303411131059246,0.3315380011968881,0.33213644524236985,0.3327348892878516,0.3333333333333333,0.3408138839018552,0.34201077199281865,0.3461998803111909,0.3467983243566726,0.34709754637941354,0.3476959904248953,0.34799521244763615,0.3491921005385996,0.35038898862956314,0.3509874326750449,0.3518850987432675,0.35248354278874927,0.3527827648114901,0.3533812088569719,0.3560742070616397,0.3566726511071215,0.35727109515260325,0.35786953919808495,0.3590664272890485,0.3599640933572711,0.360263315380012,0.3608617594254937,0.36146020347097546,0.3620586475164572,0.36475164572112506,0.3653500897666068,0.36624775583482944,0.3668461998803112,0.3677438659485338,0.36894075403949733,0.36953919808497904,0.3701376421304608,0.37043686415320165,0.3710353081986834,0.37642130460801915,0.37761819269898267,0.3782166367444644,0.3785158587672053,0.3794135248354279,0.38001196888090966,0.383901855176541,0.3845002992220227,0.38749251944943147,0.388689407540395,0.3892878515858767,0.38988629563135846,0.3904847396768402,0.391083183722322,0.3916816277678037,0.39228007181328545,0.39347695990424897,0.3943746259724716,0.3964691801316577,0.3970676241771394,0.3976660682226212,0.3994614003590664,0.4018551765409934,0.40245362058647516,0.40514661879114305,0.40574506283662476,0.40724117295032913,0.40843806104129265,0.4162178336325554,0.41741472172351884,0.41980849790544583,0.42100538599640935,0.42190305206463197,0.42519449431478157,0.42579293836026333,0.42669060442848594,0.42758827049670856,0.4302812687013764,0.43087971274685816,0.43117893476959906,0.43177737881508077,0.43447037701974867,0.4350688210652304,0.4386594853381209,0.43925792938360264,0.4404548174745661,0.44105326152004787,0.4413524835427888,0.44254937163375224,0.44434470377019747,0.4452423698384201,0.44584081388390184,0.4464392579293836,0.4473369239976062,0.447935368043088,0.4506283662477558,0.4512268102932376,0.4521244763614602,0.45272292040694195,0.4539198084979054,0.4545182525433872,0.45511669658886894,0.4557151406343507,0.4599042489527229,0.4605026929982047,0.46080191502094553,0.4614003590664273,0.46259724715739076,0.4637941352483543,0.46439257929383604,0.4649910233393178,0.4682824655894674,0.4688809096349491,0.46918013165769,0.4697785757031718,0.47426690604428484,0.4748653500897666,0.47516457211250746,0.4757630161579892,0.476361460203471,0.47695990424895274,0.4790544584081388,0.48025134649910234,0.4826451226810293,0.4832435667265111,0.48473967684021546,0.48533812088569717,0.4916217833632555,0.4922202274087373,0.4931178934769599,0.49371633752244165,0.49700777977259125,0.497606223818073,0.4988031119090365,0.49970077797725915,0.5,0.5017953321364452,0.502393776181927,0.5029922202274087,0.5035906642728905,0.5041891083183723,0.507181328545781,0.5077797725912627,0.5122681029323758,0.5131657690005984,0.5179533213644524,0.5185517654099342,0.5218432076600837,0.5224416517055656,0.5227408737283064,0.5233393177737882,0.5239377618192699,0.5245362058647517,0.528426092160383,0.5290245362058648,0.5326152004787552,0.5335128665469778,0.5338120885697187,0.5344105326152004,0.5350089766606823,0.535607420706164,0.538001196888091,0.5391980849790544,0.5409934171154998,0.5415918611609815,0.5430879712746858,0.5436864153201676,0.5481747456612807,0.5487731897067624,0.5493716337522442,0.5505685218432077,0.5541591861160982,0.5547576301615799,0.5559545182525434,0.5565529622980251,0.5574506283662477,0.5580490724117295,0.5583482944344704,0.5595451825254338,0.56163973668462,0.5622381807301018,0.5625374027528426,0.5631358467983244,0.5646319569120287,0.5655296229802513,0.5670257330939558,0.5676241771394375,0.5679233991621784,0.5685218432076601,0.5697187312986236,0.5703171753441053,0.5709156193895871,0.5715140634350688,0.5724117295032914,0.5730101735487731,0.5754039497307002,0.5760023937761819,0.5769000598444045,0.5777977259126271,0.5789946140035906,0.5825852782764811,0.5837821663674446,0.5849790544584081,0.5855774985038898,0.5861759425493717,0.587672052663076,0.590065828845003,0.5918611609814483,0.59245960502693,0.5930580490724118,0.5957510472770796,0.5963494913225613,0.5969479353680431,0.5975463794135248,0.5978456014362658,0.5990424895272292,0.5993417115499701,0.6005385996409336,0.6023339317773788,0.6035308198683423,0.604129263913824,0.6050269299820467,0.6059245960502693,0.6071214841412328,0.6080191502094554,0.6086175942549371,0.6092160383004189,0.6098144823459006,0.6104129263913824,0.6134051466187912,0.6152004787552364,0.6157989228007181,0.6178934769599043,0.618491921005386,0.6193895870736086,0.6202872531418312,0.6214841412327947,0.6220825852782765,0.6238779174147218,0.6241771394374626,0.6259724715739078,0.6262716935966487,0.6268701376421305,0.6274685816876122,0.6280670257330939,0.6286654697785757,0.6292639138240574,0.6295631358467983,0.63016157989228,0.630460801915021,0.6310592459605027,0.6316576900059845,0.6325553560742071,0.6331538001196888,0.6334530221424297,0.634949132256134,0.6352483542788749,0.6361460203470976,0.6367444643925793,0.6376421304608019,0.6406343506882106,0.6412327947336924,0.642130460801915,0.6472172351885098,0.6478156792339916,0.6487133453022143,0.649311789347696,0.6514063435068821,0.6520047875523639,0.6555954518252544,0.6561938958707361,0.6567923399162179,0.6573907839616996,0.6597845601436265,0.6603830041891083,0.66098144823459,0.6615798922800719,0.6627767803710353,0.6633752244165171,0.6636744464392579,0.6642728904847397,0.6645721125074806,0.6651705565529623,0.6663674446439258,0.6672651107121484,0.6675643327348892,0.6684619988031119,0.6810293237582286,0.6822262118491921,0.6837223219628965,0.6846199880311191,0.6852184320766008,0.6864153201675643,0.687312986235787,0.6879114302812687,0.6882106523040096,0.6891083183722322,0.6903052064631957,0.6915020945541592,0.6929982046678635,0.6935966487133453,0.694494314781568,0.6950927588270497,0.6959904248952723,0.696588868940754,0.6980849790544584,0.6986834230999401,0.7004787552363854,0.7007779772591263,0.7019748653500898,0.7022740873728306,0.7034709754637941,0.703770197486535,0.7043686415320167,0.7046678635547576,0.7058647516457212,0.706163973668462,0.7070616397366846,0.7076600837821664,0.7082585278276481,0.7097546379413525,0.7103530819868342,0.7106523040095751,0.7112507480550568,0.7121484141232794,0.7124476361460204,0.7130460801915021,0.713345302214243,0.7139437462597247,0.7154398563734291,0.7160383004189108,0.7175344105326152,0.7184320766008379,0.7190305206463196,0.7196289646918013,0.7214242968282466,0.7220227408737283,0.7229204069419509,0.7238180730101735,0.7250149611011371,0.725314183123878,0.7259126271693597,0.727408737283064,0.7280071813285458,0.7292040694195093,0.729802513464991,0.7304009575104727,0.7307001795332136,0.7312986235786954,0.7318970676241772,0.7324955116696589,0.7348892878515859,0.7354877318970676,0.7369838420107719,0.7381807301017355,0.7390783961699581,0.7396768402154399,0.7411729503291442,0.741771394374626,0.7420706163973668,0.7426690604428486,0.7444643925792939,0.7450628366247756,0.7459605026929982,0.74655894673848,0.748653500897666,0.7498503889886295,0.7510472770795931,0.7516457211250748,0.7537402752842609,0.7543387193297427,0.7564332734889287,0.7570317175344106,0.7603231597845601,0.7609216038300419,0.7630161579892281,0.7636146020347098,0.7645122681029324,0.7651107121484141,0.7672052663076002,0.7681029323758228,0.7684021543985637,0.7690005984440454,0.7749850388988629,0.7755834829443446,0.7764811490125674,0.7770795930580491,0.7788749251944943,0.7800718132854578,0.7803710353081987,0.7809694793536804,0.7839616995810892,0.7848593656493118,0.7851585876720527,0.7857570317175344,0.7902453620586475,0.7908438061041293,0.7911430281268701,0.7920406941950927,0.7926391382405745,0.7953321364452424,0.796229802513465,0.7980251346499102,0.7989228007181328,0.7998204667863554,0.800718132854578,0.8052064631956912,0.8058049072411729,0.8064033512866547,0.8070017953321365,0.8105924596050269,0.8111909036505087,0.812687013764213,0.8132854578096947,0.8144823459006583,0.8156792339916218,0.8177737881508079,0.8183722321962896,0.8201675643327349,0.8210652304009575,0.8216636744464393,0.8225613405146619,0.8231597845601436,0.8243566726511071,0.8252543387193297,0.8261520047875524,0.8279473369239976,0.8285457809694794,0.829443447037702,0.8300418910831837,0.8303411131059246,0.8309395571514063,0.8324356672651108,0.8333333333333334,0.8339317773788151,0.8360263315380012,0.8366247755834829,0.8396169958108917,0.8402154398563735,0.8414123279473369,0.8420107719928187,0.8461998803111909,0.8470975463794135,0.8473967684021544,0.848294434470377,0.8524835427887493,0.8533812088569719,0.8560742070616397,0.8569718731298623,0.8572710951526032,0.8581687612208259,0.860263315380012,0.8608617594254937,0.8632555356074207,0.8638539796529024,0.8668461998803112,0.8686415320167564,0.8692399760622381,0.86983842010772,0.8716337522441652,0.8728306403351287,0.874326750448833,0.8749251944943148,0.8758228605625374,0.8770197486535009,0.8830041891083183,0.8836026331538002,0.8850987432675045,0.8859964093357271,0.8880909634949132,0.8886894075403949,0.8892878515858768,0.8898862956313585,0.8922800718132855,0.8934769599042489,0.8964691801316577,0.8970676241771395,0.8985637342908438,0.8991621783363255,0.9024536205864752,0.9030520646319569,0.9036505086774387,0.9042489527229204,0.9060442848593656,0.9078396169958108,0.9135248354278875,0.9141232794733692,0.9168162776780371,0.9174147217235189,0.9177139437462597,0.9189108318372232,0.9198084979054458,0.9204069419509275,0.9228007181328546,0.9233991621783363,0.9242968282465589,0.9251944943147815,0.9257929383602633,0.9266906044284859,0.9272890484739676,0.9281867145421903,0.9341711549970078,0.9350688210652304,0.9353680430879713,0.935966487133453,0.9419509275882705,0.9425493716337523,0.9428485936564931,0.9434470377019749,0.9461400359066428,0.9467384799521245,0.9491322561340515,0.9503291442250149,0.9518252543387193,0.952423698384201,0.952722920406942,0.9533213644524237,0.9542190305206463,0.9548174745661281,0.9563135846798324,0.9569120287253142,0.9584081388390185,0.9593058049072412,0.9625972471573908,0.9631956912028725,0.9670855774985039,0.9676840215439856,0.9685816876122083,0.96918013165769,0.9742669060442849,0.9748653500897666,0.9763614602034709,0.9769599042489527,0.9778575703171754,0.9784560143626571,0.9814482345900658,0.9820466786355476,0.9868342309994016,0.9874326750448833,0.9922202274087373,0.992818671454219,1.0],\"y\":[0.0,0.0,0.07142857142857142,0.07142857142857142,0.21428571428571427,0.21428571428571427,0.2857142857142857,0.2857142857142857,0.2857142857142857,0.2857142857142857,0.2857142857142857,0.2857142857142857,0.2857142857142857,0.2857142857142857,0.2857142857142857,0.2857142857142857,0.2857142857142857,0.2857142857142857,0.35714285714285715,0.35714285714285715,0.35714285714285715,0.35714285714285715,0.35714285714285715,0.35714285714285715,0.35714285714285715,0.42857142857142855,0.42857142857142855,0.42857142857142855,0.42857142857142855,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.7142857142857143,0.7142857142857143,0.7142857142857143,0.7142857142857143,0.7142857142857143,0.7142857142857143,0.7142857142857143,0.7142857142857143,0.7142857142857143,0.7142857142857143,0.7142857142857143,0.7142857142857143,0.7142857142857143,0.7142857142857143,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.8571428571428571,0.8571428571428571,0.8571428571428571,0.8571428571428571,0.9285714285714286,0.9285714285714286,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"type\":\"scatter\"},{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(255, 255, 255, 0)\",\"width\":5},\"name\":\"AUC: 0.9294\",\"showlegend\":true,\"x\":[0.0,0.0002992220227408737,0.0002992220227408737,0.0008976660682226212,0.0008976660682226212,0.0017953321364452424,0.0017953321364452424,0.0023937761819269898,0.003590664272890485,0.004488330341113106,0.005385996409335727,0.005984440454817474,0.007779772591262717,0.008378216636744464,0.009575104727707959,0.010173548773189706,0.011669658886894075,0.01286654697785757,0.01286654697785757,0.013464991023339317,0.014063435068821066,0.01436265709156194,0.014961101137043686,0.01526032315978456,0.016457211250748054,0.016457211250748054,0.018252543387193298,0.018850987432675045,0.02154398563734291,0.02154398563734291,0.022142429682824656,0.022740873728306403,0.02333931777378815,0.026929982046678635,0.02752842609216038,0.028126870137642132,0.02872531418312388,0.03201675643327349,0.032615200478755234,0.033512866546977854,0.03441053261520048,0.03500897666068223,0.035607420706163975,0.036505086774386596,0.03710353081986834,0.03919808497905446,0.039796529024536204,0.04039497307001795,0.0409934171154997,0.041891083183722325,0.0466786355475763,0.0466786355475763,0.04697785757031717,0.04757630161579892,0.05475763016157989,0.05535607420706164,0.056253740275284264,0.05685218432076601,0.057151406343506884,0.05774985038898863,0.05864751645721125,0.059245960502693,0.06044284859365649,0.06104129263913824,0.06253740275284261,0.06313584679832436,0.06373429084380611,0.0649311789347696,0.06552962298025135,0.0661280670257331,0.06642728904847396,0.06702573309395571,0.06822262118491922,0.06822262118491922,0.07001795332136446,0.0706163973668462,0.07570317175344106,0.0763016157989228,0.07719928186714542,0.07779772591262717,0.07899461400359066,0.07959305804907241,0.08228605625374028,0.08288450029922202,0.08348294434470377,0.08408138839018552,0.0843806104129264,0.08497905445840814,0.08677438659485338,0.08737283064033513,0.08797127468581688,0.08916816277678037,0.09036505086774387,0.09096349491322561,0.09365649311789348,0.09425493716337523,0.09485338120885697,0.09575104727707959,0.09605026929982047,0.09664871334530221,0.09694793536804308,0.09784560143626571,0.09874326750448834,0.09934171154997008,0.10113704368641532,0.10173548773189707,0.10293237582286056,0.10383004189108318,0.1047277079593058,0.10532615200478755,0.1059245960502693,0.10652304009575105,0.10712148414123279,0.11041292639138241,0.11190903650508677,0.11310592459605028,0.11400359066427289,0.11579892280071813,0.11609814482345901,0.12088569718731298,0.12178336325553561,0.12238180730101736,0.1229802513464991,0.1229802513464991,0.12327947336923997,0.12387791741472172,0.1241771394374626,0.12477558348294435,0.12567324955116696,0.12627169359664872,0.12716935966487133,0.1277678037103531,0.1298623578695392,0.13046080191502094,0.13076002393776182,0.13135846798324358,0.13165769000598443,0.13165769000598443,0.1319569120287253,0.13255535607420707,0.13464991023339318,0.13853979652902454,0.13973668461998803,0.14033512866546977,0.14093357271095153,0.14153201675643326,0.14183123877917414,0.14302812687013763,0.14332734889287851,0.14422501496110113,0.14542190305206462,0.14721723518850988,0.14871334530221425,0.14961101137043686,0.15020945541591862,0.15110712148414124,0.15170556552962297,0.1538001196888091,0.1558946738479952,0.15858767205266308,0.16247755834829444,0.16337522441651706,0.16576900059844404,0.1687612208258528,0.16935966487133453,0.17025733093955714,0.1708557749850389,0.17115499700777978,0.1717534410532615,0.17923399162178336,0.17983243566726512,0.18043087971274685,0.18162776780371034,0.18252543387193298,0.18312387791741472,0.1843207660083782,0.1843207660083782,0.18611609814482347,0.18701376421304608,0.18761220825852784,0.18761220825852784,0.19269898264512267,0.19269898264512267,0.19299820466786355,0.19389587073608616,0.19509275882704968,0.19569120287253142,0.1959904248952723,0.19658886894075403,0.19778575703171752,0.19838420107719928,0.20766008378216635,0.20825852782764812,0.21005385996409337,0.2106523040095751,0.2118491921005386,0.2127468581687612,0.2130460801915021,0.2139437462597247,0.21543985637342908,0.21663674446439257,0.21693596648713345,0.2175344105326152,0.2187312986235787,0.21962896469180132,0.2220227408737283,0.22292040694195092,0.2256134051466188,0.2265110712148414,0.2277079593058049,0.22830640335128666,0.2289048473967684,0.22950329144225015,0.23070017953321365,0.23159784560143626,0.23279473369239975,0.2333931777378815,0.23399162178336325,0.2348892878515859,0.23668461998803111,0.2378815080789946,0.23877917414721722,0.23937761819269898,0.2402752842609216,0.24087372830640336,0.2414721723518851,0.24207061639736685,0.24236983842010773,0.24296828246558946,0.24745661280670259,0.24805505685218432,0.2492519449431478,0.24985038898862957,0.2504488330341113,0.25254338719329744,0.2546379413524835,0.2552363853979653,0.25822860562537403,0.2588270496708558,0.260622381807301,0.2612208258527828,0.26181926989826454,0.26241771394374624,0.26361460203470977,0.2642130460801915,0.2645122681029324,0.26690604428485937,0.26929982046678635,0.2698982645122681,0.27019748653500897,0.27079593058049073,0.2731897067624177,0.27408737283064033,0.27857570317175345,0.2791741472172352,0.27947336923997607,0.28067025733093953,0.2836624775583483,0.2848593656493118,0.2863554757630162,0.2872531418312388,0.29204069419509276,0.2926391382405745,0.30131657690005986,0.30191502094554157,0.30430879712746856,0.3049072411729503,0.31119090365050867,0.3117893476959904,0.3123877917414722,0.3129862357869539,0.3132854578096948,0.31388390185517656,0.31448234590065827,0.3156792339916218,0.3165769000598444,0.31717534410532616,0.3177737881508079,0.31837223219628963,0.31867145421903054,0.31926989826451224,0.3201675643327349,0.3213644524236984,0.3234590065828845,0.32375822860562536,0.3243566726511071,0.3279473369239976,0.32854578096947934,0.32974266906044286,0.3303411131059246,0.3315380011968881,0.33213644524236985,0.3327348892878516,0.3333333333333333,0.3408138839018552,0.34201077199281865,0.3461998803111909,0.3467983243566726,0.34709754637941354,0.3476959904248953,0.34799521244763615,0.3491921005385996,0.35038898862956314,0.3509874326750449,0.3518850987432675,0.35248354278874927,0.3527827648114901,0.3533812088569719,0.3560742070616397,0.3566726511071215,0.35727109515260325,0.35786953919808495,0.3590664272890485,0.3599640933572711,0.360263315380012,0.3608617594254937,0.36146020347097546,0.3620586475164572,0.36475164572112506,0.3653500897666068,0.36624775583482944,0.3668461998803112,0.3677438659485338,0.36894075403949733,0.36953919808497904,0.3701376421304608,0.37043686415320165,0.3710353081986834,0.37642130460801915,0.37761819269898267,0.3782166367444644,0.3785158587672053,0.3794135248354279,0.38001196888090966,0.383901855176541,0.3845002992220227,0.38749251944943147,0.388689407540395,0.3892878515858767,0.38988629563135846,0.3904847396768402,0.391083183722322,0.3916816277678037,0.39228007181328545,0.39347695990424897,0.3943746259724716,0.3964691801316577,0.3970676241771394,0.3976660682226212,0.3994614003590664,0.4018551765409934,0.40245362058647516,0.40514661879114305,0.40574506283662476,0.40724117295032913,0.40843806104129265,0.4162178336325554,0.41741472172351884,0.41980849790544583,0.42100538599640935,0.42190305206463197,0.42519449431478157,0.42579293836026333,0.42669060442848594,0.42758827049670856,0.4302812687013764,0.43087971274685816,0.43117893476959906,0.43177737881508077,0.43447037701974867,0.4350688210652304,0.4386594853381209,0.43925792938360264,0.4404548174745661,0.44105326152004787,0.4413524835427888,0.44254937163375224,0.44434470377019747,0.4452423698384201,0.44584081388390184,0.4464392579293836,0.4473369239976062,0.447935368043088,0.4506283662477558,0.4512268102932376,0.4521244763614602,0.45272292040694195,0.4539198084979054,0.4545182525433872,0.45511669658886894,0.4557151406343507,0.4599042489527229,0.4605026929982047,0.46080191502094553,0.4614003590664273,0.46259724715739076,0.4637941352483543,0.46439257929383604,0.4649910233393178,0.4682824655894674,0.4688809096349491,0.46918013165769,0.4697785757031718,0.47426690604428484,0.4748653500897666,0.47516457211250746,0.4757630161579892,0.476361460203471,0.47695990424895274,0.4790544584081388,0.48025134649910234,0.4826451226810293,0.4832435667265111,0.48473967684021546,0.48533812088569717,0.4916217833632555,0.4922202274087373,0.4931178934769599,0.49371633752244165,0.49700777977259125,0.497606223818073,0.4988031119090365,0.49970077797725915,0.5,0.5017953321364452,0.502393776181927,0.5029922202274087,0.5035906642728905,0.5041891083183723,0.507181328545781,0.5077797725912627,0.5122681029323758,0.5131657690005984,0.5179533213644524,0.5185517654099342,0.5218432076600837,0.5224416517055656,0.5227408737283064,0.5233393177737882,0.5239377618192699,0.5245362058647517,0.528426092160383,0.5290245362058648,0.5326152004787552,0.5335128665469778,0.5338120885697187,0.5344105326152004,0.5350089766606823,0.535607420706164,0.538001196888091,0.5391980849790544,0.5409934171154998,0.5415918611609815,0.5430879712746858,0.5436864153201676,0.5481747456612807,0.5487731897067624,0.5493716337522442,0.5505685218432077,0.5541591861160982,0.5547576301615799,0.5559545182525434,0.5565529622980251,0.5574506283662477,0.5580490724117295,0.5583482944344704,0.5595451825254338,0.56163973668462,0.5622381807301018,0.5625374027528426,0.5631358467983244,0.5646319569120287,0.5655296229802513,0.5670257330939558,0.5676241771394375,0.5679233991621784,0.5685218432076601,0.5697187312986236,0.5703171753441053,0.5709156193895871,0.5715140634350688,0.5724117295032914,0.5730101735487731,0.5754039497307002,0.5760023937761819,0.5769000598444045,0.5777977259126271,0.5789946140035906,0.5825852782764811,0.5837821663674446,0.5849790544584081,0.5855774985038898,0.5861759425493717,0.587672052663076,0.590065828845003,0.5918611609814483,0.59245960502693,0.5930580490724118,0.5957510472770796,0.5963494913225613,0.5969479353680431,0.5975463794135248,0.5978456014362658,0.5990424895272292,0.5993417115499701,0.6005385996409336,0.6023339317773788,0.6035308198683423,0.604129263913824,0.6050269299820467,0.6059245960502693,0.6071214841412328,0.6080191502094554,0.6086175942549371,0.6092160383004189,0.6098144823459006,0.6104129263913824,0.6134051466187912,0.6152004787552364,0.6157989228007181,0.6178934769599043,0.618491921005386,0.6193895870736086,0.6202872531418312,0.6214841412327947,0.6220825852782765,0.6238779174147218,0.6241771394374626,0.6259724715739078,0.6262716935966487,0.6268701376421305,0.6274685816876122,0.6280670257330939,0.6286654697785757,0.6292639138240574,0.6295631358467983,0.63016157989228,0.630460801915021,0.6310592459605027,0.6316576900059845,0.6325553560742071,0.6331538001196888,0.6334530221424297,0.634949132256134,0.6352483542788749,0.6361460203470976,0.6367444643925793,0.6376421304608019,0.6406343506882106,0.6412327947336924,0.642130460801915,0.6472172351885098,0.6478156792339916,0.6487133453022143,0.649311789347696,0.6514063435068821,0.6520047875523639,0.6555954518252544,0.6561938958707361,0.6567923399162179,0.6573907839616996,0.6597845601436265,0.6603830041891083,0.66098144823459,0.6615798922800719,0.6627767803710353,0.6633752244165171,0.6636744464392579,0.6642728904847397,0.6645721125074806,0.6651705565529623,0.6663674446439258,0.6672651107121484,0.6675643327348892,0.6684619988031119,0.6810293237582286,0.6822262118491921,0.6837223219628965,0.6846199880311191,0.6852184320766008,0.6864153201675643,0.687312986235787,0.6879114302812687,0.6882106523040096,0.6891083183722322,0.6903052064631957,0.6915020945541592,0.6929982046678635,0.6935966487133453,0.694494314781568,0.6950927588270497,0.6959904248952723,0.696588868940754,0.6980849790544584,0.6986834230999401,0.7004787552363854,0.7007779772591263,0.7019748653500898,0.7022740873728306,0.7034709754637941,0.703770197486535,0.7043686415320167,0.7046678635547576,0.7058647516457212,0.706163973668462,0.7070616397366846,0.7076600837821664,0.7082585278276481,0.7097546379413525,0.7103530819868342,0.7106523040095751,0.7112507480550568,0.7121484141232794,0.7124476361460204,0.7130460801915021,0.713345302214243,0.7139437462597247,0.7154398563734291,0.7160383004189108,0.7175344105326152,0.7184320766008379,0.7190305206463196,0.7196289646918013,0.7214242968282466,0.7220227408737283,0.7229204069419509,0.7238180730101735,0.7250149611011371,0.725314183123878,0.7259126271693597,0.727408737283064,0.7280071813285458,0.7292040694195093,0.729802513464991,0.7304009575104727,0.7307001795332136,0.7312986235786954,0.7318970676241772,0.7324955116696589,0.7348892878515859,0.7354877318970676,0.7369838420107719,0.7381807301017355,0.7390783961699581,0.7396768402154399,0.7411729503291442,0.741771394374626,0.7420706163973668,0.7426690604428486,0.7444643925792939,0.7450628366247756,0.7459605026929982,0.74655894673848,0.748653500897666,0.7498503889886295,0.7510472770795931,0.7516457211250748,0.7537402752842609,0.7543387193297427,0.7564332734889287,0.7570317175344106,0.7603231597845601,0.7609216038300419,0.7630161579892281,0.7636146020347098,0.7645122681029324,0.7651107121484141,0.7672052663076002,0.7681029323758228,0.7684021543985637,0.7690005984440454,0.7749850388988629,0.7755834829443446,0.7764811490125674,0.7770795930580491,0.7788749251944943,0.7800718132854578,0.7803710353081987,0.7809694793536804,0.7839616995810892,0.7848593656493118,0.7851585876720527,0.7857570317175344,0.7902453620586475,0.7908438061041293,0.7911430281268701,0.7920406941950927,0.7926391382405745,0.7953321364452424,0.796229802513465,0.7980251346499102,0.7989228007181328,0.7998204667863554,0.800718132854578,0.8052064631956912,0.8058049072411729,0.8064033512866547,0.8070017953321365,0.8105924596050269,0.8111909036505087,0.812687013764213,0.8132854578096947,0.8144823459006583,0.8156792339916218,0.8177737881508079,0.8183722321962896,0.8201675643327349,0.8210652304009575,0.8216636744464393,0.8225613405146619,0.8231597845601436,0.8243566726511071,0.8252543387193297,0.8261520047875524,0.8279473369239976,0.8285457809694794,0.829443447037702,0.8300418910831837,0.8303411131059246,0.8309395571514063,0.8324356672651108,0.8333333333333334,0.8339317773788151,0.8360263315380012,0.8366247755834829,0.8396169958108917,0.8402154398563735,0.8414123279473369,0.8420107719928187,0.8461998803111909,0.8470975463794135,0.8473967684021544,0.848294434470377,0.8524835427887493,0.8533812088569719,0.8560742070616397,0.8569718731298623,0.8572710951526032,0.8581687612208259,0.860263315380012,0.8608617594254937,0.8632555356074207,0.8638539796529024,0.8668461998803112,0.8686415320167564,0.8692399760622381,0.86983842010772,0.8716337522441652,0.8728306403351287,0.874326750448833,0.8749251944943148,0.8758228605625374,0.8770197486535009,0.8830041891083183,0.8836026331538002,0.8850987432675045,0.8859964093357271,0.8880909634949132,0.8886894075403949,0.8892878515858768,0.8898862956313585,0.8922800718132855,0.8934769599042489,0.8964691801316577,0.8970676241771395,0.8985637342908438,0.8991621783363255,0.9024536205864752,0.9030520646319569,0.9036505086774387,0.9042489527229204,0.9060442848593656,0.9078396169958108,0.9135248354278875,0.9141232794733692,0.9168162776780371,0.9174147217235189,0.9177139437462597,0.9189108318372232,0.9198084979054458,0.9204069419509275,0.9228007181328546,0.9233991621783363,0.9242968282465589,0.9251944943147815,0.9257929383602633,0.9266906044284859,0.9272890484739676,0.9281867145421903,0.9341711549970078,0.9350688210652304,0.9353680430879713,0.935966487133453,0.9419509275882705,0.9425493716337523,0.9428485936564931,0.9434470377019749,0.9461400359066428,0.9467384799521245,0.9491322561340515,0.9503291442250149,0.9518252543387193,0.952423698384201,0.952722920406942,0.9533213644524237,0.9542190305206463,0.9548174745661281,0.9563135846798324,0.9569120287253142,0.9584081388390185,0.9593058049072412,0.9625972471573908,0.9631956912028725,0.9670855774985039,0.9676840215439856,0.9685816876122083,0.96918013165769,0.9742669060442849,0.9748653500897666,0.9763614602034709,0.9769599042489527,0.9778575703171754,0.9784560143626571,0.9814482345900658,0.9820466786355476,0.9868342309994016,0.9874326750448833,0.9922202274087373,0.992818671454219,1.0],\"y\":[0.0,0.0,0.07142857142857142,0.07142857142857142,0.21428571428571427,0.21428571428571427,0.2857142857142857,0.2857142857142857,0.2857142857142857,0.2857142857142857,0.2857142857142857,0.2857142857142857,0.2857142857142857,0.2857142857142857,0.2857142857142857,0.2857142857142857,0.2857142857142857,0.2857142857142857,0.35714285714285715,0.35714285714285715,0.35714285714285715,0.35714285714285715,0.35714285714285715,0.35714285714285715,0.35714285714285715,0.42857142857142855,0.42857142857142855,0.42857142857142855,0.42857142857142855,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.7142857142857143,0.7142857142857143,0.7142857142857143,0.7142857142857143,0.7142857142857143,0.7142857142857143,0.7142857142857143,0.7142857142857143,0.7142857142857143,0.7142857142857143,0.7142857142857143,0.7142857142857143,0.7142857142857143,0.7142857142857143,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.8571428571428571,0.8571428571428571,0.8571428571428571,0.8571428571428571,0.9285714285714286,0.9285714285714286,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"type\":\"scatter\"},{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(255, 255, 255, 0)\",\"width\":0},\"name\":\"(95% CI: 0.8362-1.0000)\",\"showlegend\":true,\"x\":[0.0,0.0002992220227408737,0.0002992220227408737,0.0008976660682226212,0.0008976660682226212,0.0017953321364452424,0.0017953321364452424,0.0023937761819269898,0.003590664272890485,0.004488330341113106,0.005385996409335727,0.005984440454817474,0.007779772591262717,0.008378216636744464,0.009575104727707959,0.010173548773189706,0.011669658886894075,0.01286654697785757,0.01286654697785757,0.013464991023339317,0.014063435068821066,0.01436265709156194,0.014961101137043686,0.01526032315978456,0.016457211250748054,0.016457211250748054,0.018252543387193298,0.018850987432675045,0.02154398563734291,0.02154398563734291,0.022142429682824656,0.022740873728306403,0.02333931777378815,0.026929982046678635,0.02752842609216038,0.028126870137642132,0.02872531418312388,0.03201675643327349,0.032615200478755234,0.033512866546977854,0.03441053261520048,0.03500897666068223,0.035607420706163975,0.036505086774386596,0.03710353081986834,0.03919808497905446,0.039796529024536204,0.04039497307001795,0.0409934171154997,0.041891083183722325,0.0466786355475763,0.0466786355475763,0.04697785757031717,0.04757630161579892,0.05475763016157989,0.05535607420706164,0.056253740275284264,0.05685218432076601,0.057151406343506884,0.05774985038898863,0.05864751645721125,0.059245960502693,0.06044284859365649,0.06104129263913824,0.06253740275284261,0.06313584679832436,0.06373429084380611,0.0649311789347696,0.06552962298025135,0.0661280670257331,0.06642728904847396,0.06702573309395571,0.06822262118491922,0.06822262118491922,0.07001795332136446,0.0706163973668462,0.07570317175344106,0.0763016157989228,0.07719928186714542,0.07779772591262717,0.07899461400359066,0.07959305804907241,0.08228605625374028,0.08288450029922202,0.08348294434470377,0.08408138839018552,0.0843806104129264,0.08497905445840814,0.08677438659485338,0.08737283064033513,0.08797127468581688,0.08916816277678037,0.09036505086774387,0.09096349491322561,0.09365649311789348,0.09425493716337523,0.09485338120885697,0.09575104727707959,0.09605026929982047,0.09664871334530221,0.09694793536804308,0.09784560143626571,0.09874326750448834,0.09934171154997008,0.10113704368641532,0.10173548773189707,0.10293237582286056,0.10383004189108318,0.1047277079593058,0.10532615200478755,0.1059245960502693,0.10652304009575105,0.10712148414123279,0.11041292639138241,0.11190903650508677,0.11310592459605028,0.11400359066427289,0.11579892280071813,0.11609814482345901,0.12088569718731298,0.12178336325553561,0.12238180730101736,0.1229802513464991,0.1229802513464991,0.12327947336923997,0.12387791741472172,0.1241771394374626,0.12477558348294435,0.12567324955116696,0.12627169359664872,0.12716935966487133,0.1277678037103531,0.1298623578695392,0.13046080191502094,0.13076002393776182,0.13135846798324358,0.13165769000598443,0.13165769000598443,0.1319569120287253,0.13255535607420707,0.13464991023339318,0.13853979652902454,0.13973668461998803,0.14033512866546977,0.14093357271095153,0.14153201675643326,0.14183123877917414,0.14302812687013763,0.14332734889287851,0.14422501496110113,0.14542190305206462,0.14721723518850988,0.14871334530221425,0.14961101137043686,0.15020945541591862,0.15110712148414124,0.15170556552962297,0.1538001196888091,0.1558946738479952,0.15858767205266308,0.16247755834829444,0.16337522441651706,0.16576900059844404,0.1687612208258528,0.16935966487133453,0.17025733093955714,0.1708557749850389,0.17115499700777978,0.1717534410532615,0.17923399162178336,0.17983243566726512,0.18043087971274685,0.18162776780371034,0.18252543387193298,0.18312387791741472,0.1843207660083782,0.1843207660083782,0.18611609814482347,0.18701376421304608,0.18761220825852784,0.18761220825852784,0.19269898264512267,0.19269898264512267,0.19299820466786355,0.19389587073608616,0.19509275882704968,0.19569120287253142,0.1959904248952723,0.19658886894075403,0.19778575703171752,0.19838420107719928,0.20766008378216635,0.20825852782764812,0.21005385996409337,0.2106523040095751,0.2118491921005386,0.2127468581687612,0.2130460801915021,0.2139437462597247,0.21543985637342908,0.21663674446439257,0.21693596648713345,0.2175344105326152,0.2187312986235787,0.21962896469180132,0.2220227408737283,0.22292040694195092,0.2256134051466188,0.2265110712148414,0.2277079593058049,0.22830640335128666,0.2289048473967684,0.22950329144225015,0.23070017953321365,0.23159784560143626,0.23279473369239975,0.2333931777378815,0.23399162178336325,0.2348892878515859,0.23668461998803111,0.2378815080789946,0.23877917414721722,0.23937761819269898,0.2402752842609216,0.24087372830640336,0.2414721723518851,0.24207061639736685,0.24236983842010773,0.24296828246558946,0.24745661280670259,0.24805505685218432,0.2492519449431478,0.24985038898862957,0.2504488330341113,0.25254338719329744,0.2546379413524835,0.2552363853979653,0.25822860562537403,0.2588270496708558,0.260622381807301,0.2612208258527828,0.26181926989826454,0.26241771394374624,0.26361460203470977,0.2642130460801915,0.2645122681029324,0.26690604428485937,0.26929982046678635,0.2698982645122681,0.27019748653500897,0.27079593058049073,0.2731897067624177,0.27408737283064033,0.27857570317175345,0.2791741472172352,0.27947336923997607,0.28067025733093953,0.2836624775583483,0.2848593656493118,0.2863554757630162,0.2872531418312388,0.29204069419509276,0.2926391382405745,0.30131657690005986,0.30191502094554157,0.30430879712746856,0.3049072411729503,0.31119090365050867,0.3117893476959904,0.3123877917414722,0.3129862357869539,0.3132854578096948,0.31388390185517656,0.31448234590065827,0.3156792339916218,0.3165769000598444,0.31717534410532616,0.3177737881508079,0.31837223219628963,0.31867145421903054,0.31926989826451224,0.3201675643327349,0.3213644524236984,0.3234590065828845,0.32375822860562536,0.3243566726511071,0.3279473369239976,0.32854578096947934,0.32974266906044286,0.3303411131059246,0.3315380011968881,0.33213644524236985,0.3327348892878516,0.3333333333333333,0.3408138839018552,0.34201077199281865,0.3461998803111909,0.3467983243566726,0.34709754637941354,0.3476959904248953,0.34799521244763615,0.3491921005385996,0.35038898862956314,0.3509874326750449,0.3518850987432675,0.35248354278874927,0.3527827648114901,0.3533812088569719,0.3560742070616397,0.3566726511071215,0.35727109515260325,0.35786953919808495,0.3590664272890485,0.3599640933572711,0.360263315380012,0.3608617594254937,0.36146020347097546,0.3620586475164572,0.36475164572112506,0.3653500897666068,0.36624775583482944,0.3668461998803112,0.3677438659485338,0.36894075403949733,0.36953919808497904,0.3701376421304608,0.37043686415320165,0.3710353081986834,0.37642130460801915,0.37761819269898267,0.3782166367444644,0.3785158587672053,0.3794135248354279,0.38001196888090966,0.383901855176541,0.3845002992220227,0.38749251944943147,0.388689407540395,0.3892878515858767,0.38988629563135846,0.3904847396768402,0.391083183722322,0.3916816277678037,0.39228007181328545,0.39347695990424897,0.3943746259724716,0.3964691801316577,0.3970676241771394,0.3976660682226212,0.3994614003590664,0.4018551765409934,0.40245362058647516,0.40514661879114305,0.40574506283662476,0.40724117295032913,0.40843806104129265,0.4162178336325554,0.41741472172351884,0.41980849790544583,0.42100538599640935,0.42190305206463197,0.42519449431478157,0.42579293836026333,0.42669060442848594,0.42758827049670856,0.4302812687013764,0.43087971274685816,0.43117893476959906,0.43177737881508077,0.43447037701974867,0.4350688210652304,0.4386594853381209,0.43925792938360264,0.4404548174745661,0.44105326152004787,0.4413524835427888,0.44254937163375224,0.44434470377019747,0.4452423698384201,0.44584081388390184,0.4464392579293836,0.4473369239976062,0.447935368043088,0.4506283662477558,0.4512268102932376,0.4521244763614602,0.45272292040694195,0.4539198084979054,0.4545182525433872,0.45511669658886894,0.4557151406343507,0.4599042489527229,0.4605026929982047,0.46080191502094553,0.4614003590664273,0.46259724715739076,0.4637941352483543,0.46439257929383604,0.4649910233393178,0.4682824655894674,0.4688809096349491,0.46918013165769,0.4697785757031718,0.47426690604428484,0.4748653500897666,0.47516457211250746,0.4757630161579892,0.476361460203471,0.47695990424895274,0.4790544584081388,0.48025134649910234,0.4826451226810293,0.4832435667265111,0.48473967684021546,0.48533812088569717,0.4916217833632555,0.4922202274087373,0.4931178934769599,0.49371633752244165,0.49700777977259125,0.497606223818073,0.4988031119090365,0.49970077797725915,0.5,0.5017953321364452,0.502393776181927,0.5029922202274087,0.5035906642728905,0.5041891083183723,0.507181328545781,0.5077797725912627,0.5122681029323758,0.5131657690005984,0.5179533213644524,0.5185517654099342,0.5218432076600837,0.5224416517055656,0.5227408737283064,0.5233393177737882,0.5239377618192699,0.5245362058647517,0.528426092160383,0.5290245362058648,0.5326152004787552,0.5335128665469778,0.5338120885697187,0.5344105326152004,0.5350089766606823,0.535607420706164,0.538001196888091,0.5391980849790544,0.5409934171154998,0.5415918611609815,0.5430879712746858,0.5436864153201676,0.5481747456612807,0.5487731897067624,0.5493716337522442,0.5505685218432077,0.5541591861160982,0.5547576301615799,0.5559545182525434,0.5565529622980251,0.5574506283662477,0.5580490724117295,0.5583482944344704,0.5595451825254338,0.56163973668462,0.5622381807301018,0.5625374027528426,0.5631358467983244,0.5646319569120287,0.5655296229802513,0.5670257330939558,0.5676241771394375,0.5679233991621784,0.5685218432076601,0.5697187312986236,0.5703171753441053,0.5709156193895871,0.5715140634350688,0.5724117295032914,0.5730101735487731,0.5754039497307002,0.5760023937761819,0.5769000598444045,0.5777977259126271,0.5789946140035906,0.5825852782764811,0.5837821663674446,0.5849790544584081,0.5855774985038898,0.5861759425493717,0.587672052663076,0.590065828845003,0.5918611609814483,0.59245960502693,0.5930580490724118,0.5957510472770796,0.5963494913225613,0.5969479353680431,0.5975463794135248,0.5978456014362658,0.5990424895272292,0.5993417115499701,0.6005385996409336,0.6023339317773788,0.6035308198683423,0.604129263913824,0.6050269299820467,0.6059245960502693,0.6071214841412328,0.6080191502094554,0.6086175942549371,0.6092160383004189,0.6098144823459006,0.6104129263913824,0.6134051466187912,0.6152004787552364,0.6157989228007181,0.6178934769599043,0.618491921005386,0.6193895870736086,0.6202872531418312,0.6214841412327947,0.6220825852782765,0.6238779174147218,0.6241771394374626,0.6259724715739078,0.6262716935966487,0.6268701376421305,0.6274685816876122,0.6280670257330939,0.6286654697785757,0.6292639138240574,0.6295631358467983,0.63016157989228,0.630460801915021,0.6310592459605027,0.6316576900059845,0.6325553560742071,0.6331538001196888,0.6334530221424297,0.634949132256134,0.6352483542788749,0.6361460203470976,0.6367444643925793,0.6376421304608019,0.6406343506882106,0.6412327947336924,0.642130460801915,0.6472172351885098,0.6478156792339916,0.6487133453022143,0.649311789347696,0.6514063435068821,0.6520047875523639,0.6555954518252544,0.6561938958707361,0.6567923399162179,0.6573907839616996,0.6597845601436265,0.6603830041891083,0.66098144823459,0.6615798922800719,0.6627767803710353,0.6633752244165171,0.6636744464392579,0.6642728904847397,0.6645721125074806,0.6651705565529623,0.6663674446439258,0.6672651107121484,0.6675643327348892,0.6684619988031119,0.6810293237582286,0.6822262118491921,0.6837223219628965,0.6846199880311191,0.6852184320766008,0.6864153201675643,0.687312986235787,0.6879114302812687,0.6882106523040096,0.6891083183722322,0.6903052064631957,0.6915020945541592,0.6929982046678635,0.6935966487133453,0.694494314781568,0.6950927588270497,0.6959904248952723,0.696588868940754,0.6980849790544584,0.6986834230999401,0.7004787552363854,0.7007779772591263,0.7019748653500898,0.7022740873728306,0.7034709754637941,0.703770197486535,0.7043686415320167,0.7046678635547576,0.7058647516457212,0.706163973668462,0.7070616397366846,0.7076600837821664,0.7082585278276481,0.7097546379413525,0.7103530819868342,0.7106523040095751,0.7112507480550568,0.7121484141232794,0.7124476361460204,0.7130460801915021,0.713345302214243,0.7139437462597247,0.7154398563734291,0.7160383004189108,0.7175344105326152,0.7184320766008379,0.7190305206463196,0.7196289646918013,0.7214242968282466,0.7220227408737283,0.7229204069419509,0.7238180730101735,0.7250149611011371,0.725314183123878,0.7259126271693597,0.727408737283064,0.7280071813285458,0.7292040694195093,0.729802513464991,0.7304009575104727,0.7307001795332136,0.7312986235786954,0.7318970676241772,0.7324955116696589,0.7348892878515859,0.7354877318970676,0.7369838420107719,0.7381807301017355,0.7390783961699581,0.7396768402154399,0.7411729503291442,0.741771394374626,0.7420706163973668,0.7426690604428486,0.7444643925792939,0.7450628366247756,0.7459605026929982,0.74655894673848,0.748653500897666,0.7498503889886295,0.7510472770795931,0.7516457211250748,0.7537402752842609,0.7543387193297427,0.7564332734889287,0.7570317175344106,0.7603231597845601,0.7609216038300419,0.7630161579892281,0.7636146020347098,0.7645122681029324,0.7651107121484141,0.7672052663076002,0.7681029323758228,0.7684021543985637,0.7690005984440454,0.7749850388988629,0.7755834829443446,0.7764811490125674,0.7770795930580491,0.7788749251944943,0.7800718132854578,0.7803710353081987,0.7809694793536804,0.7839616995810892,0.7848593656493118,0.7851585876720527,0.7857570317175344,0.7902453620586475,0.7908438061041293,0.7911430281268701,0.7920406941950927,0.7926391382405745,0.7953321364452424,0.796229802513465,0.7980251346499102,0.7989228007181328,0.7998204667863554,0.800718132854578,0.8052064631956912,0.8058049072411729,0.8064033512866547,0.8070017953321365,0.8105924596050269,0.8111909036505087,0.812687013764213,0.8132854578096947,0.8144823459006583,0.8156792339916218,0.8177737881508079,0.8183722321962896,0.8201675643327349,0.8210652304009575,0.8216636744464393,0.8225613405146619,0.8231597845601436,0.8243566726511071,0.8252543387193297,0.8261520047875524,0.8279473369239976,0.8285457809694794,0.829443447037702,0.8300418910831837,0.8303411131059246,0.8309395571514063,0.8324356672651108,0.8333333333333334,0.8339317773788151,0.8360263315380012,0.8366247755834829,0.8396169958108917,0.8402154398563735,0.8414123279473369,0.8420107719928187,0.8461998803111909,0.8470975463794135,0.8473967684021544,0.848294434470377,0.8524835427887493,0.8533812088569719,0.8560742070616397,0.8569718731298623,0.8572710951526032,0.8581687612208259,0.860263315380012,0.8608617594254937,0.8632555356074207,0.8638539796529024,0.8668461998803112,0.8686415320167564,0.8692399760622381,0.86983842010772,0.8716337522441652,0.8728306403351287,0.874326750448833,0.8749251944943148,0.8758228605625374,0.8770197486535009,0.8830041891083183,0.8836026331538002,0.8850987432675045,0.8859964093357271,0.8880909634949132,0.8886894075403949,0.8892878515858768,0.8898862956313585,0.8922800718132855,0.8934769599042489,0.8964691801316577,0.8970676241771395,0.8985637342908438,0.8991621783363255,0.9024536205864752,0.9030520646319569,0.9036505086774387,0.9042489527229204,0.9060442848593656,0.9078396169958108,0.9135248354278875,0.9141232794733692,0.9168162776780371,0.9174147217235189,0.9177139437462597,0.9189108318372232,0.9198084979054458,0.9204069419509275,0.9228007181328546,0.9233991621783363,0.9242968282465589,0.9251944943147815,0.9257929383602633,0.9266906044284859,0.9272890484739676,0.9281867145421903,0.9341711549970078,0.9350688210652304,0.9353680430879713,0.935966487133453,0.9419509275882705,0.9425493716337523,0.9428485936564931,0.9434470377019749,0.9461400359066428,0.9467384799521245,0.9491322561340515,0.9503291442250149,0.9518252543387193,0.952423698384201,0.952722920406942,0.9533213644524237,0.9542190305206463,0.9548174745661281,0.9563135846798324,0.9569120287253142,0.9584081388390185,0.9593058049072412,0.9625972471573908,0.9631956912028725,0.9670855774985039,0.9676840215439856,0.9685816876122083,0.96918013165769,0.9742669060442849,0.9748653500897666,0.9763614602034709,0.9769599042489527,0.9778575703171754,0.9784560143626571,0.9814482345900658,0.9820466786355476,0.9868342309994016,0.9874326750448833,0.9922202274087373,0.992818671454219,1.0],\"y\":[0.0,0.0,0.07142857142857142,0.07142857142857142,0.21428571428571427,0.21428571428571427,0.2857142857142857,0.2857142857142857,0.2857142857142857,0.2857142857142857,0.2857142857142857,0.2857142857142857,0.2857142857142857,0.2857142857142857,0.2857142857142857,0.2857142857142857,0.2857142857142857,0.2857142857142857,0.35714285714285715,0.35714285714285715,0.35714285714285715,0.35714285714285715,0.35714285714285715,0.35714285714285715,0.35714285714285715,0.42857142857142855,0.42857142857142855,0.42857142857142855,0.42857142857142855,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.5714285714285714,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.6428571428571429,0.7142857142857143,0.7142857142857143,0.7142857142857143,0.7142857142857143,0.7142857142857143,0.7142857142857143,0.7142857142857143,0.7142857142857143,0.7142857142857143,0.7142857142857143,0.7142857142857143,0.7142857142857143,0.7142857142857143,0.7142857142857143,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.7857142857142857,0.8571428571428571,0.8571428571428571,0.8571428571428571,0.8571428571428571,0.9285714285714286,0.9285714285714286,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"type\":\"scatter\"},{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(50, 50, 250, 1.0)\",\"width\":5},\"name\":\"\\u003cb\\u003eFemale\\u003c\\u002fb\\u003e\",\"showlegend\":true,\"x\":[0.0,0.000625,0.000625,0.0009375,0.0015625,0.0025,0.0025,0.003125,0.003125,0.005,0.005,0.0053125,0.0053125,0.008125,0.008125,0.00875,0.0090625,0.0090625,0.0096875,0.010625,0.0109375,0.0109375,0.01125,0.011875,0.013125,0.013125,0.0134375,0.0134375,0.01625,0.0175,0.018125,0.01875,0.0196875,0.0203125,0.0234375,0.024375,0.024375,0.0246875,0.0253125,0.025625,0.025625,0.026875,0.026875,0.0275,0.028125,0.02875,0.0290625,0.0296875,0.030625,0.03125,0.031875,0.0325,0.0346875,0.035625,0.0378125,0.03875,0.0396875,0.0409375,0.04125,0.0421875,0.0425,0.0434375,0.0440625,0.0440625,0.045,0.045625,0.0465625,0.0475,0.048125,0.0496875,0.0496875,0.0503125,0.0515625,0.0525,0.05375,0.054375,0.0546875,0.0553125,0.0553125,0.055625,0.05625,0.0571875,0.0578125,0.0584375,0.0590625,0.059375,0.060625,0.0615625,0.061875,0.061875,0.0640625,0.065,0.06625,0.066875,0.069375,0.069375,0.0715625,0.0721875,0.0734375,0.074375,0.076875,0.0778125,0.0825,0.08375,0.084375,0.0853125,0.0859375,0.08875,0.0896875,0.09,0.090625,0.0909375,0.0921875,0.09375,0.094375,0.0946875,0.0953125,0.095625,0.09875,0.099375,0.10125,0.101875,0.1028125,0.103125,0.104375,0.1046875,0.1065625,0.1075,0.1125,0.115,0.115625,0.1203125,0.124375,0.12625,0.128125,0.12875,0.1296875,0.1309375,0.131875,0.1325,0.133125,0.135,0.135,0.135625,0.136875,0.1375,0.1384375,0.1396875,0.1403125,0.140625,0.1415625,0.1421875,0.1421875,0.1428125,0.1453125,0.1471875,0.1484375,0.1503125,0.1534375,0.154375,0.155,0.1559375,0.1565625,0.1575,0.15875,0.1596875,0.160625,0.161875,0.163125,0.16375,0.1646875,0.165,0.165625,0.1696875,0.1703125,0.17125,0.1725,0.1734375,0.1740625,0.1746875,0.175,0.175625,0.1778125,0.17875,0.1821875,0.1828125,0.18375,0.185,0.186875,0.1896875,0.19,0.190625,0.195625,0.1978125,0.200625,0.20125,0.2015625,0.2021875,0.2028125,0.20375,0.204375,0.2053125,0.2059375,0.20625,0.2078125,0.2090625,0.2096875,0.2115625,0.2121875,0.2153125,0.2159375,0.216875,0.2178125,0.2221875,0.2228125,0.2234375,0.224375,0.225,0.225625,0.22875,0.229375,0.230625,0.23125,0.231875,0.2325,0.2328125,0.2334375,0.2340625,0.2346875,0.235,0.235625,0.2359375,0.236875,0.243125,0.24375,0.2440625,0.2453125,0.2471875,0.24875,0.249375,0.2525,0.253125,0.254375,0.2553125,0.2559375,0.2565625,0.256875,0.2575,0.2578125,0.2584375,0.265625,0.26625,0.266875,0.2675,0.268125,0.2690625,0.27,0.2709375,0.273125,0.27375,0.274375,0.275,0.27625,0.2771875,0.2778125,0.2784375,0.279375,0.2803125,0.281875,0.2825,0.2834375,0.2840625,0.2846875,0.28625,0.286875,0.28875,0.28875,0.29,0.290625,0.2909375,0.2915625,0.2934375,0.2940625,0.29625,0.2971875,0.2996875,0.3003125,0.30125,0.301875,0.3021875,0.3028125,0.3040625,0.3046875,0.30625,0.3075,0.3084375,0.3090625,0.3103125,0.3115625,0.311875,0.3125,0.3184375,0.319375,0.325,0.325625,0.32875,0.33,0.3334375,0.3340625,0.33875,0.339375,0.34,0.340625,0.3425,0.343125,0.34375,0.344375,0.345625,0.34625,0.3465625,0.3478125,0.348125,0.34875,0.354375,0.355,0.36125,0.361875,0.36625,0.366875,0.3684375,0.3690625,0.374375,0.375625,0.3771875,0.3778125,0.379375,0.3803125,0.3809375,0.3815625,0.3853125,0.386875,0.3878125,0.388125,0.38875,0.3909375,0.3915625,0.3921875,0.3934375,0.395625,0.39625,0.3965625,0.3971875,0.3978125,0.3984375,0.4015625,0.4025,0.404375,0.405,0.4084375,0.4096875,0.418125,0.41875,0.421875,0.4225,0.4240625,0.4246875,0.4328125,0.4334375,0.4365625,0.4371875,0.4409375,0.4421875,0.4428125,0.44375,0.444375,0.445,0.4459375,0.4465625,0.446875,0.4475,0.4528125,0.4534375,0.4578125,0.4584375,0.4596875,0.460625,0.4615625,0.4621875,0.464375,0.465,0.46625,0.4675,0.4684375,0.4696875,0.47125,0.471875,0.473125,0.47375,0.4746875,0.4753125,0.476875,0.4775,0.4809375,0.4815625,0.4828125,0.4840625,0.49,0.490625,0.4946875,0.4953125,0.496875,0.4975,0.4978125,0.4984375,0.5003125,0.50125,0.504375,0.505,0.505625,0.50625,0.5084375,0.509375,0.5153125,0.5159375,0.521875,0.5225,0.523125,0.52375,0.5240625,0.5246875,0.526875,0.5278125,0.5290625,0.5303125,0.5309375,0.531875,0.5328125,0.5334375,0.5340625,0.5346875,0.5365625,0.5375,0.53875,0.541875,0.543125,0.549375,0.5503125,0.553125,0.554375,0.555,0.556875,0.5578125,0.5584375,0.5590625,0.564375,0.565,0.568125,0.56875,0.57125,0.571875,0.573125,0.57375,0.575,0.5759375,0.5765625,0.576875,0.5775,0.5784375,0.579375,0.583125,0.584375,0.58625,0.5875,0.5903125,0.59125,0.59375,0.5946875,0.595625,0.59625,0.5971875,0.5978125,0.5984375,0.5990625,0.6,0.60125,0.6025,0.603125,0.6065625,0.6071875,0.6090625,0.6096875,0.615625,0.61625,0.6175,0.618125,0.6221875,0.6228125,0.6265625,0.6271875,0.629375,0.63,0.6309375,0.6315625,0.6321875,0.633125,0.63375,0.63625,0.636875,0.638125,0.639375,0.640625,0.6415625,0.6421875,0.6425,0.643125,0.646875,0.64875,0.649375,0.650625,0.6540625,0.6546875,0.65625,0.656875,0.6571875,0.6578125,0.6584375,0.659375,0.6609375,0.665625,0.6665625,0.666875,0.6675,0.6684375,0.669375,0.6715625,0.6721875,0.6740625,0.6746875,0.6815625,0.6821875,0.685625,0.68625,0.690625,0.6915625,0.6934375,0.694375,0.6990625,0.7,0.7025,0.703125,0.7034375,0.7040625,0.708125,0.70875,0.709375,0.71,0.7159375,0.716875,0.7171875,0.7178125,0.7190625,0.7196875,0.724375,0.725,0.7259375,0.7271875,0.7284375,0.7290625,0.7303125,0.7309375,0.731875,0.7328125,0.7353125,0.7359375,0.738125,0.73875,0.7421875,0.7428125,0.748125,0.74875,0.7490625,0.7496875,0.750625,0.75125,0.7534375,0.7540625,0.7578125,0.7584375,0.7596875,0.7609375,0.766875,0.76875,0.7725,0.773125,0.7740625,0.7753125,0.778125,0.77875,0.7790625,0.7796875,0.7809375,0.7821875,0.7828125,0.7840625,0.7846875,0.7865625,0.7878125,0.7890625,0.7896875,0.7909375,0.7915625,0.791875,0.7925,0.7946875,0.7953125,0.795625,0.79625,0.7990625,0.8,0.8021875,0.8028125,0.808125,0.8090625,0.81,0.810625,0.8140625,0.8146875,0.8175,0.818125,0.8190625,0.8196875,0.8209375,0.8215625,0.821875,0.8225,0.823125,0.825,0.831875,0.8325,0.8328125,0.83375,0.8359375,0.836875,0.8371875,0.838125,0.84125,0.841875,0.8421875,0.843125,0.844375,0.8453125,0.85,0.850625,0.8515625,0.8528125,0.8540625,0.8546875,0.859375,0.860625,0.8625,0.863125,0.86625,0.866875,0.868125,0.86875,0.87,0.870625,0.8771875,0.8778125,0.8784375,0.8790625,0.8803125,0.88125,0.8871875,0.8884375,0.8890625,0.89,0.890625,0.893125,0.89375,0.896875,0.8975,0.900625,0.9015625,0.9021875,0.9028125,0.9034375,0.9040625,0.905,0.90625,0.906875,0.9090625,0.9103125,0.913125,0.91375,0.914375,0.915,0.9159375,0.9165625,0.92375,0.925,0.9265625,0.9271875,0.9303125,0.93125,0.9428125,0.9434375,0.945625,0.9465625,0.9475,0.9484375,0.94875,0.95,0.953125,0.95375,0.9546875,0.9553125,0.9609375,0.9615625,0.961875,0.9625,0.9634375,0.9640625,0.9653125,0.9659375,0.9690625,0.9696875,0.97,0.970625,0.9721875,0.973125,0.97375,0.9753125,0.9759375,0.9771875,0.9778125,0.9803125,0.9809375,0.9825,0.983125,0.986875,0.9878125,0.9896875,0.9903125,0.994375,0.995,1.0],\"y\":[0.0,0.0,0.14814814814814814,0.14814814814814814,0.14814814814814814,0.14814814814814814,0.2222222222222222,0.2222222222222222,0.25925925925925924,0.25925925925925924,0.2962962962962963,0.2962962962962963,0.3333333333333333,0.3333333333333333,0.37037037037037035,0.37037037037037035,0.37037037037037035,0.4074074074074074,0.4074074074074074,0.4074074074074074,0.4074074074074074,0.4444444444444444,0.4444444444444444,0.4444444444444444,0.4444444444444444,0.48148148148148145,0.48148148148148145,0.5185185185185185,0.5185185185185185,0.5185185185185185,0.5185185185185185,0.5185185185185185,0.5185185185185185,0.5185185185185185,0.5185185185185185,0.5185185185185185,0.5555555555555556,0.5555555555555556,0.5555555555555556,0.5555555555555556,0.5925925925925926,0.5925925925925926,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7407407407407407,0.7407407407407407,0.7407407407407407,0.7407407407407407,0.7407407407407407,0.7407407407407407,0.7407407407407407,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.8148148148148148,0.8148148148148148,0.8148148148148148,0.8148148148148148,0.8148148148148148,0.8148148148148148,0.8148148148148148,0.8148148148148148,0.8148148148148148,0.8148148148148148,0.8148148148148148,0.8518518518518519,0.8518518518518519,0.8518518518518519,0.8518518518518519,0.8518518518518519,0.8518518518518519,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.9259259259259259,0.9259259259259259,0.9259259259259259,0.9259259259259259,0.9259259259259259,0.9259259259259259,0.9259259259259259,0.9259259259259259,0.9259259259259259,0.9259259259259259,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"type\":\"scatter\"},{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(255, 255, 255, 0)\",\"width\":5},\"name\":\"AUC: 0.9610\",\"showlegend\":true,\"x\":[0.0,0.000625,0.000625,0.0009375,0.0015625,0.0025,0.0025,0.003125,0.003125,0.005,0.005,0.0053125,0.0053125,0.008125,0.008125,0.00875,0.0090625,0.0090625,0.0096875,0.010625,0.0109375,0.0109375,0.01125,0.011875,0.013125,0.013125,0.0134375,0.0134375,0.01625,0.0175,0.018125,0.01875,0.0196875,0.0203125,0.0234375,0.024375,0.024375,0.0246875,0.0253125,0.025625,0.025625,0.026875,0.026875,0.0275,0.028125,0.02875,0.0290625,0.0296875,0.030625,0.03125,0.031875,0.0325,0.0346875,0.035625,0.0378125,0.03875,0.0396875,0.0409375,0.04125,0.0421875,0.0425,0.0434375,0.0440625,0.0440625,0.045,0.045625,0.0465625,0.0475,0.048125,0.0496875,0.0496875,0.0503125,0.0515625,0.0525,0.05375,0.054375,0.0546875,0.0553125,0.0553125,0.055625,0.05625,0.0571875,0.0578125,0.0584375,0.0590625,0.059375,0.060625,0.0615625,0.061875,0.061875,0.0640625,0.065,0.06625,0.066875,0.069375,0.069375,0.0715625,0.0721875,0.0734375,0.074375,0.076875,0.0778125,0.0825,0.08375,0.084375,0.0853125,0.0859375,0.08875,0.0896875,0.09,0.090625,0.0909375,0.0921875,0.09375,0.094375,0.0946875,0.0953125,0.095625,0.09875,0.099375,0.10125,0.101875,0.1028125,0.103125,0.104375,0.1046875,0.1065625,0.1075,0.1125,0.115,0.115625,0.1203125,0.124375,0.12625,0.128125,0.12875,0.1296875,0.1309375,0.131875,0.1325,0.133125,0.135,0.135,0.135625,0.136875,0.1375,0.1384375,0.1396875,0.1403125,0.140625,0.1415625,0.1421875,0.1421875,0.1428125,0.1453125,0.1471875,0.1484375,0.1503125,0.1534375,0.154375,0.155,0.1559375,0.1565625,0.1575,0.15875,0.1596875,0.160625,0.161875,0.163125,0.16375,0.1646875,0.165,0.165625,0.1696875,0.1703125,0.17125,0.1725,0.1734375,0.1740625,0.1746875,0.175,0.175625,0.1778125,0.17875,0.1821875,0.1828125,0.18375,0.185,0.186875,0.1896875,0.19,0.190625,0.195625,0.1978125,0.200625,0.20125,0.2015625,0.2021875,0.2028125,0.20375,0.204375,0.2053125,0.2059375,0.20625,0.2078125,0.2090625,0.2096875,0.2115625,0.2121875,0.2153125,0.2159375,0.216875,0.2178125,0.2221875,0.2228125,0.2234375,0.224375,0.225,0.225625,0.22875,0.229375,0.230625,0.23125,0.231875,0.2325,0.2328125,0.2334375,0.2340625,0.2346875,0.235,0.235625,0.2359375,0.236875,0.243125,0.24375,0.2440625,0.2453125,0.2471875,0.24875,0.249375,0.2525,0.253125,0.254375,0.2553125,0.2559375,0.2565625,0.256875,0.2575,0.2578125,0.2584375,0.265625,0.26625,0.266875,0.2675,0.268125,0.2690625,0.27,0.2709375,0.273125,0.27375,0.274375,0.275,0.27625,0.2771875,0.2778125,0.2784375,0.279375,0.2803125,0.281875,0.2825,0.2834375,0.2840625,0.2846875,0.28625,0.286875,0.28875,0.28875,0.29,0.290625,0.2909375,0.2915625,0.2934375,0.2940625,0.29625,0.2971875,0.2996875,0.3003125,0.30125,0.301875,0.3021875,0.3028125,0.3040625,0.3046875,0.30625,0.3075,0.3084375,0.3090625,0.3103125,0.3115625,0.311875,0.3125,0.3184375,0.319375,0.325,0.325625,0.32875,0.33,0.3334375,0.3340625,0.33875,0.339375,0.34,0.340625,0.3425,0.343125,0.34375,0.344375,0.345625,0.34625,0.3465625,0.3478125,0.348125,0.34875,0.354375,0.355,0.36125,0.361875,0.36625,0.366875,0.3684375,0.3690625,0.374375,0.375625,0.3771875,0.3778125,0.379375,0.3803125,0.3809375,0.3815625,0.3853125,0.386875,0.3878125,0.388125,0.38875,0.3909375,0.3915625,0.3921875,0.3934375,0.395625,0.39625,0.3965625,0.3971875,0.3978125,0.3984375,0.4015625,0.4025,0.404375,0.405,0.4084375,0.4096875,0.418125,0.41875,0.421875,0.4225,0.4240625,0.4246875,0.4328125,0.4334375,0.4365625,0.4371875,0.4409375,0.4421875,0.4428125,0.44375,0.444375,0.445,0.4459375,0.4465625,0.446875,0.4475,0.4528125,0.4534375,0.4578125,0.4584375,0.4596875,0.460625,0.4615625,0.4621875,0.464375,0.465,0.46625,0.4675,0.4684375,0.4696875,0.47125,0.471875,0.473125,0.47375,0.4746875,0.4753125,0.476875,0.4775,0.4809375,0.4815625,0.4828125,0.4840625,0.49,0.490625,0.4946875,0.4953125,0.496875,0.4975,0.4978125,0.4984375,0.5003125,0.50125,0.504375,0.505,0.505625,0.50625,0.5084375,0.509375,0.5153125,0.5159375,0.521875,0.5225,0.523125,0.52375,0.5240625,0.5246875,0.526875,0.5278125,0.5290625,0.5303125,0.5309375,0.531875,0.5328125,0.5334375,0.5340625,0.5346875,0.5365625,0.5375,0.53875,0.541875,0.543125,0.549375,0.5503125,0.553125,0.554375,0.555,0.556875,0.5578125,0.5584375,0.5590625,0.564375,0.565,0.568125,0.56875,0.57125,0.571875,0.573125,0.57375,0.575,0.5759375,0.5765625,0.576875,0.5775,0.5784375,0.579375,0.583125,0.584375,0.58625,0.5875,0.5903125,0.59125,0.59375,0.5946875,0.595625,0.59625,0.5971875,0.5978125,0.5984375,0.5990625,0.6,0.60125,0.6025,0.603125,0.6065625,0.6071875,0.6090625,0.6096875,0.615625,0.61625,0.6175,0.618125,0.6221875,0.6228125,0.6265625,0.6271875,0.629375,0.63,0.6309375,0.6315625,0.6321875,0.633125,0.63375,0.63625,0.636875,0.638125,0.639375,0.640625,0.6415625,0.6421875,0.6425,0.643125,0.646875,0.64875,0.649375,0.650625,0.6540625,0.6546875,0.65625,0.656875,0.6571875,0.6578125,0.6584375,0.659375,0.6609375,0.665625,0.6665625,0.666875,0.6675,0.6684375,0.669375,0.6715625,0.6721875,0.6740625,0.6746875,0.6815625,0.6821875,0.685625,0.68625,0.690625,0.6915625,0.6934375,0.694375,0.6990625,0.7,0.7025,0.703125,0.7034375,0.7040625,0.708125,0.70875,0.709375,0.71,0.7159375,0.716875,0.7171875,0.7178125,0.7190625,0.7196875,0.724375,0.725,0.7259375,0.7271875,0.7284375,0.7290625,0.7303125,0.7309375,0.731875,0.7328125,0.7353125,0.7359375,0.738125,0.73875,0.7421875,0.7428125,0.748125,0.74875,0.7490625,0.7496875,0.750625,0.75125,0.7534375,0.7540625,0.7578125,0.7584375,0.7596875,0.7609375,0.766875,0.76875,0.7725,0.773125,0.7740625,0.7753125,0.778125,0.77875,0.7790625,0.7796875,0.7809375,0.7821875,0.7828125,0.7840625,0.7846875,0.7865625,0.7878125,0.7890625,0.7896875,0.7909375,0.7915625,0.791875,0.7925,0.7946875,0.7953125,0.795625,0.79625,0.7990625,0.8,0.8021875,0.8028125,0.808125,0.8090625,0.81,0.810625,0.8140625,0.8146875,0.8175,0.818125,0.8190625,0.8196875,0.8209375,0.8215625,0.821875,0.8225,0.823125,0.825,0.831875,0.8325,0.8328125,0.83375,0.8359375,0.836875,0.8371875,0.838125,0.84125,0.841875,0.8421875,0.843125,0.844375,0.8453125,0.85,0.850625,0.8515625,0.8528125,0.8540625,0.8546875,0.859375,0.860625,0.8625,0.863125,0.86625,0.866875,0.868125,0.86875,0.87,0.870625,0.8771875,0.8778125,0.8784375,0.8790625,0.8803125,0.88125,0.8871875,0.8884375,0.8890625,0.89,0.890625,0.893125,0.89375,0.896875,0.8975,0.900625,0.9015625,0.9021875,0.9028125,0.9034375,0.9040625,0.905,0.90625,0.906875,0.9090625,0.9103125,0.913125,0.91375,0.914375,0.915,0.9159375,0.9165625,0.92375,0.925,0.9265625,0.9271875,0.9303125,0.93125,0.9428125,0.9434375,0.945625,0.9465625,0.9475,0.9484375,0.94875,0.95,0.953125,0.95375,0.9546875,0.9553125,0.9609375,0.9615625,0.961875,0.9625,0.9634375,0.9640625,0.9653125,0.9659375,0.9690625,0.9696875,0.97,0.970625,0.9721875,0.973125,0.97375,0.9753125,0.9759375,0.9771875,0.9778125,0.9803125,0.9809375,0.9825,0.983125,0.986875,0.9878125,0.9896875,0.9903125,0.994375,0.995,1.0],\"y\":[0.0,0.0,0.14814814814814814,0.14814814814814814,0.14814814814814814,0.14814814814814814,0.2222222222222222,0.2222222222222222,0.25925925925925924,0.25925925925925924,0.2962962962962963,0.2962962962962963,0.3333333333333333,0.3333333333333333,0.37037037037037035,0.37037037037037035,0.37037037037037035,0.4074074074074074,0.4074074074074074,0.4074074074074074,0.4074074074074074,0.4444444444444444,0.4444444444444444,0.4444444444444444,0.4444444444444444,0.48148148148148145,0.48148148148148145,0.5185185185185185,0.5185185185185185,0.5185185185185185,0.5185185185185185,0.5185185185185185,0.5185185185185185,0.5185185185185185,0.5185185185185185,0.5185185185185185,0.5555555555555556,0.5555555555555556,0.5555555555555556,0.5555555555555556,0.5925925925925926,0.5925925925925926,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7407407407407407,0.7407407407407407,0.7407407407407407,0.7407407407407407,0.7407407407407407,0.7407407407407407,0.7407407407407407,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.8148148148148148,0.8148148148148148,0.8148148148148148,0.8148148148148148,0.8148148148148148,0.8148148148148148,0.8148148148148148,0.8148148148148148,0.8148148148148148,0.8148148148148148,0.8148148148148148,0.8518518518518519,0.8518518518518519,0.8518518518518519,0.8518518518518519,0.8518518518518519,0.8518518518518519,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.9259259259259259,0.9259259259259259,0.9259259259259259,0.9259259259259259,0.9259259259259259,0.9259259259259259,0.9259259259259259,0.9259259259259259,0.9259259259259259,0.9259259259259259,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"type\":\"scatter\"},{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(255, 255, 255, 0)\",\"width\":0},\"name\":\"(95% CI: 0.9099-1.0000)\",\"showlegend\":true,\"x\":[0.0,0.000625,0.000625,0.0009375,0.0015625,0.0025,0.0025,0.003125,0.003125,0.005,0.005,0.0053125,0.0053125,0.008125,0.008125,0.00875,0.0090625,0.0090625,0.0096875,0.010625,0.0109375,0.0109375,0.01125,0.011875,0.013125,0.013125,0.0134375,0.0134375,0.01625,0.0175,0.018125,0.01875,0.0196875,0.0203125,0.0234375,0.024375,0.024375,0.0246875,0.0253125,0.025625,0.025625,0.026875,0.026875,0.0275,0.028125,0.02875,0.0290625,0.0296875,0.030625,0.03125,0.031875,0.0325,0.0346875,0.035625,0.0378125,0.03875,0.0396875,0.0409375,0.04125,0.0421875,0.0425,0.0434375,0.0440625,0.0440625,0.045,0.045625,0.0465625,0.0475,0.048125,0.0496875,0.0496875,0.0503125,0.0515625,0.0525,0.05375,0.054375,0.0546875,0.0553125,0.0553125,0.055625,0.05625,0.0571875,0.0578125,0.0584375,0.0590625,0.059375,0.060625,0.0615625,0.061875,0.061875,0.0640625,0.065,0.06625,0.066875,0.069375,0.069375,0.0715625,0.0721875,0.0734375,0.074375,0.076875,0.0778125,0.0825,0.08375,0.084375,0.0853125,0.0859375,0.08875,0.0896875,0.09,0.090625,0.0909375,0.0921875,0.09375,0.094375,0.0946875,0.0953125,0.095625,0.09875,0.099375,0.10125,0.101875,0.1028125,0.103125,0.104375,0.1046875,0.1065625,0.1075,0.1125,0.115,0.115625,0.1203125,0.124375,0.12625,0.128125,0.12875,0.1296875,0.1309375,0.131875,0.1325,0.133125,0.135,0.135,0.135625,0.136875,0.1375,0.1384375,0.1396875,0.1403125,0.140625,0.1415625,0.1421875,0.1421875,0.1428125,0.1453125,0.1471875,0.1484375,0.1503125,0.1534375,0.154375,0.155,0.1559375,0.1565625,0.1575,0.15875,0.1596875,0.160625,0.161875,0.163125,0.16375,0.1646875,0.165,0.165625,0.1696875,0.1703125,0.17125,0.1725,0.1734375,0.1740625,0.1746875,0.175,0.175625,0.1778125,0.17875,0.1821875,0.1828125,0.18375,0.185,0.186875,0.1896875,0.19,0.190625,0.195625,0.1978125,0.200625,0.20125,0.2015625,0.2021875,0.2028125,0.20375,0.204375,0.2053125,0.2059375,0.20625,0.2078125,0.2090625,0.2096875,0.2115625,0.2121875,0.2153125,0.2159375,0.216875,0.2178125,0.2221875,0.2228125,0.2234375,0.224375,0.225,0.225625,0.22875,0.229375,0.230625,0.23125,0.231875,0.2325,0.2328125,0.2334375,0.2340625,0.2346875,0.235,0.235625,0.2359375,0.236875,0.243125,0.24375,0.2440625,0.2453125,0.2471875,0.24875,0.249375,0.2525,0.253125,0.254375,0.2553125,0.2559375,0.2565625,0.256875,0.2575,0.2578125,0.2584375,0.265625,0.26625,0.266875,0.2675,0.268125,0.2690625,0.27,0.2709375,0.273125,0.27375,0.274375,0.275,0.27625,0.2771875,0.2778125,0.2784375,0.279375,0.2803125,0.281875,0.2825,0.2834375,0.2840625,0.2846875,0.28625,0.286875,0.28875,0.28875,0.29,0.290625,0.2909375,0.2915625,0.2934375,0.2940625,0.29625,0.2971875,0.2996875,0.3003125,0.30125,0.301875,0.3021875,0.3028125,0.3040625,0.3046875,0.30625,0.3075,0.3084375,0.3090625,0.3103125,0.3115625,0.311875,0.3125,0.3184375,0.319375,0.325,0.325625,0.32875,0.33,0.3334375,0.3340625,0.33875,0.339375,0.34,0.340625,0.3425,0.343125,0.34375,0.344375,0.345625,0.34625,0.3465625,0.3478125,0.348125,0.34875,0.354375,0.355,0.36125,0.361875,0.36625,0.366875,0.3684375,0.3690625,0.374375,0.375625,0.3771875,0.3778125,0.379375,0.3803125,0.3809375,0.3815625,0.3853125,0.386875,0.3878125,0.388125,0.38875,0.3909375,0.3915625,0.3921875,0.3934375,0.395625,0.39625,0.3965625,0.3971875,0.3978125,0.3984375,0.4015625,0.4025,0.404375,0.405,0.4084375,0.4096875,0.418125,0.41875,0.421875,0.4225,0.4240625,0.4246875,0.4328125,0.4334375,0.4365625,0.4371875,0.4409375,0.4421875,0.4428125,0.44375,0.444375,0.445,0.4459375,0.4465625,0.446875,0.4475,0.4528125,0.4534375,0.4578125,0.4584375,0.4596875,0.460625,0.4615625,0.4621875,0.464375,0.465,0.46625,0.4675,0.4684375,0.4696875,0.47125,0.471875,0.473125,0.47375,0.4746875,0.4753125,0.476875,0.4775,0.4809375,0.4815625,0.4828125,0.4840625,0.49,0.490625,0.4946875,0.4953125,0.496875,0.4975,0.4978125,0.4984375,0.5003125,0.50125,0.504375,0.505,0.505625,0.50625,0.5084375,0.509375,0.5153125,0.5159375,0.521875,0.5225,0.523125,0.52375,0.5240625,0.5246875,0.526875,0.5278125,0.5290625,0.5303125,0.5309375,0.531875,0.5328125,0.5334375,0.5340625,0.5346875,0.5365625,0.5375,0.53875,0.541875,0.543125,0.549375,0.5503125,0.553125,0.554375,0.555,0.556875,0.5578125,0.5584375,0.5590625,0.564375,0.565,0.568125,0.56875,0.57125,0.571875,0.573125,0.57375,0.575,0.5759375,0.5765625,0.576875,0.5775,0.5784375,0.579375,0.583125,0.584375,0.58625,0.5875,0.5903125,0.59125,0.59375,0.5946875,0.595625,0.59625,0.5971875,0.5978125,0.5984375,0.5990625,0.6,0.60125,0.6025,0.603125,0.6065625,0.6071875,0.6090625,0.6096875,0.615625,0.61625,0.6175,0.618125,0.6221875,0.6228125,0.6265625,0.6271875,0.629375,0.63,0.6309375,0.6315625,0.6321875,0.633125,0.63375,0.63625,0.636875,0.638125,0.639375,0.640625,0.6415625,0.6421875,0.6425,0.643125,0.646875,0.64875,0.649375,0.650625,0.6540625,0.6546875,0.65625,0.656875,0.6571875,0.6578125,0.6584375,0.659375,0.6609375,0.665625,0.6665625,0.666875,0.6675,0.6684375,0.669375,0.6715625,0.6721875,0.6740625,0.6746875,0.6815625,0.6821875,0.685625,0.68625,0.690625,0.6915625,0.6934375,0.694375,0.6990625,0.7,0.7025,0.703125,0.7034375,0.7040625,0.708125,0.70875,0.709375,0.71,0.7159375,0.716875,0.7171875,0.7178125,0.7190625,0.7196875,0.724375,0.725,0.7259375,0.7271875,0.7284375,0.7290625,0.7303125,0.7309375,0.731875,0.7328125,0.7353125,0.7359375,0.738125,0.73875,0.7421875,0.7428125,0.748125,0.74875,0.7490625,0.7496875,0.750625,0.75125,0.7534375,0.7540625,0.7578125,0.7584375,0.7596875,0.7609375,0.766875,0.76875,0.7725,0.773125,0.7740625,0.7753125,0.778125,0.77875,0.7790625,0.7796875,0.7809375,0.7821875,0.7828125,0.7840625,0.7846875,0.7865625,0.7878125,0.7890625,0.7896875,0.7909375,0.7915625,0.791875,0.7925,0.7946875,0.7953125,0.795625,0.79625,0.7990625,0.8,0.8021875,0.8028125,0.808125,0.8090625,0.81,0.810625,0.8140625,0.8146875,0.8175,0.818125,0.8190625,0.8196875,0.8209375,0.8215625,0.821875,0.8225,0.823125,0.825,0.831875,0.8325,0.8328125,0.83375,0.8359375,0.836875,0.8371875,0.838125,0.84125,0.841875,0.8421875,0.843125,0.844375,0.8453125,0.85,0.850625,0.8515625,0.8528125,0.8540625,0.8546875,0.859375,0.860625,0.8625,0.863125,0.86625,0.866875,0.868125,0.86875,0.87,0.870625,0.8771875,0.8778125,0.8784375,0.8790625,0.8803125,0.88125,0.8871875,0.8884375,0.8890625,0.89,0.890625,0.893125,0.89375,0.896875,0.8975,0.900625,0.9015625,0.9021875,0.9028125,0.9034375,0.9040625,0.905,0.90625,0.906875,0.9090625,0.9103125,0.913125,0.91375,0.914375,0.915,0.9159375,0.9165625,0.92375,0.925,0.9265625,0.9271875,0.9303125,0.93125,0.9428125,0.9434375,0.945625,0.9465625,0.9475,0.9484375,0.94875,0.95,0.953125,0.95375,0.9546875,0.9553125,0.9609375,0.9615625,0.961875,0.9625,0.9634375,0.9640625,0.9653125,0.9659375,0.9690625,0.9696875,0.97,0.970625,0.9721875,0.973125,0.97375,0.9753125,0.9759375,0.9771875,0.9778125,0.9803125,0.9809375,0.9825,0.983125,0.986875,0.9878125,0.9896875,0.9903125,0.994375,0.995,1.0],\"y\":[0.0,0.0,0.14814814814814814,0.14814814814814814,0.14814814814814814,0.14814814814814814,0.2222222222222222,0.2222222222222222,0.25925925925925924,0.25925925925925924,0.2962962962962963,0.2962962962962963,0.3333333333333333,0.3333333333333333,0.37037037037037035,0.37037037037037035,0.37037037037037035,0.4074074074074074,0.4074074074074074,0.4074074074074074,0.4074074074074074,0.4444444444444444,0.4444444444444444,0.4444444444444444,0.4444444444444444,0.48148148148148145,0.48148148148148145,0.5185185185185185,0.5185185185185185,0.5185185185185185,0.5185185185185185,0.5185185185185185,0.5185185185185185,0.5185185185185185,0.5185185185185185,0.5185185185185185,0.5555555555555556,0.5555555555555556,0.5555555555555556,0.5555555555555556,0.5925925925925926,0.5925925925925926,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7037037037037037,0.7407407407407407,0.7407407407407407,0.7407407407407407,0.7407407407407407,0.7407407407407407,0.7407407407407407,0.7407407407407407,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.8148148148148148,0.8148148148148148,0.8148148148148148,0.8148148148148148,0.8148148148148148,0.8148148148148148,0.8148148148148148,0.8148148148148148,0.8148148148148148,0.8148148148148148,0.8148148148148148,0.8518518518518519,0.8518518518518519,0.8518518518518519,0.8518518518518519,0.8518518518518519,0.8518518518518519,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.9259259259259259,0.9259259259259259,0.9259259259259259,0.9259259259259259,0.9259259259259259,0.9259259259259259,0.9259259259259259,0.9259259259259259,0.9259259259259259,0.9259259259259259,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,0.9629629629629629,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"title\":{\"x\":1},\"legend\":{\"yanchor\":\"bottom\",\"xanchor\":\"right\",\"x\":0.95,\"y\":0.01},\"xaxis\":{\"title\":{\"text\":\"\\u003cb\\u003e1-Specificity\\u003c\\u002fb\\u003e\"},\"range\":[0,1],\"gridcolor\":\"rgba(5, 5, 5, 0.5)\",\"constrain\":\"domain\",\"linecolor\":\"black\"},\"yaxis\":{\"title\":{\"text\":\"\\u003cb\\u003eRecall\\u003c\\u002fb\\u003e\"},\"range\":[0,1],\"gridcolor\":\"rgba(5, 5, 5, 0.5)\",\"scaleanchor\":\"x\",\"scaleratio\":1,\"linecolor\":\"black\"},\"width\":600,\"height\":600,\"font\":{\"family\":\"Times New Roman\",\"size\":22,\"color\":\"Black\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('07e35f26-9733-47ef-882e-9a12f7c78218');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "test=pd.concat([X_test, y_test], axis=1)\n",
        "male1=test.drop(X_test[X_test['IRSEX_1 - Male'] == 0].index)\n",
        "#male1=male1.sample(85, random_state=43)\n",
        "male_predictors=male1.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "male_target=male1['UDPYOPI_1 - Yes']\n",
        "female1=test.drop(X_test[X_test['IRSEX_1 - Male'] == 1].index)\n",
        "#female1=female1.sample(85, random_state=43)\n",
        "female_predictors=female1.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "female_target=female1['UDPYOPI_1 - Yes']\n",
        "male_prob=network.predict(male_predictors)\n",
        "female_prob=network.predict(female_predictors)\n",
        "plot_roc_curve2(male_target, male_prob, female_target, female_prob, 'Male', 'Female')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "20b82716",
      "metadata": {
        "id": "20b82716"
      },
      "outputs": [],
      "source": [
        "def range_with_floats(start, stop, step):\n",
        "    while stop > start:\n",
        "        yield start\n",
        "        start += step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "66101aa2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66101aa2",
        "outputId": "6c572662-56ac-477c-c8e3-6056fe1b62b9",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TtestResult(statistic=37.42463648612107, pvalue=2.2819982651774558e-192, df=1000)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# Males vs. females\n",
        "\n",
        "df = []\n",
        "\n",
        "for i in range_with_floats(0.0, 100.0, 0.1):\n",
        "    y_pred_male = (male_prob >= i * 0.01).astype(bool)\n",
        "    cm_g1 = confusion_matrix(male_target, y_pred_male)\n",
        "    specificity_g1 = cm_g1[0, 0] / (cm_g1[0, 0] + cm_g1[0, 1])\n",
        "    sensitivity_g1 = cm_g1[1, 1] / (cm_g1[1, 0] + cm_g1[1, 1])\n",
        "\n",
        "    y_pred_female = (female_prob >= i * 0.01).astype(bool)\n",
        "    cm_g2 = confusion_matrix(female_target, y_pred_female)\n",
        "    specificity_g2 = cm_g2[0, 0] / (cm_g2[0, 0] + cm_g2[0, 1])\n",
        "    sensitivity_g2 = cm_g2[1, 1] / (cm_g2[1, 0] + cm_g2[1, 1])\n",
        "\n",
        "    difference = abs(specificity_g1 - specificity_g2) + abs(sensitivity_g1 - sensitivity_g2)\n",
        "\n",
        "    df.append({'difference': difference, 'threshold': i})\n",
        "\n",
        "df = pd.DataFrame(df)\n",
        "\n",
        "diff = np.array(df['difference'])\n",
        "\n",
        "stats.ttest_1samp(diff, popmean=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "df291793",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df291793",
        "outputId": "07785a7f-9eec-4d59-9ee9-bb6a4779cc35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.9756949718973112 sensitivity: 0.5121951219512195 accuracy_g1: 0.9764600715137068 accuracy_g2: 0.9748992872637124 specificity_g1: 0.9784560143626571 specificity_g2: 0.97875 sensitivity_g1: 0.5 sensitivity_g2: 0.5185185185185185 difference: 0.018812504155861443 threshold: 52.10000000000047\n",
            "accuracy: 0.9746316269178186 sensitivity: 0.5121951219512195 accuracy_g1: 0.9746722288438617 accuracy_g2: 0.9745894019212892 specificity_g1: 0.9766606822262118 specificity_g2: 0.9784375 sensitivity_g1: 0.5 sensitivity_g2: 0.5185185185185185 difference: 0.02029533629230662 threshold: 50.0\n"
          ]
        }
      ],
      "source": [
        "# Males vs. females\n",
        "\n",
        "df = []\n",
        "\n",
        "for i in range_with_floats(0.0, 100.0, 0.1):\n",
        "\n",
        "    y_pred = (prob >= i*0.01).astype(bool)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    acc = (cm[0,0] + cm[1,1]) / (cm[0,0] + cm[0,1] + cm[1,0] + cm[1,1])\n",
        "    sen = cm[1,1] / (cm[1,0] + cm[1,1])\n",
        "    if sen >= 0.5 and acc >= 0.5:\n",
        "        y_pred_male = (male_prob >= i*0.01).astype(bool)\n",
        "        cm_g1 = confusion_matrix(male_target, y_pred_male)\n",
        "        specificity_g1 = cm_g1[0,0] / (cm_g1[0,0] + cm_g1[0,1])\n",
        "        sensitivity_g1 = cm_g1[1,1] / (cm_g1[1,0] + cm_g1[1,1])\n",
        "        accuracy_g1 = (cm_g1[0,0] + cm_g1[1,1]) / (cm_g1[0,0] + cm_g1[0,1] + cm_g1[1,0] + cm_g1[1,1])\n",
        "\n",
        "        y_pred_female = (female_prob >= i*0.01).astype(bool)\n",
        "        cm_g2 = confusion_matrix(female_target, y_pred_female)\n",
        "        specificity_g2 = cm_g2[0,0] / (cm_g2[0,0] + cm_g2[0,1])\n",
        "        sensitivity_g2 = cm_g2[1,1] / (cm_g2[1,0] + cm_g2[1,1])\n",
        "        accuracy_g2 = (cm_g2[0,0] + cm_g2[1,1]) / (cm_g2[0,0] + cm_g2[0,1] + cm_g2[1,0] + cm_g2[1,1])\n",
        "\n",
        "        difference = abs(specificity_g1 - specificity_g2) + abs(sensitivity_g1 - sensitivity_g2)\n",
        "\n",
        "        df.append({'accuracy': acc, 'sensitivity': sen, 'accuracy_g1': accuracy_g1, 'accuracy_g2': accuracy_g2, 'specificity_g1': specificity_g1, 'specificity_g2': specificity_g2, 'sensitivity_g1': sensitivity_g1, 'sensitivity_g2': sensitivity_g2, 'difference': difference, 'threshold': i})\n",
        "\n",
        "df = pd.DataFrame(df)\n",
        "\n",
        "min_diff = df.iloc[df['difference'].idxmin()]\n",
        "print('accuracy:', min_diff['accuracy'], 'sensitivity:', min_diff['sensitivity'], 'accuracy_g1:', min_diff['accuracy_g1'], 'accuracy_g2:', min_diff['accuracy_g2'], 'specificity_g1:', min_diff['specificity_g1'], 'specificity_g2:', min_diff['specificity_g2'], 'sensitivity_g1:', min_diff['sensitivity_g1'], 'sensitivity_g2:', min_diff['sensitivity_g2'], 'difference:', min_diff['difference'], 'threshold:', min_diff['threshold'])\n",
        "\n",
        "y_pred = (prob >= 50*0.01).astype(bool)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "acc = (cm[0,0] + cm[1,1]) / (cm[0,0] + cm[0,1] + cm[1,0] + cm[1,1])\n",
        "sen = cm[1,1] / (cm[1,0] + cm[1,1])\n",
        "\n",
        "y_pred_male = (network.predict(male_predictors, verbose=0) >= 50*0.01).astype(bool)\n",
        "cm_g1 = confusion_matrix(male_target, y_pred_male)\n",
        "specificity_g1 = cm_g1[0,0] / (cm_g1[0,0] + cm_g1[0,1])\n",
        "sensitivity_g1 = cm_g1[1,1] / (cm_g1[1,0] + cm_g1[1,1])\n",
        "accuracy_g1 = (cm_g1[0,0] + cm_g1[1,1]) / (cm_g1[0,0] + cm_g1[0,1] + cm_g1[1,0] + cm_g1[1,1])\n",
        "\n",
        "y_pred_female = (network.predict(female_predictors, verbose=0) >= 50*0.01).astype(bool)\n",
        "cm_g2 = confusion_matrix(female_target, y_pred_female)\n",
        "specificity_g2 = cm_g2[0,0] / (cm_g2[0,0] + cm_g2[0,1])\n",
        "sensitivity_g2 = cm_g2[1,1] / (cm_g2[1,0] + cm_g2[1,1])\n",
        "accuracy_g2 = (cm_g2[0,0] + cm_g2[1,1]) / (cm_g2[0,0] + cm_g2[0,1] + cm_g2[1,0] + cm_g2[1,1])\n",
        "\n",
        "difference = abs(specificity_g1 - specificity_g2) + abs(sensitivity_g1 - sensitivity_g2)\n",
        "\n",
        "print('accuracy:', acc, 'sensitivity:', sen, 'accuracy_g1:', accuracy_g1, 'accuracy_g2:', accuracy_g2, 'specificity_g1:', specificity_g1, 'specificity_g2:', specificity_g2, 'sensitivity_g1:', sensitivity_g1, 'sensitivity_g2:', sensitivity_g2, 'difference:', difference, 'threshold:', 50.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "9507c3d0",
      "metadata": {
        "id": "9507c3d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "outputId": "58b11eea-cf0b-4a02-b283-45cf093957b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "105/105 [==============================] - 1s 6ms/step\n",
            "102/102 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"ddfbdf62-290b-4687-9490-ceb3b6251bbc\" class=\"plotly-graph-div\" style=\"height:600px; width:600px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ddfbdf62-290b-4687-9490-ceb3b6251bbc\")) {                    Plotly.newPlot(                        \"ddfbdf62-290b-4687-9490-ceb3b6251bbc\",                        [{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(250, 50, 50, 1.0)\",\"width\":5},\"name\":\"\\u003cb\\u003eNever been married\\u003c\\u002fb\\u003e\",\"showlegend\":true,\"x\":[0.0,0.0,0.0,0.0006029544769369913,0.0006029544769369913,0.002411817907747965,0.002411817907747965,0.004220681338558939,0.00482363581549593,0.006029544769369913,0.006632499246306904,0.007536930961712391,0.008139885438649382,0.011456135061802835,0.011456135061802835,0.01175761230027133,0.01236056677720832,0.01236056677720832,0.012662044015676817,0.013264998492613807,0.014169430208019295,0.014169430208019295,0.01718420259270425,0.018390111546578235,0.01929454326198372,0.01929454326198372,0.019897497738920713,0.020500452215857702,0.021103406692794695,0.02200783840820018,0.022610792885137173,0.02472113355441664,0.02562556526982213,0.027434428700633104,0.027434428700633104,0.028037383177570093,0.028640337654507086,0.029846246608381068,0.03316249623153452,0.03376545070847151,0.03527283690081399,0.03587579137775098,0.037081700331624966,0.037383177570093455,0.03919204100090443,0.039794995477841426,0.039794995477841426,0.0413023816701839,0.04190533614712089,0.04552306300874284,0.046427494724148324,0.047934880916490806,0.0485378353934278,0.04944226710883328,0.05004522158577027,0.05034669882423877,0.05094965330117576,0.05305999397045523,0.05366294844739222,0.054265902924329215,0.0551703346397347,0.05577328911667169,0.056979198070545675,0.058185107024419654,0.058788061501356646,0.060898402170636114,0.0621043111245101,0.06300874283991559,0.06361169731685258,0.06511908350919506,0.06511908350919506,0.07145010551703346,0.07205305999397045,0.07235453723243895,0.07295749170937595,0.07386192342478143,0.07446487790171842,0.07506783237865541,0.0756707868555924,0.07778112752487187,0.07838408200180887,0.07898703647874586,0.07958999095568285,0.08170033162496232,0.08230328610189931,0.08350919505577328,0.08531805848658426,0.08622249020198974,0.08682544467892674,0.08772987639433223,0.08833283087126922,0.0892372625866747,0.09014169430208019,0.09496533011757612,0.0964727163099186,0.09737714802532409,0.09798010250226108,0.09828157974072957,0.102803738317757,0.10491407898703647,0.10581851070244197,0.1100391920410009,0.1100391920410009,0.1106421465179379,0.11124510099487489,0.11456135061802834,0.11606873681037082,0.11667169128730781,0.1169731685257763,0.1178776002411818,0.11848055471811879,0.12028941814892975,0.12511305396442568,0.12631896291829967,0.12692191739523667,0.12722339463370516,0.12722339463370516,0.12782634911064214,0.12873078082604764,0.1305396442568586,0.1308411214953271,0.13204703044920107,0.13295146216460657,0.13596623454929152,0.13626771178776004,0.13687066626469702,0.13867952969550798,0.139282484172445,0.14109134760325595,0.1450105517033464,0.14651793789568887,0.14712089237262588,0.14802532408803135,0.14862827856496835,0.14892975580343684,0.15013566475731083,0.15104009647271632,0.15224600542659028,0.15375339161893278,0.15526077781127526,0.15586373228821224,0.15676816400361773,0.1573711184805547,0.1576725957190232,0.1585770274344287,0.16098884534217667,0.16370214048839313,0.16762134458848357,0.17003316249623154,0.17123907145010553,0.1724449804039795,0.17515827555019595,0.17576123002713295,0.17787157069641243,0.1784745251733494,0.1787760024118179,0.1793789568887549,0.18028338860416038,0.18118782031956587,0.18782031956587278,0.18842327404280976,0.19173952366596322,0.1929454326198372,0.19626168224299065,0.19626168224299065,0.19807054567380164,0.19807054567380164,0.20048236358154958,0.2010853180584866,0.20198974977389206,0.20259270425082906,0.20289418148929755,0.20379861320470305,0.21103406692794693,0.21163702140488394,0.2134458848356949,0.21495327102803738,0.21615917998191136,0.21706361169731686,0.21917395236659631,0.2209828157974073,0.22249020198974978,0.22339463370515525,0.22640940608984023,0.2270123605667772,0.23032861018993067,0.23123304190533614,0.23243895085921012,0.23304190533614713,0.23334338257461562,0.2339463370515526,0.23424781429002112,0.2348507687669581,0.23876997286704854,0.23937292734398552,0.2417847452517335,0.2423876997286705,0.24389508592101297,0.24449804039794995,0.24630690382876091,0.24690985830569792,0.2472113355441664,0.24781429002110342,0.2490201989749774,0.24962315345191438,0.2505275851673199,0.25113053964425686,0.25293940307506785,0.2535423575520048,0.25625565269822126,0.25836599336750077,0.2601748567983117,0.26077781127524874,0.2610792885137172,0.2616822429906542,0.2622851974675912,0.2628881519445282,0.26680735604461864,0.2674103105215556,0.2689176967138981,0.2701236056677721,0.2707265601447091,0.27132951462164606,0.27193246909858304,0.274344287006331,0.27826349110642146,0.27886644558335844,0.28700633102200784,0.2876092854989448,0.2900211034066928,0.29062405788362977,0.29152848959903527,0.2927343985529093,0.29996985227615314,0.3005728067530901,0.3041905336147121,0.3047934880916491,0.311425987337956,0.312028941814893,0.31323485076876695,0.3138378052457039,0.31413928248417244,0.3147422369611094,0.32016882725354234,0.3207717817304793,0.32197769068435333,0.3225806451612903,0.32288212239975883,0.3234850768766958,0.3237865541151643,0.3243895085921013,0.32559541754597526,0.3261983720229123,0.3268013264998493,0.32740428097678625,0.32921314440759725,0.3304190533614712,0.33252939403075066,0.3364485981308411,0.33705155260777814,0.3376545070847151,0.3382574615616521,0.3400663249924631,0.34066927946940007,0.3409707567078686,0.34157371118480556,0.34308109737714804,0.34398552909255353,0.3445884835694905,0.3451914380464275,0.3518239372927344,0.3530298462466084,0.35574314139282487,0.35634609586976185,0.3569490503466988,0.3581549593005728,0.3584564365390413,0.3590593910159783,0.3602652999698523,0.3611697316852578,0.36177268616219477,0.3629785951160687,0.3644859813084112,0.3650889357853482,0.36840518540850165,0.3690081398854386,0.37051552607778115,0.37111848055471813,0.3741332529394031,0.37473620741634006,0.3768465480856195,0.37744950256255655,0.378353934277962,0.379559843231836,0.381368706662647,0.381971661139584,0.38438347904733194,0.3849864335242689,0.38950859210129635,0.39071450105517036,0.39131745553210734,0.39222188724751283,0.3928248417244498,0.39764847753994575,0.39825143201688273,0.4015676816400362,0.40277359059391016,0.40367802230931565,0.40428097678625263,0.4085016581248116,0.40970756707868555,0.41061199879409105,0.41151643050949654,0.413023816701839,0.413626771178776,0.4139282484172445,0.4145312028941815,0.415435634609587,0.41603858908652397,0.4181489297558034,0.4187518842327404,0.42025927042508293,0.4214651793789569,0.42478142900211036,0.42538438347904733,0.43050949653301174,0.43171540548688575,0.4335242689176967,0.4341272233946337,0.4353331323485077,0.43593608682544466,0.43804642749472417,0.43864938197166115,0.44045824540247214,0.4410611998794091,0.4413626771178776,0.4419656315948146,0.44407597226409407,0.445281881217968,0.448296653602653,0.44889960807959,0.449502562556527,0.45010551703346396,0.45161290322580644,0.4522158577027434,0.45342176665661743,0.4540247211335544,0.4555321073258969,0.45613506180283386,0.4567380162797709,0.45794392523364486,0.45914983418751887,0.4600542659029243,0.46065722037986134,0.4612601748567983,0.46608381067229426,0.46668676514923124,0.4681941513415737,0.4687971058185107,0.4751281278263491,0.4757310823032861,0.47723846849562856,0.47784142297256554,0.48085619535725055,0.481760627072656,0.483569490503467,0.48417244498040396,0.4844739222188725,0.48507687669580946,0.4883931263189629,0.4892975580343684,0.49140789870364787,0.49261380765752183,0.4935182393729273,0.49412119384986436,0.4962315345191438,0.49743744347301777,0.5001507386192342,0.5007536930961712,0.5010551703346398,0.5016581248115767,0.5034669882423877,0.5040699427193247,0.5049743744347301,0.5061802833886042,0.5097980102502261,0.5104009647271631,0.5113053964425686,0.5122098281579741,0.5134157371118481,0.514018691588785,0.514621646065722,0.5152246005426591,0.5179378956888755,0.5188423274042809,0.519445281881218,0.520048236358155,0.5209526680735604,0.5215556225504975,0.5218570997889659,0.5224600542659029,0.5227615315043714,0.5233644859813084,0.5254748266505879,0.5260777811275249,0.5312028941814892,0.5321073258968948,0.5363280072354537,0.5372324389508593,0.5384383479047332,0.5390413023816701,0.5411516430509496,0.5417545975278867,0.5432619837202292,0.5438649381971661,0.5444678926741031,0.5450708471510401,0.5456738016279771,0.5462767561049141,0.5562255049743744,0.5568284594513114,0.5586373228821224,0.5598432318359964,0.5625565269822128,0.5631594814591498,0.5676816400361773,0.5682845945131143,0.5691890262285197,0.5697919807054568,0.5709978896593307,0.5719023213747362,0.5758215254748267,0.5764244799517636,0.5797407295749171,0.5803436840518541,0.5818510702441966,0.5824540247211335,0.583358456436539,0.5839614109134761,0.5848658426288815,0.585770274344287,0.5884835694905035,0.5890865239674404,0.5917998191136569,0.5924027735905939,0.5936086825444679,0.5942116370214049,0.5972264094060898,0.5981308411214953,0.5990352728369008,0.5996382273138378,0.6038589086523968,0.6044618631293337,0.6056677720832078,0.6071751582755502,0.6092854989448296,0.6104914078987036,0.6138076575218571,0.6150135664757311,0.6159179981911366,0.6165209526680736,0.6171239071450105,0.6183298160988845,0.618631293337353,0.61923424781429,0.6195357250527586,0.6207416340066325,0.622249020198975,0.623454929152849,0.6243593608682545,0.6252637925836599,0.6255652698221285,0.6261682242990654,0.6264697015375339,0.6273741332529394,0.6282785649683449,0.6294844739222188,0.6318962918299669,0.6324992463069038,0.6331022007838408,0.6337051552607779,0.6343081097377148,0.6349110642146518,0.6367199276454628,0.6373228821223997,0.6385287910762737,0.6391317455532107,0.6409406089840217,0.6418450406994272,0.6430509496533012,0.6436539041302382,0.6454627675610491,0.6457642447995177,0.6463671992764546,0.6466686765149231,0.6472716309918601,0.6478745854687971,0.6487790171842026,0.650889357853482,0.651492312330419,0.6520952668073561,0.6529996985227615,0.65330117576123,0.6539041302381671,0.6554115164305095,0.6560144709074465,0.6578233343382575,0.6593307205305999,0.6602351522460054,0.6611395839614109,0.6617425384383478,0.6623454929152849,0.6632499246306904,0.6644558335845644,0.6650587880615013,0.6701839011154658,0.6707868555924028,0.6756104914078988,0.6762134458848357,0.6798311727464577,0.6804341272233946,0.6813385589388001,0.6819415134157372,0.6825444678926741,0.6831474223696111,0.6858607175158276,0.686765149231233,0.6952065119083509,0.695809466385288,0.6967138981006934,0.6982212842930359,0.6994271932469098,0.7006331022007838,0.7012360566777208,0.7024419656315948,0.7030449201085318,0.7033463973470003,0.7039493518239373,0.7051552607778113,0.7063611697316853,0.7075670786855592,0.7084715104009647,0.7090744648779017,0.7111848055471812,0.7117877600241181,0.7123907145010552,0.7129936689779922,0.7145010551703347,0.7157069641242086,0.7184202592704251,0.7193246909858305,0.7199276454627676,0.7229424178474525,0.7235453723243895,0.724449804039795,0.7253542357552005,0.7277660536629484,0.7289719626168224,0.729876394332228,0.7301778715706964,0.7313837805245704,0.7316852577630389,0.7322882122399759,0.7334941211938498,0.7340970756707869,0.7353029846246608,0.7392221887247513,0.7398251432016882,0.7404280976786253,0.7416340066324992,0.7422369611094363,0.7431413928248417,0.7437443473017787,0.7446487790171842,0.7452517334941212,0.7455532107325897,0.7461561652095267,0.7500753693096172,0.7506783237865541,0.7521857099788966,0.7527886644558336,0.7552004823635815,0.7558034368405185,0.758516731986735,0.759119686463672,0.7633403678022309,0.763943322279168,0.7651492312330419,0.7657521857099789,0.7708772987639433,0.7714802532408803,0.7738920711486282,0.7747965028640338,0.7753994573409707,0.7763038890563763,0.7769068435333132,0.7787157069641242,0.7793186614410612,0.7808260476334037,0.7814290021103407,0.7817304793488091,0.7835393427796201,0.7850467289719626,0.7859511606873681,0.7880615013566475,0.7886644558335846,0.7889659330720531,0.7898703647874585,0.7910762737413325,0.7916792282182695,0.793186614410612,0.793789568887549,0.794392523364486,0.794995477841423,0.8004220681338559,0.8016279770877299,0.8043412722339464,0.8049442267108833,0.8091649080494423,0.8100693397648477,0.8103708170033163,0.8109737714802533,0.8118782031956587,0.8139885438649382,0.8145914983418752,0.8154959300572807,0.8160988845342176,0.8182092252034971,0.8188121796804342,0.8194151341573711,0.8200180886343081,0.8212239975881821,0.8218269520651191,0.8221284293035875,0.8233343382574616,0.82363581549593,0.824238769972867,0.8251432016882725,0.8257461561652095,0.8314742236961109,0.8323786554115165,0.8356949050346699,0.8365993367500754,0.8387096774193549,0.8393126318962918,0.8399155863732288,0.8405185408501659,0.8408200180886343,0.8414229725655713,0.8423274042809767,0.8429303587579138,0.8438347904733192,0.8444377449502563,0.8465480856195358,0.8471510400964727,0.8480554718118782,0.8492613807657522,0.8519746759119686,0.8525776303889057,0.8561953572505275,0.8570997889659331,0.8610189930660235,0.8616219475429605,0.861923424781429,0.862526379258366,0.86373228821224,0.8643352426891769,0.8673500150738619,0.868555924027736,0.8751884232740428,0.8757913777509798,0.8763943322279167,0.8769972867048538,0.8779017184202593,0.8785046728971962,0.8863430810973771,0.8875489900512511,0.8884534217666566,0.8896593307205306,0.8914681941513416,0.8926741031052156,0.8929755803436841,0.893578534820621,0.8944829665360265,0.8950859210129635,0.8968947844437745,0.8974977389207115,0.899005125113054,0.899608079589991,0.9005125113053964,0.9014169430208019,0.9017184202592704,0.9023213747362074,0.9050346698824239,0.9059391015978293,0.9089538739825144,0.9098583056979198,0.9122701236056677,0.9128730780826048,0.9131745553210733,0.9137775097980102,0.9170937594211637,0.9176967138981007,0.9186011456135061,0.9192041000904432,0.9198070545673802,0.9204100090443171,0.9243292131444076,0.9249321676213446,0.9279469400060295,0.9291528489599036,0.9297558034368405,0.930660235152246,0.931263189629183,0.93186614410612,0.9324690985830569,0.9327705758215254,0.9333735302984625,0.934880916490805,0.9354838709677419,0.936689779921616,0.9372927343985529,0.9394030750678324,0.9403075067832378,0.9496533011757612,0.9502562556526982,0.9511606873681037,0.9517636418450407,0.9562858004220681,0.9571902321374737,0.9589990955682846,0.9596020500452216,0.9617123907145011,0.962315345191438,0.962918299668375,0.963521254145312,0.964727163099186,0.965330117576123,0.967741935483871,0.968947844437745,0.9716611395839614,0.9722640940608984,0.9755803436840519,0.9761832981609888,0.9770877298763944,0.9776906843533313,0.9785951160687368,0.9791980705456738,0.9834187518842328,0.9840217063611697,0.9843231835996382,0.9849261380765753,0.9915586373228821,0.9921615917998191,1.0],\"y\":[0.0,0.058823529411764705,0.11764705882352941,0.11764705882352941,0.23529411764705882,0.23529411764705882,0.29411764705882354,0.29411764705882354,0.29411764705882354,0.29411764705882354,0.29411764705882354,0.29411764705882354,0.29411764705882354,0.29411764705882354,0.35294117647058826,0.35294117647058826,0.35294117647058826,0.4117647058823529,0.4117647058823529,0.4117647058823529,0.4117647058823529,0.5294117647058824,0.5294117647058824,0.5294117647058824,0.5294117647058824,0.5882352941176471,0.5882352941176471,0.5882352941176471,0.5882352941176471,0.5882352941176471,0.5882352941176471,0.5882352941176471,0.5882352941176471,0.5882352941176471,0.6470588235294118,0.6470588235294118,0.6470588235294118,0.6470588235294118,0.6470588235294118,0.6470588235294118,0.6470588235294118,0.6470588235294118,0.6470588235294118,0.6470588235294118,0.6470588235294118,0.6470588235294118,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.8235294117647058,0.8235294117647058,0.8235294117647058,0.8235294117647058,0.8235294117647058,0.8235294117647058,0.8235294117647058,0.8235294117647058,0.8235294117647058,0.8235294117647058,0.8235294117647058,0.8235294117647058,0.8235294117647058,0.8235294117647058,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.9411764705882353,0.9411764705882353,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"type\":\"scatter\"},{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(255, 255, 255, 0)\",\"width\":5},\"name\":\"AUC: 0.9506\",\"showlegend\":true,\"x\":[0.0,0.0,0.0,0.0006029544769369913,0.0006029544769369913,0.002411817907747965,0.002411817907747965,0.004220681338558939,0.00482363581549593,0.006029544769369913,0.006632499246306904,0.007536930961712391,0.008139885438649382,0.011456135061802835,0.011456135061802835,0.01175761230027133,0.01236056677720832,0.01236056677720832,0.012662044015676817,0.013264998492613807,0.014169430208019295,0.014169430208019295,0.01718420259270425,0.018390111546578235,0.01929454326198372,0.01929454326198372,0.019897497738920713,0.020500452215857702,0.021103406692794695,0.02200783840820018,0.022610792885137173,0.02472113355441664,0.02562556526982213,0.027434428700633104,0.027434428700633104,0.028037383177570093,0.028640337654507086,0.029846246608381068,0.03316249623153452,0.03376545070847151,0.03527283690081399,0.03587579137775098,0.037081700331624966,0.037383177570093455,0.03919204100090443,0.039794995477841426,0.039794995477841426,0.0413023816701839,0.04190533614712089,0.04552306300874284,0.046427494724148324,0.047934880916490806,0.0485378353934278,0.04944226710883328,0.05004522158577027,0.05034669882423877,0.05094965330117576,0.05305999397045523,0.05366294844739222,0.054265902924329215,0.0551703346397347,0.05577328911667169,0.056979198070545675,0.058185107024419654,0.058788061501356646,0.060898402170636114,0.0621043111245101,0.06300874283991559,0.06361169731685258,0.06511908350919506,0.06511908350919506,0.07145010551703346,0.07205305999397045,0.07235453723243895,0.07295749170937595,0.07386192342478143,0.07446487790171842,0.07506783237865541,0.0756707868555924,0.07778112752487187,0.07838408200180887,0.07898703647874586,0.07958999095568285,0.08170033162496232,0.08230328610189931,0.08350919505577328,0.08531805848658426,0.08622249020198974,0.08682544467892674,0.08772987639433223,0.08833283087126922,0.0892372625866747,0.09014169430208019,0.09496533011757612,0.0964727163099186,0.09737714802532409,0.09798010250226108,0.09828157974072957,0.102803738317757,0.10491407898703647,0.10581851070244197,0.1100391920410009,0.1100391920410009,0.1106421465179379,0.11124510099487489,0.11456135061802834,0.11606873681037082,0.11667169128730781,0.1169731685257763,0.1178776002411818,0.11848055471811879,0.12028941814892975,0.12511305396442568,0.12631896291829967,0.12692191739523667,0.12722339463370516,0.12722339463370516,0.12782634911064214,0.12873078082604764,0.1305396442568586,0.1308411214953271,0.13204703044920107,0.13295146216460657,0.13596623454929152,0.13626771178776004,0.13687066626469702,0.13867952969550798,0.139282484172445,0.14109134760325595,0.1450105517033464,0.14651793789568887,0.14712089237262588,0.14802532408803135,0.14862827856496835,0.14892975580343684,0.15013566475731083,0.15104009647271632,0.15224600542659028,0.15375339161893278,0.15526077781127526,0.15586373228821224,0.15676816400361773,0.1573711184805547,0.1576725957190232,0.1585770274344287,0.16098884534217667,0.16370214048839313,0.16762134458848357,0.17003316249623154,0.17123907145010553,0.1724449804039795,0.17515827555019595,0.17576123002713295,0.17787157069641243,0.1784745251733494,0.1787760024118179,0.1793789568887549,0.18028338860416038,0.18118782031956587,0.18782031956587278,0.18842327404280976,0.19173952366596322,0.1929454326198372,0.19626168224299065,0.19626168224299065,0.19807054567380164,0.19807054567380164,0.20048236358154958,0.2010853180584866,0.20198974977389206,0.20259270425082906,0.20289418148929755,0.20379861320470305,0.21103406692794693,0.21163702140488394,0.2134458848356949,0.21495327102803738,0.21615917998191136,0.21706361169731686,0.21917395236659631,0.2209828157974073,0.22249020198974978,0.22339463370515525,0.22640940608984023,0.2270123605667772,0.23032861018993067,0.23123304190533614,0.23243895085921012,0.23304190533614713,0.23334338257461562,0.2339463370515526,0.23424781429002112,0.2348507687669581,0.23876997286704854,0.23937292734398552,0.2417847452517335,0.2423876997286705,0.24389508592101297,0.24449804039794995,0.24630690382876091,0.24690985830569792,0.2472113355441664,0.24781429002110342,0.2490201989749774,0.24962315345191438,0.2505275851673199,0.25113053964425686,0.25293940307506785,0.2535423575520048,0.25625565269822126,0.25836599336750077,0.2601748567983117,0.26077781127524874,0.2610792885137172,0.2616822429906542,0.2622851974675912,0.2628881519445282,0.26680735604461864,0.2674103105215556,0.2689176967138981,0.2701236056677721,0.2707265601447091,0.27132951462164606,0.27193246909858304,0.274344287006331,0.27826349110642146,0.27886644558335844,0.28700633102200784,0.2876092854989448,0.2900211034066928,0.29062405788362977,0.29152848959903527,0.2927343985529093,0.29996985227615314,0.3005728067530901,0.3041905336147121,0.3047934880916491,0.311425987337956,0.312028941814893,0.31323485076876695,0.3138378052457039,0.31413928248417244,0.3147422369611094,0.32016882725354234,0.3207717817304793,0.32197769068435333,0.3225806451612903,0.32288212239975883,0.3234850768766958,0.3237865541151643,0.3243895085921013,0.32559541754597526,0.3261983720229123,0.3268013264998493,0.32740428097678625,0.32921314440759725,0.3304190533614712,0.33252939403075066,0.3364485981308411,0.33705155260777814,0.3376545070847151,0.3382574615616521,0.3400663249924631,0.34066927946940007,0.3409707567078686,0.34157371118480556,0.34308109737714804,0.34398552909255353,0.3445884835694905,0.3451914380464275,0.3518239372927344,0.3530298462466084,0.35574314139282487,0.35634609586976185,0.3569490503466988,0.3581549593005728,0.3584564365390413,0.3590593910159783,0.3602652999698523,0.3611697316852578,0.36177268616219477,0.3629785951160687,0.3644859813084112,0.3650889357853482,0.36840518540850165,0.3690081398854386,0.37051552607778115,0.37111848055471813,0.3741332529394031,0.37473620741634006,0.3768465480856195,0.37744950256255655,0.378353934277962,0.379559843231836,0.381368706662647,0.381971661139584,0.38438347904733194,0.3849864335242689,0.38950859210129635,0.39071450105517036,0.39131745553210734,0.39222188724751283,0.3928248417244498,0.39764847753994575,0.39825143201688273,0.4015676816400362,0.40277359059391016,0.40367802230931565,0.40428097678625263,0.4085016581248116,0.40970756707868555,0.41061199879409105,0.41151643050949654,0.413023816701839,0.413626771178776,0.4139282484172445,0.4145312028941815,0.415435634609587,0.41603858908652397,0.4181489297558034,0.4187518842327404,0.42025927042508293,0.4214651793789569,0.42478142900211036,0.42538438347904733,0.43050949653301174,0.43171540548688575,0.4335242689176967,0.4341272233946337,0.4353331323485077,0.43593608682544466,0.43804642749472417,0.43864938197166115,0.44045824540247214,0.4410611998794091,0.4413626771178776,0.4419656315948146,0.44407597226409407,0.445281881217968,0.448296653602653,0.44889960807959,0.449502562556527,0.45010551703346396,0.45161290322580644,0.4522158577027434,0.45342176665661743,0.4540247211335544,0.4555321073258969,0.45613506180283386,0.4567380162797709,0.45794392523364486,0.45914983418751887,0.4600542659029243,0.46065722037986134,0.4612601748567983,0.46608381067229426,0.46668676514923124,0.4681941513415737,0.4687971058185107,0.4751281278263491,0.4757310823032861,0.47723846849562856,0.47784142297256554,0.48085619535725055,0.481760627072656,0.483569490503467,0.48417244498040396,0.4844739222188725,0.48507687669580946,0.4883931263189629,0.4892975580343684,0.49140789870364787,0.49261380765752183,0.4935182393729273,0.49412119384986436,0.4962315345191438,0.49743744347301777,0.5001507386192342,0.5007536930961712,0.5010551703346398,0.5016581248115767,0.5034669882423877,0.5040699427193247,0.5049743744347301,0.5061802833886042,0.5097980102502261,0.5104009647271631,0.5113053964425686,0.5122098281579741,0.5134157371118481,0.514018691588785,0.514621646065722,0.5152246005426591,0.5179378956888755,0.5188423274042809,0.519445281881218,0.520048236358155,0.5209526680735604,0.5215556225504975,0.5218570997889659,0.5224600542659029,0.5227615315043714,0.5233644859813084,0.5254748266505879,0.5260777811275249,0.5312028941814892,0.5321073258968948,0.5363280072354537,0.5372324389508593,0.5384383479047332,0.5390413023816701,0.5411516430509496,0.5417545975278867,0.5432619837202292,0.5438649381971661,0.5444678926741031,0.5450708471510401,0.5456738016279771,0.5462767561049141,0.5562255049743744,0.5568284594513114,0.5586373228821224,0.5598432318359964,0.5625565269822128,0.5631594814591498,0.5676816400361773,0.5682845945131143,0.5691890262285197,0.5697919807054568,0.5709978896593307,0.5719023213747362,0.5758215254748267,0.5764244799517636,0.5797407295749171,0.5803436840518541,0.5818510702441966,0.5824540247211335,0.583358456436539,0.5839614109134761,0.5848658426288815,0.585770274344287,0.5884835694905035,0.5890865239674404,0.5917998191136569,0.5924027735905939,0.5936086825444679,0.5942116370214049,0.5972264094060898,0.5981308411214953,0.5990352728369008,0.5996382273138378,0.6038589086523968,0.6044618631293337,0.6056677720832078,0.6071751582755502,0.6092854989448296,0.6104914078987036,0.6138076575218571,0.6150135664757311,0.6159179981911366,0.6165209526680736,0.6171239071450105,0.6183298160988845,0.618631293337353,0.61923424781429,0.6195357250527586,0.6207416340066325,0.622249020198975,0.623454929152849,0.6243593608682545,0.6252637925836599,0.6255652698221285,0.6261682242990654,0.6264697015375339,0.6273741332529394,0.6282785649683449,0.6294844739222188,0.6318962918299669,0.6324992463069038,0.6331022007838408,0.6337051552607779,0.6343081097377148,0.6349110642146518,0.6367199276454628,0.6373228821223997,0.6385287910762737,0.6391317455532107,0.6409406089840217,0.6418450406994272,0.6430509496533012,0.6436539041302382,0.6454627675610491,0.6457642447995177,0.6463671992764546,0.6466686765149231,0.6472716309918601,0.6478745854687971,0.6487790171842026,0.650889357853482,0.651492312330419,0.6520952668073561,0.6529996985227615,0.65330117576123,0.6539041302381671,0.6554115164305095,0.6560144709074465,0.6578233343382575,0.6593307205305999,0.6602351522460054,0.6611395839614109,0.6617425384383478,0.6623454929152849,0.6632499246306904,0.6644558335845644,0.6650587880615013,0.6701839011154658,0.6707868555924028,0.6756104914078988,0.6762134458848357,0.6798311727464577,0.6804341272233946,0.6813385589388001,0.6819415134157372,0.6825444678926741,0.6831474223696111,0.6858607175158276,0.686765149231233,0.6952065119083509,0.695809466385288,0.6967138981006934,0.6982212842930359,0.6994271932469098,0.7006331022007838,0.7012360566777208,0.7024419656315948,0.7030449201085318,0.7033463973470003,0.7039493518239373,0.7051552607778113,0.7063611697316853,0.7075670786855592,0.7084715104009647,0.7090744648779017,0.7111848055471812,0.7117877600241181,0.7123907145010552,0.7129936689779922,0.7145010551703347,0.7157069641242086,0.7184202592704251,0.7193246909858305,0.7199276454627676,0.7229424178474525,0.7235453723243895,0.724449804039795,0.7253542357552005,0.7277660536629484,0.7289719626168224,0.729876394332228,0.7301778715706964,0.7313837805245704,0.7316852577630389,0.7322882122399759,0.7334941211938498,0.7340970756707869,0.7353029846246608,0.7392221887247513,0.7398251432016882,0.7404280976786253,0.7416340066324992,0.7422369611094363,0.7431413928248417,0.7437443473017787,0.7446487790171842,0.7452517334941212,0.7455532107325897,0.7461561652095267,0.7500753693096172,0.7506783237865541,0.7521857099788966,0.7527886644558336,0.7552004823635815,0.7558034368405185,0.758516731986735,0.759119686463672,0.7633403678022309,0.763943322279168,0.7651492312330419,0.7657521857099789,0.7708772987639433,0.7714802532408803,0.7738920711486282,0.7747965028640338,0.7753994573409707,0.7763038890563763,0.7769068435333132,0.7787157069641242,0.7793186614410612,0.7808260476334037,0.7814290021103407,0.7817304793488091,0.7835393427796201,0.7850467289719626,0.7859511606873681,0.7880615013566475,0.7886644558335846,0.7889659330720531,0.7898703647874585,0.7910762737413325,0.7916792282182695,0.793186614410612,0.793789568887549,0.794392523364486,0.794995477841423,0.8004220681338559,0.8016279770877299,0.8043412722339464,0.8049442267108833,0.8091649080494423,0.8100693397648477,0.8103708170033163,0.8109737714802533,0.8118782031956587,0.8139885438649382,0.8145914983418752,0.8154959300572807,0.8160988845342176,0.8182092252034971,0.8188121796804342,0.8194151341573711,0.8200180886343081,0.8212239975881821,0.8218269520651191,0.8221284293035875,0.8233343382574616,0.82363581549593,0.824238769972867,0.8251432016882725,0.8257461561652095,0.8314742236961109,0.8323786554115165,0.8356949050346699,0.8365993367500754,0.8387096774193549,0.8393126318962918,0.8399155863732288,0.8405185408501659,0.8408200180886343,0.8414229725655713,0.8423274042809767,0.8429303587579138,0.8438347904733192,0.8444377449502563,0.8465480856195358,0.8471510400964727,0.8480554718118782,0.8492613807657522,0.8519746759119686,0.8525776303889057,0.8561953572505275,0.8570997889659331,0.8610189930660235,0.8616219475429605,0.861923424781429,0.862526379258366,0.86373228821224,0.8643352426891769,0.8673500150738619,0.868555924027736,0.8751884232740428,0.8757913777509798,0.8763943322279167,0.8769972867048538,0.8779017184202593,0.8785046728971962,0.8863430810973771,0.8875489900512511,0.8884534217666566,0.8896593307205306,0.8914681941513416,0.8926741031052156,0.8929755803436841,0.893578534820621,0.8944829665360265,0.8950859210129635,0.8968947844437745,0.8974977389207115,0.899005125113054,0.899608079589991,0.9005125113053964,0.9014169430208019,0.9017184202592704,0.9023213747362074,0.9050346698824239,0.9059391015978293,0.9089538739825144,0.9098583056979198,0.9122701236056677,0.9128730780826048,0.9131745553210733,0.9137775097980102,0.9170937594211637,0.9176967138981007,0.9186011456135061,0.9192041000904432,0.9198070545673802,0.9204100090443171,0.9243292131444076,0.9249321676213446,0.9279469400060295,0.9291528489599036,0.9297558034368405,0.930660235152246,0.931263189629183,0.93186614410612,0.9324690985830569,0.9327705758215254,0.9333735302984625,0.934880916490805,0.9354838709677419,0.936689779921616,0.9372927343985529,0.9394030750678324,0.9403075067832378,0.9496533011757612,0.9502562556526982,0.9511606873681037,0.9517636418450407,0.9562858004220681,0.9571902321374737,0.9589990955682846,0.9596020500452216,0.9617123907145011,0.962315345191438,0.962918299668375,0.963521254145312,0.964727163099186,0.965330117576123,0.967741935483871,0.968947844437745,0.9716611395839614,0.9722640940608984,0.9755803436840519,0.9761832981609888,0.9770877298763944,0.9776906843533313,0.9785951160687368,0.9791980705456738,0.9834187518842328,0.9840217063611697,0.9843231835996382,0.9849261380765753,0.9915586373228821,0.9921615917998191,1.0],\"y\":[0.0,0.058823529411764705,0.11764705882352941,0.11764705882352941,0.23529411764705882,0.23529411764705882,0.29411764705882354,0.29411764705882354,0.29411764705882354,0.29411764705882354,0.29411764705882354,0.29411764705882354,0.29411764705882354,0.29411764705882354,0.35294117647058826,0.35294117647058826,0.35294117647058826,0.4117647058823529,0.4117647058823529,0.4117647058823529,0.4117647058823529,0.5294117647058824,0.5294117647058824,0.5294117647058824,0.5294117647058824,0.5882352941176471,0.5882352941176471,0.5882352941176471,0.5882352941176471,0.5882352941176471,0.5882352941176471,0.5882352941176471,0.5882352941176471,0.5882352941176471,0.6470588235294118,0.6470588235294118,0.6470588235294118,0.6470588235294118,0.6470588235294118,0.6470588235294118,0.6470588235294118,0.6470588235294118,0.6470588235294118,0.6470588235294118,0.6470588235294118,0.6470588235294118,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.8235294117647058,0.8235294117647058,0.8235294117647058,0.8235294117647058,0.8235294117647058,0.8235294117647058,0.8235294117647058,0.8235294117647058,0.8235294117647058,0.8235294117647058,0.8235294117647058,0.8235294117647058,0.8235294117647058,0.8235294117647058,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.9411764705882353,0.9411764705882353,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"type\":\"scatter\"},{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(255, 255, 255, 0)\",\"width\":0},\"name\":\"(95% CI: 0.8787-1.0000)\",\"showlegend\":true,\"x\":[0.0,0.0,0.0,0.0006029544769369913,0.0006029544769369913,0.002411817907747965,0.002411817907747965,0.004220681338558939,0.00482363581549593,0.006029544769369913,0.006632499246306904,0.007536930961712391,0.008139885438649382,0.011456135061802835,0.011456135061802835,0.01175761230027133,0.01236056677720832,0.01236056677720832,0.012662044015676817,0.013264998492613807,0.014169430208019295,0.014169430208019295,0.01718420259270425,0.018390111546578235,0.01929454326198372,0.01929454326198372,0.019897497738920713,0.020500452215857702,0.021103406692794695,0.02200783840820018,0.022610792885137173,0.02472113355441664,0.02562556526982213,0.027434428700633104,0.027434428700633104,0.028037383177570093,0.028640337654507086,0.029846246608381068,0.03316249623153452,0.03376545070847151,0.03527283690081399,0.03587579137775098,0.037081700331624966,0.037383177570093455,0.03919204100090443,0.039794995477841426,0.039794995477841426,0.0413023816701839,0.04190533614712089,0.04552306300874284,0.046427494724148324,0.047934880916490806,0.0485378353934278,0.04944226710883328,0.05004522158577027,0.05034669882423877,0.05094965330117576,0.05305999397045523,0.05366294844739222,0.054265902924329215,0.0551703346397347,0.05577328911667169,0.056979198070545675,0.058185107024419654,0.058788061501356646,0.060898402170636114,0.0621043111245101,0.06300874283991559,0.06361169731685258,0.06511908350919506,0.06511908350919506,0.07145010551703346,0.07205305999397045,0.07235453723243895,0.07295749170937595,0.07386192342478143,0.07446487790171842,0.07506783237865541,0.0756707868555924,0.07778112752487187,0.07838408200180887,0.07898703647874586,0.07958999095568285,0.08170033162496232,0.08230328610189931,0.08350919505577328,0.08531805848658426,0.08622249020198974,0.08682544467892674,0.08772987639433223,0.08833283087126922,0.0892372625866747,0.09014169430208019,0.09496533011757612,0.0964727163099186,0.09737714802532409,0.09798010250226108,0.09828157974072957,0.102803738317757,0.10491407898703647,0.10581851070244197,0.1100391920410009,0.1100391920410009,0.1106421465179379,0.11124510099487489,0.11456135061802834,0.11606873681037082,0.11667169128730781,0.1169731685257763,0.1178776002411818,0.11848055471811879,0.12028941814892975,0.12511305396442568,0.12631896291829967,0.12692191739523667,0.12722339463370516,0.12722339463370516,0.12782634911064214,0.12873078082604764,0.1305396442568586,0.1308411214953271,0.13204703044920107,0.13295146216460657,0.13596623454929152,0.13626771178776004,0.13687066626469702,0.13867952969550798,0.139282484172445,0.14109134760325595,0.1450105517033464,0.14651793789568887,0.14712089237262588,0.14802532408803135,0.14862827856496835,0.14892975580343684,0.15013566475731083,0.15104009647271632,0.15224600542659028,0.15375339161893278,0.15526077781127526,0.15586373228821224,0.15676816400361773,0.1573711184805547,0.1576725957190232,0.1585770274344287,0.16098884534217667,0.16370214048839313,0.16762134458848357,0.17003316249623154,0.17123907145010553,0.1724449804039795,0.17515827555019595,0.17576123002713295,0.17787157069641243,0.1784745251733494,0.1787760024118179,0.1793789568887549,0.18028338860416038,0.18118782031956587,0.18782031956587278,0.18842327404280976,0.19173952366596322,0.1929454326198372,0.19626168224299065,0.19626168224299065,0.19807054567380164,0.19807054567380164,0.20048236358154958,0.2010853180584866,0.20198974977389206,0.20259270425082906,0.20289418148929755,0.20379861320470305,0.21103406692794693,0.21163702140488394,0.2134458848356949,0.21495327102803738,0.21615917998191136,0.21706361169731686,0.21917395236659631,0.2209828157974073,0.22249020198974978,0.22339463370515525,0.22640940608984023,0.2270123605667772,0.23032861018993067,0.23123304190533614,0.23243895085921012,0.23304190533614713,0.23334338257461562,0.2339463370515526,0.23424781429002112,0.2348507687669581,0.23876997286704854,0.23937292734398552,0.2417847452517335,0.2423876997286705,0.24389508592101297,0.24449804039794995,0.24630690382876091,0.24690985830569792,0.2472113355441664,0.24781429002110342,0.2490201989749774,0.24962315345191438,0.2505275851673199,0.25113053964425686,0.25293940307506785,0.2535423575520048,0.25625565269822126,0.25836599336750077,0.2601748567983117,0.26077781127524874,0.2610792885137172,0.2616822429906542,0.2622851974675912,0.2628881519445282,0.26680735604461864,0.2674103105215556,0.2689176967138981,0.2701236056677721,0.2707265601447091,0.27132951462164606,0.27193246909858304,0.274344287006331,0.27826349110642146,0.27886644558335844,0.28700633102200784,0.2876092854989448,0.2900211034066928,0.29062405788362977,0.29152848959903527,0.2927343985529093,0.29996985227615314,0.3005728067530901,0.3041905336147121,0.3047934880916491,0.311425987337956,0.312028941814893,0.31323485076876695,0.3138378052457039,0.31413928248417244,0.3147422369611094,0.32016882725354234,0.3207717817304793,0.32197769068435333,0.3225806451612903,0.32288212239975883,0.3234850768766958,0.3237865541151643,0.3243895085921013,0.32559541754597526,0.3261983720229123,0.3268013264998493,0.32740428097678625,0.32921314440759725,0.3304190533614712,0.33252939403075066,0.3364485981308411,0.33705155260777814,0.3376545070847151,0.3382574615616521,0.3400663249924631,0.34066927946940007,0.3409707567078686,0.34157371118480556,0.34308109737714804,0.34398552909255353,0.3445884835694905,0.3451914380464275,0.3518239372927344,0.3530298462466084,0.35574314139282487,0.35634609586976185,0.3569490503466988,0.3581549593005728,0.3584564365390413,0.3590593910159783,0.3602652999698523,0.3611697316852578,0.36177268616219477,0.3629785951160687,0.3644859813084112,0.3650889357853482,0.36840518540850165,0.3690081398854386,0.37051552607778115,0.37111848055471813,0.3741332529394031,0.37473620741634006,0.3768465480856195,0.37744950256255655,0.378353934277962,0.379559843231836,0.381368706662647,0.381971661139584,0.38438347904733194,0.3849864335242689,0.38950859210129635,0.39071450105517036,0.39131745553210734,0.39222188724751283,0.3928248417244498,0.39764847753994575,0.39825143201688273,0.4015676816400362,0.40277359059391016,0.40367802230931565,0.40428097678625263,0.4085016581248116,0.40970756707868555,0.41061199879409105,0.41151643050949654,0.413023816701839,0.413626771178776,0.4139282484172445,0.4145312028941815,0.415435634609587,0.41603858908652397,0.4181489297558034,0.4187518842327404,0.42025927042508293,0.4214651793789569,0.42478142900211036,0.42538438347904733,0.43050949653301174,0.43171540548688575,0.4335242689176967,0.4341272233946337,0.4353331323485077,0.43593608682544466,0.43804642749472417,0.43864938197166115,0.44045824540247214,0.4410611998794091,0.4413626771178776,0.4419656315948146,0.44407597226409407,0.445281881217968,0.448296653602653,0.44889960807959,0.449502562556527,0.45010551703346396,0.45161290322580644,0.4522158577027434,0.45342176665661743,0.4540247211335544,0.4555321073258969,0.45613506180283386,0.4567380162797709,0.45794392523364486,0.45914983418751887,0.4600542659029243,0.46065722037986134,0.4612601748567983,0.46608381067229426,0.46668676514923124,0.4681941513415737,0.4687971058185107,0.4751281278263491,0.4757310823032861,0.47723846849562856,0.47784142297256554,0.48085619535725055,0.481760627072656,0.483569490503467,0.48417244498040396,0.4844739222188725,0.48507687669580946,0.4883931263189629,0.4892975580343684,0.49140789870364787,0.49261380765752183,0.4935182393729273,0.49412119384986436,0.4962315345191438,0.49743744347301777,0.5001507386192342,0.5007536930961712,0.5010551703346398,0.5016581248115767,0.5034669882423877,0.5040699427193247,0.5049743744347301,0.5061802833886042,0.5097980102502261,0.5104009647271631,0.5113053964425686,0.5122098281579741,0.5134157371118481,0.514018691588785,0.514621646065722,0.5152246005426591,0.5179378956888755,0.5188423274042809,0.519445281881218,0.520048236358155,0.5209526680735604,0.5215556225504975,0.5218570997889659,0.5224600542659029,0.5227615315043714,0.5233644859813084,0.5254748266505879,0.5260777811275249,0.5312028941814892,0.5321073258968948,0.5363280072354537,0.5372324389508593,0.5384383479047332,0.5390413023816701,0.5411516430509496,0.5417545975278867,0.5432619837202292,0.5438649381971661,0.5444678926741031,0.5450708471510401,0.5456738016279771,0.5462767561049141,0.5562255049743744,0.5568284594513114,0.5586373228821224,0.5598432318359964,0.5625565269822128,0.5631594814591498,0.5676816400361773,0.5682845945131143,0.5691890262285197,0.5697919807054568,0.5709978896593307,0.5719023213747362,0.5758215254748267,0.5764244799517636,0.5797407295749171,0.5803436840518541,0.5818510702441966,0.5824540247211335,0.583358456436539,0.5839614109134761,0.5848658426288815,0.585770274344287,0.5884835694905035,0.5890865239674404,0.5917998191136569,0.5924027735905939,0.5936086825444679,0.5942116370214049,0.5972264094060898,0.5981308411214953,0.5990352728369008,0.5996382273138378,0.6038589086523968,0.6044618631293337,0.6056677720832078,0.6071751582755502,0.6092854989448296,0.6104914078987036,0.6138076575218571,0.6150135664757311,0.6159179981911366,0.6165209526680736,0.6171239071450105,0.6183298160988845,0.618631293337353,0.61923424781429,0.6195357250527586,0.6207416340066325,0.622249020198975,0.623454929152849,0.6243593608682545,0.6252637925836599,0.6255652698221285,0.6261682242990654,0.6264697015375339,0.6273741332529394,0.6282785649683449,0.6294844739222188,0.6318962918299669,0.6324992463069038,0.6331022007838408,0.6337051552607779,0.6343081097377148,0.6349110642146518,0.6367199276454628,0.6373228821223997,0.6385287910762737,0.6391317455532107,0.6409406089840217,0.6418450406994272,0.6430509496533012,0.6436539041302382,0.6454627675610491,0.6457642447995177,0.6463671992764546,0.6466686765149231,0.6472716309918601,0.6478745854687971,0.6487790171842026,0.650889357853482,0.651492312330419,0.6520952668073561,0.6529996985227615,0.65330117576123,0.6539041302381671,0.6554115164305095,0.6560144709074465,0.6578233343382575,0.6593307205305999,0.6602351522460054,0.6611395839614109,0.6617425384383478,0.6623454929152849,0.6632499246306904,0.6644558335845644,0.6650587880615013,0.6701839011154658,0.6707868555924028,0.6756104914078988,0.6762134458848357,0.6798311727464577,0.6804341272233946,0.6813385589388001,0.6819415134157372,0.6825444678926741,0.6831474223696111,0.6858607175158276,0.686765149231233,0.6952065119083509,0.695809466385288,0.6967138981006934,0.6982212842930359,0.6994271932469098,0.7006331022007838,0.7012360566777208,0.7024419656315948,0.7030449201085318,0.7033463973470003,0.7039493518239373,0.7051552607778113,0.7063611697316853,0.7075670786855592,0.7084715104009647,0.7090744648779017,0.7111848055471812,0.7117877600241181,0.7123907145010552,0.7129936689779922,0.7145010551703347,0.7157069641242086,0.7184202592704251,0.7193246909858305,0.7199276454627676,0.7229424178474525,0.7235453723243895,0.724449804039795,0.7253542357552005,0.7277660536629484,0.7289719626168224,0.729876394332228,0.7301778715706964,0.7313837805245704,0.7316852577630389,0.7322882122399759,0.7334941211938498,0.7340970756707869,0.7353029846246608,0.7392221887247513,0.7398251432016882,0.7404280976786253,0.7416340066324992,0.7422369611094363,0.7431413928248417,0.7437443473017787,0.7446487790171842,0.7452517334941212,0.7455532107325897,0.7461561652095267,0.7500753693096172,0.7506783237865541,0.7521857099788966,0.7527886644558336,0.7552004823635815,0.7558034368405185,0.758516731986735,0.759119686463672,0.7633403678022309,0.763943322279168,0.7651492312330419,0.7657521857099789,0.7708772987639433,0.7714802532408803,0.7738920711486282,0.7747965028640338,0.7753994573409707,0.7763038890563763,0.7769068435333132,0.7787157069641242,0.7793186614410612,0.7808260476334037,0.7814290021103407,0.7817304793488091,0.7835393427796201,0.7850467289719626,0.7859511606873681,0.7880615013566475,0.7886644558335846,0.7889659330720531,0.7898703647874585,0.7910762737413325,0.7916792282182695,0.793186614410612,0.793789568887549,0.794392523364486,0.794995477841423,0.8004220681338559,0.8016279770877299,0.8043412722339464,0.8049442267108833,0.8091649080494423,0.8100693397648477,0.8103708170033163,0.8109737714802533,0.8118782031956587,0.8139885438649382,0.8145914983418752,0.8154959300572807,0.8160988845342176,0.8182092252034971,0.8188121796804342,0.8194151341573711,0.8200180886343081,0.8212239975881821,0.8218269520651191,0.8221284293035875,0.8233343382574616,0.82363581549593,0.824238769972867,0.8251432016882725,0.8257461561652095,0.8314742236961109,0.8323786554115165,0.8356949050346699,0.8365993367500754,0.8387096774193549,0.8393126318962918,0.8399155863732288,0.8405185408501659,0.8408200180886343,0.8414229725655713,0.8423274042809767,0.8429303587579138,0.8438347904733192,0.8444377449502563,0.8465480856195358,0.8471510400964727,0.8480554718118782,0.8492613807657522,0.8519746759119686,0.8525776303889057,0.8561953572505275,0.8570997889659331,0.8610189930660235,0.8616219475429605,0.861923424781429,0.862526379258366,0.86373228821224,0.8643352426891769,0.8673500150738619,0.868555924027736,0.8751884232740428,0.8757913777509798,0.8763943322279167,0.8769972867048538,0.8779017184202593,0.8785046728971962,0.8863430810973771,0.8875489900512511,0.8884534217666566,0.8896593307205306,0.8914681941513416,0.8926741031052156,0.8929755803436841,0.893578534820621,0.8944829665360265,0.8950859210129635,0.8968947844437745,0.8974977389207115,0.899005125113054,0.899608079589991,0.9005125113053964,0.9014169430208019,0.9017184202592704,0.9023213747362074,0.9050346698824239,0.9059391015978293,0.9089538739825144,0.9098583056979198,0.9122701236056677,0.9128730780826048,0.9131745553210733,0.9137775097980102,0.9170937594211637,0.9176967138981007,0.9186011456135061,0.9192041000904432,0.9198070545673802,0.9204100090443171,0.9243292131444076,0.9249321676213446,0.9279469400060295,0.9291528489599036,0.9297558034368405,0.930660235152246,0.931263189629183,0.93186614410612,0.9324690985830569,0.9327705758215254,0.9333735302984625,0.934880916490805,0.9354838709677419,0.936689779921616,0.9372927343985529,0.9394030750678324,0.9403075067832378,0.9496533011757612,0.9502562556526982,0.9511606873681037,0.9517636418450407,0.9562858004220681,0.9571902321374737,0.9589990955682846,0.9596020500452216,0.9617123907145011,0.962315345191438,0.962918299668375,0.963521254145312,0.964727163099186,0.965330117576123,0.967741935483871,0.968947844437745,0.9716611395839614,0.9722640940608984,0.9755803436840519,0.9761832981609888,0.9770877298763944,0.9776906843533313,0.9785951160687368,0.9791980705456738,0.9834187518842328,0.9840217063611697,0.9843231835996382,0.9849261380765753,0.9915586373228821,0.9921615917998191,1.0],\"y\":[0.0,0.058823529411764705,0.11764705882352941,0.11764705882352941,0.23529411764705882,0.23529411764705882,0.29411764705882354,0.29411764705882354,0.29411764705882354,0.29411764705882354,0.29411764705882354,0.29411764705882354,0.29411764705882354,0.29411764705882354,0.35294117647058826,0.35294117647058826,0.35294117647058826,0.4117647058823529,0.4117647058823529,0.4117647058823529,0.4117647058823529,0.5294117647058824,0.5294117647058824,0.5294117647058824,0.5294117647058824,0.5882352941176471,0.5882352941176471,0.5882352941176471,0.5882352941176471,0.5882352941176471,0.5882352941176471,0.5882352941176471,0.5882352941176471,0.5882352941176471,0.6470588235294118,0.6470588235294118,0.6470588235294118,0.6470588235294118,0.6470588235294118,0.6470588235294118,0.6470588235294118,0.6470588235294118,0.6470588235294118,0.6470588235294118,0.6470588235294118,0.6470588235294118,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7058823529411765,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.7647058823529411,0.8235294117647058,0.8235294117647058,0.8235294117647058,0.8235294117647058,0.8235294117647058,0.8235294117647058,0.8235294117647058,0.8235294117647058,0.8235294117647058,0.8235294117647058,0.8235294117647058,0.8235294117647058,0.8235294117647058,0.8235294117647058,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.8823529411764706,0.9411764705882353,0.9411764705882353,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"type\":\"scatter\"},{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(50, 50, 250, 1.0)\",\"width\":5},\"name\":\"\\u003cb\\u003eOthers\\u003c\\u002fb\\u003e\",\"showlegend\":true,\"x\":[0.0,0.000310077519379845,0.0009302325581395349,0.0009302325581395349,0.00124031007751938,0.0018604651162790699,0.0018604651162790699,0.0027906976744186047,0.004031007751937985,0.004031007751937985,0.00496124031007752,0.0065116279069767444,0.0065116279069767444,0.007131782945736434,0.007131782945736434,0.008682170542635658,0.00992248062015504,0.00992248062015504,0.010542635658914728,0.011472868217054264,0.011472868217054264,0.013333333333333334,0.014263565891472868,0.015503875968992248,0.015503875968992248,0.017674418604651163,0.018294573643410854,0.020465116279069766,0.021085271317829456,0.024496124031007753,0.024496124031007753,0.024806201550387597,0.025426356589147287,0.02573643410852713,0.02573643410852713,0.02635658914728682,0.027286821705426356,0.027286821705426356,0.027596899224806203,0.028217054263565893,0.02945736434108527,0.03007751937984496,0.03162790697674418,0.03224806201550388,0.032868217054263564,0.03348837209302326,0.03441860465116279,0.03472868217054263,0.035348837209302326,0.03689922480620155,0.03782945736434108,0.03813953488372093,0.03875968992248062,0.041550387596899226,0.042480620155038756,0.044651162790697675,0.04527131782945736,0.0462015503875969,0.04744186046511628,0.04837209302325581,0.04961240310077519,0.05023255813953489,0.05147286821705426,0.05147286821705426,0.05271317829457364,0.05581395348837209,0.05581395348837209,0.056434108527131786,0.05798449612403101,0.0586046511627907,0.059224806201550385,0.05984496124031008,0.06077519379844961,0.06108527131782946,0.06108527131782946,0.06697674418604652,0.0675968992248062,0.0703875968992248,0.07100775193798449,0.07131782945736434,0.07131782945736434,0.07286821705426356,0.07348837209302325,0.07410852713178294,0.07472868217054264,0.07565891472868216,0.07627906976744186,0.07689922480620155,0.07782945736434109,0.07937984496124031,0.08062015503875969,0.08155038759689923,0.08217054263565891,0.08682170542635659,0.08744186046511628,0.08775193798449613,0.08868217054263566,0.08930232558139535,0.08992248062015504,0.09302325581395349,0.09395348837209302,0.09457364341085271,0.0951937984496124,0.09550387596899225,0.09674418604651162,0.09798449612403101,0.0986046511627907,0.09922480620155039,0.10232558139534884,0.10263565891472869,0.10325581395348837,0.10418604651162791,0.10449612403100775,0.10635658914728682,0.10728682170542636,0.1082170542635659,0.11162790697674418,0.11224806201550387,0.11348837209302326,0.11410852713178295,0.11503875968992248,0.11906976744186047,0.11968992248062016,0.12,0.12186046511627907,0.12403100775193798,0.12527131782945736,0.1262015503875969,0.12806201550387597,0.12868217054263567,0.12930232558139534,0.12992248062015505,0.13178294573643412,0.1330232558139535,0.13488372093023257,0.13550387596899224,0.13581395348837208,0.13643410852713178,0.13674418604651162,0.13767441860465116,0.13798449612403102,0.13798449612403102,0.13953488372093023,0.14201550387596898,0.14263565891472868,0.14325581395348838,0.14387596899224805,0.1475968992248062,0.14821705426356588,0.14852713178294574,0.14914728682170542,0.14976744186046512,0.15038759689922482,0.15069767441860465,0.15069767441860465,0.15131782945736433,0.1516279069767442,0.15224806201550387,0.15348837209302327,0.15441860465116278,0.15534883720930232,0.15658914728682172,0.15751937984496123,0.15813953488372093,0.16031007751937984,0.16093023255813954,0.16248062015503875,0.16310077519379845,0.16465116279069766,0.16589147286821707,0.1662015503875969,0.16837209302325581,0.16868217054263565,0.16930232558139535,0.1702325581395349,0.17085271317829456,0.17271317829457364,0.17364341085271318,0.17519379844961241,0.17767441860465116,0.17829457364341086,0.17891472868217054,0.17984496124031008,0.1813953488372093,0.1863565891472868,0.18821705426356589,0.1910077519379845,0.19224806201550387,0.19286821705426357,0.19348837209302325,0.19472868217054262,0.19565891472868216,0.19627906976744186,0.19689922480620156,0.1987596899224806,0.1993798449612403,0.2,0.20031007751937985,0.20217054263565892,0.2027906976744186,0.20589147286821705,0.20651162790697675,0.20744186046511628,0.20806201550387596,0.20868217054263566,0.21054263565891473,0.21054263565891473,0.2111627906976744,0.2117829457364341,0.21302325581395348,0.21364341085271318,0.21395348837209302,0.21488372093023256,0.2158139534883721,0.2164341085271318,0.2226356589147287,0.22325581395348837,0.2241860465116279,0.22511627906976744,0.22573643410852715,0.22666666666666666,0.22728682170542636,0.2275968992248062,0.2288372093023256,0.22945736434108527,0.23007751937984497,0.2303875968992248,0.2310077519379845,0.23317829457364342,0.2337984496124031,0.23906976744186045,0.23968992248062015,0.24,0.2412403100775194,0.2427906976744186,0.2434108527131783,0.24372093023255814,0.24434108527131784,0.24527131782945735,0.24589147286821705,0.24651162790697675,0.2474418604651163,0.24806201550387597,0.2496124031007752,0.2505426356589147,0.25116279069767444,0.2517829457364341,0.25333333333333335,0.25395348837209303,0.2545736434108527,0.25519379844961243,0.25829457364341085,0.25922480620155036,0.2598449612403101,0.26046511627906976,0.26170542635658917,0.26232558139534884,0.26325581395348835,0.2641860465116279,0.2648062015503876,0.26573643410852715,0.2682170542635659,0.2688372093023256,0.26976744186046514,0.27162790697674416,0.2722480620155039,0.2731782945736434,0.27472868217054264,0.27565891472868215,0.27689922480620155,0.27782945736434106,0.2787596899224806,0.27906976744186046,0.27968992248062013,0.2806201550387597,0.2812403100775194,0.2827906976744186,0.2834108527131783,0.2834108527131783,0.28713178294573644,0.28837209302325584,0.2896124031007752,0.29054263565891475,0.29426356589147284,0.2948837209302326,0.29550387596899225,0.2961240310077519,0.2973643410852713,0.2986046511627907,0.2992248062015504,0.29984496124031007,0.302015503875969,0.3032558139534884,0.30387596899224806,0.30449612403100773,0.30697674418604654,0.3075968992248062,0.3094573643410853,0.3103875968992248,0.3116279069767442,0.3125581395348837,0.3165891472868217,0.3172093023255814,0.3178294573643411,0.31906976744186044,0.3206201550387597,0.32124031007751935,0.3234108527131783,0.32434108527131783,0.33178294573643413,0.3324031007751938,0.3342635658914729,0.3351937984496124,0.3358139534883721,0.33674418604651163,0.33767441860465114,0.33891472868217054,0.3395348837209302,0.3537984496124031,0.3544186046511628,0.3553488372093023,0.355968992248062,0.35751937984496124,0.3581395348837209,0.35844961240310075,0.3590697674418605,0.3603100775193798,0.36093023255813955,0.3668217054263566,0.36806201550387596,0.37488372093023253,0.37643410852713177,0.3767441860465116,0.3776744186046512,0.377984496124031,0.3786046511627907,0.37953488372093025,0.3801550387596899,0.38046511627906976,0.38170542635658916,0.3841860465116279,0.3848062015503876,0.38666666666666666,0.38790697674418606,0.3937984496124031,0.3944186046511628,0.3965891472868217,0.3978294573643411,0.4006201550387597,0.40124031007751937,0.4018604651162791,0.40248062015503877,0.40651162790697676,0.40713178294573643,0.408062015503876,0.40868217054263567,0.4102325581395349,0.4108527131782946,0.41457364341085273,0.4151937984496124,0.4182945736434108,0.41891472868217056,0.42077519379844963,0.4213953488372093,0.42170542635658914,0.4223255813953488,0.42387596899224805,0.4244961240310077,0.4254263565891473,0.4263565891472868,0.4288372093023256,0.4294573643410853,0.43131782945736435,0.43317829457364343,0.4337984496124031,0.4431007751937984,0.44372093023255815,0.4449612403100775,0.44589147286821706,0.44651162790697674,0.4471317829457364,0.448062015503876,0.44868217054263565,0.4493023255813953,0.4502325581395349,0.4524031007751938,0.4530232558139535,0.4533333333333333,0.45395348837209304,0.4545736434108527,0.4555038759689922,0.45705426356589146,0.4576744186046512,0.45891472868217054,0.4595348837209302,0.46511627906976744,0.4657364341085271,0.4669767441860465,0.4682170542635659,0.46852713178294575,0.4691472868217054,0.4722480620155039,0.4728682170542636,0.4737984496124031,0.4744186046511628,0.4750387596899225,0.47565891472868216,0.4781395348837209,0.47875968992248064,0.4812403100775194,0.48186046511627906,0.4821705426356589,0.4834108527131783,0.48806201550387596,0.4886821705426357,0.48930232558139536,0.48992248062015503,0.49736434108527133,0.497984496124031,0.5017054263565891,0.5023255813953489,0.5072868217054264,0.5082170542635659,0.5091472868217054,0.5097674418604651,0.5103875968992249,0.5110077519379845,0.511937984496124,0.5125581395348837,0.5153488372093024,0.515968992248062,0.5162790697674419,0.5168992248062015,0.517829457364341,0.5184496124031007,0.5190697674418605,0.5196899224806202,0.5212403100775194,0.5224806201550387,0.5227906976744187,0.5234108527131783,0.5311627906976745,0.5324031007751938,0.5348837209302325,0.5358139534883721,0.536124031007752,0.5367441860465116,0.54015503875969,0.5407751937984496,0.5432558139534883,0.5438759689922481,0.5482170542635659,0.5491472868217054,0.5503875968992248,0.5510077519379845,0.5516279069767441,0.5534883720930233,0.5544186046511628,0.5547286821705426,0.5553488372093023,0.5556589147286821,0.5562790697674419,0.5568992248062016,0.5578294573643411,0.5603100775193799,0.5615503875968992,0.5627906976744186,0.5634108527131783,0.5646511627906977,0.5652713178294574,0.5655813953488372,0.5662015503875969,0.569922480620155,0.5705426356589147,0.5714728682170542,0.5720930232558139,0.5742635658914729,0.5748837209302325,0.575813953488372,0.5764341085271317,0.5767441860465117,0.5773643410852713,0.5786046511627907,0.5795348837209302,0.5807751937984497,0.582015503875969,0.5832558139534884,0.5848062015503876,0.5854263565891473,0.586046511627907,0.5866666666666667,0.587906976744186,0.5885271317829457,0.5894573643410853,0.590077519379845,0.5925581395348837,0.5931782945736435,0.5937984496124031,0.5944186046511628,0.5953488372093023,0.595968992248062,0.5978294573643411,0.5984496124031008,0.5987596899224806,0.5993798449612403,0.6003100775193798,0.6009302325581395,0.6034108527131783,0.604031007751938,0.6055813953488373,0.6068217054263566,0.6093023255813953,0.6105426356589148,0.6108527131782946,0.6114728682170543,0.6127131782945736,0.6139534883720931,0.6155038759689923,0.6161240310077519,0.6170542635658914,0.6176744186046511,0.6189147286821706,0.6195348837209302,0.6207751937984496,0.6217054263565891,0.626046511627907,0.6266666666666667,0.6275968992248062,0.6282170542635659,0.6316279069767442,0.6322480620155039,0.6328682170542635,0.6334883720930232,0.6337984496124031,0.6344186046511628,0.6350387596899225,0.6356589147286822,0.635968992248062,0.6365891472868217,0.6368992248062015,0.6375193798449612,0.6384496124031008,0.64,0.6406201550387597,0.6412403100775194,0.6449612403100775,0.6455813953488372,0.6465116279069767,0.649922480620155,0.6505426356589147,0.6551937984496125,0.6558139534883721,0.6567441860465116,0.6573643410852713,0.6610852713178295,0.6617054263565891,0.6629457364341085,0.6635658914728683,0.6648062015503876,0.6654263565891473,0.666046511627907,0.6666666666666666,0.6703875968992248,0.6710077519379845,0.6716279069767442,0.6725581395348837,0.6734883720930233,0.6753488372093023,0.6818604651162791,0.6827906976744186,0.6902325581395349,0.6911627906976744,0.6920930232558139,0.6927131782945737,0.6933333333333334,0.6942635658914729,0.6948837209302325,0.695813953488372,0.7010852713178295,0.7023255813953488,0.7035658914728682,0.7041860465116279,0.7048062015503876,0.7054263565891473,0.7072868217054263,0.707906976744186,0.7082170542635658,0.710077519379845,0.7103875968992248,0.7116279069767442,0.7131782945736435,0.7137984496124031,0.714108527131783,0.7147286821705426,0.7150387596899225,0.7156589147286821,0.7162790697674418,0.7168992248062015,0.7172093023255814,0.7178294573643411,0.72,0.7206201550387596,0.7212403100775194,0.7224806201550388,0.7237209302325581,0.7243410852713178,0.7249612403100775,0.7258914728682171,0.7274418604651163,0.728062015503876,0.7302325581395349,0.7308527131782946,0.7336434108527132,0.7342635658914729,0.7358139534883721,0.7364341085271318,0.7367441860465116,0.7373643410852713,0.7376744186046512,0.7382945736434109,0.7395348837209302,0.7401550387596899,0.7444961240310077,0.7451162790697674,0.7466666666666667,0.7472868217054264,0.7485271317829457,0.7491472868217054,0.7503875968992249,0.7516279069767442,0.7541085271317829,0.7547286821705427,0.7562790697674419,0.7568992248062015,0.7584496124031008,0.7590697674418605,0.76,0.7612403100775194,0.7655813953488372,0.7662015503875969,0.7689922480620155,0.7696124031007752,0.769922480620155,0.7708527131782946,0.7714728682170543,0.772093023255814,0.7727131782945736,0.7773643410852713,0.777984496124031,0.7792248062015504,0.7798449612403101,0.7807751937984496,0.7813953488372093,0.7823255813953488,0.7829457364341085,0.7838759689922481,0.7851162790697674,0.7894573643410853,0.7900775193798449,0.7906976744186046,0.7919379844961241,0.7968992248062016,0.7981395348837209,0.8,0.8009302325581396,0.8027906976744186,0.8034108527131782,0.8043410852713179,0.8049612403100775,0.8062015503875969,0.8068217054263566,0.8096124031007752,0.8105426356589147,0.813953488372093,0.8145736434108527,0.8167441860465117,0.8173643410852713,0.8186046511627907,0.8195348837209302,0.8201550387596899,0.8210852713178295,0.822015503875969,0.8226356589147287,0.8232558139534883,0.823875968992248,0.8244961240310078,0.8251162790697675,0.8269767441860465,0.8282170542635658,0.8288372093023256,0.8297674418604651,0.8303875968992248,0.8310077519379845,0.8316279069767442,0.8334883720930233,0.8344186046511628,0.838139534883721,0.8387596899224806,0.8427906976744186,0.8434108527131783,0.8437209302325581,0.8443410852713178,0.8462015503875969,0.8471317829457364,0.8477519379844961,0.8486821705426356,0.8536434108527132,0.8545736434108527,0.8570542635658914,0.857984496124031,0.8586046511627907,0.8592248062015504,0.8601550387596899,0.8610852713178294,0.8617054263565892,0.8648062015503876,0.8657364341085272,0.8663565891472869,0.8694573643410852,0.8706976744186047,0.8744186046511628,0.8750387596899225,0.8787596899224807,0.8793798449612403,0.8806201550387597,0.881860465116279,0.8877519379844961,0.8883720930232558,0.8893023255813953,0.8905426356589148,0.8911627906976745,0.8917829457364341,0.8924031007751938,0.8930232558139535,0.8967441860465116,0.8973643410852713,0.8982945736434108,0.8989147286821706,0.9026356589147286,0.9032558139534884,0.9054263565891473,0.906046511627907,0.9066666666666666,0.9075968992248062,0.9085271317829458,0.9103875968992248,0.9172093023255814,0.9178294573643411,0.92,0.9206201550387597,0.9237209302325582,0.9243410852713179,0.9252713178294574,0.9262015503875969,0.9268217054263566,0.928062015503876,0.9289922480620155,0.9296124031007752,0.929922480620155,0.9308527131782945,0.9324031007751938,0.9333333333333333,0.9345736434108527,0.9351937984496124,0.9386046511627907,0.9392248062015504,0.9395348837209302,0.94015503875969,0.946046511627907,0.9466666666666667,0.9510077519379845,0.951937984496124,0.9575193798449613,0.958139534883721,0.9612403100775194,0.9618604651162791,0.9631007751937984,0.964031007751938,0.9643410852713178,0.9655813953488372,0.9683720930232558,0.9696124031007752,0.9755038759689922,0.9761240310077519,0.9770542635658914,0.9776744186046512,0.9829457364341085,0.983875968992248,0.9854263565891472,0.986046511627907,0.9866666666666667,0.9872868217054264,0.9906976744186047,0.9913178294573644,0.993798449612403,0.9947286821705427,1.0],\"y\":[0.0,0.0,0.0,0.125,0.125,0.125,0.20833333333333334,0.20833333333333334,0.20833333333333334,0.25,0.25,0.25,0.2916666666666667,0.2916666666666667,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.375,0.375,0.375,0.4166666666666667,0.4166666666666667,0.4166666666666667,0.4166666666666667,0.4583333333333333,0.4583333333333333,0.4583333333333333,0.4583333333333333,0.4583333333333333,0.4583333333333333,0.5,0.5,0.5,0.5,0.5416666666666666,0.5416666666666666,0.5416666666666666,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.7083333333333334,0.7083333333333334,0.7083333333333334,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.7916666666666666,0.7916666666666666,0.7916666666666666,0.7916666666666666,0.7916666666666666,0.7916666666666666,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"type\":\"scatter\"},{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(255, 255, 255, 0)\",\"width\":5},\"name\":\"AUC: 0.9483\",\"showlegend\":true,\"x\":[0.0,0.000310077519379845,0.0009302325581395349,0.0009302325581395349,0.00124031007751938,0.0018604651162790699,0.0018604651162790699,0.0027906976744186047,0.004031007751937985,0.004031007751937985,0.00496124031007752,0.0065116279069767444,0.0065116279069767444,0.007131782945736434,0.007131782945736434,0.008682170542635658,0.00992248062015504,0.00992248062015504,0.010542635658914728,0.011472868217054264,0.011472868217054264,0.013333333333333334,0.014263565891472868,0.015503875968992248,0.015503875968992248,0.017674418604651163,0.018294573643410854,0.020465116279069766,0.021085271317829456,0.024496124031007753,0.024496124031007753,0.024806201550387597,0.025426356589147287,0.02573643410852713,0.02573643410852713,0.02635658914728682,0.027286821705426356,0.027286821705426356,0.027596899224806203,0.028217054263565893,0.02945736434108527,0.03007751937984496,0.03162790697674418,0.03224806201550388,0.032868217054263564,0.03348837209302326,0.03441860465116279,0.03472868217054263,0.035348837209302326,0.03689922480620155,0.03782945736434108,0.03813953488372093,0.03875968992248062,0.041550387596899226,0.042480620155038756,0.044651162790697675,0.04527131782945736,0.0462015503875969,0.04744186046511628,0.04837209302325581,0.04961240310077519,0.05023255813953489,0.05147286821705426,0.05147286821705426,0.05271317829457364,0.05581395348837209,0.05581395348837209,0.056434108527131786,0.05798449612403101,0.0586046511627907,0.059224806201550385,0.05984496124031008,0.06077519379844961,0.06108527131782946,0.06108527131782946,0.06697674418604652,0.0675968992248062,0.0703875968992248,0.07100775193798449,0.07131782945736434,0.07131782945736434,0.07286821705426356,0.07348837209302325,0.07410852713178294,0.07472868217054264,0.07565891472868216,0.07627906976744186,0.07689922480620155,0.07782945736434109,0.07937984496124031,0.08062015503875969,0.08155038759689923,0.08217054263565891,0.08682170542635659,0.08744186046511628,0.08775193798449613,0.08868217054263566,0.08930232558139535,0.08992248062015504,0.09302325581395349,0.09395348837209302,0.09457364341085271,0.0951937984496124,0.09550387596899225,0.09674418604651162,0.09798449612403101,0.0986046511627907,0.09922480620155039,0.10232558139534884,0.10263565891472869,0.10325581395348837,0.10418604651162791,0.10449612403100775,0.10635658914728682,0.10728682170542636,0.1082170542635659,0.11162790697674418,0.11224806201550387,0.11348837209302326,0.11410852713178295,0.11503875968992248,0.11906976744186047,0.11968992248062016,0.12,0.12186046511627907,0.12403100775193798,0.12527131782945736,0.1262015503875969,0.12806201550387597,0.12868217054263567,0.12930232558139534,0.12992248062015505,0.13178294573643412,0.1330232558139535,0.13488372093023257,0.13550387596899224,0.13581395348837208,0.13643410852713178,0.13674418604651162,0.13767441860465116,0.13798449612403102,0.13798449612403102,0.13953488372093023,0.14201550387596898,0.14263565891472868,0.14325581395348838,0.14387596899224805,0.1475968992248062,0.14821705426356588,0.14852713178294574,0.14914728682170542,0.14976744186046512,0.15038759689922482,0.15069767441860465,0.15069767441860465,0.15131782945736433,0.1516279069767442,0.15224806201550387,0.15348837209302327,0.15441860465116278,0.15534883720930232,0.15658914728682172,0.15751937984496123,0.15813953488372093,0.16031007751937984,0.16093023255813954,0.16248062015503875,0.16310077519379845,0.16465116279069766,0.16589147286821707,0.1662015503875969,0.16837209302325581,0.16868217054263565,0.16930232558139535,0.1702325581395349,0.17085271317829456,0.17271317829457364,0.17364341085271318,0.17519379844961241,0.17767441860465116,0.17829457364341086,0.17891472868217054,0.17984496124031008,0.1813953488372093,0.1863565891472868,0.18821705426356589,0.1910077519379845,0.19224806201550387,0.19286821705426357,0.19348837209302325,0.19472868217054262,0.19565891472868216,0.19627906976744186,0.19689922480620156,0.1987596899224806,0.1993798449612403,0.2,0.20031007751937985,0.20217054263565892,0.2027906976744186,0.20589147286821705,0.20651162790697675,0.20744186046511628,0.20806201550387596,0.20868217054263566,0.21054263565891473,0.21054263565891473,0.2111627906976744,0.2117829457364341,0.21302325581395348,0.21364341085271318,0.21395348837209302,0.21488372093023256,0.2158139534883721,0.2164341085271318,0.2226356589147287,0.22325581395348837,0.2241860465116279,0.22511627906976744,0.22573643410852715,0.22666666666666666,0.22728682170542636,0.2275968992248062,0.2288372093023256,0.22945736434108527,0.23007751937984497,0.2303875968992248,0.2310077519379845,0.23317829457364342,0.2337984496124031,0.23906976744186045,0.23968992248062015,0.24,0.2412403100775194,0.2427906976744186,0.2434108527131783,0.24372093023255814,0.24434108527131784,0.24527131782945735,0.24589147286821705,0.24651162790697675,0.2474418604651163,0.24806201550387597,0.2496124031007752,0.2505426356589147,0.25116279069767444,0.2517829457364341,0.25333333333333335,0.25395348837209303,0.2545736434108527,0.25519379844961243,0.25829457364341085,0.25922480620155036,0.2598449612403101,0.26046511627906976,0.26170542635658917,0.26232558139534884,0.26325581395348835,0.2641860465116279,0.2648062015503876,0.26573643410852715,0.2682170542635659,0.2688372093023256,0.26976744186046514,0.27162790697674416,0.2722480620155039,0.2731782945736434,0.27472868217054264,0.27565891472868215,0.27689922480620155,0.27782945736434106,0.2787596899224806,0.27906976744186046,0.27968992248062013,0.2806201550387597,0.2812403100775194,0.2827906976744186,0.2834108527131783,0.2834108527131783,0.28713178294573644,0.28837209302325584,0.2896124031007752,0.29054263565891475,0.29426356589147284,0.2948837209302326,0.29550387596899225,0.2961240310077519,0.2973643410852713,0.2986046511627907,0.2992248062015504,0.29984496124031007,0.302015503875969,0.3032558139534884,0.30387596899224806,0.30449612403100773,0.30697674418604654,0.3075968992248062,0.3094573643410853,0.3103875968992248,0.3116279069767442,0.3125581395348837,0.3165891472868217,0.3172093023255814,0.3178294573643411,0.31906976744186044,0.3206201550387597,0.32124031007751935,0.3234108527131783,0.32434108527131783,0.33178294573643413,0.3324031007751938,0.3342635658914729,0.3351937984496124,0.3358139534883721,0.33674418604651163,0.33767441860465114,0.33891472868217054,0.3395348837209302,0.3537984496124031,0.3544186046511628,0.3553488372093023,0.355968992248062,0.35751937984496124,0.3581395348837209,0.35844961240310075,0.3590697674418605,0.3603100775193798,0.36093023255813955,0.3668217054263566,0.36806201550387596,0.37488372093023253,0.37643410852713177,0.3767441860465116,0.3776744186046512,0.377984496124031,0.3786046511627907,0.37953488372093025,0.3801550387596899,0.38046511627906976,0.38170542635658916,0.3841860465116279,0.3848062015503876,0.38666666666666666,0.38790697674418606,0.3937984496124031,0.3944186046511628,0.3965891472868217,0.3978294573643411,0.4006201550387597,0.40124031007751937,0.4018604651162791,0.40248062015503877,0.40651162790697676,0.40713178294573643,0.408062015503876,0.40868217054263567,0.4102325581395349,0.4108527131782946,0.41457364341085273,0.4151937984496124,0.4182945736434108,0.41891472868217056,0.42077519379844963,0.4213953488372093,0.42170542635658914,0.4223255813953488,0.42387596899224805,0.4244961240310077,0.4254263565891473,0.4263565891472868,0.4288372093023256,0.4294573643410853,0.43131782945736435,0.43317829457364343,0.4337984496124031,0.4431007751937984,0.44372093023255815,0.4449612403100775,0.44589147286821706,0.44651162790697674,0.4471317829457364,0.448062015503876,0.44868217054263565,0.4493023255813953,0.4502325581395349,0.4524031007751938,0.4530232558139535,0.4533333333333333,0.45395348837209304,0.4545736434108527,0.4555038759689922,0.45705426356589146,0.4576744186046512,0.45891472868217054,0.4595348837209302,0.46511627906976744,0.4657364341085271,0.4669767441860465,0.4682170542635659,0.46852713178294575,0.4691472868217054,0.4722480620155039,0.4728682170542636,0.4737984496124031,0.4744186046511628,0.4750387596899225,0.47565891472868216,0.4781395348837209,0.47875968992248064,0.4812403100775194,0.48186046511627906,0.4821705426356589,0.4834108527131783,0.48806201550387596,0.4886821705426357,0.48930232558139536,0.48992248062015503,0.49736434108527133,0.497984496124031,0.5017054263565891,0.5023255813953489,0.5072868217054264,0.5082170542635659,0.5091472868217054,0.5097674418604651,0.5103875968992249,0.5110077519379845,0.511937984496124,0.5125581395348837,0.5153488372093024,0.515968992248062,0.5162790697674419,0.5168992248062015,0.517829457364341,0.5184496124031007,0.5190697674418605,0.5196899224806202,0.5212403100775194,0.5224806201550387,0.5227906976744187,0.5234108527131783,0.5311627906976745,0.5324031007751938,0.5348837209302325,0.5358139534883721,0.536124031007752,0.5367441860465116,0.54015503875969,0.5407751937984496,0.5432558139534883,0.5438759689922481,0.5482170542635659,0.5491472868217054,0.5503875968992248,0.5510077519379845,0.5516279069767441,0.5534883720930233,0.5544186046511628,0.5547286821705426,0.5553488372093023,0.5556589147286821,0.5562790697674419,0.5568992248062016,0.5578294573643411,0.5603100775193799,0.5615503875968992,0.5627906976744186,0.5634108527131783,0.5646511627906977,0.5652713178294574,0.5655813953488372,0.5662015503875969,0.569922480620155,0.5705426356589147,0.5714728682170542,0.5720930232558139,0.5742635658914729,0.5748837209302325,0.575813953488372,0.5764341085271317,0.5767441860465117,0.5773643410852713,0.5786046511627907,0.5795348837209302,0.5807751937984497,0.582015503875969,0.5832558139534884,0.5848062015503876,0.5854263565891473,0.586046511627907,0.5866666666666667,0.587906976744186,0.5885271317829457,0.5894573643410853,0.590077519379845,0.5925581395348837,0.5931782945736435,0.5937984496124031,0.5944186046511628,0.5953488372093023,0.595968992248062,0.5978294573643411,0.5984496124031008,0.5987596899224806,0.5993798449612403,0.6003100775193798,0.6009302325581395,0.6034108527131783,0.604031007751938,0.6055813953488373,0.6068217054263566,0.6093023255813953,0.6105426356589148,0.6108527131782946,0.6114728682170543,0.6127131782945736,0.6139534883720931,0.6155038759689923,0.6161240310077519,0.6170542635658914,0.6176744186046511,0.6189147286821706,0.6195348837209302,0.6207751937984496,0.6217054263565891,0.626046511627907,0.6266666666666667,0.6275968992248062,0.6282170542635659,0.6316279069767442,0.6322480620155039,0.6328682170542635,0.6334883720930232,0.6337984496124031,0.6344186046511628,0.6350387596899225,0.6356589147286822,0.635968992248062,0.6365891472868217,0.6368992248062015,0.6375193798449612,0.6384496124031008,0.64,0.6406201550387597,0.6412403100775194,0.6449612403100775,0.6455813953488372,0.6465116279069767,0.649922480620155,0.6505426356589147,0.6551937984496125,0.6558139534883721,0.6567441860465116,0.6573643410852713,0.6610852713178295,0.6617054263565891,0.6629457364341085,0.6635658914728683,0.6648062015503876,0.6654263565891473,0.666046511627907,0.6666666666666666,0.6703875968992248,0.6710077519379845,0.6716279069767442,0.6725581395348837,0.6734883720930233,0.6753488372093023,0.6818604651162791,0.6827906976744186,0.6902325581395349,0.6911627906976744,0.6920930232558139,0.6927131782945737,0.6933333333333334,0.6942635658914729,0.6948837209302325,0.695813953488372,0.7010852713178295,0.7023255813953488,0.7035658914728682,0.7041860465116279,0.7048062015503876,0.7054263565891473,0.7072868217054263,0.707906976744186,0.7082170542635658,0.710077519379845,0.7103875968992248,0.7116279069767442,0.7131782945736435,0.7137984496124031,0.714108527131783,0.7147286821705426,0.7150387596899225,0.7156589147286821,0.7162790697674418,0.7168992248062015,0.7172093023255814,0.7178294573643411,0.72,0.7206201550387596,0.7212403100775194,0.7224806201550388,0.7237209302325581,0.7243410852713178,0.7249612403100775,0.7258914728682171,0.7274418604651163,0.728062015503876,0.7302325581395349,0.7308527131782946,0.7336434108527132,0.7342635658914729,0.7358139534883721,0.7364341085271318,0.7367441860465116,0.7373643410852713,0.7376744186046512,0.7382945736434109,0.7395348837209302,0.7401550387596899,0.7444961240310077,0.7451162790697674,0.7466666666666667,0.7472868217054264,0.7485271317829457,0.7491472868217054,0.7503875968992249,0.7516279069767442,0.7541085271317829,0.7547286821705427,0.7562790697674419,0.7568992248062015,0.7584496124031008,0.7590697674418605,0.76,0.7612403100775194,0.7655813953488372,0.7662015503875969,0.7689922480620155,0.7696124031007752,0.769922480620155,0.7708527131782946,0.7714728682170543,0.772093023255814,0.7727131782945736,0.7773643410852713,0.777984496124031,0.7792248062015504,0.7798449612403101,0.7807751937984496,0.7813953488372093,0.7823255813953488,0.7829457364341085,0.7838759689922481,0.7851162790697674,0.7894573643410853,0.7900775193798449,0.7906976744186046,0.7919379844961241,0.7968992248062016,0.7981395348837209,0.8,0.8009302325581396,0.8027906976744186,0.8034108527131782,0.8043410852713179,0.8049612403100775,0.8062015503875969,0.8068217054263566,0.8096124031007752,0.8105426356589147,0.813953488372093,0.8145736434108527,0.8167441860465117,0.8173643410852713,0.8186046511627907,0.8195348837209302,0.8201550387596899,0.8210852713178295,0.822015503875969,0.8226356589147287,0.8232558139534883,0.823875968992248,0.8244961240310078,0.8251162790697675,0.8269767441860465,0.8282170542635658,0.8288372093023256,0.8297674418604651,0.8303875968992248,0.8310077519379845,0.8316279069767442,0.8334883720930233,0.8344186046511628,0.838139534883721,0.8387596899224806,0.8427906976744186,0.8434108527131783,0.8437209302325581,0.8443410852713178,0.8462015503875969,0.8471317829457364,0.8477519379844961,0.8486821705426356,0.8536434108527132,0.8545736434108527,0.8570542635658914,0.857984496124031,0.8586046511627907,0.8592248062015504,0.8601550387596899,0.8610852713178294,0.8617054263565892,0.8648062015503876,0.8657364341085272,0.8663565891472869,0.8694573643410852,0.8706976744186047,0.8744186046511628,0.8750387596899225,0.8787596899224807,0.8793798449612403,0.8806201550387597,0.881860465116279,0.8877519379844961,0.8883720930232558,0.8893023255813953,0.8905426356589148,0.8911627906976745,0.8917829457364341,0.8924031007751938,0.8930232558139535,0.8967441860465116,0.8973643410852713,0.8982945736434108,0.8989147286821706,0.9026356589147286,0.9032558139534884,0.9054263565891473,0.906046511627907,0.9066666666666666,0.9075968992248062,0.9085271317829458,0.9103875968992248,0.9172093023255814,0.9178294573643411,0.92,0.9206201550387597,0.9237209302325582,0.9243410852713179,0.9252713178294574,0.9262015503875969,0.9268217054263566,0.928062015503876,0.9289922480620155,0.9296124031007752,0.929922480620155,0.9308527131782945,0.9324031007751938,0.9333333333333333,0.9345736434108527,0.9351937984496124,0.9386046511627907,0.9392248062015504,0.9395348837209302,0.94015503875969,0.946046511627907,0.9466666666666667,0.9510077519379845,0.951937984496124,0.9575193798449613,0.958139534883721,0.9612403100775194,0.9618604651162791,0.9631007751937984,0.964031007751938,0.9643410852713178,0.9655813953488372,0.9683720930232558,0.9696124031007752,0.9755038759689922,0.9761240310077519,0.9770542635658914,0.9776744186046512,0.9829457364341085,0.983875968992248,0.9854263565891472,0.986046511627907,0.9866666666666667,0.9872868217054264,0.9906976744186047,0.9913178294573644,0.993798449612403,0.9947286821705427,1.0],\"y\":[0.0,0.0,0.0,0.125,0.125,0.125,0.20833333333333334,0.20833333333333334,0.20833333333333334,0.25,0.25,0.25,0.2916666666666667,0.2916666666666667,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.375,0.375,0.375,0.4166666666666667,0.4166666666666667,0.4166666666666667,0.4166666666666667,0.4583333333333333,0.4583333333333333,0.4583333333333333,0.4583333333333333,0.4583333333333333,0.4583333333333333,0.5,0.5,0.5,0.5,0.5416666666666666,0.5416666666666666,0.5416666666666666,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.7083333333333334,0.7083333333333334,0.7083333333333334,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.7916666666666666,0.7916666666666666,0.7916666666666666,0.7916666666666666,0.7916666666666666,0.7916666666666666,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"type\":\"scatter\"},{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(255, 255, 255, 0)\",\"width\":0},\"name\":\"(95% CI: 0.8865-1.0000)\",\"showlegend\":true,\"x\":[0.0,0.000310077519379845,0.0009302325581395349,0.0009302325581395349,0.00124031007751938,0.0018604651162790699,0.0018604651162790699,0.0027906976744186047,0.004031007751937985,0.004031007751937985,0.00496124031007752,0.0065116279069767444,0.0065116279069767444,0.007131782945736434,0.007131782945736434,0.008682170542635658,0.00992248062015504,0.00992248062015504,0.010542635658914728,0.011472868217054264,0.011472868217054264,0.013333333333333334,0.014263565891472868,0.015503875968992248,0.015503875968992248,0.017674418604651163,0.018294573643410854,0.020465116279069766,0.021085271317829456,0.024496124031007753,0.024496124031007753,0.024806201550387597,0.025426356589147287,0.02573643410852713,0.02573643410852713,0.02635658914728682,0.027286821705426356,0.027286821705426356,0.027596899224806203,0.028217054263565893,0.02945736434108527,0.03007751937984496,0.03162790697674418,0.03224806201550388,0.032868217054263564,0.03348837209302326,0.03441860465116279,0.03472868217054263,0.035348837209302326,0.03689922480620155,0.03782945736434108,0.03813953488372093,0.03875968992248062,0.041550387596899226,0.042480620155038756,0.044651162790697675,0.04527131782945736,0.0462015503875969,0.04744186046511628,0.04837209302325581,0.04961240310077519,0.05023255813953489,0.05147286821705426,0.05147286821705426,0.05271317829457364,0.05581395348837209,0.05581395348837209,0.056434108527131786,0.05798449612403101,0.0586046511627907,0.059224806201550385,0.05984496124031008,0.06077519379844961,0.06108527131782946,0.06108527131782946,0.06697674418604652,0.0675968992248062,0.0703875968992248,0.07100775193798449,0.07131782945736434,0.07131782945736434,0.07286821705426356,0.07348837209302325,0.07410852713178294,0.07472868217054264,0.07565891472868216,0.07627906976744186,0.07689922480620155,0.07782945736434109,0.07937984496124031,0.08062015503875969,0.08155038759689923,0.08217054263565891,0.08682170542635659,0.08744186046511628,0.08775193798449613,0.08868217054263566,0.08930232558139535,0.08992248062015504,0.09302325581395349,0.09395348837209302,0.09457364341085271,0.0951937984496124,0.09550387596899225,0.09674418604651162,0.09798449612403101,0.0986046511627907,0.09922480620155039,0.10232558139534884,0.10263565891472869,0.10325581395348837,0.10418604651162791,0.10449612403100775,0.10635658914728682,0.10728682170542636,0.1082170542635659,0.11162790697674418,0.11224806201550387,0.11348837209302326,0.11410852713178295,0.11503875968992248,0.11906976744186047,0.11968992248062016,0.12,0.12186046511627907,0.12403100775193798,0.12527131782945736,0.1262015503875969,0.12806201550387597,0.12868217054263567,0.12930232558139534,0.12992248062015505,0.13178294573643412,0.1330232558139535,0.13488372093023257,0.13550387596899224,0.13581395348837208,0.13643410852713178,0.13674418604651162,0.13767441860465116,0.13798449612403102,0.13798449612403102,0.13953488372093023,0.14201550387596898,0.14263565891472868,0.14325581395348838,0.14387596899224805,0.1475968992248062,0.14821705426356588,0.14852713178294574,0.14914728682170542,0.14976744186046512,0.15038759689922482,0.15069767441860465,0.15069767441860465,0.15131782945736433,0.1516279069767442,0.15224806201550387,0.15348837209302327,0.15441860465116278,0.15534883720930232,0.15658914728682172,0.15751937984496123,0.15813953488372093,0.16031007751937984,0.16093023255813954,0.16248062015503875,0.16310077519379845,0.16465116279069766,0.16589147286821707,0.1662015503875969,0.16837209302325581,0.16868217054263565,0.16930232558139535,0.1702325581395349,0.17085271317829456,0.17271317829457364,0.17364341085271318,0.17519379844961241,0.17767441860465116,0.17829457364341086,0.17891472868217054,0.17984496124031008,0.1813953488372093,0.1863565891472868,0.18821705426356589,0.1910077519379845,0.19224806201550387,0.19286821705426357,0.19348837209302325,0.19472868217054262,0.19565891472868216,0.19627906976744186,0.19689922480620156,0.1987596899224806,0.1993798449612403,0.2,0.20031007751937985,0.20217054263565892,0.2027906976744186,0.20589147286821705,0.20651162790697675,0.20744186046511628,0.20806201550387596,0.20868217054263566,0.21054263565891473,0.21054263565891473,0.2111627906976744,0.2117829457364341,0.21302325581395348,0.21364341085271318,0.21395348837209302,0.21488372093023256,0.2158139534883721,0.2164341085271318,0.2226356589147287,0.22325581395348837,0.2241860465116279,0.22511627906976744,0.22573643410852715,0.22666666666666666,0.22728682170542636,0.2275968992248062,0.2288372093023256,0.22945736434108527,0.23007751937984497,0.2303875968992248,0.2310077519379845,0.23317829457364342,0.2337984496124031,0.23906976744186045,0.23968992248062015,0.24,0.2412403100775194,0.2427906976744186,0.2434108527131783,0.24372093023255814,0.24434108527131784,0.24527131782945735,0.24589147286821705,0.24651162790697675,0.2474418604651163,0.24806201550387597,0.2496124031007752,0.2505426356589147,0.25116279069767444,0.2517829457364341,0.25333333333333335,0.25395348837209303,0.2545736434108527,0.25519379844961243,0.25829457364341085,0.25922480620155036,0.2598449612403101,0.26046511627906976,0.26170542635658917,0.26232558139534884,0.26325581395348835,0.2641860465116279,0.2648062015503876,0.26573643410852715,0.2682170542635659,0.2688372093023256,0.26976744186046514,0.27162790697674416,0.2722480620155039,0.2731782945736434,0.27472868217054264,0.27565891472868215,0.27689922480620155,0.27782945736434106,0.2787596899224806,0.27906976744186046,0.27968992248062013,0.2806201550387597,0.2812403100775194,0.2827906976744186,0.2834108527131783,0.2834108527131783,0.28713178294573644,0.28837209302325584,0.2896124031007752,0.29054263565891475,0.29426356589147284,0.2948837209302326,0.29550387596899225,0.2961240310077519,0.2973643410852713,0.2986046511627907,0.2992248062015504,0.29984496124031007,0.302015503875969,0.3032558139534884,0.30387596899224806,0.30449612403100773,0.30697674418604654,0.3075968992248062,0.3094573643410853,0.3103875968992248,0.3116279069767442,0.3125581395348837,0.3165891472868217,0.3172093023255814,0.3178294573643411,0.31906976744186044,0.3206201550387597,0.32124031007751935,0.3234108527131783,0.32434108527131783,0.33178294573643413,0.3324031007751938,0.3342635658914729,0.3351937984496124,0.3358139534883721,0.33674418604651163,0.33767441860465114,0.33891472868217054,0.3395348837209302,0.3537984496124031,0.3544186046511628,0.3553488372093023,0.355968992248062,0.35751937984496124,0.3581395348837209,0.35844961240310075,0.3590697674418605,0.3603100775193798,0.36093023255813955,0.3668217054263566,0.36806201550387596,0.37488372093023253,0.37643410852713177,0.3767441860465116,0.3776744186046512,0.377984496124031,0.3786046511627907,0.37953488372093025,0.3801550387596899,0.38046511627906976,0.38170542635658916,0.3841860465116279,0.3848062015503876,0.38666666666666666,0.38790697674418606,0.3937984496124031,0.3944186046511628,0.3965891472868217,0.3978294573643411,0.4006201550387597,0.40124031007751937,0.4018604651162791,0.40248062015503877,0.40651162790697676,0.40713178294573643,0.408062015503876,0.40868217054263567,0.4102325581395349,0.4108527131782946,0.41457364341085273,0.4151937984496124,0.4182945736434108,0.41891472868217056,0.42077519379844963,0.4213953488372093,0.42170542635658914,0.4223255813953488,0.42387596899224805,0.4244961240310077,0.4254263565891473,0.4263565891472868,0.4288372093023256,0.4294573643410853,0.43131782945736435,0.43317829457364343,0.4337984496124031,0.4431007751937984,0.44372093023255815,0.4449612403100775,0.44589147286821706,0.44651162790697674,0.4471317829457364,0.448062015503876,0.44868217054263565,0.4493023255813953,0.4502325581395349,0.4524031007751938,0.4530232558139535,0.4533333333333333,0.45395348837209304,0.4545736434108527,0.4555038759689922,0.45705426356589146,0.4576744186046512,0.45891472868217054,0.4595348837209302,0.46511627906976744,0.4657364341085271,0.4669767441860465,0.4682170542635659,0.46852713178294575,0.4691472868217054,0.4722480620155039,0.4728682170542636,0.4737984496124031,0.4744186046511628,0.4750387596899225,0.47565891472868216,0.4781395348837209,0.47875968992248064,0.4812403100775194,0.48186046511627906,0.4821705426356589,0.4834108527131783,0.48806201550387596,0.4886821705426357,0.48930232558139536,0.48992248062015503,0.49736434108527133,0.497984496124031,0.5017054263565891,0.5023255813953489,0.5072868217054264,0.5082170542635659,0.5091472868217054,0.5097674418604651,0.5103875968992249,0.5110077519379845,0.511937984496124,0.5125581395348837,0.5153488372093024,0.515968992248062,0.5162790697674419,0.5168992248062015,0.517829457364341,0.5184496124031007,0.5190697674418605,0.5196899224806202,0.5212403100775194,0.5224806201550387,0.5227906976744187,0.5234108527131783,0.5311627906976745,0.5324031007751938,0.5348837209302325,0.5358139534883721,0.536124031007752,0.5367441860465116,0.54015503875969,0.5407751937984496,0.5432558139534883,0.5438759689922481,0.5482170542635659,0.5491472868217054,0.5503875968992248,0.5510077519379845,0.5516279069767441,0.5534883720930233,0.5544186046511628,0.5547286821705426,0.5553488372093023,0.5556589147286821,0.5562790697674419,0.5568992248062016,0.5578294573643411,0.5603100775193799,0.5615503875968992,0.5627906976744186,0.5634108527131783,0.5646511627906977,0.5652713178294574,0.5655813953488372,0.5662015503875969,0.569922480620155,0.5705426356589147,0.5714728682170542,0.5720930232558139,0.5742635658914729,0.5748837209302325,0.575813953488372,0.5764341085271317,0.5767441860465117,0.5773643410852713,0.5786046511627907,0.5795348837209302,0.5807751937984497,0.582015503875969,0.5832558139534884,0.5848062015503876,0.5854263565891473,0.586046511627907,0.5866666666666667,0.587906976744186,0.5885271317829457,0.5894573643410853,0.590077519379845,0.5925581395348837,0.5931782945736435,0.5937984496124031,0.5944186046511628,0.5953488372093023,0.595968992248062,0.5978294573643411,0.5984496124031008,0.5987596899224806,0.5993798449612403,0.6003100775193798,0.6009302325581395,0.6034108527131783,0.604031007751938,0.6055813953488373,0.6068217054263566,0.6093023255813953,0.6105426356589148,0.6108527131782946,0.6114728682170543,0.6127131782945736,0.6139534883720931,0.6155038759689923,0.6161240310077519,0.6170542635658914,0.6176744186046511,0.6189147286821706,0.6195348837209302,0.6207751937984496,0.6217054263565891,0.626046511627907,0.6266666666666667,0.6275968992248062,0.6282170542635659,0.6316279069767442,0.6322480620155039,0.6328682170542635,0.6334883720930232,0.6337984496124031,0.6344186046511628,0.6350387596899225,0.6356589147286822,0.635968992248062,0.6365891472868217,0.6368992248062015,0.6375193798449612,0.6384496124031008,0.64,0.6406201550387597,0.6412403100775194,0.6449612403100775,0.6455813953488372,0.6465116279069767,0.649922480620155,0.6505426356589147,0.6551937984496125,0.6558139534883721,0.6567441860465116,0.6573643410852713,0.6610852713178295,0.6617054263565891,0.6629457364341085,0.6635658914728683,0.6648062015503876,0.6654263565891473,0.666046511627907,0.6666666666666666,0.6703875968992248,0.6710077519379845,0.6716279069767442,0.6725581395348837,0.6734883720930233,0.6753488372093023,0.6818604651162791,0.6827906976744186,0.6902325581395349,0.6911627906976744,0.6920930232558139,0.6927131782945737,0.6933333333333334,0.6942635658914729,0.6948837209302325,0.695813953488372,0.7010852713178295,0.7023255813953488,0.7035658914728682,0.7041860465116279,0.7048062015503876,0.7054263565891473,0.7072868217054263,0.707906976744186,0.7082170542635658,0.710077519379845,0.7103875968992248,0.7116279069767442,0.7131782945736435,0.7137984496124031,0.714108527131783,0.7147286821705426,0.7150387596899225,0.7156589147286821,0.7162790697674418,0.7168992248062015,0.7172093023255814,0.7178294573643411,0.72,0.7206201550387596,0.7212403100775194,0.7224806201550388,0.7237209302325581,0.7243410852713178,0.7249612403100775,0.7258914728682171,0.7274418604651163,0.728062015503876,0.7302325581395349,0.7308527131782946,0.7336434108527132,0.7342635658914729,0.7358139534883721,0.7364341085271318,0.7367441860465116,0.7373643410852713,0.7376744186046512,0.7382945736434109,0.7395348837209302,0.7401550387596899,0.7444961240310077,0.7451162790697674,0.7466666666666667,0.7472868217054264,0.7485271317829457,0.7491472868217054,0.7503875968992249,0.7516279069767442,0.7541085271317829,0.7547286821705427,0.7562790697674419,0.7568992248062015,0.7584496124031008,0.7590697674418605,0.76,0.7612403100775194,0.7655813953488372,0.7662015503875969,0.7689922480620155,0.7696124031007752,0.769922480620155,0.7708527131782946,0.7714728682170543,0.772093023255814,0.7727131782945736,0.7773643410852713,0.777984496124031,0.7792248062015504,0.7798449612403101,0.7807751937984496,0.7813953488372093,0.7823255813953488,0.7829457364341085,0.7838759689922481,0.7851162790697674,0.7894573643410853,0.7900775193798449,0.7906976744186046,0.7919379844961241,0.7968992248062016,0.7981395348837209,0.8,0.8009302325581396,0.8027906976744186,0.8034108527131782,0.8043410852713179,0.8049612403100775,0.8062015503875969,0.8068217054263566,0.8096124031007752,0.8105426356589147,0.813953488372093,0.8145736434108527,0.8167441860465117,0.8173643410852713,0.8186046511627907,0.8195348837209302,0.8201550387596899,0.8210852713178295,0.822015503875969,0.8226356589147287,0.8232558139534883,0.823875968992248,0.8244961240310078,0.8251162790697675,0.8269767441860465,0.8282170542635658,0.8288372093023256,0.8297674418604651,0.8303875968992248,0.8310077519379845,0.8316279069767442,0.8334883720930233,0.8344186046511628,0.838139534883721,0.8387596899224806,0.8427906976744186,0.8434108527131783,0.8437209302325581,0.8443410852713178,0.8462015503875969,0.8471317829457364,0.8477519379844961,0.8486821705426356,0.8536434108527132,0.8545736434108527,0.8570542635658914,0.857984496124031,0.8586046511627907,0.8592248062015504,0.8601550387596899,0.8610852713178294,0.8617054263565892,0.8648062015503876,0.8657364341085272,0.8663565891472869,0.8694573643410852,0.8706976744186047,0.8744186046511628,0.8750387596899225,0.8787596899224807,0.8793798449612403,0.8806201550387597,0.881860465116279,0.8877519379844961,0.8883720930232558,0.8893023255813953,0.8905426356589148,0.8911627906976745,0.8917829457364341,0.8924031007751938,0.8930232558139535,0.8967441860465116,0.8973643410852713,0.8982945736434108,0.8989147286821706,0.9026356589147286,0.9032558139534884,0.9054263565891473,0.906046511627907,0.9066666666666666,0.9075968992248062,0.9085271317829458,0.9103875968992248,0.9172093023255814,0.9178294573643411,0.92,0.9206201550387597,0.9237209302325582,0.9243410852713179,0.9252713178294574,0.9262015503875969,0.9268217054263566,0.928062015503876,0.9289922480620155,0.9296124031007752,0.929922480620155,0.9308527131782945,0.9324031007751938,0.9333333333333333,0.9345736434108527,0.9351937984496124,0.9386046511627907,0.9392248062015504,0.9395348837209302,0.94015503875969,0.946046511627907,0.9466666666666667,0.9510077519379845,0.951937984496124,0.9575193798449613,0.958139534883721,0.9612403100775194,0.9618604651162791,0.9631007751937984,0.964031007751938,0.9643410852713178,0.9655813953488372,0.9683720930232558,0.9696124031007752,0.9755038759689922,0.9761240310077519,0.9770542635658914,0.9776744186046512,0.9829457364341085,0.983875968992248,0.9854263565891472,0.986046511627907,0.9866666666666667,0.9872868217054264,0.9906976744186047,0.9913178294573644,0.993798449612403,0.9947286821705427,1.0],\"y\":[0.0,0.0,0.0,0.125,0.125,0.125,0.20833333333333334,0.20833333333333334,0.20833333333333334,0.25,0.25,0.25,0.2916666666666667,0.2916666666666667,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.375,0.375,0.375,0.4166666666666667,0.4166666666666667,0.4166666666666667,0.4166666666666667,0.4583333333333333,0.4583333333333333,0.4583333333333333,0.4583333333333333,0.4583333333333333,0.4583333333333333,0.5,0.5,0.5,0.5,0.5416666666666666,0.5416666666666666,0.5416666666666666,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.7083333333333334,0.7083333333333334,0.7083333333333334,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.7916666666666666,0.7916666666666666,0.7916666666666666,0.7916666666666666,0.7916666666666666,0.7916666666666666,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.8333333333333334,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9166666666666666,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,0.9583333333333334,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"title\":{\"x\":1},\"legend\":{\"yanchor\":\"bottom\",\"xanchor\":\"right\",\"x\":0.95,\"y\":0.01},\"xaxis\":{\"title\":{\"text\":\"\\u003cb\\u003e1-Specificity\\u003c\\u002fb\\u003e\"},\"range\":[0,1],\"gridcolor\":\"rgba(5, 5, 5, 0.5)\",\"constrain\":\"domain\",\"linecolor\":\"black\"},\"yaxis\":{\"title\":{\"text\":\"\\u003cb\\u003eRecall\\u003c\\u002fb\\u003e\"},\"range\":[0,1],\"gridcolor\":\"rgba(5, 5, 5, 0.5)\",\"scaleanchor\":\"x\",\"scaleratio\":1,\"linecolor\":\"black\"},\"width\":600,\"height\":600,\"font\":{\"family\":\"Times New Roman\",\"size\":22,\"color\":\"Black\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ddfbdf62-290b-4687-9490-ceb3b6251bbc');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "notmarried=test.drop(X_test[X_test['IRMARIT_4 - Never Been Married'] == 0].index)\n",
        "#notmarried=notmarried.sample(85, random_state=43)\n",
        "notmarried_predictors=notmarried.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "notmarried_target=notmarried['UDPYOPI_1 - Yes']\n",
        "elsee=test.drop(X_test[X_test['IRMARIT_4 - Never Been Married'] == 1].index)\n",
        "#elsee=elsee.sample(85, random_state=43)\n",
        "elsee_predictors=elsee.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "elsee_target=elsee['UDPYOPI_1 - Yes']\n",
        "notmarried_prob=network.predict(notmarried_predictors)\n",
        "elsee_prob=network.predict(elsee_predictors)\n",
        "plot_roc_curve2(notmarried_target, notmarried_prob, elsee_target, elsee_prob, 'Never been married', 'Others')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "7f400d98",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f400d98",
        "outputId": "7995179d-d2ef-4604-9fbf-525fc461368e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TtestResult(statistic=46.22787108488224, pvalue=1.6850469005522777e-250, df=1000)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# Not married vs. others\n",
        "df = []\n",
        "for i in range_with_floats(0.0, 100.0, 0.1):\n",
        "        y_pred_notmarried = (notmarried_prob >= i*0.01).astype(bool)\n",
        "        cm_g1 = confusion_matrix(notmarried_target, y_pred_notmarried)\n",
        "        specificity_g1 = cm_g1[0,0]/(cm_g1[0,0]+cm_g1[0,1])\n",
        "        sensitivity_g1 = cm_g1[1,1]/(cm_g1[1,0]+cm_g1[1,1])\n",
        "\n",
        "        y_pred_elsee = (elsee_prob >= i*0.01).astype(bool)\n",
        "        cm_g2 = confusion_matrix(elsee_target, y_pred_elsee)\n",
        "        specificity_g2 = cm_g2[0,0]/(cm_g2[0,0]+cm_g2[0,1])\n",
        "        sensitivity_g2 = cm_g2[1,1]/(cm_g2[1,0]+cm_g2[1,1])\n",
        "\n",
        "        difference=abs(specificity_g1-specificity_g2)+abs(sensitivity_g1-sensitivity_g2)\n",
        "\n",
        "        df.append({'difference':difference, 'threshold':i})\n",
        "\n",
        "df = pd.DataFrame(df)\n",
        "diff=np.array(df['difference'])\n",
        "\n",
        "stats.ttest_1samp(diff, popmean=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "4d260f64",
      "metadata": {
        "id": "4d260f64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a63d403-730a-45a8-809b-ddd5dc4e4568"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.5060003038128513 sensitivity: 1.0 accuracy_g1: 0.5050989802039592 accuracy_g2: 0.5069252077562327 specificity_g1: 0.5025625565269822 specificity_g2: 0.5032558139534884 sensitivity_g1: 1.0 sensitivity_g2: 1.0 difference: 0.0006932574265061664 threshold: 5.799999999999995\n",
            "accuracy: 0.9746316269178186 sensitivity: 0.5121951219512195 accuracy_g1: 0.9754049190161967 accuracy_g2: 0.9738381040320099 specificity_g1: 0.9773892071148629 specificity_g2: 0.9776744186046512 sensitivity_g1: 0.5882352941176471 sensitivity_g2: 0.4583333333333333 difference: 0.1301871722741021 threshold: 50.0\n"
          ]
        }
      ],
      "source": [
        "# Not married vs. others\n",
        "\n",
        "df=[]\n",
        "\n",
        "for i in range_with_floats(0.0, 100.0, 0.1):\n",
        "    y_pred = (prob >= i*0.01).astype(bool)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    acc=(cm[0,0]+cm[1,1])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])\n",
        "    sen=cm[1,1]/(cm[1,0]+cm[1,1])\n",
        "    if sen>=0.5 and  acc>=0.5:\n",
        "        y_pred_notmarried = (notmarried_prob >= i*0.01).astype(bool)\n",
        "        cm_g1 = confusion_matrix(notmarried_target, y_pred_notmarried)\n",
        "        specificity_g1 = cm_g1[0,0]/(cm_g1[0,0]+cm_g1[0,1])\n",
        "        sensitivity_g1 = cm_g1[1,1]/(cm_g1[1,0]+cm_g1[1,1])\n",
        "        accuracy_g1=(cm_g1[0,0]+cm_g1[1,1])/(cm_g1[0,0]+cm_g1[0,1]+cm_g1[1,0]+cm_g1[1,1])\n",
        "        y_pred_elsee = (elsee_prob >= i*0.01).astype(bool)\n",
        "        cm_g2 = confusion_matrix(elsee_target, y_pred_elsee)\n",
        "        specificity_g2 = cm_g2[0,0]/(cm_g2[0,0]+cm_g2[0,1])\n",
        "        sensitivity_g2 = cm_g2[1,1]/(cm_g2[1,0]+cm_g2[1,1])\n",
        "        accuracy_g2=(cm_g2[0,0]+cm_g2[1,1])/(cm_g2[0,0]+cm_g2[0,1]+cm_g2[1,0]+cm_g2[1,1])\n",
        "        difference=abs(specificity_g1-specificity_g2)+abs(sensitivity_g1-sensitivity_g2)\n",
        "\n",
        "        df.append({'accuracy':acc, 'sensitivity':sen, 'accuracy_g1':accuracy_g1, 'accuracy_g2':accuracy_g2, 'specificity_g1':specificity_g1, 'specificity_g2':specificity_g2,'sensitivity_g1':sensitivity_g1,'sensitivity_g2':sensitivity_g2, 'difference':difference, 'threshold':i})\n",
        "\n",
        "df = pd.DataFrame(df)\n",
        "min_diff = df.iloc[df['difference'].idxmin()]\n",
        "print('accuracy:', min_diff[0], 'sensitivity:', min_diff[1], 'accuracy_g1:', min_diff[2], 'accuracy_g2:', min_diff[3], 'specificity_g1:', min_diff[4], 'specificity_g2:', min_diff[5], 'sensitivity_g1:', min_diff[6], 'sensitivity_g2:', min_diff[7], 'difference:', min_diff[8], 'threshold:', min_diff[9])\n",
        "\n",
        "y_pred = (prob >= 50*0.01).astype(bool)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "acc=(cm[0,0]+cm[1,1])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])\n",
        "sen=cm[1,1]/(cm[1,0]+cm[1,1])\n",
        "\n",
        "y_pred_notmarried = (notmarried_prob >= 50*0.01).astype(bool)\n",
        "cm_g1 = confusion_matrix(notmarried_target, y_pred_notmarried)\n",
        "specificity_g1 = cm_g1[0,0]/(cm_g1[0,0]+cm_g1[0,1])\n",
        "sensitivity_g1 = cm_g1[1,1]/(cm_g1[1,0]+cm_g1[1,1])\n",
        "accuracy_g1=(cm_g1[0,0]+cm_g1[1,1])/(cm_g1[0,0]+cm_g1[0,1]+cm_g1[1,0]+cm_g1[1,1])\n",
        "\n",
        "y_pred_elsee = (elsee_prob >= 50*0.01).astype(bool)\n",
        "cm_g2 = confusion_matrix(elsee_target, y_pred_elsee)\n",
        "specificity_g2 = cm_g2[0,0]/(cm_g2[0,0]+cm_g2[0,1])\n",
        "sensitivity_g2 = cm_g2[1,1]/(cm_g2[1,0]+cm_g2[1,1])\n",
        "accuracy_g2=(cm_g2[0,0]+cm_g2[1,1])/(cm_g2[0,0]+cm_g2[0,1]+cm_g2[1,0]+cm_g2[1,1])\n",
        "difference=abs(specificity_g1-specificity_g2)+abs(sensitivity_g1-sensitivity_g2)\n",
        "\n",
        "print('accuracy:', acc, 'sensitivity:', sen, 'accuracy_g1:', accuracy_g1, 'accuracy_g2:', accuracy_g2, 'specificity_g1:', specificity_g1, 'specificity_g2:', specificity_g2, 'sensitivity_g1:', sensitivity_g1, 'sensitivity_g2:', sensitivity_g2, 'difference:', difference, 'threshold:', 50.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "8d97f79b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "id": "8d97f79b",
        "outputId": "f1fdcc66-e2da-4a60-abc5-f3d212921b76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50/50 [==============================] - 0s 3ms/step\n",
            "157/157 [==============================] - 1s 4ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"947457eb-0a52-4c27-b23a-4188d1c69fa4\" class=\"plotly-graph-div\" style=\"height:600px; width:600px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"947457eb-0a52-4c27-b23a-4188d1c69fa4\")) {                    Plotly.newPlot(                        \"947457eb-0a52-4c27-b23a-4188d1c69fa4\",                        [{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(250, 50, 50, 1.0)\",\"width\":5},\"name\":\"\\u003cb\\u003eWorking 35 hours or more\\u003c\\u002fb\\u003e\",\"showlegend\":true,\"x\":[0.0,0.0006349206349206349,0.0006349206349206349,0.0019047619047619048,0.0019047619047619048,0.011428571428571429,0.012698412698412698,0.012698412698412698,0.013333333333333334,0.013333333333333334,0.015873015873015872,0.017142857142857144,0.018412698412698412,0.018412698412698412,0.020317460317460317,0.02158730158730159,0.024761904761904763,0.024761904761904763,0.03492063492063492,0.03619047619047619,0.0380952380952381,0.03936507936507937,0.04634920634920635,0.04634920634920635,0.059682539682539684,0.06095238095238095,0.06222222222222222,0.06349206349206349,0.07428571428571429,0.07555555555555556,0.08063492063492063,0.08190476190476191,0.09714285714285714,0.09841269841269841,0.09968253968253968,0.10095238095238095,0.10222222222222223,0.10476190476190476,0.11174603174603175,0.11428571428571428,0.11936507936507937,0.12063492063492064,0.1288888888888889,0.1307936507936508,0.1384126984126984,0.13968253968253969,0.1492063492063492,0.15047619047619049,0.15555555555555556,0.1568253968253968,0.1619047619047619,0.16317460317460317,0.16444444444444445,0.1657142857142857,0.1688888888888889,0.17142857142857143,0.17587301587301588,0.17714285714285713,0.18031746031746032,0.18158730158730158,0.18666666666666668,0.18666666666666668,0.18984126984126984,0.19111111111111112,0.20063492063492064,0.2019047619047619,0.20253968253968255,0.2038095238095238,0.20952380952380953,0.21079365079365078,0.2146031746031746,0.21587301587301588,0.22095238095238096,0.2222222222222222,0.2311111111111111,0.23238095238095238,0.2342857142857143,0.23555555555555555,0.24,0.24126984126984127,0.24761904761904763,0.24888888888888888,0.2571428571428571,0.2584126984126984,0.2596825396825397,0.2615873015873016,0.2653968253968254,0.2679365079365079,0.2723809523809524,0.27365079365079364,0.28,0.28253968253968254,0.2850793650793651,0.28634920634920635,0.2946031746031746,0.2965079365079365,0.3003174603174603,0.30158730158730157,0.30793650793650795,0.3092063492063492,0.31238095238095237,0.3136507936507936,0.32825396825396824,0.3295238095238095,0.3326984126984127,0.33396825396825397,0.3511111111111111,0.35365079365079366,0.35428571428571426,0.35555555555555557,0.3568253968253968,0.3580952380952381,0.3619047619047619,0.36317460317460315,0.36634920634920637,0.3676190476190476,0.37142857142857144,0.3726984126984127,0.3834920634920635,0.38603174603174606,0.4012698412698413,0.40253968253968253,0.4057142857142857,0.406984126984127,0.4076190476190476,0.41015873015873017,0.41333333333333333,0.4146031746031746,0.41523809523809524,0.4165079365079365,0.4266666666666667,0.42857142857142855,0.4292063492063492,0.43047619047619046,0.433015873015873,0.4342857142857143,0.43555555555555553,0.43682539682539684,0.44126984126984126,0.44253968253968257,0.44571428571428573,0.446984126984127,0.4488888888888889,0.4507936507936508,0.4577777777777778,0.45904761904761904,0.4634920634920635,0.46476190476190476,0.4704761904761905,0.47174603174603175,0.473015873015873,0.4742857142857143,0.47873015873015873,0.48,0.4838095238095238,0.48507936507936505,0.48698412698412696,0.4882539682539683,0.4946031746031746,0.49587301587301585,0.5034920634920635,0.5053968253968254,0.506031746031746,0.5098412698412699,0.5155555555555555,0.5187301587301587,0.5212698412698412,0.5225396825396825,0.525079365079365,0.5288888888888889,0.5295238095238095,0.5307936507936508,0.5346031746031746,0.5358730158730158,0.5371428571428571,0.540952380952381,0.5422222222222223,0.5441269841269841,0.5473015873015873,0.5511111111111111,0.5517460317460318,0.553015873015873,0.5536507936507936,0.5549206349206349,0.5561904761904762,0.5574603174603174,0.5593650793650794,0.5606349206349206,0.5619047619047619,0.5638095238095238,0.566984126984127,0.5688888888888889,0.5707936507936507,0.580952380952381,0.5822222222222222,0.5898412698412698,0.5911111111111111,0.5961904761904762,0.5974603174603175,0.6012698412698413,0.6025396825396825,0.6057142857142858,0.6076190476190476,0.6190476190476191,0.6203174603174603,0.6215873015873016,0.6228571428571429,0.6285714285714286,0.6298412698412699,0.6323809523809524,0.6336507936507937,0.6355555555555555,0.6368253968253968,0.6406349206349207,0.6419047619047619,0.6457142857142857,0.646984126984127,0.6514285714285715,0.6526984126984127,0.6558730158730158,0.6577777777777778,0.6603174603174603,0.6622222222222223,0.6634920634920635,0.6660317460317461,0.6666666666666666,0.6679365079365079,0.6692063492063492,0.6704761904761904,0.6711111111111111,0.6723809523809524,0.6749206349206349,0.6761904761904762,0.6825396825396826,0.6838095238095238,0.693968253968254,0.6952380952380952,0.7168253968253968,0.7180952380952381,0.7193650793650793,0.7206349206349206,0.7225396825396826,0.7238095238095238,0.726984126984127,0.7295238095238096,0.7346031746031746,0.7365079365079366,0.7441269841269841,0.7453968253968254,0.7644444444444445,0.7657142857142857,0.7707936507936508,0.7733333333333333,0.7758730158730158,0.7777777777777778,0.7790476190476191,0.7803174603174603,0.7841269841269841,0.7879365079365079,0.7904761904761904,0.7923809523809524,0.8050793650793651,0.8063492063492064,0.8114285714285714,0.8133333333333334,0.8298412698412698,0.8311111111111111,0.833015873015873,0.8355555555555556,0.8380952380952381,0.8393650793650793,0.8558730158730159,0.8571428571428571,0.8603174603174604,0.8615873015873016,0.8926984126984127,0.8946031746031746,0.8965079365079365,0.8977777777777778,0.9073015873015873,0.9085714285714286,0.9098412698412699,0.9111111111111111,0.9276190476190476,0.9288888888888889,0.9326984126984127,0.933968253968254,0.9650793650793651,0.9663492063492064,0.9676190476190476,0.9688888888888889,0.9841269841269841,0.9853968253968254,0.9949206349206349,0.9961904761904762,1.0],\"y\":[0.0,0.0,0.2222222222222222,0.2222222222222222,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.4444444444444444,0.4444444444444444,0.5555555555555556,0.5555555555555556,0.5555555555555556,0.5555555555555556,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"type\":\"scatter\"},{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(255, 255, 255, 0)\",\"width\":5},\"name\":\"AUC: 0.9661\",\"showlegend\":true,\"x\":[0.0,0.0006349206349206349,0.0006349206349206349,0.0019047619047619048,0.0019047619047619048,0.011428571428571429,0.012698412698412698,0.012698412698412698,0.013333333333333334,0.013333333333333334,0.015873015873015872,0.017142857142857144,0.018412698412698412,0.018412698412698412,0.020317460317460317,0.02158730158730159,0.024761904761904763,0.024761904761904763,0.03492063492063492,0.03619047619047619,0.0380952380952381,0.03936507936507937,0.04634920634920635,0.04634920634920635,0.059682539682539684,0.06095238095238095,0.06222222222222222,0.06349206349206349,0.07428571428571429,0.07555555555555556,0.08063492063492063,0.08190476190476191,0.09714285714285714,0.09841269841269841,0.09968253968253968,0.10095238095238095,0.10222222222222223,0.10476190476190476,0.11174603174603175,0.11428571428571428,0.11936507936507937,0.12063492063492064,0.1288888888888889,0.1307936507936508,0.1384126984126984,0.13968253968253969,0.1492063492063492,0.15047619047619049,0.15555555555555556,0.1568253968253968,0.1619047619047619,0.16317460317460317,0.16444444444444445,0.1657142857142857,0.1688888888888889,0.17142857142857143,0.17587301587301588,0.17714285714285713,0.18031746031746032,0.18158730158730158,0.18666666666666668,0.18666666666666668,0.18984126984126984,0.19111111111111112,0.20063492063492064,0.2019047619047619,0.20253968253968255,0.2038095238095238,0.20952380952380953,0.21079365079365078,0.2146031746031746,0.21587301587301588,0.22095238095238096,0.2222222222222222,0.2311111111111111,0.23238095238095238,0.2342857142857143,0.23555555555555555,0.24,0.24126984126984127,0.24761904761904763,0.24888888888888888,0.2571428571428571,0.2584126984126984,0.2596825396825397,0.2615873015873016,0.2653968253968254,0.2679365079365079,0.2723809523809524,0.27365079365079364,0.28,0.28253968253968254,0.2850793650793651,0.28634920634920635,0.2946031746031746,0.2965079365079365,0.3003174603174603,0.30158730158730157,0.30793650793650795,0.3092063492063492,0.31238095238095237,0.3136507936507936,0.32825396825396824,0.3295238095238095,0.3326984126984127,0.33396825396825397,0.3511111111111111,0.35365079365079366,0.35428571428571426,0.35555555555555557,0.3568253968253968,0.3580952380952381,0.3619047619047619,0.36317460317460315,0.36634920634920637,0.3676190476190476,0.37142857142857144,0.3726984126984127,0.3834920634920635,0.38603174603174606,0.4012698412698413,0.40253968253968253,0.4057142857142857,0.406984126984127,0.4076190476190476,0.41015873015873017,0.41333333333333333,0.4146031746031746,0.41523809523809524,0.4165079365079365,0.4266666666666667,0.42857142857142855,0.4292063492063492,0.43047619047619046,0.433015873015873,0.4342857142857143,0.43555555555555553,0.43682539682539684,0.44126984126984126,0.44253968253968257,0.44571428571428573,0.446984126984127,0.4488888888888889,0.4507936507936508,0.4577777777777778,0.45904761904761904,0.4634920634920635,0.46476190476190476,0.4704761904761905,0.47174603174603175,0.473015873015873,0.4742857142857143,0.47873015873015873,0.48,0.4838095238095238,0.48507936507936505,0.48698412698412696,0.4882539682539683,0.4946031746031746,0.49587301587301585,0.5034920634920635,0.5053968253968254,0.506031746031746,0.5098412698412699,0.5155555555555555,0.5187301587301587,0.5212698412698412,0.5225396825396825,0.525079365079365,0.5288888888888889,0.5295238095238095,0.5307936507936508,0.5346031746031746,0.5358730158730158,0.5371428571428571,0.540952380952381,0.5422222222222223,0.5441269841269841,0.5473015873015873,0.5511111111111111,0.5517460317460318,0.553015873015873,0.5536507936507936,0.5549206349206349,0.5561904761904762,0.5574603174603174,0.5593650793650794,0.5606349206349206,0.5619047619047619,0.5638095238095238,0.566984126984127,0.5688888888888889,0.5707936507936507,0.580952380952381,0.5822222222222222,0.5898412698412698,0.5911111111111111,0.5961904761904762,0.5974603174603175,0.6012698412698413,0.6025396825396825,0.6057142857142858,0.6076190476190476,0.6190476190476191,0.6203174603174603,0.6215873015873016,0.6228571428571429,0.6285714285714286,0.6298412698412699,0.6323809523809524,0.6336507936507937,0.6355555555555555,0.6368253968253968,0.6406349206349207,0.6419047619047619,0.6457142857142857,0.646984126984127,0.6514285714285715,0.6526984126984127,0.6558730158730158,0.6577777777777778,0.6603174603174603,0.6622222222222223,0.6634920634920635,0.6660317460317461,0.6666666666666666,0.6679365079365079,0.6692063492063492,0.6704761904761904,0.6711111111111111,0.6723809523809524,0.6749206349206349,0.6761904761904762,0.6825396825396826,0.6838095238095238,0.693968253968254,0.6952380952380952,0.7168253968253968,0.7180952380952381,0.7193650793650793,0.7206349206349206,0.7225396825396826,0.7238095238095238,0.726984126984127,0.7295238095238096,0.7346031746031746,0.7365079365079366,0.7441269841269841,0.7453968253968254,0.7644444444444445,0.7657142857142857,0.7707936507936508,0.7733333333333333,0.7758730158730158,0.7777777777777778,0.7790476190476191,0.7803174603174603,0.7841269841269841,0.7879365079365079,0.7904761904761904,0.7923809523809524,0.8050793650793651,0.8063492063492064,0.8114285714285714,0.8133333333333334,0.8298412698412698,0.8311111111111111,0.833015873015873,0.8355555555555556,0.8380952380952381,0.8393650793650793,0.8558730158730159,0.8571428571428571,0.8603174603174604,0.8615873015873016,0.8926984126984127,0.8946031746031746,0.8965079365079365,0.8977777777777778,0.9073015873015873,0.9085714285714286,0.9098412698412699,0.9111111111111111,0.9276190476190476,0.9288888888888889,0.9326984126984127,0.933968253968254,0.9650793650793651,0.9663492063492064,0.9676190476190476,0.9688888888888889,0.9841269841269841,0.9853968253968254,0.9949206349206349,0.9961904761904762,1.0],\"y\":[0.0,0.0,0.2222222222222222,0.2222222222222222,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.4444444444444444,0.4444444444444444,0.5555555555555556,0.5555555555555556,0.5555555555555556,0.5555555555555556,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"type\":\"scatter\"},{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(255, 255, 255, 0)\",\"width\":0},\"name\":\"(95% CI: 0.8831-1.0000)\",\"showlegend\":true,\"x\":[0.0,0.0006349206349206349,0.0006349206349206349,0.0019047619047619048,0.0019047619047619048,0.011428571428571429,0.012698412698412698,0.012698412698412698,0.013333333333333334,0.013333333333333334,0.015873015873015872,0.017142857142857144,0.018412698412698412,0.018412698412698412,0.020317460317460317,0.02158730158730159,0.024761904761904763,0.024761904761904763,0.03492063492063492,0.03619047619047619,0.0380952380952381,0.03936507936507937,0.04634920634920635,0.04634920634920635,0.059682539682539684,0.06095238095238095,0.06222222222222222,0.06349206349206349,0.07428571428571429,0.07555555555555556,0.08063492063492063,0.08190476190476191,0.09714285714285714,0.09841269841269841,0.09968253968253968,0.10095238095238095,0.10222222222222223,0.10476190476190476,0.11174603174603175,0.11428571428571428,0.11936507936507937,0.12063492063492064,0.1288888888888889,0.1307936507936508,0.1384126984126984,0.13968253968253969,0.1492063492063492,0.15047619047619049,0.15555555555555556,0.1568253968253968,0.1619047619047619,0.16317460317460317,0.16444444444444445,0.1657142857142857,0.1688888888888889,0.17142857142857143,0.17587301587301588,0.17714285714285713,0.18031746031746032,0.18158730158730158,0.18666666666666668,0.18666666666666668,0.18984126984126984,0.19111111111111112,0.20063492063492064,0.2019047619047619,0.20253968253968255,0.2038095238095238,0.20952380952380953,0.21079365079365078,0.2146031746031746,0.21587301587301588,0.22095238095238096,0.2222222222222222,0.2311111111111111,0.23238095238095238,0.2342857142857143,0.23555555555555555,0.24,0.24126984126984127,0.24761904761904763,0.24888888888888888,0.2571428571428571,0.2584126984126984,0.2596825396825397,0.2615873015873016,0.2653968253968254,0.2679365079365079,0.2723809523809524,0.27365079365079364,0.28,0.28253968253968254,0.2850793650793651,0.28634920634920635,0.2946031746031746,0.2965079365079365,0.3003174603174603,0.30158730158730157,0.30793650793650795,0.3092063492063492,0.31238095238095237,0.3136507936507936,0.32825396825396824,0.3295238095238095,0.3326984126984127,0.33396825396825397,0.3511111111111111,0.35365079365079366,0.35428571428571426,0.35555555555555557,0.3568253968253968,0.3580952380952381,0.3619047619047619,0.36317460317460315,0.36634920634920637,0.3676190476190476,0.37142857142857144,0.3726984126984127,0.3834920634920635,0.38603174603174606,0.4012698412698413,0.40253968253968253,0.4057142857142857,0.406984126984127,0.4076190476190476,0.41015873015873017,0.41333333333333333,0.4146031746031746,0.41523809523809524,0.4165079365079365,0.4266666666666667,0.42857142857142855,0.4292063492063492,0.43047619047619046,0.433015873015873,0.4342857142857143,0.43555555555555553,0.43682539682539684,0.44126984126984126,0.44253968253968257,0.44571428571428573,0.446984126984127,0.4488888888888889,0.4507936507936508,0.4577777777777778,0.45904761904761904,0.4634920634920635,0.46476190476190476,0.4704761904761905,0.47174603174603175,0.473015873015873,0.4742857142857143,0.47873015873015873,0.48,0.4838095238095238,0.48507936507936505,0.48698412698412696,0.4882539682539683,0.4946031746031746,0.49587301587301585,0.5034920634920635,0.5053968253968254,0.506031746031746,0.5098412698412699,0.5155555555555555,0.5187301587301587,0.5212698412698412,0.5225396825396825,0.525079365079365,0.5288888888888889,0.5295238095238095,0.5307936507936508,0.5346031746031746,0.5358730158730158,0.5371428571428571,0.540952380952381,0.5422222222222223,0.5441269841269841,0.5473015873015873,0.5511111111111111,0.5517460317460318,0.553015873015873,0.5536507936507936,0.5549206349206349,0.5561904761904762,0.5574603174603174,0.5593650793650794,0.5606349206349206,0.5619047619047619,0.5638095238095238,0.566984126984127,0.5688888888888889,0.5707936507936507,0.580952380952381,0.5822222222222222,0.5898412698412698,0.5911111111111111,0.5961904761904762,0.5974603174603175,0.6012698412698413,0.6025396825396825,0.6057142857142858,0.6076190476190476,0.6190476190476191,0.6203174603174603,0.6215873015873016,0.6228571428571429,0.6285714285714286,0.6298412698412699,0.6323809523809524,0.6336507936507937,0.6355555555555555,0.6368253968253968,0.6406349206349207,0.6419047619047619,0.6457142857142857,0.646984126984127,0.6514285714285715,0.6526984126984127,0.6558730158730158,0.6577777777777778,0.6603174603174603,0.6622222222222223,0.6634920634920635,0.6660317460317461,0.6666666666666666,0.6679365079365079,0.6692063492063492,0.6704761904761904,0.6711111111111111,0.6723809523809524,0.6749206349206349,0.6761904761904762,0.6825396825396826,0.6838095238095238,0.693968253968254,0.6952380952380952,0.7168253968253968,0.7180952380952381,0.7193650793650793,0.7206349206349206,0.7225396825396826,0.7238095238095238,0.726984126984127,0.7295238095238096,0.7346031746031746,0.7365079365079366,0.7441269841269841,0.7453968253968254,0.7644444444444445,0.7657142857142857,0.7707936507936508,0.7733333333333333,0.7758730158730158,0.7777777777777778,0.7790476190476191,0.7803174603174603,0.7841269841269841,0.7879365079365079,0.7904761904761904,0.7923809523809524,0.8050793650793651,0.8063492063492064,0.8114285714285714,0.8133333333333334,0.8298412698412698,0.8311111111111111,0.833015873015873,0.8355555555555556,0.8380952380952381,0.8393650793650793,0.8558730158730159,0.8571428571428571,0.8603174603174604,0.8615873015873016,0.8926984126984127,0.8946031746031746,0.8965079365079365,0.8977777777777778,0.9073015873015873,0.9085714285714286,0.9098412698412699,0.9111111111111111,0.9276190476190476,0.9288888888888889,0.9326984126984127,0.933968253968254,0.9650793650793651,0.9663492063492064,0.9676190476190476,0.9688888888888889,0.9841269841269841,0.9853968253968254,0.9949206349206349,0.9961904761904762,1.0],\"y\":[0.0,0.0,0.2222222222222222,0.2222222222222222,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.4444444444444444,0.4444444444444444,0.5555555555555556,0.5555555555555556,0.5555555555555556,0.5555555555555556,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,0.8888888888888888,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"type\":\"scatter\"},{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(50, 50, 250, 1.0)\",\"width\":5},\"name\":\"\\u003cb\\u003eOthers\\u003c\\u002fb\\u003e\",\"showlegend\":true,\"x\":[0.0,0.0004026575397624321,0.0004026575397624321,0.0008053150795248641,0.0008053150795248641,0.0010066438494060802,0.0014093013891685123,0.002214616468693376,0.002214616468693376,0.0028186027783370245,0.0036239178578618887,0.0036239178578618887,0.0042279041675055366,0.005435876786792832,0.005838534326555265,0.006442520636198913,0.006442520636198913,0.006845178175961345,0.007046506945842561,0.007046506945842561,0.007650493255486209,0.008053150795248641,0.00865713710489229,0.009462452184417153,0.00966378095429837,0.00966378095429837,0.010267767263942018,0.01067042480370445,0.011274411113348098,0.011274411113348098,0.01167706865311053,0.012079726192872961,0.012482383732635393,0.013086370042279041,0.013287698812160258,0.013287698812160258,0.013489027582041473,0.013891685121803906,0.014294342661566338,0.015099657741091201,0.015300986510972418,0.015300986510972418,0.015502315280853635,0.015502315280853635,0.018320918059190658,0.01912623313871552,0.019931548218240388,0.020334205758002818,0.0213408496074089,0.02174350714717133,0.021944835917052548,0.022347493456814978,0.024964767465270786,0.025568753774914434,0.025568753774914434,0.0263740688544393,0.02677672639420173,0.026978055164082946,0.026978055164082946,0.027179383933964164,0.027582041473726594,0.028186027783370243,0.028186027783370243,0.02838735655325146,0.029192671632776324,0.029595329172538754,0.03040064425206362,0.030601973021944836,0.03100463056170727,0.031205959331588484,0.031608616871350914,0.03180994564123213,0.032212603180994566,0.032615260720756996,0.03321924703040065,0.03342057580028186,0.03382323334004429,0.034829877189450374,0.035232534729212804,0.035836521038856456,0.0364405073485001,0.03825246627743104,0.038856452587074694,0.039863096436480776,0.040668411516005636,0.04127239782564929,0.04187638413529293,0.04207771290517415,0.042480370444936584,0.04368834306422388,0.04409100060398631,0.04409100060398631,0.044694986913629955,0.04509764445339239,0.04570163076303604,0.047312260922085764,0.0477149184618482,0.048721562311254275,0.048721562311254275,0.0489228910811355,0.04972820616066036,0.05113750754982887,0.05174149385947252,0.0527481377088786,0.05315079524864103,0.05355345278840346,0.05395611032816589,0.05395611032816589,0.054157439098047114,0.054560096637809544,0.055566740487215625,0.055969398026978055,0.056372055566740485,0.05717737064626535,0.05737869941614657,0.057781356955909,0.05838534326555265,0.05838534326555265,0.06140527481377089,0.06180793235353332,0.062210589893295754,0.0628145762029394,0.06361989128246426,0.06442520636198913,0.06462653513187035,0.06502919267163278,0.06583450775115764,0.06623716529092007,0.06724380914032616,0.06764646668008858,0.0678477954499698,0.0678477954499698,0.0690557680692571,0.06945842560901953,0.07006241191866318,0.07046506945842561,0.07066639822830682,0.07106905576806925,0.07147171330783168,0.07207569961747534,0.07247835715723777,0.07368632977652506,0.07368632977652506,0.07489430239581236,0.07569961747533722,0.07630360378498087,0.0767062613247433,0.08073283672236763,0.08194080934165492,0.082947453191061,0.08355143950070465,0.08375276827058586,0.08455808335011072,0.0867726998188041,0.08717535735856653,0.08777934366821019,0.08838332997785384,0.08878598751761627,0.0891886450573787,0.08938997382725991,0.09019528890678478,0.09059794644654721,0.09140326152607207,0.0918059190658345,0.09200724783571572,0.09240990537547815,0.09442319307429031,0.09522850815381519,0.09643648077310248,0.0968391383128649,0.09724179585262734,0.097845782162271,0.09824843970203342,0.09865109724179585,0.09885242601167707,0.10006039863096436,0.10066438494060802,0.10106704248037045,0.10227501509965774,0.1028790014093014,0.10610026172740085,0.10750956311656935,0.10791222065633178,0.10871753573585666,0.1093215220455003,0.10952285081538152,0.11032816589490638,0.11052949466478759,0.11354942621300584,0.11415341252264949,0.1167706865311053,0.11797865915039259,0.1181799879202738,0.11858264546003625,0.1205959331588484,0.12140124823837327,0.1218039057781357,0.12220656331789813,0.12281054962754177,0.12341453593718542,0.12381719347694786,0.12442117978659151,0.12603180994564123,0.12603180994564123,0.12643446748540366,0.1268371250251661,0.12723978256492852,0.1294543990336219,0.13025971411314677,0.13106502919267163,0.13166901550231527,0.13227300181195892,0.13267565935172135,0.13388363197100867,0.13408496074088988,0.13730622105898932,0.13791020736863296,0.13831286490839542,0.13871552244815785,0.13911817998792028,0.1393195087578015,0.13992349506744514,0.14012482383732636,0.14012482383732636,0.1405274813770888,0.14093013891685122,0.14133279645661365,0.14133279645661365,0.14153412522649486,0.1419367827662573,0.14233944030601972,0.14395007046506947,0.14415139923495068,0.1445540567747131,0.14475538554459433,0.14596335816388162,0.14636601570364405,0.14757398832293134,0.14898328971209987,0.15099657741091202,0.15160056372055566,0.1520032212603181,0.15240587880008052,0.15280853633984295,0.1534125226494866,0.1534125226494866,0.15361385141936781,0.15401650895913027,0.15462049526877392,0.15502315280853635,0.15522448157841756,0.15562713911818,0.15643245419770485,0.1570364405073485,0.15784175558687336,0.15864707066639822,0.15884839943627943,0.16146567344473525,0.1620696597543789,0.16247231729414133,0.16287497483390376,0.16307630360378497,0.1634789611435474,0.16508959130259715,0.165894906382122,0.16629756392188444,0.16690155023152808,0.1671028790014093,0.16790819408093416,0.16891483793034023,0.1693174954701027,0.16972015300986512,0.1707267968592712,0.17153211193879606,0.17193476947855849,0.17253875578820213,0.173344070867727,0.17374672840748942,0.17435071471713307,0.1757600161063016,0.17616267364606403,0.17656533118582646,0.1769679887255889,0.17737064626535132,0.17877994765451982,0.18059190658345078,0.18300785182202536,0.1848198107509563,0.18643044091000605,0.1870344272196497,0.18743708475941212,0.18804107106905577,0.18824239983893698,0.18904771491846184,0.19005435876786791,0.19186631769679888,0.1920676464666801,0.19247030400644252,0.195691564324542,0.19770485202335414,0.19810750956311657,0.19830883833299778,0.20012079726192872,0.20052345480169118,0.2009261123414536,0.20132876988121604,0.20153009865109725,0.20193275619085968,0.2023354137306221,0.20273807127038454,0.20293940004026575,0.2035433863499094,0.20394604388967183,0.2057580028186028,0.20676464666800887,0.20797261928729616,0.2083752768270586,0.2085766055969398,0.2097845782162271,0.2099859069861083,0.21038856452587074,0.21401248238373263,0.21441513992349506,0.21522045500301992,0.21562311254278235,0.21622709885242603,0.21783772901147574,0.2186430440910006,0.21924703040064425,0.21964968794040668,0.22085766055969397,0.22085766055969397,0.22146164686933764,0.22186430440910007,0.22266961948862493,0.22327360579826858,0.223676263338031,0.22428024964767465,0.2248842359573183,0.2248842359573183,0.22528689349708073,0.22971612643446748,0.2301187839742299,0.23032011274411113,0.23032011274411113,0.231125427823636,0.23172941413327963,0.23193074290316087,0.2323334004429233,0.23334004429232938,0.23414535937185424,0.23454801691161667,0.2349506744513791,0.23575598953090396,0.2361586470706664,0.2363599758405476,0.23676263338031003,0.23696396215019125,0.23756794845983492,0.23797060599959735,0.24421179786591504,0.24461445540567747,0.2450171129454399,0.24541977048520233,0.2462250855647272,0.24662774310448962,0.24783571572377694,0.24823837326353937,0.24904368834306423,0.2500503321924703,0.25045298973223273,0.2512583048117576,0.25186229112140124,0.2528689349708073,0.25347292128045096,0.2536742500503322,0.2540769075900946,0.25488222266961946,0.25548620897926316,0.2558888665190256,0.256291524058788,0.25689551036843167,0.2572981679081941,0.2577008254479565,0.25810348298771896,0.2585061405274814,0.2589087980672438,0.2599154419166499,0.26051942822629354,0.26333803100463055,0.263740688544393,0.26474733239379905,0.2653513187034427,0.2655526474733239,0.2659553050130864,0.2671632776323737,0.2675659351721361,0.26816992148177976,0.2687739077914234,0.2689752365613046,0.26957922287094827,0.2701832091805919,0.27078719549023555,0.27179383933964163,0.27219649687940406,0.2730018119589289,0.2738071270384538,0.2744111133480974,0.27481377088785985,0.27582041473726593,0.27642440104690963,0.27682705858667206,0.2774310448963157,0.278639017515603,0.2790416750553654,0.27924300382524664,0.2798469901348903,0.28085363398429636,0.28145762029394,0.2816589490638212,0.2824642641433461,0.28326957922287094,0.28367223676263337,0.284276223072277,0.28467888061203944,0.28508153815180187,0.28608818200120795,0.28649083954097043,0.28669216831085165,0.2870948258506141,0.28830279846990137,0.2887054560096638,0.28971209985906987,0.2901147573988323,0.2903160861687135,0.29071874370847595,0.2915240587880008,0.29192671632776324,0.29232937386752567,0.2927320314072881,0.2955506341856251,0.29595329172538754,0.29615462049526875,0.2965572780350312,0.29816790819408096,0.29957720958324946,0.2999798671230119,0.30058385343265553,0.3029997986712301,0.30340245621099254,0.30360378498087376,0.3040064425206362,0.3042077712905174,0.30461042883027983,0.30481175760016105,0.3052144151399235,0.3058184014495671,0.30622105898932955,0.3086370042279042,0.30944231930742905,0.3100463056170727,0.31085162069659755,0.3128649083954097,0.31367022347493456,0.3138715522448158,0.31467686732434064,0.31487819609422185,0.3152808536339843,0.3158848399436279,0.31628749748339036,0.316891483793034,0.3185021139520838,0.3229313468894705,0.32353533319911415,0.3245419770485202,0.32514596335816387,0.3313871552244816,0.331789812764244,0.33199114153412523,0.33239379907388766,0.3344070867726998,0.33480974431246224,0.33501107308234346,0.3354137306221059,0.33642037447151196,0.3372256895510368,0.3390376484799678,0.33964163478961146,0.34487618280652305,0.3452788403462855,0.3456814978860479,0.34608415542581034,0.3470907992752164,0.34749345681497884,0.3491040869740286,0.34970807328367226,0.3501107308234347,0.3505133883631971,0.35232534729212805,0.3531306623716529,0.3539359774511778,0.3543386349909402,0.3593718542379706,0.35977451177773306,0.3613851419367828,0.3617877994765452,0.36219045701630764,0.3625931145560701,0.3684316488826253,0.36883430642238774,0.3700422790416751,0.3704449365814375,0.37125025166096237,0.3716529092007248,0.37346486812965574,0.3742701832091806,0.37487416951882424,0.37527682705858667,0.3770887859875176,0.37749144352728004,0.37769277229716125,0.3780954298369237,0.3786994161465673,0.3795047312260922,0.38091403261526074,0.3813166901550232,0.3817193476947856,0.3857459230924099,0.38614858063217233,0.3871552244815784,0.38755788202134084,0.3881618683309845,0.3885645258707469,0.389571169720153,0.3899738272599154,0.39017515602979663,0.39098047110932155,0.39259110126837127,0.3931950875780149,0.39379907388765856,0.394201731427421,0.3968190054358768,0.39782564928528286,0.39802697805516407,0.3986309643648077,0.40104690960338235,0.4014495671431448,0.4018522246829072,0.40225488222266964,0.40265753976243207,0.4030601973021945,0.40386551238171936,0.4058788000805315,0.40628145762029394,0.40648278639017515,0.4068854439299376,0.40769075900946244,0.4080934165492249,0.4084960740889873,0.40930138916851216,0.410106704248037,0.41050936178779945,0.4131266357962553,0.41393195087578016,0.4157439098047111,0.41614656734447353,0.4183611838131669,0.4187638413529293,0.4197704852023354,0.4201731427420978,0.4209784578216227,0.42158244413126633,0.4219851016710288,0.42238775921079125,0.4241997181397222,0.4246023756794846,0.42661566337829676,0.4270183209180592,0.42762230722770284,0.42802496476746527,0.4288302798469901,0.42923293738675256,0.43064223877592106,0.4310448963156835,0.43185021139520835,0.4322528689349708,0.4360781155627139,0.4368834306422388,0.4372860881820012,0.43809140326152607,0.4384940608012885,0.44191664988926915,0.4423193074290316,0.44372860881820014,0.4441312663579626,0.4443325951278438,0.4447352526676062,0.4459432252868935,0.44674854036641837,0.4475538554459432,0.44795651298570566,0.44916448560499295,0.4497684719146366,0.45198308838332996,0.4523857459230924,0.4527884034628548,0.4533923897724985,0.45379504731226095,0.4543990336219046,0.454801691161667,0.4556070062411919,0.4562109925508355,0.45782162270988525,0.4582242802496477,0.4586269377894101,0.45902959532917254,0.4598349104086974,0.4602375679484598,0.46184819810750954,0.462250855647272,0.46406281457620296,0.4648681296557278,0.4715119790618079,0.4727199516810952,0.4737265955305013,0.474330581840145,0.47533722568955106,0.4757398832293135,0.4775518421582444,0.47815582846788807,0.4787598147775317,0.47916247231729414,0.48057177370646265,0.4809744312462251,0.4815784175558687,0.48198107509563115,0.4823837326353936,0.4829877189450372,0.4837930340245621,0.4841956915643245,0.4843970203342058,0.4847996778739682,0.4860076504932555,0.48641030803301794,0.48661163680289915,0.487416951882424,0.4896315683511174,0.49043688343064223,0.4910408697402859,0.4914435272800483,0.4928528286692168,0.49325548620897924,0.494866116368029,0.49526877390779145,0.4962754177571975,0.49667807529695995,0.4970807328367224,0.49768471914636603,0.4984900342258909,0.4988926917656533,0.4996980068451782,0.5003019931548218,0.5007046506945843,0.5011073082343467,0.5013086370042279,0.5021139520837528,0.50332192470304,0.5037245822428025,0.5059391987114958,0.5063418562512583,0.5131870344272197,0.5135896919669821,0.5137910207368633,0.5141936782766258,0.5147976645862694,0.5152003221260318,0.5158043084356755,0.5166096235152003,0.5168109522850816,0.517213609824844,0.5188242399838937,0.5194282262935374,0.5218441715321119,0.5222468290718744,0.5244614455405677,0.5248641030803302,0.5258707469297362,0.5264747332393799,0.528488020938192,0.5288906784779545,0.5292933360177169,0.5296959935574793,0.530299979867123,0.5307026374068854,0.5329172538755789,0.5333199114153413,0.5359371854237971,0.5363398429635595,0.536742500503322,0.5371451580430844,0.537749144352728,0.5381518018924905,0.5387557882021341,0.5391584457418965,0.5407690759009463,0.5411717334407087,0.5413730622105899,0.5417757197503523,0.5429836923696396,0.5435876786792833,0.5447956512985705,0.5456009663780954,0.5466076102275015,0.5472115965371451,0.5474129253070263,0.5478155828467888,0.54801691161667,0.5484195691564324,0.5486208979263136,0.5490235554660761,0.5516408294745319,0.5520434870142943,0.5524461445540568,0.5530501308637005,0.5536541171733441,0.5542581034829878,0.554459432252869,0.5548620897926314,0.5558687336420375,0.5562713911817999,0.5568753774914436,0.557278035031206,0.5586873364203745,0.5594926514998994,0.5631165693577612,0.5637205556674049,0.5693577612240789,0.5701630763036037,0.5705657338433662,0.5725790215421783,0.5731830078518221,0.5735856653915845,0.5739883229313469,0.5751962955506342,0.5755989530903967,0.5784175558687337,0.5788202134084961,0.5818401449567143,0.5822428024964768,0.5850614052748138,0.5856653915844574,0.5860680491242198,0.5864707066639823,0.5868733642037447,0.5878800080531508,0.5882826655929132,0.5900946245218441,0.590899939601369,0.5911012683712502,0.5915039259110126,0.5917052546808939,0.5921079122206563,0.5925105697604187,0.5931145560700624,0.5953291725387558,0.5957318300785183,0.5961344876182807,0.5969398026978056,0.5979464465472116,0.5983491040869741,0.5989530903966177,0.5993557479363801,0.6021743507147171,0.6025770082544796,0.6031809945641232,0.6033823233340044,0.6037849808737669,0.6039863096436481,0.6043889671834105,0.6055969398026978,0.6062009261123414,0.6070062411918663,0.6074088987316287,0.6080128850412724,0.6084155425810348,0.6094221864304409,0.6102275015099657,0.611435474129253,0.6122407892087779,0.6130461042883028,0.6138514193678276,0.615059391987115,0.6158647070666399,0.6166700221461647,0.6170726796859272,0.6200926112341454,0.6204952687739078,0.6229112140124824,0.6233138715522448,0.6239178578618885,0.6243205154016509,0.6247231729414133,0.6251258304811758,0.625327159251057,0.6257298167908194,0.6273404469498691,0.6277431044896316,0.6321723374270183,0.6329776525065431,0.633782967586068,0.6341856251258304,0.6343869538957116,0.6347896114354741,0.6372055566740488,0.6384135292933361,0.6386148580632173,0.6390175156029797,0.6408294745319106,0.6416347896114355,0.6420374471511979,0.6424401046909604,0.643044091000604,0.6436480773102476,0.6440507348500101,0.6444533923897725,0.6454600362391786,0.6462653513187034,0.6464666800885847,0.6468693376283471,0.6470706663982283,0.6478759814777532,0.6492852828669217,0.6500905979464465,0.6512985705657338,0.6519025568753775,0.6521038856452587,0.6527078719549023,0.6529092007247835,0.6537145158043084,0.6541171733440708,0.6547211596537145,0.6551238171934769,0.6555264747332393,0.6581437487416952,0.6589490638212201,0.6593517213609825,0.659754378900745,0.6605596939802698,0.6609623515200322,0.6611636802899135,0.6619689953694383,0.6631769679887256,0.663579625528488,0.6659955707670626,0.6668008858465875,0.6670022146164687,0.6674048721562311,0.6680088584658748,0.6684115160056372,0.6688141735453996,0.6696194886249245,0.6702234749345681,0.6708274612442118,0.671028790014093,0.6720354338634991,0.6724380914032615,0.6728407489430239,0.6732434064827864,0.6736460640225488,0.6750553654117173,0.6754580229514797,0.6762633380310046,0.6768673243406482,0.6770686531105294,0.677471310650292,0.6778739681900544,0.678477954499698,0.6792832695792229,0.6798872558888666,0.6816992148177975,0.6821018723575599,0.6823032011274411,0.6827058586672036,0.6833098449768472,0.6843164888262533,0.6847191463660157,0.6869337628347091,0.6873364203744715,0.6899536943829273,0.6903563519226897,0.6931749547010267,0.6935776122407892,0.6947855848600765,0.6951882423998389,0.6965975437890074,0.6970002013287698,0.6974028588685323,0.6978055164082947,0.699818804107107,0.7002214616468694,0.7004227904167506,0.700825447956513,0.7016307630360379,0.7022347493456815,0.7030400644252064,0.70364405073485,0.7038453795047313,0.7044493658143749,0.7108918864505738,0.7114958727602174,0.7147171330783169,0.7151197906180793,0.7157237769277229,0.7179383933964163,0.7183410509361787,0.7185423797060599,0.7189450372458225,0.7197503523253473,0.7201530098651098,0.7205556674048722,0.7211596537145158,0.7219649687940407,0.7223676263338031,0.7227702838735656,0.7235755989530904,0.7239782564928529,0.7245822428024965,0.7247835715723777,0.7253875578820214,0.7286088182001208,0.7292128045097644,0.7296154620495269,0.7300181195892893,0.7304207771290517,0.731628749748339,0.7320314072881015,0.7324340648278639,0.7328367223676263,0.7338433662170324,0.734447352526676,0.7346486812965572,0.7350513388363197,0.7352526676062009,0.7356553251459633,0.7360579826857258,0.7364606402254882,0.7370646265351318,0.7374672840748943,0.7376686128447755,0.7380712703845379,0.7382725991544191,0.7386752566941815,0.739077914233944,0.7396819005435877,0.7400845580833502,0.7404872156231126,0.7406885443929938,0.7414938594725187,0.7425005033219247,0.7431044896315684,0.7439098047110932,0.7443124622508557,0.7447151197906181,0.7449164485604993,0.7453191061002618,0.7457217636400242,0.7461244211797866,0.746527078719549,0.7471310650291927,0.7485403664183612,0.7489430239581236,0.7515602979665794,0.7523656130461043,0.7549828870545601,0.7553855445943225,0.7561908596738474,0.7565935172136098,0.7573988322931346,0.7578014898328971,0.759613448761828,0.7600161063015904,0.7610227501509966,0.7618280652305215,0.7620293940004027,0.7626333803100463,0.7628347090799276,0.76323736661969,0.7636400241594524,0.7640426816992149,0.7644453392389773,0.7652506543185021,0.7664586269377894,0.7668612844775519,0.7678679283269579,0.7686732434064828,0.770686531105295,0.7710891886450574,0.7720958324944635,0.7724984900342259,0.7743104489631568,0.7751157640426817,0.7767263942017314,0.7771290517414938,0.7775317092812563,0.7783370243607811,0.780148983289712,0.7805516408294745,0.782766257298168,0.7831689148379304,0.7839742299174552,0.7843768874572177,0.7853835313066238,0.7857861888463862,0.7859875176162674,0.786591503925911,0.7867928326957923,0.7875981477753171,0.7877994765451983,0.7882021340849608,0.7926313670223475,0.7938393396416348,0.7954499698006845,0.7962552848802094,0.7972619287296154,0.7978659150392591,0.8000805315079524,0.8004831890477149,0.801489832897121,0.8022951479766459,0.8024964767465271,0.8028991342862896,0.803301791826052,0.8037044493658144,0.8043084356754581,0.8047110932152205,0.8049124219851017,0.8053150795248641,0.8067243809140326,0.8073283672236763,0.8075296959935575,0.8083350110730824,0.8093416549224884,0.8099456412321321,0.8103482987718945,0.8109522850815382,0.8113549426213006,0.8121602577008254,0.8139722166297564,0.8143748741695188,0.8147775317092812,0.8151801892490437,0.8155828467888061,0.8159855043285685,0.8167908194080934,0.8171934769478558,0.8175961344876183,0.8182001207972619,0.8196094221864304,0.8200120797261928,0.8210187235755989,0.8214213811153613,0.8250452989732233,0.825649285282867,0.8260519428226294,0.8276625729816791,0.8282665592913228,0.828467888061204,0.8288705456009664,0.8290718743708476,0.82947453191061,0.8300785182202537,0.8314878196094222,0.8320918059190658,0.8324944634588283,0.8328971209985907,0.8351117374672841,0.8355143950070465,0.8363197100865714,0.8367223676263338,0.8379303402456211,0.8383329977853835,0.8387356553251459,0.8391383128649084,0.839742299174552,0.8401449567143144,0.8403462854841957,0.8407489430239581,0.8411516005637205,0.8415542581034829,0.8419569156432454,0.8423595731830078,0.8431648882625327,0.8439702033420576,0.8453795047312261,0.8459834910408698,0.8465874773505134,0.8471914636601571,0.8530299979867123,0.8542379706059996,0.854640628145762,0.8550432856855245,0.8556472719951681,0.8562512583048117,0.8566539158445742,0.857459230924099,0.8580632172337427,0.8582645460036239,0.8588685323132675,0.85927118985303,0.8614858063217233,0.8622911214012482,0.8634990940205355,0.8641030803301791,0.8649083954097041,0.8655123817193477,0.8659150392591102,0.8687336420374472,0.8691362995772096,0.8693376283470908,0.8697402858868533,0.8703442721964969,0.8711495872760218,0.8719549023555466,0.8727602174350715,0.87416951882424,0.8745721763640024,0.8783974229917455,0.8792027380712704,0.879806724380914,0.8814173545399637,0.8818200120797262,0.8832293134688947,0.8836319710086571,0.8854439299375881,0.886249245017113,0.8868532313267566,0.8872558888665191,0.8896718341050937,0.8900744916448561,0.8922891081135494,0.8926917656533119,0.8955103684316489,0.8959130259714113,0.8961143547412925,0.8969196698208174,0.8979263136702235,0.8983289712099859,0.8985302999798671,0.8991342862895108,0.9001409301389168,0.9013489027582041,0.9045701630763036,0.9053754781558284,0.9057781356955908,0.9061807932353533,0.9063821220052346,0.906784779544997,0.9083954097040468,0.9087980672438092,0.9098047110932153,0.9106100261727401,0.9120193275619086,0.912421985101671,0.9126233138715523,0.9130259714113147,0.9158445741896517,0.9162472317294141,0.9164485604992954,0.9168512180390578,0.9178578618884639,0.9184618481981075,0.9186631769679887,0.9192671632776324,0.9194684920475136,0.919871149587276,0.9206764646668009,0.9212804509764445,0.9214817797463257,0.9218844372860882,0.9224884235957318,0.9230924099053754,0.9236963962150191,0.924501711294544,0.9251056976041876,0.9261123414535937,0.9267163277632373,0.9283269579222871,0.9287296154620496,0.9313468894705054,0.9317495470102678,0.9323535333199114,0.9335615059391987,0.9343668210187236,0.9349708073283672,0.9381920676464667,0.9385947251862291,0.9408093416549225,0.9416146567344473,0.9420173142742098,0.942218643044091,0.9426213005838534,0.9434266156633783,0.9438292732031407,0.9444332595127843,0.9452385745923092,0.9470505335212401,0.9476545198308838,0.9498691362995773,0.9504731226092209,0.9583249446345883,0.9587276021743507,0.9593315884839944,0.9597342460237568,0.959935574793638,0.9603382323334004,0.9623515200322126,0.9629555063418562,0.9635594926514999,0.9641634789611435,0.9643648077310247,0.9647674652707872,0.9649687940406684,0.9653714515804308,0.9663780954298369,0.9667807529695993,0.9677873968190054,0.9681900543587678,0.9689953694382928,0.9698006845178176,0.9706059995973425,0.9710086571371049,0.9736259311455607,0.9744312462250856,0.9762432051540165,0.976645862693779,0.9790618079323535,0.979464465472116,0.980471109321522,0.9808737668612845,0.9820817394805718,0.9826857257902154,0.9828870545600966,0.983289712099859,0.9844976847191463,0.9849003422589088,0.9855043285685524,0.9859069861083148,0.9877189450372458,0.9881216025770082,0.9885242601167706,0.9889269176565331,0.9921481779746326,0.9927521642842763,0.9941614656734448,0.9945641232132072,1.0],\"y\":[0.0,0.0,0.0625,0.0625,0.15625,0.15625,0.15625,0.15625,0.21875,0.21875,0.21875,0.25,0.25,0.25,0.25,0.25,0.28125,0.28125,0.28125,0.3125,0.3125,0.3125,0.3125,0.3125,0.3125,0.34375,0.34375,0.34375,0.34375,0.375,0.375,0.375,0.375,0.375,0.375,0.40625,0.40625,0.40625,0.40625,0.40625,0.40625,0.4375,0.4375,0.46875,0.46875,0.46875,0.46875,0.46875,0.46875,0.46875,0.46875,0.46875,0.46875,0.46875,0.5,0.5,0.5,0.5,0.53125,0.53125,0.53125,0.53125,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.65625,0.65625,0.65625,0.65625,0.65625,0.65625,0.65625,0.65625,0.65625,0.6875,0.6875,0.6875,0.6875,0.6875,0.6875,0.6875,0.6875,0.6875,0.6875,0.71875,0.71875,0.71875,0.71875,0.71875,0.71875,0.71875,0.71875,0.71875,0.71875,0.71875,0.71875,0.71875,0.71875,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.84375,0.84375,0.84375,0.84375,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.9375,0.9375,0.9375,0.9375,0.9375,0.9375,0.9375,0.9375,0.96875,0.96875,0.96875,0.96875,0.96875,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"type\":\"scatter\"},{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(255, 255, 255, 0)\",\"width\":5},\"name\":\"AUC: 0.9443\",\"showlegend\":true,\"x\":[0.0,0.0004026575397624321,0.0004026575397624321,0.0008053150795248641,0.0008053150795248641,0.0010066438494060802,0.0014093013891685123,0.002214616468693376,0.002214616468693376,0.0028186027783370245,0.0036239178578618887,0.0036239178578618887,0.0042279041675055366,0.005435876786792832,0.005838534326555265,0.006442520636198913,0.006442520636198913,0.006845178175961345,0.007046506945842561,0.007046506945842561,0.007650493255486209,0.008053150795248641,0.00865713710489229,0.009462452184417153,0.00966378095429837,0.00966378095429837,0.010267767263942018,0.01067042480370445,0.011274411113348098,0.011274411113348098,0.01167706865311053,0.012079726192872961,0.012482383732635393,0.013086370042279041,0.013287698812160258,0.013287698812160258,0.013489027582041473,0.013891685121803906,0.014294342661566338,0.015099657741091201,0.015300986510972418,0.015300986510972418,0.015502315280853635,0.015502315280853635,0.018320918059190658,0.01912623313871552,0.019931548218240388,0.020334205758002818,0.0213408496074089,0.02174350714717133,0.021944835917052548,0.022347493456814978,0.024964767465270786,0.025568753774914434,0.025568753774914434,0.0263740688544393,0.02677672639420173,0.026978055164082946,0.026978055164082946,0.027179383933964164,0.027582041473726594,0.028186027783370243,0.028186027783370243,0.02838735655325146,0.029192671632776324,0.029595329172538754,0.03040064425206362,0.030601973021944836,0.03100463056170727,0.031205959331588484,0.031608616871350914,0.03180994564123213,0.032212603180994566,0.032615260720756996,0.03321924703040065,0.03342057580028186,0.03382323334004429,0.034829877189450374,0.035232534729212804,0.035836521038856456,0.0364405073485001,0.03825246627743104,0.038856452587074694,0.039863096436480776,0.040668411516005636,0.04127239782564929,0.04187638413529293,0.04207771290517415,0.042480370444936584,0.04368834306422388,0.04409100060398631,0.04409100060398631,0.044694986913629955,0.04509764445339239,0.04570163076303604,0.047312260922085764,0.0477149184618482,0.048721562311254275,0.048721562311254275,0.0489228910811355,0.04972820616066036,0.05113750754982887,0.05174149385947252,0.0527481377088786,0.05315079524864103,0.05355345278840346,0.05395611032816589,0.05395611032816589,0.054157439098047114,0.054560096637809544,0.055566740487215625,0.055969398026978055,0.056372055566740485,0.05717737064626535,0.05737869941614657,0.057781356955909,0.05838534326555265,0.05838534326555265,0.06140527481377089,0.06180793235353332,0.062210589893295754,0.0628145762029394,0.06361989128246426,0.06442520636198913,0.06462653513187035,0.06502919267163278,0.06583450775115764,0.06623716529092007,0.06724380914032616,0.06764646668008858,0.0678477954499698,0.0678477954499698,0.0690557680692571,0.06945842560901953,0.07006241191866318,0.07046506945842561,0.07066639822830682,0.07106905576806925,0.07147171330783168,0.07207569961747534,0.07247835715723777,0.07368632977652506,0.07368632977652506,0.07489430239581236,0.07569961747533722,0.07630360378498087,0.0767062613247433,0.08073283672236763,0.08194080934165492,0.082947453191061,0.08355143950070465,0.08375276827058586,0.08455808335011072,0.0867726998188041,0.08717535735856653,0.08777934366821019,0.08838332997785384,0.08878598751761627,0.0891886450573787,0.08938997382725991,0.09019528890678478,0.09059794644654721,0.09140326152607207,0.0918059190658345,0.09200724783571572,0.09240990537547815,0.09442319307429031,0.09522850815381519,0.09643648077310248,0.0968391383128649,0.09724179585262734,0.097845782162271,0.09824843970203342,0.09865109724179585,0.09885242601167707,0.10006039863096436,0.10066438494060802,0.10106704248037045,0.10227501509965774,0.1028790014093014,0.10610026172740085,0.10750956311656935,0.10791222065633178,0.10871753573585666,0.1093215220455003,0.10952285081538152,0.11032816589490638,0.11052949466478759,0.11354942621300584,0.11415341252264949,0.1167706865311053,0.11797865915039259,0.1181799879202738,0.11858264546003625,0.1205959331588484,0.12140124823837327,0.1218039057781357,0.12220656331789813,0.12281054962754177,0.12341453593718542,0.12381719347694786,0.12442117978659151,0.12603180994564123,0.12603180994564123,0.12643446748540366,0.1268371250251661,0.12723978256492852,0.1294543990336219,0.13025971411314677,0.13106502919267163,0.13166901550231527,0.13227300181195892,0.13267565935172135,0.13388363197100867,0.13408496074088988,0.13730622105898932,0.13791020736863296,0.13831286490839542,0.13871552244815785,0.13911817998792028,0.1393195087578015,0.13992349506744514,0.14012482383732636,0.14012482383732636,0.1405274813770888,0.14093013891685122,0.14133279645661365,0.14133279645661365,0.14153412522649486,0.1419367827662573,0.14233944030601972,0.14395007046506947,0.14415139923495068,0.1445540567747131,0.14475538554459433,0.14596335816388162,0.14636601570364405,0.14757398832293134,0.14898328971209987,0.15099657741091202,0.15160056372055566,0.1520032212603181,0.15240587880008052,0.15280853633984295,0.1534125226494866,0.1534125226494866,0.15361385141936781,0.15401650895913027,0.15462049526877392,0.15502315280853635,0.15522448157841756,0.15562713911818,0.15643245419770485,0.1570364405073485,0.15784175558687336,0.15864707066639822,0.15884839943627943,0.16146567344473525,0.1620696597543789,0.16247231729414133,0.16287497483390376,0.16307630360378497,0.1634789611435474,0.16508959130259715,0.165894906382122,0.16629756392188444,0.16690155023152808,0.1671028790014093,0.16790819408093416,0.16891483793034023,0.1693174954701027,0.16972015300986512,0.1707267968592712,0.17153211193879606,0.17193476947855849,0.17253875578820213,0.173344070867727,0.17374672840748942,0.17435071471713307,0.1757600161063016,0.17616267364606403,0.17656533118582646,0.1769679887255889,0.17737064626535132,0.17877994765451982,0.18059190658345078,0.18300785182202536,0.1848198107509563,0.18643044091000605,0.1870344272196497,0.18743708475941212,0.18804107106905577,0.18824239983893698,0.18904771491846184,0.19005435876786791,0.19186631769679888,0.1920676464666801,0.19247030400644252,0.195691564324542,0.19770485202335414,0.19810750956311657,0.19830883833299778,0.20012079726192872,0.20052345480169118,0.2009261123414536,0.20132876988121604,0.20153009865109725,0.20193275619085968,0.2023354137306221,0.20273807127038454,0.20293940004026575,0.2035433863499094,0.20394604388967183,0.2057580028186028,0.20676464666800887,0.20797261928729616,0.2083752768270586,0.2085766055969398,0.2097845782162271,0.2099859069861083,0.21038856452587074,0.21401248238373263,0.21441513992349506,0.21522045500301992,0.21562311254278235,0.21622709885242603,0.21783772901147574,0.2186430440910006,0.21924703040064425,0.21964968794040668,0.22085766055969397,0.22085766055969397,0.22146164686933764,0.22186430440910007,0.22266961948862493,0.22327360579826858,0.223676263338031,0.22428024964767465,0.2248842359573183,0.2248842359573183,0.22528689349708073,0.22971612643446748,0.2301187839742299,0.23032011274411113,0.23032011274411113,0.231125427823636,0.23172941413327963,0.23193074290316087,0.2323334004429233,0.23334004429232938,0.23414535937185424,0.23454801691161667,0.2349506744513791,0.23575598953090396,0.2361586470706664,0.2363599758405476,0.23676263338031003,0.23696396215019125,0.23756794845983492,0.23797060599959735,0.24421179786591504,0.24461445540567747,0.2450171129454399,0.24541977048520233,0.2462250855647272,0.24662774310448962,0.24783571572377694,0.24823837326353937,0.24904368834306423,0.2500503321924703,0.25045298973223273,0.2512583048117576,0.25186229112140124,0.2528689349708073,0.25347292128045096,0.2536742500503322,0.2540769075900946,0.25488222266961946,0.25548620897926316,0.2558888665190256,0.256291524058788,0.25689551036843167,0.2572981679081941,0.2577008254479565,0.25810348298771896,0.2585061405274814,0.2589087980672438,0.2599154419166499,0.26051942822629354,0.26333803100463055,0.263740688544393,0.26474733239379905,0.2653513187034427,0.2655526474733239,0.2659553050130864,0.2671632776323737,0.2675659351721361,0.26816992148177976,0.2687739077914234,0.2689752365613046,0.26957922287094827,0.2701832091805919,0.27078719549023555,0.27179383933964163,0.27219649687940406,0.2730018119589289,0.2738071270384538,0.2744111133480974,0.27481377088785985,0.27582041473726593,0.27642440104690963,0.27682705858667206,0.2774310448963157,0.278639017515603,0.2790416750553654,0.27924300382524664,0.2798469901348903,0.28085363398429636,0.28145762029394,0.2816589490638212,0.2824642641433461,0.28326957922287094,0.28367223676263337,0.284276223072277,0.28467888061203944,0.28508153815180187,0.28608818200120795,0.28649083954097043,0.28669216831085165,0.2870948258506141,0.28830279846990137,0.2887054560096638,0.28971209985906987,0.2901147573988323,0.2903160861687135,0.29071874370847595,0.2915240587880008,0.29192671632776324,0.29232937386752567,0.2927320314072881,0.2955506341856251,0.29595329172538754,0.29615462049526875,0.2965572780350312,0.29816790819408096,0.29957720958324946,0.2999798671230119,0.30058385343265553,0.3029997986712301,0.30340245621099254,0.30360378498087376,0.3040064425206362,0.3042077712905174,0.30461042883027983,0.30481175760016105,0.3052144151399235,0.3058184014495671,0.30622105898932955,0.3086370042279042,0.30944231930742905,0.3100463056170727,0.31085162069659755,0.3128649083954097,0.31367022347493456,0.3138715522448158,0.31467686732434064,0.31487819609422185,0.3152808536339843,0.3158848399436279,0.31628749748339036,0.316891483793034,0.3185021139520838,0.3229313468894705,0.32353533319911415,0.3245419770485202,0.32514596335816387,0.3313871552244816,0.331789812764244,0.33199114153412523,0.33239379907388766,0.3344070867726998,0.33480974431246224,0.33501107308234346,0.3354137306221059,0.33642037447151196,0.3372256895510368,0.3390376484799678,0.33964163478961146,0.34487618280652305,0.3452788403462855,0.3456814978860479,0.34608415542581034,0.3470907992752164,0.34749345681497884,0.3491040869740286,0.34970807328367226,0.3501107308234347,0.3505133883631971,0.35232534729212805,0.3531306623716529,0.3539359774511778,0.3543386349909402,0.3593718542379706,0.35977451177773306,0.3613851419367828,0.3617877994765452,0.36219045701630764,0.3625931145560701,0.3684316488826253,0.36883430642238774,0.3700422790416751,0.3704449365814375,0.37125025166096237,0.3716529092007248,0.37346486812965574,0.3742701832091806,0.37487416951882424,0.37527682705858667,0.3770887859875176,0.37749144352728004,0.37769277229716125,0.3780954298369237,0.3786994161465673,0.3795047312260922,0.38091403261526074,0.3813166901550232,0.3817193476947856,0.3857459230924099,0.38614858063217233,0.3871552244815784,0.38755788202134084,0.3881618683309845,0.3885645258707469,0.389571169720153,0.3899738272599154,0.39017515602979663,0.39098047110932155,0.39259110126837127,0.3931950875780149,0.39379907388765856,0.394201731427421,0.3968190054358768,0.39782564928528286,0.39802697805516407,0.3986309643648077,0.40104690960338235,0.4014495671431448,0.4018522246829072,0.40225488222266964,0.40265753976243207,0.4030601973021945,0.40386551238171936,0.4058788000805315,0.40628145762029394,0.40648278639017515,0.4068854439299376,0.40769075900946244,0.4080934165492249,0.4084960740889873,0.40930138916851216,0.410106704248037,0.41050936178779945,0.4131266357962553,0.41393195087578016,0.4157439098047111,0.41614656734447353,0.4183611838131669,0.4187638413529293,0.4197704852023354,0.4201731427420978,0.4209784578216227,0.42158244413126633,0.4219851016710288,0.42238775921079125,0.4241997181397222,0.4246023756794846,0.42661566337829676,0.4270183209180592,0.42762230722770284,0.42802496476746527,0.4288302798469901,0.42923293738675256,0.43064223877592106,0.4310448963156835,0.43185021139520835,0.4322528689349708,0.4360781155627139,0.4368834306422388,0.4372860881820012,0.43809140326152607,0.4384940608012885,0.44191664988926915,0.4423193074290316,0.44372860881820014,0.4441312663579626,0.4443325951278438,0.4447352526676062,0.4459432252868935,0.44674854036641837,0.4475538554459432,0.44795651298570566,0.44916448560499295,0.4497684719146366,0.45198308838332996,0.4523857459230924,0.4527884034628548,0.4533923897724985,0.45379504731226095,0.4543990336219046,0.454801691161667,0.4556070062411919,0.4562109925508355,0.45782162270988525,0.4582242802496477,0.4586269377894101,0.45902959532917254,0.4598349104086974,0.4602375679484598,0.46184819810750954,0.462250855647272,0.46406281457620296,0.4648681296557278,0.4715119790618079,0.4727199516810952,0.4737265955305013,0.474330581840145,0.47533722568955106,0.4757398832293135,0.4775518421582444,0.47815582846788807,0.4787598147775317,0.47916247231729414,0.48057177370646265,0.4809744312462251,0.4815784175558687,0.48198107509563115,0.4823837326353936,0.4829877189450372,0.4837930340245621,0.4841956915643245,0.4843970203342058,0.4847996778739682,0.4860076504932555,0.48641030803301794,0.48661163680289915,0.487416951882424,0.4896315683511174,0.49043688343064223,0.4910408697402859,0.4914435272800483,0.4928528286692168,0.49325548620897924,0.494866116368029,0.49526877390779145,0.4962754177571975,0.49667807529695995,0.4970807328367224,0.49768471914636603,0.4984900342258909,0.4988926917656533,0.4996980068451782,0.5003019931548218,0.5007046506945843,0.5011073082343467,0.5013086370042279,0.5021139520837528,0.50332192470304,0.5037245822428025,0.5059391987114958,0.5063418562512583,0.5131870344272197,0.5135896919669821,0.5137910207368633,0.5141936782766258,0.5147976645862694,0.5152003221260318,0.5158043084356755,0.5166096235152003,0.5168109522850816,0.517213609824844,0.5188242399838937,0.5194282262935374,0.5218441715321119,0.5222468290718744,0.5244614455405677,0.5248641030803302,0.5258707469297362,0.5264747332393799,0.528488020938192,0.5288906784779545,0.5292933360177169,0.5296959935574793,0.530299979867123,0.5307026374068854,0.5329172538755789,0.5333199114153413,0.5359371854237971,0.5363398429635595,0.536742500503322,0.5371451580430844,0.537749144352728,0.5381518018924905,0.5387557882021341,0.5391584457418965,0.5407690759009463,0.5411717334407087,0.5413730622105899,0.5417757197503523,0.5429836923696396,0.5435876786792833,0.5447956512985705,0.5456009663780954,0.5466076102275015,0.5472115965371451,0.5474129253070263,0.5478155828467888,0.54801691161667,0.5484195691564324,0.5486208979263136,0.5490235554660761,0.5516408294745319,0.5520434870142943,0.5524461445540568,0.5530501308637005,0.5536541171733441,0.5542581034829878,0.554459432252869,0.5548620897926314,0.5558687336420375,0.5562713911817999,0.5568753774914436,0.557278035031206,0.5586873364203745,0.5594926514998994,0.5631165693577612,0.5637205556674049,0.5693577612240789,0.5701630763036037,0.5705657338433662,0.5725790215421783,0.5731830078518221,0.5735856653915845,0.5739883229313469,0.5751962955506342,0.5755989530903967,0.5784175558687337,0.5788202134084961,0.5818401449567143,0.5822428024964768,0.5850614052748138,0.5856653915844574,0.5860680491242198,0.5864707066639823,0.5868733642037447,0.5878800080531508,0.5882826655929132,0.5900946245218441,0.590899939601369,0.5911012683712502,0.5915039259110126,0.5917052546808939,0.5921079122206563,0.5925105697604187,0.5931145560700624,0.5953291725387558,0.5957318300785183,0.5961344876182807,0.5969398026978056,0.5979464465472116,0.5983491040869741,0.5989530903966177,0.5993557479363801,0.6021743507147171,0.6025770082544796,0.6031809945641232,0.6033823233340044,0.6037849808737669,0.6039863096436481,0.6043889671834105,0.6055969398026978,0.6062009261123414,0.6070062411918663,0.6074088987316287,0.6080128850412724,0.6084155425810348,0.6094221864304409,0.6102275015099657,0.611435474129253,0.6122407892087779,0.6130461042883028,0.6138514193678276,0.615059391987115,0.6158647070666399,0.6166700221461647,0.6170726796859272,0.6200926112341454,0.6204952687739078,0.6229112140124824,0.6233138715522448,0.6239178578618885,0.6243205154016509,0.6247231729414133,0.6251258304811758,0.625327159251057,0.6257298167908194,0.6273404469498691,0.6277431044896316,0.6321723374270183,0.6329776525065431,0.633782967586068,0.6341856251258304,0.6343869538957116,0.6347896114354741,0.6372055566740488,0.6384135292933361,0.6386148580632173,0.6390175156029797,0.6408294745319106,0.6416347896114355,0.6420374471511979,0.6424401046909604,0.643044091000604,0.6436480773102476,0.6440507348500101,0.6444533923897725,0.6454600362391786,0.6462653513187034,0.6464666800885847,0.6468693376283471,0.6470706663982283,0.6478759814777532,0.6492852828669217,0.6500905979464465,0.6512985705657338,0.6519025568753775,0.6521038856452587,0.6527078719549023,0.6529092007247835,0.6537145158043084,0.6541171733440708,0.6547211596537145,0.6551238171934769,0.6555264747332393,0.6581437487416952,0.6589490638212201,0.6593517213609825,0.659754378900745,0.6605596939802698,0.6609623515200322,0.6611636802899135,0.6619689953694383,0.6631769679887256,0.663579625528488,0.6659955707670626,0.6668008858465875,0.6670022146164687,0.6674048721562311,0.6680088584658748,0.6684115160056372,0.6688141735453996,0.6696194886249245,0.6702234749345681,0.6708274612442118,0.671028790014093,0.6720354338634991,0.6724380914032615,0.6728407489430239,0.6732434064827864,0.6736460640225488,0.6750553654117173,0.6754580229514797,0.6762633380310046,0.6768673243406482,0.6770686531105294,0.677471310650292,0.6778739681900544,0.678477954499698,0.6792832695792229,0.6798872558888666,0.6816992148177975,0.6821018723575599,0.6823032011274411,0.6827058586672036,0.6833098449768472,0.6843164888262533,0.6847191463660157,0.6869337628347091,0.6873364203744715,0.6899536943829273,0.6903563519226897,0.6931749547010267,0.6935776122407892,0.6947855848600765,0.6951882423998389,0.6965975437890074,0.6970002013287698,0.6974028588685323,0.6978055164082947,0.699818804107107,0.7002214616468694,0.7004227904167506,0.700825447956513,0.7016307630360379,0.7022347493456815,0.7030400644252064,0.70364405073485,0.7038453795047313,0.7044493658143749,0.7108918864505738,0.7114958727602174,0.7147171330783169,0.7151197906180793,0.7157237769277229,0.7179383933964163,0.7183410509361787,0.7185423797060599,0.7189450372458225,0.7197503523253473,0.7201530098651098,0.7205556674048722,0.7211596537145158,0.7219649687940407,0.7223676263338031,0.7227702838735656,0.7235755989530904,0.7239782564928529,0.7245822428024965,0.7247835715723777,0.7253875578820214,0.7286088182001208,0.7292128045097644,0.7296154620495269,0.7300181195892893,0.7304207771290517,0.731628749748339,0.7320314072881015,0.7324340648278639,0.7328367223676263,0.7338433662170324,0.734447352526676,0.7346486812965572,0.7350513388363197,0.7352526676062009,0.7356553251459633,0.7360579826857258,0.7364606402254882,0.7370646265351318,0.7374672840748943,0.7376686128447755,0.7380712703845379,0.7382725991544191,0.7386752566941815,0.739077914233944,0.7396819005435877,0.7400845580833502,0.7404872156231126,0.7406885443929938,0.7414938594725187,0.7425005033219247,0.7431044896315684,0.7439098047110932,0.7443124622508557,0.7447151197906181,0.7449164485604993,0.7453191061002618,0.7457217636400242,0.7461244211797866,0.746527078719549,0.7471310650291927,0.7485403664183612,0.7489430239581236,0.7515602979665794,0.7523656130461043,0.7549828870545601,0.7553855445943225,0.7561908596738474,0.7565935172136098,0.7573988322931346,0.7578014898328971,0.759613448761828,0.7600161063015904,0.7610227501509966,0.7618280652305215,0.7620293940004027,0.7626333803100463,0.7628347090799276,0.76323736661969,0.7636400241594524,0.7640426816992149,0.7644453392389773,0.7652506543185021,0.7664586269377894,0.7668612844775519,0.7678679283269579,0.7686732434064828,0.770686531105295,0.7710891886450574,0.7720958324944635,0.7724984900342259,0.7743104489631568,0.7751157640426817,0.7767263942017314,0.7771290517414938,0.7775317092812563,0.7783370243607811,0.780148983289712,0.7805516408294745,0.782766257298168,0.7831689148379304,0.7839742299174552,0.7843768874572177,0.7853835313066238,0.7857861888463862,0.7859875176162674,0.786591503925911,0.7867928326957923,0.7875981477753171,0.7877994765451983,0.7882021340849608,0.7926313670223475,0.7938393396416348,0.7954499698006845,0.7962552848802094,0.7972619287296154,0.7978659150392591,0.8000805315079524,0.8004831890477149,0.801489832897121,0.8022951479766459,0.8024964767465271,0.8028991342862896,0.803301791826052,0.8037044493658144,0.8043084356754581,0.8047110932152205,0.8049124219851017,0.8053150795248641,0.8067243809140326,0.8073283672236763,0.8075296959935575,0.8083350110730824,0.8093416549224884,0.8099456412321321,0.8103482987718945,0.8109522850815382,0.8113549426213006,0.8121602577008254,0.8139722166297564,0.8143748741695188,0.8147775317092812,0.8151801892490437,0.8155828467888061,0.8159855043285685,0.8167908194080934,0.8171934769478558,0.8175961344876183,0.8182001207972619,0.8196094221864304,0.8200120797261928,0.8210187235755989,0.8214213811153613,0.8250452989732233,0.825649285282867,0.8260519428226294,0.8276625729816791,0.8282665592913228,0.828467888061204,0.8288705456009664,0.8290718743708476,0.82947453191061,0.8300785182202537,0.8314878196094222,0.8320918059190658,0.8324944634588283,0.8328971209985907,0.8351117374672841,0.8355143950070465,0.8363197100865714,0.8367223676263338,0.8379303402456211,0.8383329977853835,0.8387356553251459,0.8391383128649084,0.839742299174552,0.8401449567143144,0.8403462854841957,0.8407489430239581,0.8411516005637205,0.8415542581034829,0.8419569156432454,0.8423595731830078,0.8431648882625327,0.8439702033420576,0.8453795047312261,0.8459834910408698,0.8465874773505134,0.8471914636601571,0.8530299979867123,0.8542379706059996,0.854640628145762,0.8550432856855245,0.8556472719951681,0.8562512583048117,0.8566539158445742,0.857459230924099,0.8580632172337427,0.8582645460036239,0.8588685323132675,0.85927118985303,0.8614858063217233,0.8622911214012482,0.8634990940205355,0.8641030803301791,0.8649083954097041,0.8655123817193477,0.8659150392591102,0.8687336420374472,0.8691362995772096,0.8693376283470908,0.8697402858868533,0.8703442721964969,0.8711495872760218,0.8719549023555466,0.8727602174350715,0.87416951882424,0.8745721763640024,0.8783974229917455,0.8792027380712704,0.879806724380914,0.8814173545399637,0.8818200120797262,0.8832293134688947,0.8836319710086571,0.8854439299375881,0.886249245017113,0.8868532313267566,0.8872558888665191,0.8896718341050937,0.8900744916448561,0.8922891081135494,0.8926917656533119,0.8955103684316489,0.8959130259714113,0.8961143547412925,0.8969196698208174,0.8979263136702235,0.8983289712099859,0.8985302999798671,0.8991342862895108,0.9001409301389168,0.9013489027582041,0.9045701630763036,0.9053754781558284,0.9057781356955908,0.9061807932353533,0.9063821220052346,0.906784779544997,0.9083954097040468,0.9087980672438092,0.9098047110932153,0.9106100261727401,0.9120193275619086,0.912421985101671,0.9126233138715523,0.9130259714113147,0.9158445741896517,0.9162472317294141,0.9164485604992954,0.9168512180390578,0.9178578618884639,0.9184618481981075,0.9186631769679887,0.9192671632776324,0.9194684920475136,0.919871149587276,0.9206764646668009,0.9212804509764445,0.9214817797463257,0.9218844372860882,0.9224884235957318,0.9230924099053754,0.9236963962150191,0.924501711294544,0.9251056976041876,0.9261123414535937,0.9267163277632373,0.9283269579222871,0.9287296154620496,0.9313468894705054,0.9317495470102678,0.9323535333199114,0.9335615059391987,0.9343668210187236,0.9349708073283672,0.9381920676464667,0.9385947251862291,0.9408093416549225,0.9416146567344473,0.9420173142742098,0.942218643044091,0.9426213005838534,0.9434266156633783,0.9438292732031407,0.9444332595127843,0.9452385745923092,0.9470505335212401,0.9476545198308838,0.9498691362995773,0.9504731226092209,0.9583249446345883,0.9587276021743507,0.9593315884839944,0.9597342460237568,0.959935574793638,0.9603382323334004,0.9623515200322126,0.9629555063418562,0.9635594926514999,0.9641634789611435,0.9643648077310247,0.9647674652707872,0.9649687940406684,0.9653714515804308,0.9663780954298369,0.9667807529695993,0.9677873968190054,0.9681900543587678,0.9689953694382928,0.9698006845178176,0.9706059995973425,0.9710086571371049,0.9736259311455607,0.9744312462250856,0.9762432051540165,0.976645862693779,0.9790618079323535,0.979464465472116,0.980471109321522,0.9808737668612845,0.9820817394805718,0.9826857257902154,0.9828870545600966,0.983289712099859,0.9844976847191463,0.9849003422589088,0.9855043285685524,0.9859069861083148,0.9877189450372458,0.9881216025770082,0.9885242601167706,0.9889269176565331,0.9921481779746326,0.9927521642842763,0.9941614656734448,0.9945641232132072,1.0],\"y\":[0.0,0.0,0.0625,0.0625,0.15625,0.15625,0.15625,0.15625,0.21875,0.21875,0.21875,0.25,0.25,0.25,0.25,0.25,0.28125,0.28125,0.28125,0.3125,0.3125,0.3125,0.3125,0.3125,0.3125,0.34375,0.34375,0.34375,0.34375,0.375,0.375,0.375,0.375,0.375,0.375,0.40625,0.40625,0.40625,0.40625,0.40625,0.40625,0.4375,0.4375,0.46875,0.46875,0.46875,0.46875,0.46875,0.46875,0.46875,0.46875,0.46875,0.46875,0.46875,0.5,0.5,0.5,0.5,0.53125,0.53125,0.53125,0.53125,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.65625,0.65625,0.65625,0.65625,0.65625,0.65625,0.65625,0.65625,0.65625,0.6875,0.6875,0.6875,0.6875,0.6875,0.6875,0.6875,0.6875,0.6875,0.6875,0.71875,0.71875,0.71875,0.71875,0.71875,0.71875,0.71875,0.71875,0.71875,0.71875,0.71875,0.71875,0.71875,0.71875,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.84375,0.84375,0.84375,0.84375,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.9375,0.9375,0.9375,0.9375,0.9375,0.9375,0.9375,0.9375,0.96875,0.96875,0.96875,0.96875,0.96875,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"type\":\"scatter\"},{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(255, 255, 255, 0)\",\"width\":0},\"name\":\"(95% CI: 0.8889-0.9997)\",\"showlegend\":true,\"x\":[0.0,0.0004026575397624321,0.0004026575397624321,0.0008053150795248641,0.0008053150795248641,0.0010066438494060802,0.0014093013891685123,0.002214616468693376,0.002214616468693376,0.0028186027783370245,0.0036239178578618887,0.0036239178578618887,0.0042279041675055366,0.005435876786792832,0.005838534326555265,0.006442520636198913,0.006442520636198913,0.006845178175961345,0.007046506945842561,0.007046506945842561,0.007650493255486209,0.008053150795248641,0.00865713710489229,0.009462452184417153,0.00966378095429837,0.00966378095429837,0.010267767263942018,0.01067042480370445,0.011274411113348098,0.011274411113348098,0.01167706865311053,0.012079726192872961,0.012482383732635393,0.013086370042279041,0.013287698812160258,0.013287698812160258,0.013489027582041473,0.013891685121803906,0.014294342661566338,0.015099657741091201,0.015300986510972418,0.015300986510972418,0.015502315280853635,0.015502315280853635,0.018320918059190658,0.01912623313871552,0.019931548218240388,0.020334205758002818,0.0213408496074089,0.02174350714717133,0.021944835917052548,0.022347493456814978,0.024964767465270786,0.025568753774914434,0.025568753774914434,0.0263740688544393,0.02677672639420173,0.026978055164082946,0.026978055164082946,0.027179383933964164,0.027582041473726594,0.028186027783370243,0.028186027783370243,0.02838735655325146,0.029192671632776324,0.029595329172538754,0.03040064425206362,0.030601973021944836,0.03100463056170727,0.031205959331588484,0.031608616871350914,0.03180994564123213,0.032212603180994566,0.032615260720756996,0.03321924703040065,0.03342057580028186,0.03382323334004429,0.034829877189450374,0.035232534729212804,0.035836521038856456,0.0364405073485001,0.03825246627743104,0.038856452587074694,0.039863096436480776,0.040668411516005636,0.04127239782564929,0.04187638413529293,0.04207771290517415,0.042480370444936584,0.04368834306422388,0.04409100060398631,0.04409100060398631,0.044694986913629955,0.04509764445339239,0.04570163076303604,0.047312260922085764,0.0477149184618482,0.048721562311254275,0.048721562311254275,0.0489228910811355,0.04972820616066036,0.05113750754982887,0.05174149385947252,0.0527481377088786,0.05315079524864103,0.05355345278840346,0.05395611032816589,0.05395611032816589,0.054157439098047114,0.054560096637809544,0.055566740487215625,0.055969398026978055,0.056372055566740485,0.05717737064626535,0.05737869941614657,0.057781356955909,0.05838534326555265,0.05838534326555265,0.06140527481377089,0.06180793235353332,0.062210589893295754,0.0628145762029394,0.06361989128246426,0.06442520636198913,0.06462653513187035,0.06502919267163278,0.06583450775115764,0.06623716529092007,0.06724380914032616,0.06764646668008858,0.0678477954499698,0.0678477954499698,0.0690557680692571,0.06945842560901953,0.07006241191866318,0.07046506945842561,0.07066639822830682,0.07106905576806925,0.07147171330783168,0.07207569961747534,0.07247835715723777,0.07368632977652506,0.07368632977652506,0.07489430239581236,0.07569961747533722,0.07630360378498087,0.0767062613247433,0.08073283672236763,0.08194080934165492,0.082947453191061,0.08355143950070465,0.08375276827058586,0.08455808335011072,0.0867726998188041,0.08717535735856653,0.08777934366821019,0.08838332997785384,0.08878598751761627,0.0891886450573787,0.08938997382725991,0.09019528890678478,0.09059794644654721,0.09140326152607207,0.0918059190658345,0.09200724783571572,0.09240990537547815,0.09442319307429031,0.09522850815381519,0.09643648077310248,0.0968391383128649,0.09724179585262734,0.097845782162271,0.09824843970203342,0.09865109724179585,0.09885242601167707,0.10006039863096436,0.10066438494060802,0.10106704248037045,0.10227501509965774,0.1028790014093014,0.10610026172740085,0.10750956311656935,0.10791222065633178,0.10871753573585666,0.1093215220455003,0.10952285081538152,0.11032816589490638,0.11052949466478759,0.11354942621300584,0.11415341252264949,0.1167706865311053,0.11797865915039259,0.1181799879202738,0.11858264546003625,0.1205959331588484,0.12140124823837327,0.1218039057781357,0.12220656331789813,0.12281054962754177,0.12341453593718542,0.12381719347694786,0.12442117978659151,0.12603180994564123,0.12603180994564123,0.12643446748540366,0.1268371250251661,0.12723978256492852,0.1294543990336219,0.13025971411314677,0.13106502919267163,0.13166901550231527,0.13227300181195892,0.13267565935172135,0.13388363197100867,0.13408496074088988,0.13730622105898932,0.13791020736863296,0.13831286490839542,0.13871552244815785,0.13911817998792028,0.1393195087578015,0.13992349506744514,0.14012482383732636,0.14012482383732636,0.1405274813770888,0.14093013891685122,0.14133279645661365,0.14133279645661365,0.14153412522649486,0.1419367827662573,0.14233944030601972,0.14395007046506947,0.14415139923495068,0.1445540567747131,0.14475538554459433,0.14596335816388162,0.14636601570364405,0.14757398832293134,0.14898328971209987,0.15099657741091202,0.15160056372055566,0.1520032212603181,0.15240587880008052,0.15280853633984295,0.1534125226494866,0.1534125226494866,0.15361385141936781,0.15401650895913027,0.15462049526877392,0.15502315280853635,0.15522448157841756,0.15562713911818,0.15643245419770485,0.1570364405073485,0.15784175558687336,0.15864707066639822,0.15884839943627943,0.16146567344473525,0.1620696597543789,0.16247231729414133,0.16287497483390376,0.16307630360378497,0.1634789611435474,0.16508959130259715,0.165894906382122,0.16629756392188444,0.16690155023152808,0.1671028790014093,0.16790819408093416,0.16891483793034023,0.1693174954701027,0.16972015300986512,0.1707267968592712,0.17153211193879606,0.17193476947855849,0.17253875578820213,0.173344070867727,0.17374672840748942,0.17435071471713307,0.1757600161063016,0.17616267364606403,0.17656533118582646,0.1769679887255889,0.17737064626535132,0.17877994765451982,0.18059190658345078,0.18300785182202536,0.1848198107509563,0.18643044091000605,0.1870344272196497,0.18743708475941212,0.18804107106905577,0.18824239983893698,0.18904771491846184,0.19005435876786791,0.19186631769679888,0.1920676464666801,0.19247030400644252,0.195691564324542,0.19770485202335414,0.19810750956311657,0.19830883833299778,0.20012079726192872,0.20052345480169118,0.2009261123414536,0.20132876988121604,0.20153009865109725,0.20193275619085968,0.2023354137306221,0.20273807127038454,0.20293940004026575,0.2035433863499094,0.20394604388967183,0.2057580028186028,0.20676464666800887,0.20797261928729616,0.2083752768270586,0.2085766055969398,0.2097845782162271,0.2099859069861083,0.21038856452587074,0.21401248238373263,0.21441513992349506,0.21522045500301992,0.21562311254278235,0.21622709885242603,0.21783772901147574,0.2186430440910006,0.21924703040064425,0.21964968794040668,0.22085766055969397,0.22085766055969397,0.22146164686933764,0.22186430440910007,0.22266961948862493,0.22327360579826858,0.223676263338031,0.22428024964767465,0.2248842359573183,0.2248842359573183,0.22528689349708073,0.22971612643446748,0.2301187839742299,0.23032011274411113,0.23032011274411113,0.231125427823636,0.23172941413327963,0.23193074290316087,0.2323334004429233,0.23334004429232938,0.23414535937185424,0.23454801691161667,0.2349506744513791,0.23575598953090396,0.2361586470706664,0.2363599758405476,0.23676263338031003,0.23696396215019125,0.23756794845983492,0.23797060599959735,0.24421179786591504,0.24461445540567747,0.2450171129454399,0.24541977048520233,0.2462250855647272,0.24662774310448962,0.24783571572377694,0.24823837326353937,0.24904368834306423,0.2500503321924703,0.25045298973223273,0.2512583048117576,0.25186229112140124,0.2528689349708073,0.25347292128045096,0.2536742500503322,0.2540769075900946,0.25488222266961946,0.25548620897926316,0.2558888665190256,0.256291524058788,0.25689551036843167,0.2572981679081941,0.2577008254479565,0.25810348298771896,0.2585061405274814,0.2589087980672438,0.2599154419166499,0.26051942822629354,0.26333803100463055,0.263740688544393,0.26474733239379905,0.2653513187034427,0.2655526474733239,0.2659553050130864,0.2671632776323737,0.2675659351721361,0.26816992148177976,0.2687739077914234,0.2689752365613046,0.26957922287094827,0.2701832091805919,0.27078719549023555,0.27179383933964163,0.27219649687940406,0.2730018119589289,0.2738071270384538,0.2744111133480974,0.27481377088785985,0.27582041473726593,0.27642440104690963,0.27682705858667206,0.2774310448963157,0.278639017515603,0.2790416750553654,0.27924300382524664,0.2798469901348903,0.28085363398429636,0.28145762029394,0.2816589490638212,0.2824642641433461,0.28326957922287094,0.28367223676263337,0.284276223072277,0.28467888061203944,0.28508153815180187,0.28608818200120795,0.28649083954097043,0.28669216831085165,0.2870948258506141,0.28830279846990137,0.2887054560096638,0.28971209985906987,0.2901147573988323,0.2903160861687135,0.29071874370847595,0.2915240587880008,0.29192671632776324,0.29232937386752567,0.2927320314072881,0.2955506341856251,0.29595329172538754,0.29615462049526875,0.2965572780350312,0.29816790819408096,0.29957720958324946,0.2999798671230119,0.30058385343265553,0.3029997986712301,0.30340245621099254,0.30360378498087376,0.3040064425206362,0.3042077712905174,0.30461042883027983,0.30481175760016105,0.3052144151399235,0.3058184014495671,0.30622105898932955,0.3086370042279042,0.30944231930742905,0.3100463056170727,0.31085162069659755,0.3128649083954097,0.31367022347493456,0.3138715522448158,0.31467686732434064,0.31487819609422185,0.3152808536339843,0.3158848399436279,0.31628749748339036,0.316891483793034,0.3185021139520838,0.3229313468894705,0.32353533319911415,0.3245419770485202,0.32514596335816387,0.3313871552244816,0.331789812764244,0.33199114153412523,0.33239379907388766,0.3344070867726998,0.33480974431246224,0.33501107308234346,0.3354137306221059,0.33642037447151196,0.3372256895510368,0.3390376484799678,0.33964163478961146,0.34487618280652305,0.3452788403462855,0.3456814978860479,0.34608415542581034,0.3470907992752164,0.34749345681497884,0.3491040869740286,0.34970807328367226,0.3501107308234347,0.3505133883631971,0.35232534729212805,0.3531306623716529,0.3539359774511778,0.3543386349909402,0.3593718542379706,0.35977451177773306,0.3613851419367828,0.3617877994765452,0.36219045701630764,0.3625931145560701,0.3684316488826253,0.36883430642238774,0.3700422790416751,0.3704449365814375,0.37125025166096237,0.3716529092007248,0.37346486812965574,0.3742701832091806,0.37487416951882424,0.37527682705858667,0.3770887859875176,0.37749144352728004,0.37769277229716125,0.3780954298369237,0.3786994161465673,0.3795047312260922,0.38091403261526074,0.3813166901550232,0.3817193476947856,0.3857459230924099,0.38614858063217233,0.3871552244815784,0.38755788202134084,0.3881618683309845,0.3885645258707469,0.389571169720153,0.3899738272599154,0.39017515602979663,0.39098047110932155,0.39259110126837127,0.3931950875780149,0.39379907388765856,0.394201731427421,0.3968190054358768,0.39782564928528286,0.39802697805516407,0.3986309643648077,0.40104690960338235,0.4014495671431448,0.4018522246829072,0.40225488222266964,0.40265753976243207,0.4030601973021945,0.40386551238171936,0.4058788000805315,0.40628145762029394,0.40648278639017515,0.4068854439299376,0.40769075900946244,0.4080934165492249,0.4084960740889873,0.40930138916851216,0.410106704248037,0.41050936178779945,0.4131266357962553,0.41393195087578016,0.4157439098047111,0.41614656734447353,0.4183611838131669,0.4187638413529293,0.4197704852023354,0.4201731427420978,0.4209784578216227,0.42158244413126633,0.4219851016710288,0.42238775921079125,0.4241997181397222,0.4246023756794846,0.42661566337829676,0.4270183209180592,0.42762230722770284,0.42802496476746527,0.4288302798469901,0.42923293738675256,0.43064223877592106,0.4310448963156835,0.43185021139520835,0.4322528689349708,0.4360781155627139,0.4368834306422388,0.4372860881820012,0.43809140326152607,0.4384940608012885,0.44191664988926915,0.4423193074290316,0.44372860881820014,0.4441312663579626,0.4443325951278438,0.4447352526676062,0.4459432252868935,0.44674854036641837,0.4475538554459432,0.44795651298570566,0.44916448560499295,0.4497684719146366,0.45198308838332996,0.4523857459230924,0.4527884034628548,0.4533923897724985,0.45379504731226095,0.4543990336219046,0.454801691161667,0.4556070062411919,0.4562109925508355,0.45782162270988525,0.4582242802496477,0.4586269377894101,0.45902959532917254,0.4598349104086974,0.4602375679484598,0.46184819810750954,0.462250855647272,0.46406281457620296,0.4648681296557278,0.4715119790618079,0.4727199516810952,0.4737265955305013,0.474330581840145,0.47533722568955106,0.4757398832293135,0.4775518421582444,0.47815582846788807,0.4787598147775317,0.47916247231729414,0.48057177370646265,0.4809744312462251,0.4815784175558687,0.48198107509563115,0.4823837326353936,0.4829877189450372,0.4837930340245621,0.4841956915643245,0.4843970203342058,0.4847996778739682,0.4860076504932555,0.48641030803301794,0.48661163680289915,0.487416951882424,0.4896315683511174,0.49043688343064223,0.4910408697402859,0.4914435272800483,0.4928528286692168,0.49325548620897924,0.494866116368029,0.49526877390779145,0.4962754177571975,0.49667807529695995,0.4970807328367224,0.49768471914636603,0.4984900342258909,0.4988926917656533,0.4996980068451782,0.5003019931548218,0.5007046506945843,0.5011073082343467,0.5013086370042279,0.5021139520837528,0.50332192470304,0.5037245822428025,0.5059391987114958,0.5063418562512583,0.5131870344272197,0.5135896919669821,0.5137910207368633,0.5141936782766258,0.5147976645862694,0.5152003221260318,0.5158043084356755,0.5166096235152003,0.5168109522850816,0.517213609824844,0.5188242399838937,0.5194282262935374,0.5218441715321119,0.5222468290718744,0.5244614455405677,0.5248641030803302,0.5258707469297362,0.5264747332393799,0.528488020938192,0.5288906784779545,0.5292933360177169,0.5296959935574793,0.530299979867123,0.5307026374068854,0.5329172538755789,0.5333199114153413,0.5359371854237971,0.5363398429635595,0.536742500503322,0.5371451580430844,0.537749144352728,0.5381518018924905,0.5387557882021341,0.5391584457418965,0.5407690759009463,0.5411717334407087,0.5413730622105899,0.5417757197503523,0.5429836923696396,0.5435876786792833,0.5447956512985705,0.5456009663780954,0.5466076102275015,0.5472115965371451,0.5474129253070263,0.5478155828467888,0.54801691161667,0.5484195691564324,0.5486208979263136,0.5490235554660761,0.5516408294745319,0.5520434870142943,0.5524461445540568,0.5530501308637005,0.5536541171733441,0.5542581034829878,0.554459432252869,0.5548620897926314,0.5558687336420375,0.5562713911817999,0.5568753774914436,0.557278035031206,0.5586873364203745,0.5594926514998994,0.5631165693577612,0.5637205556674049,0.5693577612240789,0.5701630763036037,0.5705657338433662,0.5725790215421783,0.5731830078518221,0.5735856653915845,0.5739883229313469,0.5751962955506342,0.5755989530903967,0.5784175558687337,0.5788202134084961,0.5818401449567143,0.5822428024964768,0.5850614052748138,0.5856653915844574,0.5860680491242198,0.5864707066639823,0.5868733642037447,0.5878800080531508,0.5882826655929132,0.5900946245218441,0.590899939601369,0.5911012683712502,0.5915039259110126,0.5917052546808939,0.5921079122206563,0.5925105697604187,0.5931145560700624,0.5953291725387558,0.5957318300785183,0.5961344876182807,0.5969398026978056,0.5979464465472116,0.5983491040869741,0.5989530903966177,0.5993557479363801,0.6021743507147171,0.6025770082544796,0.6031809945641232,0.6033823233340044,0.6037849808737669,0.6039863096436481,0.6043889671834105,0.6055969398026978,0.6062009261123414,0.6070062411918663,0.6074088987316287,0.6080128850412724,0.6084155425810348,0.6094221864304409,0.6102275015099657,0.611435474129253,0.6122407892087779,0.6130461042883028,0.6138514193678276,0.615059391987115,0.6158647070666399,0.6166700221461647,0.6170726796859272,0.6200926112341454,0.6204952687739078,0.6229112140124824,0.6233138715522448,0.6239178578618885,0.6243205154016509,0.6247231729414133,0.6251258304811758,0.625327159251057,0.6257298167908194,0.6273404469498691,0.6277431044896316,0.6321723374270183,0.6329776525065431,0.633782967586068,0.6341856251258304,0.6343869538957116,0.6347896114354741,0.6372055566740488,0.6384135292933361,0.6386148580632173,0.6390175156029797,0.6408294745319106,0.6416347896114355,0.6420374471511979,0.6424401046909604,0.643044091000604,0.6436480773102476,0.6440507348500101,0.6444533923897725,0.6454600362391786,0.6462653513187034,0.6464666800885847,0.6468693376283471,0.6470706663982283,0.6478759814777532,0.6492852828669217,0.6500905979464465,0.6512985705657338,0.6519025568753775,0.6521038856452587,0.6527078719549023,0.6529092007247835,0.6537145158043084,0.6541171733440708,0.6547211596537145,0.6551238171934769,0.6555264747332393,0.6581437487416952,0.6589490638212201,0.6593517213609825,0.659754378900745,0.6605596939802698,0.6609623515200322,0.6611636802899135,0.6619689953694383,0.6631769679887256,0.663579625528488,0.6659955707670626,0.6668008858465875,0.6670022146164687,0.6674048721562311,0.6680088584658748,0.6684115160056372,0.6688141735453996,0.6696194886249245,0.6702234749345681,0.6708274612442118,0.671028790014093,0.6720354338634991,0.6724380914032615,0.6728407489430239,0.6732434064827864,0.6736460640225488,0.6750553654117173,0.6754580229514797,0.6762633380310046,0.6768673243406482,0.6770686531105294,0.677471310650292,0.6778739681900544,0.678477954499698,0.6792832695792229,0.6798872558888666,0.6816992148177975,0.6821018723575599,0.6823032011274411,0.6827058586672036,0.6833098449768472,0.6843164888262533,0.6847191463660157,0.6869337628347091,0.6873364203744715,0.6899536943829273,0.6903563519226897,0.6931749547010267,0.6935776122407892,0.6947855848600765,0.6951882423998389,0.6965975437890074,0.6970002013287698,0.6974028588685323,0.6978055164082947,0.699818804107107,0.7002214616468694,0.7004227904167506,0.700825447956513,0.7016307630360379,0.7022347493456815,0.7030400644252064,0.70364405073485,0.7038453795047313,0.7044493658143749,0.7108918864505738,0.7114958727602174,0.7147171330783169,0.7151197906180793,0.7157237769277229,0.7179383933964163,0.7183410509361787,0.7185423797060599,0.7189450372458225,0.7197503523253473,0.7201530098651098,0.7205556674048722,0.7211596537145158,0.7219649687940407,0.7223676263338031,0.7227702838735656,0.7235755989530904,0.7239782564928529,0.7245822428024965,0.7247835715723777,0.7253875578820214,0.7286088182001208,0.7292128045097644,0.7296154620495269,0.7300181195892893,0.7304207771290517,0.731628749748339,0.7320314072881015,0.7324340648278639,0.7328367223676263,0.7338433662170324,0.734447352526676,0.7346486812965572,0.7350513388363197,0.7352526676062009,0.7356553251459633,0.7360579826857258,0.7364606402254882,0.7370646265351318,0.7374672840748943,0.7376686128447755,0.7380712703845379,0.7382725991544191,0.7386752566941815,0.739077914233944,0.7396819005435877,0.7400845580833502,0.7404872156231126,0.7406885443929938,0.7414938594725187,0.7425005033219247,0.7431044896315684,0.7439098047110932,0.7443124622508557,0.7447151197906181,0.7449164485604993,0.7453191061002618,0.7457217636400242,0.7461244211797866,0.746527078719549,0.7471310650291927,0.7485403664183612,0.7489430239581236,0.7515602979665794,0.7523656130461043,0.7549828870545601,0.7553855445943225,0.7561908596738474,0.7565935172136098,0.7573988322931346,0.7578014898328971,0.759613448761828,0.7600161063015904,0.7610227501509966,0.7618280652305215,0.7620293940004027,0.7626333803100463,0.7628347090799276,0.76323736661969,0.7636400241594524,0.7640426816992149,0.7644453392389773,0.7652506543185021,0.7664586269377894,0.7668612844775519,0.7678679283269579,0.7686732434064828,0.770686531105295,0.7710891886450574,0.7720958324944635,0.7724984900342259,0.7743104489631568,0.7751157640426817,0.7767263942017314,0.7771290517414938,0.7775317092812563,0.7783370243607811,0.780148983289712,0.7805516408294745,0.782766257298168,0.7831689148379304,0.7839742299174552,0.7843768874572177,0.7853835313066238,0.7857861888463862,0.7859875176162674,0.786591503925911,0.7867928326957923,0.7875981477753171,0.7877994765451983,0.7882021340849608,0.7926313670223475,0.7938393396416348,0.7954499698006845,0.7962552848802094,0.7972619287296154,0.7978659150392591,0.8000805315079524,0.8004831890477149,0.801489832897121,0.8022951479766459,0.8024964767465271,0.8028991342862896,0.803301791826052,0.8037044493658144,0.8043084356754581,0.8047110932152205,0.8049124219851017,0.8053150795248641,0.8067243809140326,0.8073283672236763,0.8075296959935575,0.8083350110730824,0.8093416549224884,0.8099456412321321,0.8103482987718945,0.8109522850815382,0.8113549426213006,0.8121602577008254,0.8139722166297564,0.8143748741695188,0.8147775317092812,0.8151801892490437,0.8155828467888061,0.8159855043285685,0.8167908194080934,0.8171934769478558,0.8175961344876183,0.8182001207972619,0.8196094221864304,0.8200120797261928,0.8210187235755989,0.8214213811153613,0.8250452989732233,0.825649285282867,0.8260519428226294,0.8276625729816791,0.8282665592913228,0.828467888061204,0.8288705456009664,0.8290718743708476,0.82947453191061,0.8300785182202537,0.8314878196094222,0.8320918059190658,0.8324944634588283,0.8328971209985907,0.8351117374672841,0.8355143950070465,0.8363197100865714,0.8367223676263338,0.8379303402456211,0.8383329977853835,0.8387356553251459,0.8391383128649084,0.839742299174552,0.8401449567143144,0.8403462854841957,0.8407489430239581,0.8411516005637205,0.8415542581034829,0.8419569156432454,0.8423595731830078,0.8431648882625327,0.8439702033420576,0.8453795047312261,0.8459834910408698,0.8465874773505134,0.8471914636601571,0.8530299979867123,0.8542379706059996,0.854640628145762,0.8550432856855245,0.8556472719951681,0.8562512583048117,0.8566539158445742,0.857459230924099,0.8580632172337427,0.8582645460036239,0.8588685323132675,0.85927118985303,0.8614858063217233,0.8622911214012482,0.8634990940205355,0.8641030803301791,0.8649083954097041,0.8655123817193477,0.8659150392591102,0.8687336420374472,0.8691362995772096,0.8693376283470908,0.8697402858868533,0.8703442721964969,0.8711495872760218,0.8719549023555466,0.8727602174350715,0.87416951882424,0.8745721763640024,0.8783974229917455,0.8792027380712704,0.879806724380914,0.8814173545399637,0.8818200120797262,0.8832293134688947,0.8836319710086571,0.8854439299375881,0.886249245017113,0.8868532313267566,0.8872558888665191,0.8896718341050937,0.8900744916448561,0.8922891081135494,0.8926917656533119,0.8955103684316489,0.8959130259714113,0.8961143547412925,0.8969196698208174,0.8979263136702235,0.8983289712099859,0.8985302999798671,0.8991342862895108,0.9001409301389168,0.9013489027582041,0.9045701630763036,0.9053754781558284,0.9057781356955908,0.9061807932353533,0.9063821220052346,0.906784779544997,0.9083954097040468,0.9087980672438092,0.9098047110932153,0.9106100261727401,0.9120193275619086,0.912421985101671,0.9126233138715523,0.9130259714113147,0.9158445741896517,0.9162472317294141,0.9164485604992954,0.9168512180390578,0.9178578618884639,0.9184618481981075,0.9186631769679887,0.9192671632776324,0.9194684920475136,0.919871149587276,0.9206764646668009,0.9212804509764445,0.9214817797463257,0.9218844372860882,0.9224884235957318,0.9230924099053754,0.9236963962150191,0.924501711294544,0.9251056976041876,0.9261123414535937,0.9267163277632373,0.9283269579222871,0.9287296154620496,0.9313468894705054,0.9317495470102678,0.9323535333199114,0.9335615059391987,0.9343668210187236,0.9349708073283672,0.9381920676464667,0.9385947251862291,0.9408093416549225,0.9416146567344473,0.9420173142742098,0.942218643044091,0.9426213005838534,0.9434266156633783,0.9438292732031407,0.9444332595127843,0.9452385745923092,0.9470505335212401,0.9476545198308838,0.9498691362995773,0.9504731226092209,0.9583249446345883,0.9587276021743507,0.9593315884839944,0.9597342460237568,0.959935574793638,0.9603382323334004,0.9623515200322126,0.9629555063418562,0.9635594926514999,0.9641634789611435,0.9643648077310247,0.9647674652707872,0.9649687940406684,0.9653714515804308,0.9663780954298369,0.9667807529695993,0.9677873968190054,0.9681900543587678,0.9689953694382928,0.9698006845178176,0.9706059995973425,0.9710086571371049,0.9736259311455607,0.9744312462250856,0.9762432051540165,0.976645862693779,0.9790618079323535,0.979464465472116,0.980471109321522,0.9808737668612845,0.9820817394805718,0.9826857257902154,0.9828870545600966,0.983289712099859,0.9844976847191463,0.9849003422589088,0.9855043285685524,0.9859069861083148,0.9877189450372458,0.9881216025770082,0.9885242601167706,0.9889269176565331,0.9921481779746326,0.9927521642842763,0.9941614656734448,0.9945641232132072,1.0],\"y\":[0.0,0.0,0.0625,0.0625,0.15625,0.15625,0.15625,0.15625,0.21875,0.21875,0.21875,0.25,0.25,0.25,0.25,0.25,0.28125,0.28125,0.28125,0.3125,0.3125,0.3125,0.3125,0.3125,0.3125,0.34375,0.34375,0.34375,0.34375,0.375,0.375,0.375,0.375,0.375,0.375,0.40625,0.40625,0.40625,0.40625,0.40625,0.40625,0.4375,0.4375,0.46875,0.46875,0.46875,0.46875,0.46875,0.46875,0.46875,0.46875,0.46875,0.46875,0.46875,0.5,0.5,0.5,0.5,0.53125,0.53125,0.53125,0.53125,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.59375,0.625,0.625,0.625,0.625,0.625,0.625,0.625,0.65625,0.65625,0.65625,0.65625,0.65625,0.65625,0.65625,0.65625,0.65625,0.6875,0.6875,0.6875,0.6875,0.6875,0.6875,0.6875,0.6875,0.6875,0.6875,0.71875,0.71875,0.71875,0.71875,0.71875,0.71875,0.71875,0.71875,0.71875,0.71875,0.71875,0.71875,0.71875,0.71875,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.78125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.8125,0.84375,0.84375,0.84375,0.84375,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.875,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.90625,0.9375,0.9375,0.9375,0.9375,0.9375,0.9375,0.9375,0.9375,0.96875,0.96875,0.96875,0.96875,0.96875,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"title\":{\"x\":1},\"legend\":{\"yanchor\":\"bottom\",\"xanchor\":\"right\",\"x\":0.95,\"y\":0.01},\"xaxis\":{\"title\":{\"text\":\"\\u003cb\\u003e1-Specificity\\u003c\\u002fb\\u003e\"},\"range\":[0,1],\"gridcolor\":\"rgba(5, 5, 5, 0.5)\",\"constrain\":\"domain\",\"linecolor\":\"black\"},\"yaxis\":{\"title\":{\"text\":\"\\u003cb\\u003eRecall\\u003c\\u002fb\\u003e\"},\"range\":[0,1],\"gridcolor\":\"rgba(5, 5, 5, 0.5)\",\"scaleanchor\":\"x\",\"scaleratio\":1,\"linecolor\":\"black\"},\"width\":600,\"height\":600,\"font\":{\"family\":\"Times New Roman\",\"size\":22,\"color\":\"Black\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('947457eb-0a52-4c27-b23a-4188d1c69fa4');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "work=test.drop(X_test[X_test['WRK35WKUS_1 - Yes'] == 0].index)\n",
        "#pop=pop.sample(95, random_state=25)\n",
        "work_predictors=work.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "work_target=work['UDPYOPI_1 - Yes']\n",
        "elsee=test.drop(X_test[X_test['WRK35WKUS_1 - Yes'] == 1].index)\n",
        "#elsee=elsee.sample(95, random_state=25)\n",
        "elsee_predictors=elsee.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "elsee_target=elsee['UDPYOPI_1 - Yes']\n",
        "work_prob=network.predict(work_predictors)\n",
        "elsee_prob=network.predict(elsee_predictors)\n",
        "plot_roc_curve2(work_target, work_prob, elsee_target, elsee_prob, 'Working 35 hours or more', 'Others')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "0b760779",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b760779",
        "outputId": "75997348-db34-41da-a448-91f38cb20627"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TtestResult(statistic=53.03622079584519, pvalue=6.97265095969996e-293, df=1000)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "# Working more than 35 hours vs. others\n",
        "df=[]\n",
        "for i in range_with_floats(0.0, 100.0, 0.1):\n",
        "        y_pred_work = (work_prob >= i*0.01).astype(bool)\n",
        "        cm_g1 = confusion_matrix(work_target, y_pred_work)\n",
        "        specificity_g1 = cm_g1[0,0]/(cm_g1[0,0]+cm_g1[0,1])\n",
        "        sensitivity_g1 = cm_g1[1,1]/(cm_g1[1,0]+cm_g1[1,1])\n",
        "\n",
        "        y_pred_elsee = (elsee_prob >= i*0.01).astype(bool)\n",
        "        cm_g2 = confusion_matrix(elsee_target, y_pred_elsee)\n",
        "        specificity_g2 = cm_g2[0,0]/(cm_g2[0,0]+cm_g2[0,1])\n",
        "        sensitivity_g2 = cm_g2[1,1]/(cm_g2[1,0]+cm_g2[1,1])\n",
        "\n",
        "        difference=abs(specificity_g1-specificity_g2)+abs(sensitivity_g1-sensitivity_g2)\n",
        "\n",
        "        df.append({'difference':difference, 'threshold':i})\n",
        "\n",
        "df = pd.DataFrame(df)\n",
        "diff=np.array(df['difference'])\n",
        "\n",
        "stats.ttest_1samp(diff, popmean=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "4bedc6be",
      "metadata": {
        "id": "4bedc6be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21f3624c-9e7a-4dbb-bf88-b9ce988b40ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.8644994683275102 sensitivity: 0.8780487804878049 accuracy_g1: 0.8926767676767676 accuracy_g2: 0.8555711142228446 specificity_g1: 0.8926984126984127 specificity_g2: 0.8554459432252869 sensitivity_g1: 0.8888888888888888 sensitivity_g2: 0.875 difference: 0.05114135836201461 threshold: 12.499999999999972\n",
            "accuracy: 0.9746316269178186 sensitivity: 0.5121951219512195 accuracy_g1: 0.9766414141414141 accuracy_g2: 0.9739947989597919 specificity_g1: 0.9784126984126984 specificity_g2: 0.9772498490034226 sensitivity_g1: 0.6666666666666666 sensitivity_g2: 0.46875 difference: 0.19907951607594243 threshold: 50.0\n"
          ]
        }
      ],
      "source": [
        "# Working more than 35 hours vs. others\n",
        "\n",
        "df=[]\n",
        "\n",
        "\n",
        "for i in range_with_floats(0.0, 100.0, 0.1):\n",
        "    y_pred = (prob >= i*0.01).astype(bool)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    acc=(cm[0,0]+cm[1,1])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])\n",
        "    sen=cm[1,1]/(cm[1,0]+cm[1,1])\n",
        "    if sen>=0.5 and  acc>=0.5:\n",
        "        y_pred_work = (work_prob >= i*0.01).astype(bool)\n",
        "        cm_g1 = confusion_matrix(work_target, y_pred_work)\n",
        "        specificity_g1 = cm_g1[0,0]/(cm_g1[0,0]+cm_g1[0,1])\n",
        "        sensitivity_g1 = cm_g1[1,1]/(cm_g1[1,0]+cm_g1[1,1])\n",
        "        accuracy_g1=(cm_g1[0,0]+cm_g1[1,1])/(cm_g1[0,0]+cm_g1[0,1]+cm_g1[1,0]+cm_g1[1,1])\n",
        "        y_pred_elsee = (elsee_prob >= i*0.01).astype(bool)\n",
        "        cm_g2 = confusion_matrix(elsee_target, y_pred_elsee)\n",
        "        specificity_g2 = cm_g2[0,0]/(cm_g2[0,0]+cm_g2[0,1])\n",
        "        sensitivity_g2 = cm_g2[1,1]/(cm_g2[1,0]+cm_g2[1,1])\n",
        "        accuracy_g2=(cm_g2[0,0]+cm_g2[1,1])/(cm_g2[0,0]+cm_g2[0,1]+cm_g2[1,0]+cm_g2[1,1])\n",
        "        difference=abs(specificity_g1-specificity_g2)+abs(sensitivity_g1-sensitivity_g2)\n",
        "\n",
        "        df.append({'accuracy':acc, 'sensitivity':sen, 'accuracy_g1':accuracy_g1, 'accuracy_g2':accuracy_g2, 'specificity_g1':specificity_g1, 'specificity_g2':specificity_g2,'sensitivity_g1':sensitivity_g1,'sensitivity_g2':sensitivity_g2, 'difference':difference, 'threshold':i})\n",
        "\n",
        "df = pd.DataFrame(df)\n",
        "min_diff = df.iloc[df['difference'].idxmin()]\n",
        "print('accuracy:', min_diff[0], 'sensitivity:', min_diff[1], 'accuracy_g1:', min_diff[2], 'accuracy_g2:', min_diff[3], 'specificity_g1:', min_diff[4], 'specificity_g2:', min_diff[5], 'sensitivity_g1:', min_diff[6], 'sensitivity_g2:', min_diff[7], 'difference:', min_diff[8], 'threshold:', min_diff[9])\n",
        "\n",
        "y_pred = (prob >= 50*0.01).astype(bool)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "acc=(cm[0,0]+cm[1,1])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])\n",
        "sen=cm[1,1]/(cm[1,0]+cm[1,1])\n",
        "\n",
        "y_pred_work = (work_prob >= 50*0.01).astype(bool)\n",
        "cm_g1 = confusion_matrix(work_target, y_pred_work)\n",
        "specificity_g1 = cm_g1[0,0]/(cm_g1[0,0]+cm_g1[0,1])\n",
        "sensitivity_g1 = cm_g1[1,1]/(cm_g1[1,0]+cm_g1[1,1])\n",
        "accuracy_g1=(cm_g1[0,0]+cm_g1[1,1])/(cm_g1[0,0]+cm_g1[0,1]+cm_g1[1,0]+cm_g1[1,1])\n",
        "\n",
        "y_pred_elsee = (elsee_prob >= 50*0.01).astype(bool)\n",
        "cm_g2 = confusion_matrix(elsee_target, y_pred_elsee)\n",
        "specificity_g2 = cm_g2[0,0]/(cm_g2[0,0]+cm_g2[0,1])\n",
        "sensitivity_g2 = cm_g2[1,1]/(cm_g2[1,0]+cm_g2[1,1])\n",
        "accuracy_g2=(cm_g2[0,0]+cm_g2[1,1])/(cm_g2[0,0]+cm_g2[0,1]+cm_g2[1,0]+cm_g2[1,1])\n",
        "difference=abs(specificity_g1-specificity_g2)+abs(sensitivity_g1-sensitivity_g2)\n",
        "\n",
        "print('accuracy:', acc, 'sensitivity:', sen, 'accuracy_g1:', accuracy_g1, 'accuracy_g2:', accuracy_g2, 'specificity_g1:', specificity_g1, 'specificity_g2:', specificity_g2, 'sensitivity_g1:', sensitivity_g1, 'sensitivity_g2:', sensitivity_g2, 'difference:', difference, 'threshold:', 50.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "f197048e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "id": "f197048e",
        "outputId": "505552d6-c44e-4ff8-b6e7-e6b2d542fdf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "146/146 [==============================] - 1s 4ms/step\n",
            "19/19 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"123ae061-3934-4f3a-9c41-e5cea1d2aa66\" class=\"plotly-graph-div\" style=\"height:600px; width:600px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"123ae061-3934-4f3a-9c41-e5cea1d2aa66\")) {                    Plotly.newPlot(                        \"123ae061-3934-4f3a-9c41-e5cea1d2aa66\",                        [{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(250, 50, 50, 1.0)\",\"width\":5},\"name\":\"\\u003cb\\u003eWhite\\u003c\\u002fb\\u003e\",\"showlegend\":true,\"x\":[0.0,0.00021561017680034498,0.000646830530401035,0.000646830530401035,0.0010780508840017248,0.0010780508840017248,0.0017248814144027599,0.0017248814144027599,0.0019404915912031048,0.0019404915912031048,0.00258732212160414,0.0034497628288055198,0.0034497628288055198,0.00603708495040966,0.00603708495040966,0.0071151358344113845,0.0071151358344113845,0.008193186718413108,0.008624407072013798,0.009918068132815868,0.01078050884001725,0.010996119016817595,0.010996119016817595,0.011858559724018974,0.012289780077619664,0.0129366106080207,0.0129366106080207,0.013367830961621389,0.014014661492022424,0.014445881845623114,0.015092712376024149,0.015092712376024149,0.015308322552824494,0.015739542906425184,0.016386373436826217,0.017248814144027597,0.017248814144027597,0.017464424320827943,0.017464424320827943,0.019620526088831393,0.020051746442432083,0.02026735661923243,0.02112979732643381,0.02199223803363519,0.02242345838723588,0.023501509271237602,0.023501509271237602,0.023932729624838292,0.02501078050884002,0.02544200086244071,0.027166882276843468,0.0278137128072445,0.028029322984044848,0.028029322984044848,0.028460543337645538,0.028891763691246228,0.02953859422164726,0.02953859422164726,0.02996981457524795,0.030616645105648987,0.03147908581285037,0.032772746873652434,0.03320396722725313,0.03363518758085381,0.03406640793445451,0.03471323846485554,0.03536006899525657,0.035791289348857266,0.03622250970245795,0.03773178094006037,0.038378611470461406,0.03988788270806382,0.04053471323846486,0.04204398447606727,0.04247520482966796,0.04333764553686934,0.04398447606727038,0.044415696420871065,0.0450625269512721,0.04592496765847348,0.04592496765847348,0.04721862871927555,0.04764984907287624,0.04829667960327728,0.0517464424320828,0.0517464424320828,0.05196205260888314,0.052393272962483826,0.054118154376886586,0.05454937473048728,0.054980595084087966,0.055843035791289346,0.05713669685209142,0.057567917205692105,0.05821474773609314,0.058645968089693835,0.059292798620094865,0.0623113410952997,0.06274256144890039,0.06317378180250108,0.06382061233290211,0.0646830530401035,0.06554549374730487,0.06576110392410522,0.06619232427770591,0.06727037516170763,0.06770159551530833,0.06877964639931004,0.06921086675291074,0.06964208710651143,0.06964208710651143,0.07072013799051315,0.07115135834411385,0.07158257869771453,0.07201379905131522,0.07266062958171626,0.07309184993531695,0.07352307028891764,0.07416990081931867,0.07654161276412247,0.07740405347132384,0.07826649417852523,0.07869771453212591,0.0838723587753342,0.08430357912893488,0.08473479948253558,0.08516601983613627,0.08559724018973695,0.086244070720138,0.08667529107373868,0.08753773178094006,0.08969383354894352,0.0901250539025442,0.09120310478654592,0.09163432514014662,0.09184993531694696,0.09228115567054765,0.09292798620094868,0.09335920655454938,0.09357481673134972,0.09400603708495041,0.0944372574385511,0.0948684777921518,0.09616213885295385,0.09745579991375593,0.09788702026735661,0.09853385079775766,0.09918068132815869,0.10047434238896076,0.10133678309616213,0.10176800344976283,0.1030616645105649,0.10370849504096594,0.10715825786977146,0.10974557999137559,0.11017680034497629,0.11103924105217766,0.11190168175937905,0.11211729193617939,0.11276412246658042,0.11319534282018111,0.11341095299698145,0.11384217335058215,0.11427339370418284,0.11470461405778352,0.11621388529538594,0.11664510564898663,0.11750754635618801,0.1179387667097887,0.11923242777059077,0.11966364812419146,0.1203104786545925,0.1203104786545925,0.12203536006899526,0.12289780077619664,0.12332902112979732,0.12354463130659767,0.12397585166019837,0.12419146183699871,0.12483829236739974,0.12548512289780078,0.12677878395860284,0.12721000431220353,0.13065976714100905,0.1313065976714101,0.13173781802501078,0.13216903837861146,0.13260025873221215,0.1328158689090125,0.13346269943941355,0.13367830961621388,0.13367830961621388,0.13389391979301424,0.13432514014661492,0.1347563605002156,0.1351875808538163,0.13561880120741698,0.13734368262181976,0.1375592927986201,0.13799051315222077,0.1384217335058215,0.13971539456662355,0.14165588615782665,0.1438119879258301,0.14445881845623113,0.1448900388098318,0.14510564898663217,0.14553686934023286,0.1461836998706339,0.14661492022423459,0.14747736093143596,0.14790858128503664,0.1485554118154377,0.14920224234583873,0.15028029322984046,0.15092712376024148,0.15135834411384216,0.15178956446744285,0.15286761535144458,0.15329883570504527,0.154376886589047,0.15502371711944804,0.1558861578266494,0.1563173781802501,0.15739542906425183,0.15847347994825356,0.15933592065545493,0.15976714100905562,0.16041397153945666,0.16127641224665804,0.16192324277705908,0.1634325140146615,0.16386373436826218,0.16429495472186287,0.1649417852522639,0.1653730056058646,0.16666666666666666,0.16946959896507116,0.16990081931867185,0.17054764984907286,0.1711944803794739,0.17291936179387668,0.17378180250107805,0.1744286330314791,0.17615351444588184,0.17809400603708495,0.1783096162138853,0.178740836567486,0.1821905993962915,0.18477792151789565,0.18520914187149634,0.18564036222509703,0.18607158257869771,0.1865028029322984,0.1869340232858991,0.1884432945235015,0.1888745148771022,0.18930573523070288,0.1903837861147046,0.1927554980595084,0.1931867184131091,0.1955584303579129,0.19598965071151359,0.19642087106511427,0.19706770159551532,0.19857697283311773,0.19900819318671842,0.20116429495472185,0.20159551530832256,0.20267356619232427,0.2033203967227253,0.20353600689952567,0.20418283742992668,0.20482966796032773,0.20482966796032773,0.2052608883139284,0.20978870202673566,0.21021992238033635,0.2104355325571367,0.2104355325571367,0.21129797326433808,0.21172919361793877,0.2123760241483398,0.2128072445019405,0.21302285467874083,0.21345407503234154,0.21366968520914187,0.21410090556274256,0.21496334626994393,0.21539456662354464,0.21561017680034497,0.21604139715394566,0.21625700733074602,0.21690383786114706,0.21733505821474774,0.22035360068995258,0.22078482104355326,0.2238033635187581,0.22423458387235878,0.2244501940491591,0.2253126347563605,0.2257438551099612,0.2261750754635619,0.22703751617076326,0.22746873652436395,0.22789995687796463,0.22833117723156532,0.2296248382923674,0.23027166882276842,0.23134971970677015,0.2319965502371712,0.23285899094437257,0.23329021129797325,0.2335058214747736,0.2339370418283743,0.23415265200517466,0.23458387235877534,0.23479948253557567,0.23523070288917636,0.23609314359637776,0.23673997412677877,0.23846485554118155,0.23889607589478223,0.2397585166019836,0.24040534713238465,0.24277705907718844,0.24342388960758948,0.24514877102199223,0.24557999137559292,0.24622682190599396,0.24665804225959465,0.24752048296679605,0.24795170332039673,0.24859853385079775,0.2492453643811988,0.24967658473479948,0.2503234152652005,0.25097024579560157,0.2514014661492022,0.2516170763260026,0.25204829667960327,0.2522639068564036,0.25291073738680464,0.2542043984476067,0.2550668391548081,0.2559292798620095,0.2563605002156102,0.25700733074601123,0.2574385510996119,0.25851660198361365,0.2589478223372143,0.25916343251401464,0.25959465286761535,0.2602414833980164,0.26067270375161705,0.26088831392841744,0.26088831392841744,0.2615351444588185,0.26196636481241914,0.2630444156964209,0.26347563605002156,0.2636912462268219,0.2641224665804226,0.2688658904700302,0.2695127210004312,0.2716688227684347,0.27210004312203534,0.27253126347563605,0.2729624838292367,0.2731780940060371,0.27360931435963776,0.27404053471323847,0.27447175506683913,0.27598102630444155,0.276843467011643,0.27749029754204396,0.2783527382492454,0.27986200948684775,0.28029322984044847,0.2805088400172488,0.28137128072445017,0.2818025010780509,0.2822337214316516,0.2861147046140578,0.28654592496765846,0.28676153514445885,0.2871927554980595,0.2884864165588616,0.28913324708926263,0.2897800776196636,0.29042690815006467,0.29452350150927126,0.2949547218628719,0.2958171625700733,0.296248382923674,0.29646399310047433,0.29689521345407505,0.2990513152220785,0.29948253557567917,0.30228546787408367,0.3029322984044847,0.30444156964208713,0.3048727899956878,0.30832255282449333,0.308753773178094,0.3089693833548944,0.30940060370849504,0.30961621388529537,0.3100474342388961,0.31090987494609745,0.3115567054764985,0.31198792583009916,0.31241914618369987,0.31349719706770157,0.314359637774903,0.315006468305304,0.3154376886589047,0.3193186718413109,0.3197498921949116,0.3264338076757223,0.326865028029323,0.3279430789133247,0.3283742992669254,0.32902112979732645,0.3294523501509271,0.33009918068132815,0.33053040103492887,0.33139284174213024,0.3322552824493316,0.333117723156533,0.33398016386373436,0.3346269943941354,0.3350582147477361,0.33527382492453645,0.3361362656317378,0.33656748598533853,0.3374299266925399,0.33807675722294095,0.3385079775765416,0.3421733505821475,0.34260457093574814,0.3436826218197499,0.34411384217335056,0.3445450625269513,0.34540750323415265,0.346269943941354,0.34670116429495473,0.34691677447175506,0.3473479948253558,0.3475636050021561,0.34799482535575677,0.3495040965933592,0.3501509271237602,0.35079775765416127,0.351228978007762,0.35338507977576544,0.35446313065976714,0.3551099611901682,0.35554118154376885,0.35705045278137126,0.357481673134972,0.35834411384217335,0.35877533419577406,0.35963777490297544,0.3624407072013799,0.36330314790858126,0.364381198792583,0.3648124191461837,0.3654592496765847,0.36589047003018543,0.3665373005605865,0.36696852091418714,0.36869340232858994,0.3691246226821906,0.3693402328589909,0.36977145321259164,0.37084950409659334,0.37128072445019406,0.3717119448037947,0.37214316515739543,0.3738680465717982,0.37516170763260026,0.37645536869340235,0.376886589047003,0.3783958602846054,0.37904269081500647,0.3792583009918068,0.3796895213454075,0.38012074169900817,0.3805519620526089,0.383139284174213,0.3835705045278137,0.3857266062958172,0.38658904700301855,0.3868046571798189,0.38766709788702025,0.38939197930142305,0.3898231996550237,0.39003880983182404,0.39047003018542475,0.39284174213022854,0.39327296248382926,0.3962915049590341,0.39715394566623546,0.3975851660198361,0.39823199655023717,0.3988788270806382,0.40189736955584304,0.4027598102630444,0.40470030185424755,0.4051315222078482,0.4064251832686503,0.40685640362225095,0.40707201379905134,0.407503234152652,0.40858128503665375,0.4090125053902544,0.40965933592065545,0.4103061664510565,0.4118154376886589,0.4122466580422596,0.41246226821905996,0.413109098749461,0.4139715394566624,0.41483398016386375,0.4154808106942648,0.41720569210866754,0.4180681328158689,0.42022423458387237,0.42065545493747303,0.42216472617507544,0.4230271668822768,0.42539887882708066,0.4258300991806813,0.4310047434238896,0.4314359637774903,0.43272962483829236,0.4333764553686934,0.4342388960758948,0.4346701164294955,0.43510133678309615,0.43553255713669686,0.4359637774902975,0.43639499784389824,0.43941354031910307,0.4398447606727037,0.4400603708495041,0.44070720137990516,0.44135403191030614,0.44178525226390686,0.4420008624407072,0.4424320827943079,0.44415696420871065,0.44458818456231136,0.4448037947391117,0.44523501509271235,0.44674428633031477,0.4476067270375162,0.44846916774471757,0.4489003880983182,0.45191893057352306,0.4523501509271238,0.4536438119879258,0.45450625269512723,0.4551530832255282,0.45558430357912894,0.456877964639931,0.45752479517033207,0.4577404053471324,0.45817162570073305,0.4590340664079344,0.45968089693833547,0.4601121172919362,0.4629150495903407,0.46334626994394135,0.46463993100474343,0.4650711513583441,0.46571798188874514,0.46614920224234585,0.4674428633031479,0.4678740836567486,0.4715394566623545,0.47197067701595513,0.47240189736955585,0.47283311772315656,0.4743423889607589,0.47477360931435963,0.47498921949115996,0.4754204398447607,0.4760672703751617,0.4769297110823631,0.47887020267356617,0.4795170332039672,0.48145752479517034,0.481888745148771,0.4821043553255714,0.48253557567917205,0.48404484691677446,0.4844760672703752,0.48490728762397584,0.48533850797757655,0.48684777921517897,0.48749460974558,0.49072876239758517,0.49115998275118583,0.49159120310478654,0.49202242345838726,0.49417852522639066,0.4950409659335921,0.4961190168175938,0.49655023717119445,0.49935316946959896,0.49978438982319967,0.5004312203536007,0.5008624407072014,0.5015092712376024,0.5019404915912031,0.504959034066408,0.5058214747736093,0.5081931867184131,0.5088400172488141,0.5101336783096162,0.5109961190168176,0.5120741699008193,0.51250539025442,0.5127210004312204,0.513152220784821,0.5140146614920225,0.5144458818456231,0.5146614920224235,0.5150927123760242,0.5157395429064252,0.5161707632600259,0.5176800344976283,0.518111254851229,0.51875808538163,0.5194049159120311,0.5202673566192324,0.5209141871496334,0.5215610176800345,0.5217766278568349,0.5222078482104355,0.5224234583872359,0.5232858990944372,0.5235015092712376,0.5239327296248383,0.5245795601552393,0.52501078050884,0.5267356619232427,0.5275981026304442,0.5278137128072445,0.5282449331608452,0.5323415265200517,0.5329883570504528,0.536222509702458,0.536869340232859,0.53751617076326,0.5379473911168607,0.5398878827080639,0.5407503234152652,0.5411815437688658,0.5435532557136696,0.5439844760672704,0.5442000862440707,0.5450625269512721,0.5459249676584734,0.5463561880120742,0.5470030185424752,0.5474342388960759,0.5498059508408797,0.5502371711944803,0.5519620526088831,0.5523932729624839,0.5534713238464856,0.5539025442000862,0.5564898663216904,0.5571366968520914,0.5575679172056921,0.5577835273824925,0.5582147477360931,0.5590771884432946,0.5595084087968952,0.5601552393272963,0.5605864596808969,0.5625269512721001,0.5631737818025011,0.5636050021561018,0.5638206123329021,0.5642518326865028,0.5648986632169039,0.567485985338508,0.5679172056921087,0.568132815868909,0.5689952565761104,0.5705045278137129,0.5709357481673135,0.5717981888745148,0.5722294092281156,0.5724450194049159,0.5728762397585166,0.5765416127641224,0.5771884432945235,0.5776196636481242,0.5778352738249245,0.5782664941785253,0.5786977145321259,0.5791289348857266,0.5802069857697283,0.5808538163001293,0.5815006468305304,0.5819318671841311,0.5827943078913325,0.5832255282449331,0.5838723587753342,0.5843035791289349,0.5847347994825356,0.5851660198361363,0.5860284605433377,0.5871065114273394,0.58753773178094,0.5879689521345407,0.5884001724881415,0.5896938335489436,0.5905562742561449,0.5920655454937473,0.592496765847348,0.5933592065545493,0.5937904269081501,0.5940060370849504,0.5944372574385511,0.5955153083225528,0.5961621388529539,0.5965933592065545,0.598102630444157,0.5985338507977577,0.6017680034497628,0.6021992238033635,0.6026304441569642,0.6030616645105649,0.6039241052177663,0.6047865459249676,0.6069426476929711,0.6073738680465718,0.6080206985769728,0.6086675291073739,0.6095299698145753,0.6103924105217766,0.6108236308753773,0.6144890038809832,0.6153514445881846,0.6164294954721863,0.6168607158257869,0.6172919361793877,0.6183699870633894,0.6196636481241915,0.6209573091849935,0.6213885295385942,0.6218197498921949,0.623113410952997,0.6244070720137991,0.6248382923673997,0.6252695127210004,0.6254851228978008,0.6261319534282018,0.6263475636050022,0.6267787839586029,0.6274256144890039,0.6282880551962052,0.628719275549806,0.6289348857266063,0.6293661060802069,0.6295817162570073,0.6304441569642087,0.6319534282018111,0.6328158689090125,0.6336783096162139,0.6343251401466149,0.6345407503234153,0.6351875808538163,0.635618801207417,0.6358344113842174,0.636265631737818,0.6366968520914187,0.6373436826218197,0.6386373436826218,0.6390685640362225,0.641224665804226,0.6420871065114273,0.6425183268650281,0.6429495472186287,0.6433807675722294,0.64381198792583,0.6451056489866321,0.6455368693402329,0.6468305304010349,0.6472617507546357,0.648124191461837,0.648771021992238,0.6500646830530401,0.6509271237602415,0.6517895644674429,0.6522207848210435,0.6526520051746443,0.6530832255282449,0.6535144458818456,0.654376886589047,0.6548081069426477,0.6552393272962483,0.6554549374730487,0.6563173781802502,0.6565329883570504,0.6571798188874515,0.6573954290642519,0.6584734799482536,0.6589047003018542,0.659335920655455,0.6595515308322553,0.6599827511858559,0.6604139715394567,0.6608451918930573,0.6614920224234584,0.6621388529538594,0.6625700733074601,0.6630012936610608,0.6632169038378611,0.6642949547218628,0.6649417852522639,0.666235446313066,0.6666666666666666,0.6673134971970677,0.6677447175506684,0.6683915480810694,0.6714100905562742,0.671841310909875,0.6720569210866753,0.6727037516170763,0.6735661923242777,0.6739974126778784,0.6774471755066839,0.6778783958602846,0.6789564467442863,0.679387667097887,0.6817593790426908,0.6821905993962915,0.6832686502802933,0.6836998706338939,0.684993531694696,0.6854247520482967,0.6869340232858991,0.6873652436394998,0.6877964639931005,0.6882276843467011,0.6886589047003019,0.6890901250539025,0.689952565761104,0.6903837861147046,0.6908150064683053,0.6916774471755067,0.692539887882708,0.6931867184131091,0.6940491591203105,0.6953428201811126,0.7003018542475204,0.7009486847779215,0.703104786545925,0.7035360068995257,0.7041828374299267,0.7059077188443295,0.7063389391979301,0.7074169900819318,0.7080638206123329,0.7084950409659336,0.7097887020267356,0.710004312203536,0.7104355325571367,0.7110823630875377,0.7123760241483398,0.7132384648555412,0.7160413971539457,0.7169038378611471,0.7173350582147477,0.7181974989219491,0.7192755498059509,0.7197067701595515,0.7201379905131522,0.720569210866753,0.7218628719275549,0.7222940922811557,0.722509702457956,0.7238033635187581,0.7240189736955585,0.7244501940491591,0.7246658042259595,0.7250970245795602,0.7257438551099612,0.7261750754635619,0.7263906856403622,0.7272531263475636,0.7278999568779646,0.7283311772315654,0.7285467874083656,0.7294092281155671,0.7296248382923674,0.7300560586459681,0.7311341095299698,0.7317809400603709,0.7322121604139715,0.7324277705907719,0.7332902112979732,0.7335058214747736,0.7339370418283743,0.7341526520051747,0.735015092712376,0.7354463130659767,0.7360931435963778,0.7380336351875808,0.7388960758947822,0.7401897369555843,0.7408365674859854,0.7414833980163864,0.7419146183699871,0.7429926692539888,0.7434238896075894,0.7440707201379905,0.7447175506683915,0.7455799913755929,0.7460112117291936,0.7464424320827943,0.7470892626131953,0.7475204829667961,0.7479517033203967,0.7483829236739974,0.7485985338507978,0.7494609745579991,0.7501078050884001,0.7505390254420009,0.7507546356188012,0.7516170763260026,0.753126347563605,0.7535575679172057,0.7565761103924106,0.7570073307460112,0.7572229409228115,0.7576541612764123,0.7578697714532125,0.7585166019836136,0.758732212160414,0.7591634325140146,0.7600258732212161,0.7608883139284174,0.7632600258732212,0.7636912462268219,0.765631737818025,0.7660629581716257,0.7664941785252264,0.766925398878827,0.7680034497628289,0.7684346701164295,0.7699439413540319,0.7708063820612333,0.7723156532988357,0.7727468736524364,0.7736093143596378,0.7744717550668392,0.776843467011643,0.7772746873652436,0.7792151789564468,0.7796463993100474,0.7805088400172489,0.7809400603708495,0.7820181112548512,0.7824493316084519,0.7828805519620526,0.7835273824924537,0.783742992669254,0.7841742130228547,0.784389823199655,0.7848210435532557,0.7887020267356619,0.7891332470892626,0.789995687796464,0.7908581285036653,0.7921517895644674,0.7925830099180682,0.7938766709788702,0.7945235015092712,0.7951703320396722,0.795601552393273,0.797542043984476,0.7979732643380768,0.7988357050452781,0.7996981457524796,0.7999137559292798,0.8003449762828806,0.8009918068132816,0.8014230271668823,0.801854247520483,0.802501078050884,0.8029322984044847,0.803147908581285,0.8035791289348857,0.8055196205260888,0.8061664510564899,0.8070288917636912,0.808753773178094,0.8094006037084951,0.8098318240620958,0.8102630444156964,0.8104786545924968,0.8111254851228978,0.8119879258300992,0.8124191461836999,0.8134971970677016,0.8139284174213023,0.8145752479517033,0.815006468305304,0.8160845191893057,0.8165157395429065,0.8173781802501078,0.8180250107805088,0.8203967227253126,0.8208279430789134,0.8210435532557137,0.8214747736093143,0.8223372143165157,0.8227684346701164,0.8244933160845191,0.8253557567917206,0.827511858559724,0.828158689090125,0.8283742992669254,0.8288055196205261,0.8296679603277275,0.8303147908581285,0.8311772315653299,0.8320396722725313,0.8326865028029323,0.8329021129797326,0.8341957740405347,0.8346269943941355,0.8352738249245364,0.8357050452781372,0.8361362656317378,0.8365674859853385,0.8374299266925399,0.8385079775765416,0.8391548081069427,0.8395860284605433,0.8423889607589479,0.8428201811125485,0.8434670116429496,0.8438982319965502,0.8445450625269513,0.8449762828805519,0.8451918930573523,0.845623113410953,0.8460543337645536,0.8464855541181544,0.8477792151789565,0.8482104355325571,0.8501509271237603,0.8507977576541613,0.8510133678309616,0.8516601983613626,0.8551099611901681,0.8557567917205692,0.8579128934885727,0.8585597240189737,0.8596377749029754,0.8602846054333765,0.8607158257869771,0.8630875377317809,0.864381198792583,0.8648124191461837,0.8676153514445882,0.8689090125053902,0.8695558430357913,0.869987063389392,0.8708495040965933,0.8714963346269944,0.8723587753341958,0.8730056058645969,0.8732212160413971,0.8736524363949978,0.8764553686934023,0.876886589047003,0.8783958602846055,0.8788270806382061,0.8794739111686072,0.8803363518758085,0.8814144027598103,0.881845623113411,0.8852953859422165,0.8857266062958171,0.8863734368262182,0.8872358775334196,0.88745148771022,0.8880983182406209,0.8896075894782234,0.890038809831824,0.8932729624838293,0.8937041828374299,0.8973695558430358,0.8978007761966365,0.8980163863734368,0.8984476067270375,0.901250539025442,0.9016817593790427,0.9044846916774472,0.9049159120310478,0.9051315222078482,0.9055627425614489,0.9062095730918499,0.9066407934454507,0.9072876239758516,0.9079344545062527,0.9092281155670547,0.9128934885726606,0.913755929279862,0.9139715394566623,0.9144027598102631,0.9148339801638637,0.9152652005174644,0.9167744717550669,0.9176369124622682,0.9180681328158689,0.9184993531694696,0.9219491159982751,0.9228115567054765,0.9234583872358776,0.9243208279430789,0.925614489003881,0.9264769297110823,0.9271237602414834,0.9275549805950841,0.9277705907718844,0.9284174213022854,0.9303579128934886,0.9307891332470892,0.931867184131091,0.9322984044846917,0.9329452350150927,0.9333764553686934,0.9355325571366968,0.9359637774902976,0.9366106080206986,0.9374730487278999,0.9379042690815006,0.9385510996119016,0.9409228115567054,0.9413540319103062,0.9441569642087106,0.9445881845623113,0.9456662354463131,0.9460974557999138,0.9482535575679172,0.9486847779215178,0.9497628288055197,0.9504096593359207,0.9514877102199224,0.9519189305735231,0.9523501509271237,0.9529969814575248,0.9555843035791289,0.9560155239327296,0.9592496765847348,0.9601121172919361,0.961836998706339,0.96248382923674,0.9635618801207417,0.9642087106511428,0.9646399310047434,0.9648555411815438,0.9652867615351445,0.9672272531263476,0.9676584734799483,0.96873652436395,0.9695989650711514,0.9708926261319534,0.9713238464855541,0.9752048296679603,0.9756360500215611,0.9758516601983613,0.9762828805519621,0.976929711082363,0.9773609314359638,0.9777921517895645,0.9782233721431651,0.9805950840879689,0.9810263044415697,0.981888745148771,0.982535575679172,0.9855541181543769,0.9859853385079775,0.9877102199223803,0.988141440275981,0.9887882708063821,0.9892194911599828,0.9900819318671842,0.9905131522207848,0.9922380336351876,0.9928848641655886,0.994394135403191,0.9948253557567918,0.9974126778783958,0.9978438982319966,1.0],\"y\":[0.0,0.0,0.0,0.06896551724137931,0.06896551724137931,0.20689655172413793,0.20689655172413793,0.2413793103448276,0.2413793103448276,0.27586206896551724,0.27586206896551724,0.27586206896551724,0.3103448275862069,0.3103448275862069,0.3448275862068966,0.3448275862068966,0.3793103448275862,0.3793103448275862,0.3793103448275862,0.3793103448275862,0.3793103448275862,0.3793103448275862,0.41379310344827586,0.41379310344827586,0.41379310344827586,0.41379310344827586,0.4482758620689655,0.4482758620689655,0.4482758620689655,0.4482758620689655,0.4482758620689655,0.4827586206896552,0.4827586206896552,0.4827586206896552,0.4827586206896552,0.4827586206896552,0.5172413793103449,0.5172413793103449,0.5517241379310345,0.5517241379310345,0.5517241379310345,0.5517241379310345,0.5517241379310345,0.5517241379310345,0.5517241379310345,0.5517241379310345,0.5862068965517241,0.5862068965517241,0.5862068965517241,0.5862068965517241,0.5862068965517241,0.5862068965517241,0.5862068965517241,0.6206896551724138,0.6206896551724138,0.6206896551724138,0.6206896551724138,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.7241379310344828,0.7241379310344828,0.7241379310344828,0.7241379310344828,0.7241379310344828,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.9310344827586207,0.9310344827586207,0.9310344827586207,0.9310344827586207,0.9310344827586207,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"type\":\"scatter\"},{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(255, 255, 255, 0)\",\"width\":5},\"name\":\"AUC: 0.9531\",\"showlegend\":true,\"x\":[0.0,0.00021561017680034498,0.000646830530401035,0.000646830530401035,0.0010780508840017248,0.0010780508840017248,0.0017248814144027599,0.0017248814144027599,0.0019404915912031048,0.0019404915912031048,0.00258732212160414,0.0034497628288055198,0.0034497628288055198,0.00603708495040966,0.00603708495040966,0.0071151358344113845,0.0071151358344113845,0.008193186718413108,0.008624407072013798,0.009918068132815868,0.01078050884001725,0.010996119016817595,0.010996119016817595,0.011858559724018974,0.012289780077619664,0.0129366106080207,0.0129366106080207,0.013367830961621389,0.014014661492022424,0.014445881845623114,0.015092712376024149,0.015092712376024149,0.015308322552824494,0.015739542906425184,0.016386373436826217,0.017248814144027597,0.017248814144027597,0.017464424320827943,0.017464424320827943,0.019620526088831393,0.020051746442432083,0.02026735661923243,0.02112979732643381,0.02199223803363519,0.02242345838723588,0.023501509271237602,0.023501509271237602,0.023932729624838292,0.02501078050884002,0.02544200086244071,0.027166882276843468,0.0278137128072445,0.028029322984044848,0.028029322984044848,0.028460543337645538,0.028891763691246228,0.02953859422164726,0.02953859422164726,0.02996981457524795,0.030616645105648987,0.03147908581285037,0.032772746873652434,0.03320396722725313,0.03363518758085381,0.03406640793445451,0.03471323846485554,0.03536006899525657,0.035791289348857266,0.03622250970245795,0.03773178094006037,0.038378611470461406,0.03988788270806382,0.04053471323846486,0.04204398447606727,0.04247520482966796,0.04333764553686934,0.04398447606727038,0.044415696420871065,0.0450625269512721,0.04592496765847348,0.04592496765847348,0.04721862871927555,0.04764984907287624,0.04829667960327728,0.0517464424320828,0.0517464424320828,0.05196205260888314,0.052393272962483826,0.054118154376886586,0.05454937473048728,0.054980595084087966,0.055843035791289346,0.05713669685209142,0.057567917205692105,0.05821474773609314,0.058645968089693835,0.059292798620094865,0.0623113410952997,0.06274256144890039,0.06317378180250108,0.06382061233290211,0.0646830530401035,0.06554549374730487,0.06576110392410522,0.06619232427770591,0.06727037516170763,0.06770159551530833,0.06877964639931004,0.06921086675291074,0.06964208710651143,0.06964208710651143,0.07072013799051315,0.07115135834411385,0.07158257869771453,0.07201379905131522,0.07266062958171626,0.07309184993531695,0.07352307028891764,0.07416990081931867,0.07654161276412247,0.07740405347132384,0.07826649417852523,0.07869771453212591,0.0838723587753342,0.08430357912893488,0.08473479948253558,0.08516601983613627,0.08559724018973695,0.086244070720138,0.08667529107373868,0.08753773178094006,0.08969383354894352,0.0901250539025442,0.09120310478654592,0.09163432514014662,0.09184993531694696,0.09228115567054765,0.09292798620094868,0.09335920655454938,0.09357481673134972,0.09400603708495041,0.0944372574385511,0.0948684777921518,0.09616213885295385,0.09745579991375593,0.09788702026735661,0.09853385079775766,0.09918068132815869,0.10047434238896076,0.10133678309616213,0.10176800344976283,0.1030616645105649,0.10370849504096594,0.10715825786977146,0.10974557999137559,0.11017680034497629,0.11103924105217766,0.11190168175937905,0.11211729193617939,0.11276412246658042,0.11319534282018111,0.11341095299698145,0.11384217335058215,0.11427339370418284,0.11470461405778352,0.11621388529538594,0.11664510564898663,0.11750754635618801,0.1179387667097887,0.11923242777059077,0.11966364812419146,0.1203104786545925,0.1203104786545925,0.12203536006899526,0.12289780077619664,0.12332902112979732,0.12354463130659767,0.12397585166019837,0.12419146183699871,0.12483829236739974,0.12548512289780078,0.12677878395860284,0.12721000431220353,0.13065976714100905,0.1313065976714101,0.13173781802501078,0.13216903837861146,0.13260025873221215,0.1328158689090125,0.13346269943941355,0.13367830961621388,0.13367830961621388,0.13389391979301424,0.13432514014661492,0.1347563605002156,0.1351875808538163,0.13561880120741698,0.13734368262181976,0.1375592927986201,0.13799051315222077,0.1384217335058215,0.13971539456662355,0.14165588615782665,0.1438119879258301,0.14445881845623113,0.1448900388098318,0.14510564898663217,0.14553686934023286,0.1461836998706339,0.14661492022423459,0.14747736093143596,0.14790858128503664,0.1485554118154377,0.14920224234583873,0.15028029322984046,0.15092712376024148,0.15135834411384216,0.15178956446744285,0.15286761535144458,0.15329883570504527,0.154376886589047,0.15502371711944804,0.1558861578266494,0.1563173781802501,0.15739542906425183,0.15847347994825356,0.15933592065545493,0.15976714100905562,0.16041397153945666,0.16127641224665804,0.16192324277705908,0.1634325140146615,0.16386373436826218,0.16429495472186287,0.1649417852522639,0.1653730056058646,0.16666666666666666,0.16946959896507116,0.16990081931867185,0.17054764984907286,0.1711944803794739,0.17291936179387668,0.17378180250107805,0.1744286330314791,0.17615351444588184,0.17809400603708495,0.1783096162138853,0.178740836567486,0.1821905993962915,0.18477792151789565,0.18520914187149634,0.18564036222509703,0.18607158257869771,0.1865028029322984,0.1869340232858991,0.1884432945235015,0.1888745148771022,0.18930573523070288,0.1903837861147046,0.1927554980595084,0.1931867184131091,0.1955584303579129,0.19598965071151359,0.19642087106511427,0.19706770159551532,0.19857697283311773,0.19900819318671842,0.20116429495472185,0.20159551530832256,0.20267356619232427,0.2033203967227253,0.20353600689952567,0.20418283742992668,0.20482966796032773,0.20482966796032773,0.2052608883139284,0.20978870202673566,0.21021992238033635,0.2104355325571367,0.2104355325571367,0.21129797326433808,0.21172919361793877,0.2123760241483398,0.2128072445019405,0.21302285467874083,0.21345407503234154,0.21366968520914187,0.21410090556274256,0.21496334626994393,0.21539456662354464,0.21561017680034497,0.21604139715394566,0.21625700733074602,0.21690383786114706,0.21733505821474774,0.22035360068995258,0.22078482104355326,0.2238033635187581,0.22423458387235878,0.2244501940491591,0.2253126347563605,0.2257438551099612,0.2261750754635619,0.22703751617076326,0.22746873652436395,0.22789995687796463,0.22833117723156532,0.2296248382923674,0.23027166882276842,0.23134971970677015,0.2319965502371712,0.23285899094437257,0.23329021129797325,0.2335058214747736,0.2339370418283743,0.23415265200517466,0.23458387235877534,0.23479948253557567,0.23523070288917636,0.23609314359637776,0.23673997412677877,0.23846485554118155,0.23889607589478223,0.2397585166019836,0.24040534713238465,0.24277705907718844,0.24342388960758948,0.24514877102199223,0.24557999137559292,0.24622682190599396,0.24665804225959465,0.24752048296679605,0.24795170332039673,0.24859853385079775,0.2492453643811988,0.24967658473479948,0.2503234152652005,0.25097024579560157,0.2514014661492022,0.2516170763260026,0.25204829667960327,0.2522639068564036,0.25291073738680464,0.2542043984476067,0.2550668391548081,0.2559292798620095,0.2563605002156102,0.25700733074601123,0.2574385510996119,0.25851660198361365,0.2589478223372143,0.25916343251401464,0.25959465286761535,0.2602414833980164,0.26067270375161705,0.26088831392841744,0.26088831392841744,0.2615351444588185,0.26196636481241914,0.2630444156964209,0.26347563605002156,0.2636912462268219,0.2641224665804226,0.2688658904700302,0.2695127210004312,0.2716688227684347,0.27210004312203534,0.27253126347563605,0.2729624838292367,0.2731780940060371,0.27360931435963776,0.27404053471323847,0.27447175506683913,0.27598102630444155,0.276843467011643,0.27749029754204396,0.2783527382492454,0.27986200948684775,0.28029322984044847,0.2805088400172488,0.28137128072445017,0.2818025010780509,0.2822337214316516,0.2861147046140578,0.28654592496765846,0.28676153514445885,0.2871927554980595,0.2884864165588616,0.28913324708926263,0.2897800776196636,0.29042690815006467,0.29452350150927126,0.2949547218628719,0.2958171625700733,0.296248382923674,0.29646399310047433,0.29689521345407505,0.2990513152220785,0.29948253557567917,0.30228546787408367,0.3029322984044847,0.30444156964208713,0.3048727899956878,0.30832255282449333,0.308753773178094,0.3089693833548944,0.30940060370849504,0.30961621388529537,0.3100474342388961,0.31090987494609745,0.3115567054764985,0.31198792583009916,0.31241914618369987,0.31349719706770157,0.314359637774903,0.315006468305304,0.3154376886589047,0.3193186718413109,0.3197498921949116,0.3264338076757223,0.326865028029323,0.3279430789133247,0.3283742992669254,0.32902112979732645,0.3294523501509271,0.33009918068132815,0.33053040103492887,0.33139284174213024,0.3322552824493316,0.333117723156533,0.33398016386373436,0.3346269943941354,0.3350582147477361,0.33527382492453645,0.3361362656317378,0.33656748598533853,0.3374299266925399,0.33807675722294095,0.3385079775765416,0.3421733505821475,0.34260457093574814,0.3436826218197499,0.34411384217335056,0.3445450625269513,0.34540750323415265,0.346269943941354,0.34670116429495473,0.34691677447175506,0.3473479948253558,0.3475636050021561,0.34799482535575677,0.3495040965933592,0.3501509271237602,0.35079775765416127,0.351228978007762,0.35338507977576544,0.35446313065976714,0.3551099611901682,0.35554118154376885,0.35705045278137126,0.357481673134972,0.35834411384217335,0.35877533419577406,0.35963777490297544,0.3624407072013799,0.36330314790858126,0.364381198792583,0.3648124191461837,0.3654592496765847,0.36589047003018543,0.3665373005605865,0.36696852091418714,0.36869340232858994,0.3691246226821906,0.3693402328589909,0.36977145321259164,0.37084950409659334,0.37128072445019406,0.3717119448037947,0.37214316515739543,0.3738680465717982,0.37516170763260026,0.37645536869340235,0.376886589047003,0.3783958602846054,0.37904269081500647,0.3792583009918068,0.3796895213454075,0.38012074169900817,0.3805519620526089,0.383139284174213,0.3835705045278137,0.3857266062958172,0.38658904700301855,0.3868046571798189,0.38766709788702025,0.38939197930142305,0.3898231996550237,0.39003880983182404,0.39047003018542475,0.39284174213022854,0.39327296248382926,0.3962915049590341,0.39715394566623546,0.3975851660198361,0.39823199655023717,0.3988788270806382,0.40189736955584304,0.4027598102630444,0.40470030185424755,0.4051315222078482,0.4064251832686503,0.40685640362225095,0.40707201379905134,0.407503234152652,0.40858128503665375,0.4090125053902544,0.40965933592065545,0.4103061664510565,0.4118154376886589,0.4122466580422596,0.41246226821905996,0.413109098749461,0.4139715394566624,0.41483398016386375,0.4154808106942648,0.41720569210866754,0.4180681328158689,0.42022423458387237,0.42065545493747303,0.42216472617507544,0.4230271668822768,0.42539887882708066,0.4258300991806813,0.4310047434238896,0.4314359637774903,0.43272962483829236,0.4333764553686934,0.4342388960758948,0.4346701164294955,0.43510133678309615,0.43553255713669686,0.4359637774902975,0.43639499784389824,0.43941354031910307,0.4398447606727037,0.4400603708495041,0.44070720137990516,0.44135403191030614,0.44178525226390686,0.4420008624407072,0.4424320827943079,0.44415696420871065,0.44458818456231136,0.4448037947391117,0.44523501509271235,0.44674428633031477,0.4476067270375162,0.44846916774471757,0.4489003880983182,0.45191893057352306,0.4523501509271238,0.4536438119879258,0.45450625269512723,0.4551530832255282,0.45558430357912894,0.456877964639931,0.45752479517033207,0.4577404053471324,0.45817162570073305,0.4590340664079344,0.45968089693833547,0.4601121172919362,0.4629150495903407,0.46334626994394135,0.46463993100474343,0.4650711513583441,0.46571798188874514,0.46614920224234585,0.4674428633031479,0.4678740836567486,0.4715394566623545,0.47197067701595513,0.47240189736955585,0.47283311772315656,0.4743423889607589,0.47477360931435963,0.47498921949115996,0.4754204398447607,0.4760672703751617,0.4769297110823631,0.47887020267356617,0.4795170332039672,0.48145752479517034,0.481888745148771,0.4821043553255714,0.48253557567917205,0.48404484691677446,0.4844760672703752,0.48490728762397584,0.48533850797757655,0.48684777921517897,0.48749460974558,0.49072876239758517,0.49115998275118583,0.49159120310478654,0.49202242345838726,0.49417852522639066,0.4950409659335921,0.4961190168175938,0.49655023717119445,0.49935316946959896,0.49978438982319967,0.5004312203536007,0.5008624407072014,0.5015092712376024,0.5019404915912031,0.504959034066408,0.5058214747736093,0.5081931867184131,0.5088400172488141,0.5101336783096162,0.5109961190168176,0.5120741699008193,0.51250539025442,0.5127210004312204,0.513152220784821,0.5140146614920225,0.5144458818456231,0.5146614920224235,0.5150927123760242,0.5157395429064252,0.5161707632600259,0.5176800344976283,0.518111254851229,0.51875808538163,0.5194049159120311,0.5202673566192324,0.5209141871496334,0.5215610176800345,0.5217766278568349,0.5222078482104355,0.5224234583872359,0.5232858990944372,0.5235015092712376,0.5239327296248383,0.5245795601552393,0.52501078050884,0.5267356619232427,0.5275981026304442,0.5278137128072445,0.5282449331608452,0.5323415265200517,0.5329883570504528,0.536222509702458,0.536869340232859,0.53751617076326,0.5379473911168607,0.5398878827080639,0.5407503234152652,0.5411815437688658,0.5435532557136696,0.5439844760672704,0.5442000862440707,0.5450625269512721,0.5459249676584734,0.5463561880120742,0.5470030185424752,0.5474342388960759,0.5498059508408797,0.5502371711944803,0.5519620526088831,0.5523932729624839,0.5534713238464856,0.5539025442000862,0.5564898663216904,0.5571366968520914,0.5575679172056921,0.5577835273824925,0.5582147477360931,0.5590771884432946,0.5595084087968952,0.5601552393272963,0.5605864596808969,0.5625269512721001,0.5631737818025011,0.5636050021561018,0.5638206123329021,0.5642518326865028,0.5648986632169039,0.567485985338508,0.5679172056921087,0.568132815868909,0.5689952565761104,0.5705045278137129,0.5709357481673135,0.5717981888745148,0.5722294092281156,0.5724450194049159,0.5728762397585166,0.5765416127641224,0.5771884432945235,0.5776196636481242,0.5778352738249245,0.5782664941785253,0.5786977145321259,0.5791289348857266,0.5802069857697283,0.5808538163001293,0.5815006468305304,0.5819318671841311,0.5827943078913325,0.5832255282449331,0.5838723587753342,0.5843035791289349,0.5847347994825356,0.5851660198361363,0.5860284605433377,0.5871065114273394,0.58753773178094,0.5879689521345407,0.5884001724881415,0.5896938335489436,0.5905562742561449,0.5920655454937473,0.592496765847348,0.5933592065545493,0.5937904269081501,0.5940060370849504,0.5944372574385511,0.5955153083225528,0.5961621388529539,0.5965933592065545,0.598102630444157,0.5985338507977577,0.6017680034497628,0.6021992238033635,0.6026304441569642,0.6030616645105649,0.6039241052177663,0.6047865459249676,0.6069426476929711,0.6073738680465718,0.6080206985769728,0.6086675291073739,0.6095299698145753,0.6103924105217766,0.6108236308753773,0.6144890038809832,0.6153514445881846,0.6164294954721863,0.6168607158257869,0.6172919361793877,0.6183699870633894,0.6196636481241915,0.6209573091849935,0.6213885295385942,0.6218197498921949,0.623113410952997,0.6244070720137991,0.6248382923673997,0.6252695127210004,0.6254851228978008,0.6261319534282018,0.6263475636050022,0.6267787839586029,0.6274256144890039,0.6282880551962052,0.628719275549806,0.6289348857266063,0.6293661060802069,0.6295817162570073,0.6304441569642087,0.6319534282018111,0.6328158689090125,0.6336783096162139,0.6343251401466149,0.6345407503234153,0.6351875808538163,0.635618801207417,0.6358344113842174,0.636265631737818,0.6366968520914187,0.6373436826218197,0.6386373436826218,0.6390685640362225,0.641224665804226,0.6420871065114273,0.6425183268650281,0.6429495472186287,0.6433807675722294,0.64381198792583,0.6451056489866321,0.6455368693402329,0.6468305304010349,0.6472617507546357,0.648124191461837,0.648771021992238,0.6500646830530401,0.6509271237602415,0.6517895644674429,0.6522207848210435,0.6526520051746443,0.6530832255282449,0.6535144458818456,0.654376886589047,0.6548081069426477,0.6552393272962483,0.6554549374730487,0.6563173781802502,0.6565329883570504,0.6571798188874515,0.6573954290642519,0.6584734799482536,0.6589047003018542,0.659335920655455,0.6595515308322553,0.6599827511858559,0.6604139715394567,0.6608451918930573,0.6614920224234584,0.6621388529538594,0.6625700733074601,0.6630012936610608,0.6632169038378611,0.6642949547218628,0.6649417852522639,0.666235446313066,0.6666666666666666,0.6673134971970677,0.6677447175506684,0.6683915480810694,0.6714100905562742,0.671841310909875,0.6720569210866753,0.6727037516170763,0.6735661923242777,0.6739974126778784,0.6774471755066839,0.6778783958602846,0.6789564467442863,0.679387667097887,0.6817593790426908,0.6821905993962915,0.6832686502802933,0.6836998706338939,0.684993531694696,0.6854247520482967,0.6869340232858991,0.6873652436394998,0.6877964639931005,0.6882276843467011,0.6886589047003019,0.6890901250539025,0.689952565761104,0.6903837861147046,0.6908150064683053,0.6916774471755067,0.692539887882708,0.6931867184131091,0.6940491591203105,0.6953428201811126,0.7003018542475204,0.7009486847779215,0.703104786545925,0.7035360068995257,0.7041828374299267,0.7059077188443295,0.7063389391979301,0.7074169900819318,0.7080638206123329,0.7084950409659336,0.7097887020267356,0.710004312203536,0.7104355325571367,0.7110823630875377,0.7123760241483398,0.7132384648555412,0.7160413971539457,0.7169038378611471,0.7173350582147477,0.7181974989219491,0.7192755498059509,0.7197067701595515,0.7201379905131522,0.720569210866753,0.7218628719275549,0.7222940922811557,0.722509702457956,0.7238033635187581,0.7240189736955585,0.7244501940491591,0.7246658042259595,0.7250970245795602,0.7257438551099612,0.7261750754635619,0.7263906856403622,0.7272531263475636,0.7278999568779646,0.7283311772315654,0.7285467874083656,0.7294092281155671,0.7296248382923674,0.7300560586459681,0.7311341095299698,0.7317809400603709,0.7322121604139715,0.7324277705907719,0.7332902112979732,0.7335058214747736,0.7339370418283743,0.7341526520051747,0.735015092712376,0.7354463130659767,0.7360931435963778,0.7380336351875808,0.7388960758947822,0.7401897369555843,0.7408365674859854,0.7414833980163864,0.7419146183699871,0.7429926692539888,0.7434238896075894,0.7440707201379905,0.7447175506683915,0.7455799913755929,0.7460112117291936,0.7464424320827943,0.7470892626131953,0.7475204829667961,0.7479517033203967,0.7483829236739974,0.7485985338507978,0.7494609745579991,0.7501078050884001,0.7505390254420009,0.7507546356188012,0.7516170763260026,0.753126347563605,0.7535575679172057,0.7565761103924106,0.7570073307460112,0.7572229409228115,0.7576541612764123,0.7578697714532125,0.7585166019836136,0.758732212160414,0.7591634325140146,0.7600258732212161,0.7608883139284174,0.7632600258732212,0.7636912462268219,0.765631737818025,0.7660629581716257,0.7664941785252264,0.766925398878827,0.7680034497628289,0.7684346701164295,0.7699439413540319,0.7708063820612333,0.7723156532988357,0.7727468736524364,0.7736093143596378,0.7744717550668392,0.776843467011643,0.7772746873652436,0.7792151789564468,0.7796463993100474,0.7805088400172489,0.7809400603708495,0.7820181112548512,0.7824493316084519,0.7828805519620526,0.7835273824924537,0.783742992669254,0.7841742130228547,0.784389823199655,0.7848210435532557,0.7887020267356619,0.7891332470892626,0.789995687796464,0.7908581285036653,0.7921517895644674,0.7925830099180682,0.7938766709788702,0.7945235015092712,0.7951703320396722,0.795601552393273,0.797542043984476,0.7979732643380768,0.7988357050452781,0.7996981457524796,0.7999137559292798,0.8003449762828806,0.8009918068132816,0.8014230271668823,0.801854247520483,0.802501078050884,0.8029322984044847,0.803147908581285,0.8035791289348857,0.8055196205260888,0.8061664510564899,0.8070288917636912,0.808753773178094,0.8094006037084951,0.8098318240620958,0.8102630444156964,0.8104786545924968,0.8111254851228978,0.8119879258300992,0.8124191461836999,0.8134971970677016,0.8139284174213023,0.8145752479517033,0.815006468305304,0.8160845191893057,0.8165157395429065,0.8173781802501078,0.8180250107805088,0.8203967227253126,0.8208279430789134,0.8210435532557137,0.8214747736093143,0.8223372143165157,0.8227684346701164,0.8244933160845191,0.8253557567917206,0.827511858559724,0.828158689090125,0.8283742992669254,0.8288055196205261,0.8296679603277275,0.8303147908581285,0.8311772315653299,0.8320396722725313,0.8326865028029323,0.8329021129797326,0.8341957740405347,0.8346269943941355,0.8352738249245364,0.8357050452781372,0.8361362656317378,0.8365674859853385,0.8374299266925399,0.8385079775765416,0.8391548081069427,0.8395860284605433,0.8423889607589479,0.8428201811125485,0.8434670116429496,0.8438982319965502,0.8445450625269513,0.8449762828805519,0.8451918930573523,0.845623113410953,0.8460543337645536,0.8464855541181544,0.8477792151789565,0.8482104355325571,0.8501509271237603,0.8507977576541613,0.8510133678309616,0.8516601983613626,0.8551099611901681,0.8557567917205692,0.8579128934885727,0.8585597240189737,0.8596377749029754,0.8602846054333765,0.8607158257869771,0.8630875377317809,0.864381198792583,0.8648124191461837,0.8676153514445882,0.8689090125053902,0.8695558430357913,0.869987063389392,0.8708495040965933,0.8714963346269944,0.8723587753341958,0.8730056058645969,0.8732212160413971,0.8736524363949978,0.8764553686934023,0.876886589047003,0.8783958602846055,0.8788270806382061,0.8794739111686072,0.8803363518758085,0.8814144027598103,0.881845623113411,0.8852953859422165,0.8857266062958171,0.8863734368262182,0.8872358775334196,0.88745148771022,0.8880983182406209,0.8896075894782234,0.890038809831824,0.8932729624838293,0.8937041828374299,0.8973695558430358,0.8978007761966365,0.8980163863734368,0.8984476067270375,0.901250539025442,0.9016817593790427,0.9044846916774472,0.9049159120310478,0.9051315222078482,0.9055627425614489,0.9062095730918499,0.9066407934454507,0.9072876239758516,0.9079344545062527,0.9092281155670547,0.9128934885726606,0.913755929279862,0.9139715394566623,0.9144027598102631,0.9148339801638637,0.9152652005174644,0.9167744717550669,0.9176369124622682,0.9180681328158689,0.9184993531694696,0.9219491159982751,0.9228115567054765,0.9234583872358776,0.9243208279430789,0.925614489003881,0.9264769297110823,0.9271237602414834,0.9275549805950841,0.9277705907718844,0.9284174213022854,0.9303579128934886,0.9307891332470892,0.931867184131091,0.9322984044846917,0.9329452350150927,0.9333764553686934,0.9355325571366968,0.9359637774902976,0.9366106080206986,0.9374730487278999,0.9379042690815006,0.9385510996119016,0.9409228115567054,0.9413540319103062,0.9441569642087106,0.9445881845623113,0.9456662354463131,0.9460974557999138,0.9482535575679172,0.9486847779215178,0.9497628288055197,0.9504096593359207,0.9514877102199224,0.9519189305735231,0.9523501509271237,0.9529969814575248,0.9555843035791289,0.9560155239327296,0.9592496765847348,0.9601121172919361,0.961836998706339,0.96248382923674,0.9635618801207417,0.9642087106511428,0.9646399310047434,0.9648555411815438,0.9652867615351445,0.9672272531263476,0.9676584734799483,0.96873652436395,0.9695989650711514,0.9708926261319534,0.9713238464855541,0.9752048296679603,0.9756360500215611,0.9758516601983613,0.9762828805519621,0.976929711082363,0.9773609314359638,0.9777921517895645,0.9782233721431651,0.9805950840879689,0.9810263044415697,0.981888745148771,0.982535575679172,0.9855541181543769,0.9859853385079775,0.9877102199223803,0.988141440275981,0.9887882708063821,0.9892194911599828,0.9900819318671842,0.9905131522207848,0.9922380336351876,0.9928848641655886,0.994394135403191,0.9948253557567918,0.9974126778783958,0.9978438982319966,1.0],\"y\":[0.0,0.0,0.0,0.06896551724137931,0.06896551724137931,0.20689655172413793,0.20689655172413793,0.2413793103448276,0.2413793103448276,0.27586206896551724,0.27586206896551724,0.27586206896551724,0.3103448275862069,0.3103448275862069,0.3448275862068966,0.3448275862068966,0.3793103448275862,0.3793103448275862,0.3793103448275862,0.3793103448275862,0.3793103448275862,0.3793103448275862,0.41379310344827586,0.41379310344827586,0.41379310344827586,0.41379310344827586,0.4482758620689655,0.4482758620689655,0.4482758620689655,0.4482758620689655,0.4482758620689655,0.4827586206896552,0.4827586206896552,0.4827586206896552,0.4827586206896552,0.4827586206896552,0.5172413793103449,0.5172413793103449,0.5517241379310345,0.5517241379310345,0.5517241379310345,0.5517241379310345,0.5517241379310345,0.5517241379310345,0.5517241379310345,0.5517241379310345,0.5862068965517241,0.5862068965517241,0.5862068965517241,0.5862068965517241,0.5862068965517241,0.5862068965517241,0.5862068965517241,0.6206896551724138,0.6206896551724138,0.6206896551724138,0.6206896551724138,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.7241379310344828,0.7241379310344828,0.7241379310344828,0.7241379310344828,0.7241379310344828,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.9310344827586207,0.9310344827586207,0.9310344827586207,0.9310344827586207,0.9310344827586207,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"type\":\"scatter\"},{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(255, 255, 255, 0)\",\"width\":0},\"name\":\"(95% CI: 0.8994-1.0000)\",\"showlegend\":true,\"x\":[0.0,0.00021561017680034498,0.000646830530401035,0.000646830530401035,0.0010780508840017248,0.0010780508840017248,0.0017248814144027599,0.0017248814144027599,0.0019404915912031048,0.0019404915912031048,0.00258732212160414,0.0034497628288055198,0.0034497628288055198,0.00603708495040966,0.00603708495040966,0.0071151358344113845,0.0071151358344113845,0.008193186718413108,0.008624407072013798,0.009918068132815868,0.01078050884001725,0.010996119016817595,0.010996119016817595,0.011858559724018974,0.012289780077619664,0.0129366106080207,0.0129366106080207,0.013367830961621389,0.014014661492022424,0.014445881845623114,0.015092712376024149,0.015092712376024149,0.015308322552824494,0.015739542906425184,0.016386373436826217,0.017248814144027597,0.017248814144027597,0.017464424320827943,0.017464424320827943,0.019620526088831393,0.020051746442432083,0.02026735661923243,0.02112979732643381,0.02199223803363519,0.02242345838723588,0.023501509271237602,0.023501509271237602,0.023932729624838292,0.02501078050884002,0.02544200086244071,0.027166882276843468,0.0278137128072445,0.028029322984044848,0.028029322984044848,0.028460543337645538,0.028891763691246228,0.02953859422164726,0.02953859422164726,0.02996981457524795,0.030616645105648987,0.03147908581285037,0.032772746873652434,0.03320396722725313,0.03363518758085381,0.03406640793445451,0.03471323846485554,0.03536006899525657,0.035791289348857266,0.03622250970245795,0.03773178094006037,0.038378611470461406,0.03988788270806382,0.04053471323846486,0.04204398447606727,0.04247520482966796,0.04333764553686934,0.04398447606727038,0.044415696420871065,0.0450625269512721,0.04592496765847348,0.04592496765847348,0.04721862871927555,0.04764984907287624,0.04829667960327728,0.0517464424320828,0.0517464424320828,0.05196205260888314,0.052393272962483826,0.054118154376886586,0.05454937473048728,0.054980595084087966,0.055843035791289346,0.05713669685209142,0.057567917205692105,0.05821474773609314,0.058645968089693835,0.059292798620094865,0.0623113410952997,0.06274256144890039,0.06317378180250108,0.06382061233290211,0.0646830530401035,0.06554549374730487,0.06576110392410522,0.06619232427770591,0.06727037516170763,0.06770159551530833,0.06877964639931004,0.06921086675291074,0.06964208710651143,0.06964208710651143,0.07072013799051315,0.07115135834411385,0.07158257869771453,0.07201379905131522,0.07266062958171626,0.07309184993531695,0.07352307028891764,0.07416990081931867,0.07654161276412247,0.07740405347132384,0.07826649417852523,0.07869771453212591,0.0838723587753342,0.08430357912893488,0.08473479948253558,0.08516601983613627,0.08559724018973695,0.086244070720138,0.08667529107373868,0.08753773178094006,0.08969383354894352,0.0901250539025442,0.09120310478654592,0.09163432514014662,0.09184993531694696,0.09228115567054765,0.09292798620094868,0.09335920655454938,0.09357481673134972,0.09400603708495041,0.0944372574385511,0.0948684777921518,0.09616213885295385,0.09745579991375593,0.09788702026735661,0.09853385079775766,0.09918068132815869,0.10047434238896076,0.10133678309616213,0.10176800344976283,0.1030616645105649,0.10370849504096594,0.10715825786977146,0.10974557999137559,0.11017680034497629,0.11103924105217766,0.11190168175937905,0.11211729193617939,0.11276412246658042,0.11319534282018111,0.11341095299698145,0.11384217335058215,0.11427339370418284,0.11470461405778352,0.11621388529538594,0.11664510564898663,0.11750754635618801,0.1179387667097887,0.11923242777059077,0.11966364812419146,0.1203104786545925,0.1203104786545925,0.12203536006899526,0.12289780077619664,0.12332902112979732,0.12354463130659767,0.12397585166019837,0.12419146183699871,0.12483829236739974,0.12548512289780078,0.12677878395860284,0.12721000431220353,0.13065976714100905,0.1313065976714101,0.13173781802501078,0.13216903837861146,0.13260025873221215,0.1328158689090125,0.13346269943941355,0.13367830961621388,0.13367830961621388,0.13389391979301424,0.13432514014661492,0.1347563605002156,0.1351875808538163,0.13561880120741698,0.13734368262181976,0.1375592927986201,0.13799051315222077,0.1384217335058215,0.13971539456662355,0.14165588615782665,0.1438119879258301,0.14445881845623113,0.1448900388098318,0.14510564898663217,0.14553686934023286,0.1461836998706339,0.14661492022423459,0.14747736093143596,0.14790858128503664,0.1485554118154377,0.14920224234583873,0.15028029322984046,0.15092712376024148,0.15135834411384216,0.15178956446744285,0.15286761535144458,0.15329883570504527,0.154376886589047,0.15502371711944804,0.1558861578266494,0.1563173781802501,0.15739542906425183,0.15847347994825356,0.15933592065545493,0.15976714100905562,0.16041397153945666,0.16127641224665804,0.16192324277705908,0.1634325140146615,0.16386373436826218,0.16429495472186287,0.1649417852522639,0.1653730056058646,0.16666666666666666,0.16946959896507116,0.16990081931867185,0.17054764984907286,0.1711944803794739,0.17291936179387668,0.17378180250107805,0.1744286330314791,0.17615351444588184,0.17809400603708495,0.1783096162138853,0.178740836567486,0.1821905993962915,0.18477792151789565,0.18520914187149634,0.18564036222509703,0.18607158257869771,0.1865028029322984,0.1869340232858991,0.1884432945235015,0.1888745148771022,0.18930573523070288,0.1903837861147046,0.1927554980595084,0.1931867184131091,0.1955584303579129,0.19598965071151359,0.19642087106511427,0.19706770159551532,0.19857697283311773,0.19900819318671842,0.20116429495472185,0.20159551530832256,0.20267356619232427,0.2033203967227253,0.20353600689952567,0.20418283742992668,0.20482966796032773,0.20482966796032773,0.2052608883139284,0.20978870202673566,0.21021992238033635,0.2104355325571367,0.2104355325571367,0.21129797326433808,0.21172919361793877,0.2123760241483398,0.2128072445019405,0.21302285467874083,0.21345407503234154,0.21366968520914187,0.21410090556274256,0.21496334626994393,0.21539456662354464,0.21561017680034497,0.21604139715394566,0.21625700733074602,0.21690383786114706,0.21733505821474774,0.22035360068995258,0.22078482104355326,0.2238033635187581,0.22423458387235878,0.2244501940491591,0.2253126347563605,0.2257438551099612,0.2261750754635619,0.22703751617076326,0.22746873652436395,0.22789995687796463,0.22833117723156532,0.2296248382923674,0.23027166882276842,0.23134971970677015,0.2319965502371712,0.23285899094437257,0.23329021129797325,0.2335058214747736,0.2339370418283743,0.23415265200517466,0.23458387235877534,0.23479948253557567,0.23523070288917636,0.23609314359637776,0.23673997412677877,0.23846485554118155,0.23889607589478223,0.2397585166019836,0.24040534713238465,0.24277705907718844,0.24342388960758948,0.24514877102199223,0.24557999137559292,0.24622682190599396,0.24665804225959465,0.24752048296679605,0.24795170332039673,0.24859853385079775,0.2492453643811988,0.24967658473479948,0.2503234152652005,0.25097024579560157,0.2514014661492022,0.2516170763260026,0.25204829667960327,0.2522639068564036,0.25291073738680464,0.2542043984476067,0.2550668391548081,0.2559292798620095,0.2563605002156102,0.25700733074601123,0.2574385510996119,0.25851660198361365,0.2589478223372143,0.25916343251401464,0.25959465286761535,0.2602414833980164,0.26067270375161705,0.26088831392841744,0.26088831392841744,0.2615351444588185,0.26196636481241914,0.2630444156964209,0.26347563605002156,0.2636912462268219,0.2641224665804226,0.2688658904700302,0.2695127210004312,0.2716688227684347,0.27210004312203534,0.27253126347563605,0.2729624838292367,0.2731780940060371,0.27360931435963776,0.27404053471323847,0.27447175506683913,0.27598102630444155,0.276843467011643,0.27749029754204396,0.2783527382492454,0.27986200948684775,0.28029322984044847,0.2805088400172488,0.28137128072445017,0.2818025010780509,0.2822337214316516,0.2861147046140578,0.28654592496765846,0.28676153514445885,0.2871927554980595,0.2884864165588616,0.28913324708926263,0.2897800776196636,0.29042690815006467,0.29452350150927126,0.2949547218628719,0.2958171625700733,0.296248382923674,0.29646399310047433,0.29689521345407505,0.2990513152220785,0.29948253557567917,0.30228546787408367,0.3029322984044847,0.30444156964208713,0.3048727899956878,0.30832255282449333,0.308753773178094,0.3089693833548944,0.30940060370849504,0.30961621388529537,0.3100474342388961,0.31090987494609745,0.3115567054764985,0.31198792583009916,0.31241914618369987,0.31349719706770157,0.314359637774903,0.315006468305304,0.3154376886589047,0.3193186718413109,0.3197498921949116,0.3264338076757223,0.326865028029323,0.3279430789133247,0.3283742992669254,0.32902112979732645,0.3294523501509271,0.33009918068132815,0.33053040103492887,0.33139284174213024,0.3322552824493316,0.333117723156533,0.33398016386373436,0.3346269943941354,0.3350582147477361,0.33527382492453645,0.3361362656317378,0.33656748598533853,0.3374299266925399,0.33807675722294095,0.3385079775765416,0.3421733505821475,0.34260457093574814,0.3436826218197499,0.34411384217335056,0.3445450625269513,0.34540750323415265,0.346269943941354,0.34670116429495473,0.34691677447175506,0.3473479948253558,0.3475636050021561,0.34799482535575677,0.3495040965933592,0.3501509271237602,0.35079775765416127,0.351228978007762,0.35338507977576544,0.35446313065976714,0.3551099611901682,0.35554118154376885,0.35705045278137126,0.357481673134972,0.35834411384217335,0.35877533419577406,0.35963777490297544,0.3624407072013799,0.36330314790858126,0.364381198792583,0.3648124191461837,0.3654592496765847,0.36589047003018543,0.3665373005605865,0.36696852091418714,0.36869340232858994,0.3691246226821906,0.3693402328589909,0.36977145321259164,0.37084950409659334,0.37128072445019406,0.3717119448037947,0.37214316515739543,0.3738680465717982,0.37516170763260026,0.37645536869340235,0.376886589047003,0.3783958602846054,0.37904269081500647,0.3792583009918068,0.3796895213454075,0.38012074169900817,0.3805519620526089,0.383139284174213,0.3835705045278137,0.3857266062958172,0.38658904700301855,0.3868046571798189,0.38766709788702025,0.38939197930142305,0.3898231996550237,0.39003880983182404,0.39047003018542475,0.39284174213022854,0.39327296248382926,0.3962915049590341,0.39715394566623546,0.3975851660198361,0.39823199655023717,0.3988788270806382,0.40189736955584304,0.4027598102630444,0.40470030185424755,0.4051315222078482,0.4064251832686503,0.40685640362225095,0.40707201379905134,0.407503234152652,0.40858128503665375,0.4090125053902544,0.40965933592065545,0.4103061664510565,0.4118154376886589,0.4122466580422596,0.41246226821905996,0.413109098749461,0.4139715394566624,0.41483398016386375,0.4154808106942648,0.41720569210866754,0.4180681328158689,0.42022423458387237,0.42065545493747303,0.42216472617507544,0.4230271668822768,0.42539887882708066,0.4258300991806813,0.4310047434238896,0.4314359637774903,0.43272962483829236,0.4333764553686934,0.4342388960758948,0.4346701164294955,0.43510133678309615,0.43553255713669686,0.4359637774902975,0.43639499784389824,0.43941354031910307,0.4398447606727037,0.4400603708495041,0.44070720137990516,0.44135403191030614,0.44178525226390686,0.4420008624407072,0.4424320827943079,0.44415696420871065,0.44458818456231136,0.4448037947391117,0.44523501509271235,0.44674428633031477,0.4476067270375162,0.44846916774471757,0.4489003880983182,0.45191893057352306,0.4523501509271238,0.4536438119879258,0.45450625269512723,0.4551530832255282,0.45558430357912894,0.456877964639931,0.45752479517033207,0.4577404053471324,0.45817162570073305,0.4590340664079344,0.45968089693833547,0.4601121172919362,0.4629150495903407,0.46334626994394135,0.46463993100474343,0.4650711513583441,0.46571798188874514,0.46614920224234585,0.4674428633031479,0.4678740836567486,0.4715394566623545,0.47197067701595513,0.47240189736955585,0.47283311772315656,0.4743423889607589,0.47477360931435963,0.47498921949115996,0.4754204398447607,0.4760672703751617,0.4769297110823631,0.47887020267356617,0.4795170332039672,0.48145752479517034,0.481888745148771,0.4821043553255714,0.48253557567917205,0.48404484691677446,0.4844760672703752,0.48490728762397584,0.48533850797757655,0.48684777921517897,0.48749460974558,0.49072876239758517,0.49115998275118583,0.49159120310478654,0.49202242345838726,0.49417852522639066,0.4950409659335921,0.4961190168175938,0.49655023717119445,0.49935316946959896,0.49978438982319967,0.5004312203536007,0.5008624407072014,0.5015092712376024,0.5019404915912031,0.504959034066408,0.5058214747736093,0.5081931867184131,0.5088400172488141,0.5101336783096162,0.5109961190168176,0.5120741699008193,0.51250539025442,0.5127210004312204,0.513152220784821,0.5140146614920225,0.5144458818456231,0.5146614920224235,0.5150927123760242,0.5157395429064252,0.5161707632600259,0.5176800344976283,0.518111254851229,0.51875808538163,0.5194049159120311,0.5202673566192324,0.5209141871496334,0.5215610176800345,0.5217766278568349,0.5222078482104355,0.5224234583872359,0.5232858990944372,0.5235015092712376,0.5239327296248383,0.5245795601552393,0.52501078050884,0.5267356619232427,0.5275981026304442,0.5278137128072445,0.5282449331608452,0.5323415265200517,0.5329883570504528,0.536222509702458,0.536869340232859,0.53751617076326,0.5379473911168607,0.5398878827080639,0.5407503234152652,0.5411815437688658,0.5435532557136696,0.5439844760672704,0.5442000862440707,0.5450625269512721,0.5459249676584734,0.5463561880120742,0.5470030185424752,0.5474342388960759,0.5498059508408797,0.5502371711944803,0.5519620526088831,0.5523932729624839,0.5534713238464856,0.5539025442000862,0.5564898663216904,0.5571366968520914,0.5575679172056921,0.5577835273824925,0.5582147477360931,0.5590771884432946,0.5595084087968952,0.5601552393272963,0.5605864596808969,0.5625269512721001,0.5631737818025011,0.5636050021561018,0.5638206123329021,0.5642518326865028,0.5648986632169039,0.567485985338508,0.5679172056921087,0.568132815868909,0.5689952565761104,0.5705045278137129,0.5709357481673135,0.5717981888745148,0.5722294092281156,0.5724450194049159,0.5728762397585166,0.5765416127641224,0.5771884432945235,0.5776196636481242,0.5778352738249245,0.5782664941785253,0.5786977145321259,0.5791289348857266,0.5802069857697283,0.5808538163001293,0.5815006468305304,0.5819318671841311,0.5827943078913325,0.5832255282449331,0.5838723587753342,0.5843035791289349,0.5847347994825356,0.5851660198361363,0.5860284605433377,0.5871065114273394,0.58753773178094,0.5879689521345407,0.5884001724881415,0.5896938335489436,0.5905562742561449,0.5920655454937473,0.592496765847348,0.5933592065545493,0.5937904269081501,0.5940060370849504,0.5944372574385511,0.5955153083225528,0.5961621388529539,0.5965933592065545,0.598102630444157,0.5985338507977577,0.6017680034497628,0.6021992238033635,0.6026304441569642,0.6030616645105649,0.6039241052177663,0.6047865459249676,0.6069426476929711,0.6073738680465718,0.6080206985769728,0.6086675291073739,0.6095299698145753,0.6103924105217766,0.6108236308753773,0.6144890038809832,0.6153514445881846,0.6164294954721863,0.6168607158257869,0.6172919361793877,0.6183699870633894,0.6196636481241915,0.6209573091849935,0.6213885295385942,0.6218197498921949,0.623113410952997,0.6244070720137991,0.6248382923673997,0.6252695127210004,0.6254851228978008,0.6261319534282018,0.6263475636050022,0.6267787839586029,0.6274256144890039,0.6282880551962052,0.628719275549806,0.6289348857266063,0.6293661060802069,0.6295817162570073,0.6304441569642087,0.6319534282018111,0.6328158689090125,0.6336783096162139,0.6343251401466149,0.6345407503234153,0.6351875808538163,0.635618801207417,0.6358344113842174,0.636265631737818,0.6366968520914187,0.6373436826218197,0.6386373436826218,0.6390685640362225,0.641224665804226,0.6420871065114273,0.6425183268650281,0.6429495472186287,0.6433807675722294,0.64381198792583,0.6451056489866321,0.6455368693402329,0.6468305304010349,0.6472617507546357,0.648124191461837,0.648771021992238,0.6500646830530401,0.6509271237602415,0.6517895644674429,0.6522207848210435,0.6526520051746443,0.6530832255282449,0.6535144458818456,0.654376886589047,0.6548081069426477,0.6552393272962483,0.6554549374730487,0.6563173781802502,0.6565329883570504,0.6571798188874515,0.6573954290642519,0.6584734799482536,0.6589047003018542,0.659335920655455,0.6595515308322553,0.6599827511858559,0.6604139715394567,0.6608451918930573,0.6614920224234584,0.6621388529538594,0.6625700733074601,0.6630012936610608,0.6632169038378611,0.6642949547218628,0.6649417852522639,0.666235446313066,0.6666666666666666,0.6673134971970677,0.6677447175506684,0.6683915480810694,0.6714100905562742,0.671841310909875,0.6720569210866753,0.6727037516170763,0.6735661923242777,0.6739974126778784,0.6774471755066839,0.6778783958602846,0.6789564467442863,0.679387667097887,0.6817593790426908,0.6821905993962915,0.6832686502802933,0.6836998706338939,0.684993531694696,0.6854247520482967,0.6869340232858991,0.6873652436394998,0.6877964639931005,0.6882276843467011,0.6886589047003019,0.6890901250539025,0.689952565761104,0.6903837861147046,0.6908150064683053,0.6916774471755067,0.692539887882708,0.6931867184131091,0.6940491591203105,0.6953428201811126,0.7003018542475204,0.7009486847779215,0.703104786545925,0.7035360068995257,0.7041828374299267,0.7059077188443295,0.7063389391979301,0.7074169900819318,0.7080638206123329,0.7084950409659336,0.7097887020267356,0.710004312203536,0.7104355325571367,0.7110823630875377,0.7123760241483398,0.7132384648555412,0.7160413971539457,0.7169038378611471,0.7173350582147477,0.7181974989219491,0.7192755498059509,0.7197067701595515,0.7201379905131522,0.720569210866753,0.7218628719275549,0.7222940922811557,0.722509702457956,0.7238033635187581,0.7240189736955585,0.7244501940491591,0.7246658042259595,0.7250970245795602,0.7257438551099612,0.7261750754635619,0.7263906856403622,0.7272531263475636,0.7278999568779646,0.7283311772315654,0.7285467874083656,0.7294092281155671,0.7296248382923674,0.7300560586459681,0.7311341095299698,0.7317809400603709,0.7322121604139715,0.7324277705907719,0.7332902112979732,0.7335058214747736,0.7339370418283743,0.7341526520051747,0.735015092712376,0.7354463130659767,0.7360931435963778,0.7380336351875808,0.7388960758947822,0.7401897369555843,0.7408365674859854,0.7414833980163864,0.7419146183699871,0.7429926692539888,0.7434238896075894,0.7440707201379905,0.7447175506683915,0.7455799913755929,0.7460112117291936,0.7464424320827943,0.7470892626131953,0.7475204829667961,0.7479517033203967,0.7483829236739974,0.7485985338507978,0.7494609745579991,0.7501078050884001,0.7505390254420009,0.7507546356188012,0.7516170763260026,0.753126347563605,0.7535575679172057,0.7565761103924106,0.7570073307460112,0.7572229409228115,0.7576541612764123,0.7578697714532125,0.7585166019836136,0.758732212160414,0.7591634325140146,0.7600258732212161,0.7608883139284174,0.7632600258732212,0.7636912462268219,0.765631737818025,0.7660629581716257,0.7664941785252264,0.766925398878827,0.7680034497628289,0.7684346701164295,0.7699439413540319,0.7708063820612333,0.7723156532988357,0.7727468736524364,0.7736093143596378,0.7744717550668392,0.776843467011643,0.7772746873652436,0.7792151789564468,0.7796463993100474,0.7805088400172489,0.7809400603708495,0.7820181112548512,0.7824493316084519,0.7828805519620526,0.7835273824924537,0.783742992669254,0.7841742130228547,0.784389823199655,0.7848210435532557,0.7887020267356619,0.7891332470892626,0.789995687796464,0.7908581285036653,0.7921517895644674,0.7925830099180682,0.7938766709788702,0.7945235015092712,0.7951703320396722,0.795601552393273,0.797542043984476,0.7979732643380768,0.7988357050452781,0.7996981457524796,0.7999137559292798,0.8003449762828806,0.8009918068132816,0.8014230271668823,0.801854247520483,0.802501078050884,0.8029322984044847,0.803147908581285,0.8035791289348857,0.8055196205260888,0.8061664510564899,0.8070288917636912,0.808753773178094,0.8094006037084951,0.8098318240620958,0.8102630444156964,0.8104786545924968,0.8111254851228978,0.8119879258300992,0.8124191461836999,0.8134971970677016,0.8139284174213023,0.8145752479517033,0.815006468305304,0.8160845191893057,0.8165157395429065,0.8173781802501078,0.8180250107805088,0.8203967227253126,0.8208279430789134,0.8210435532557137,0.8214747736093143,0.8223372143165157,0.8227684346701164,0.8244933160845191,0.8253557567917206,0.827511858559724,0.828158689090125,0.8283742992669254,0.8288055196205261,0.8296679603277275,0.8303147908581285,0.8311772315653299,0.8320396722725313,0.8326865028029323,0.8329021129797326,0.8341957740405347,0.8346269943941355,0.8352738249245364,0.8357050452781372,0.8361362656317378,0.8365674859853385,0.8374299266925399,0.8385079775765416,0.8391548081069427,0.8395860284605433,0.8423889607589479,0.8428201811125485,0.8434670116429496,0.8438982319965502,0.8445450625269513,0.8449762828805519,0.8451918930573523,0.845623113410953,0.8460543337645536,0.8464855541181544,0.8477792151789565,0.8482104355325571,0.8501509271237603,0.8507977576541613,0.8510133678309616,0.8516601983613626,0.8551099611901681,0.8557567917205692,0.8579128934885727,0.8585597240189737,0.8596377749029754,0.8602846054333765,0.8607158257869771,0.8630875377317809,0.864381198792583,0.8648124191461837,0.8676153514445882,0.8689090125053902,0.8695558430357913,0.869987063389392,0.8708495040965933,0.8714963346269944,0.8723587753341958,0.8730056058645969,0.8732212160413971,0.8736524363949978,0.8764553686934023,0.876886589047003,0.8783958602846055,0.8788270806382061,0.8794739111686072,0.8803363518758085,0.8814144027598103,0.881845623113411,0.8852953859422165,0.8857266062958171,0.8863734368262182,0.8872358775334196,0.88745148771022,0.8880983182406209,0.8896075894782234,0.890038809831824,0.8932729624838293,0.8937041828374299,0.8973695558430358,0.8978007761966365,0.8980163863734368,0.8984476067270375,0.901250539025442,0.9016817593790427,0.9044846916774472,0.9049159120310478,0.9051315222078482,0.9055627425614489,0.9062095730918499,0.9066407934454507,0.9072876239758516,0.9079344545062527,0.9092281155670547,0.9128934885726606,0.913755929279862,0.9139715394566623,0.9144027598102631,0.9148339801638637,0.9152652005174644,0.9167744717550669,0.9176369124622682,0.9180681328158689,0.9184993531694696,0.9219491159982751,0.9228115567054765,0.9234583872358776,0.9243208279430789,0.925614489003881,0.9264769297110823,0.9271237602414834,0.9275549805950841,0.9277705907718844,0.9284174213022854,0.9303579128934886,0.9307891332470892,0.931867184131091,0.9322984044846917,0.9329452350150927,0.9333764553686934,0.9355325571366968,0.9359637774902976,0.9366106080206986,0.9374730487278999,0.9379042690815006,0.9385510996119016,0.9409228115567054,0.9413540319103062,0.9441569642087106,0.9445881845623113,0.9456662354463131,0.9460974557999138,0.9482535575679172,0.9486847779215178,0.9497628288055197,0.9504096593359207,0.9514877102199224,0.9519189305735231,0.9523501509271237,0.9529969814575248,0.9555843035791289,0.9560155239327296,0.9592496765847348,0.9601121172919361,0.961836998706339,0.96248382923674,0.9635618801207417,0.9642087106511428,0.9646399310047434,0.9648555411815438,0.9652867615351445,0.9672272531263476,0.9676584734799483,0.96873652436395,0.9695989650711514,0.9708926261319534,0.9713238464855541,0.9752048296679603,0.9756360500215611,0.9758516601983613,0.9762828805519621,0.976929711082363,0.9773609314359638,0.9777921517895645,0.9782233721431651,0.9805950840879689,0.9810263044415697,0.981888745148771,0.982535575679172,0.9855541181543769,0.9859853385079775,0.9877102199223803,0.988141440275981,0.9887882708063821,0.9892194911599828,0.9900819318671842,0.9905131522207848,0.9922380336351876,0.9928848641655886,0.994394135403191,0.9948253557567918,0.9974126778783958,0.9978438982319966,1.0],\"y\":[0.0,0.0,0.0,0.06896551724137931,0.06896551724137931,0.20689655172413793,0.20689655172413793,0.2413793103448276,0.2413793103448276,0.27586206896551724,0.27586206896551724,0.27586206896551724,0.3103448275862069,0.3103448275862069,0.3448275862068966,0.3448275862068966,0.3793103448275862,0.3793103448275862,0.3793103448275862,0.3793103448275862,0.3793103448275862,0.3793103448275862,0.41379310344827586,0.41379310344827586,0.41379310344827586,0.41379310344827586,0.4482758620689655,0.4482758620689655,0.4482758620689655,0.4482758620689655,0.4482758620689655,0.4827586206896552,0.4827586206896552,0.4827586206896552,0.4827586206896552,0.4827586206896552,0.5172413793103449,0.5172413793103449,0.5517241379310345,0.5517241379310345,0.5517241379310345,0.5517241379310345,0.5517241379310345,0.5517241379310345,0.5517241379310345,0.5517241379310345,0.5862068965517241,0.5862068965517241,0.5862068965517241,0.5862068965517241,0.5862068965517241,0.5862068965517241,0.5862068965517241,0.6206896551724138,0.6206896551724138,0.6206896551724138,0.6206896551724138,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.6896551724137931,0.7241379310344828,0.7241379310344828,0.7241379310344828,0.7241379310344828,0.7241379310344828,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.7931034482758621,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.8620689655172413,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.896551724137931,0.9310344827586207,0.9310344827586207,0.9310344827586207,0.9310344827586207,0.9310344827586207,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,0.9655172413793104,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"type\":\"scatter\"},{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(50, 50, 250, 1.0)\",\"width\":5},\"name\":\"\\u003cb\\u003eBlack\\u003c\\u002fb\\u003e\",\"showlegend\":true,\"x\":[0.0,0.0016611295681063123,0.018272425249169437,0.02159468438538206,0.023255813953488372,0.026578073089700997,0.029900332225913623,0.03488372093023256,0.03820598006644518,0.03986710963455149,0.044850498338870434,0.05149501661129568,0.054817275747508304,0.059800664451827246,0.06312292358803986,0.07142857142857142,0.07475083056478406,0.08139534883720931,0.08637873754152824,0.11129568106312292,0.11295681063122924,0.11794019933554817,0.1212624584717608,0.12458471760797342,0.12790697674418605,0.12790697674418605,0.12956810631229235,0.13953488372093023,0.13953488372093023,0.14950166112956811,0.15614617940199335,0.16279069767441862,0.1777408637873754,0.17940199335548174,0.18272425249169436,0.1893687707641196,0.19435215946843853,0.2026578073089701,0.2026578073089701,0.20764119601328904,0.21262458471760798,0.22757475083056478,0.23588039867109634,0.23754152823920266,0.24086378737541528,0.24584717607973422,0.25083056478405313,0.2541528239202658,0.2574750830564784,0.26578073089701,0.2691029900332226,0.28903654485049834,0.2956810631229236,0.31727574750830567,0.3289036544850498,0.3488372093023256,0.3521594684385382,0.35714285714285715,0.36046511627906974,0.3903654485049834,0.39368770764119604,0.41362126245847175,0.4169435215946844,0.48006644518272423,0.4833887043189369,0.5033222591362126,0.5066445182724253,0.5083056478405316,0.5116279069767442,0.6112956810631229,0.6146179401993356,0.6295681063122923,0.6345514950166113,0.6478405315614618,0.6511627906976745,0.7192691029900332,0.7242524916943521,0.7308970099667774,0.7342192691029901,0.739202657807309,0.7425249169435216,0.7475083056478405,0.7508305647840532,0.7641196013289037,0.7691029900332226,0.7724252491694352,0.7840531561461794,0.7873754152823921,0.7906976744186046,0.7940199335548173,0.8039867109634552,0.8073089700996677,0.8372093023255814,0.840531561461794,0.8438538205980066,0.8471760797342193,0.8521594684385382,0.8554817275747508,0.8687707641196013,0.872093023255814,0.8887043189368771,0.8953488372093024,0.9385382059800664,0.9418604651162791,0.946843853820598,0.9501661129568106,0.9601328903654485,0.9634551495016611,0.9667774086378738,0.9700996677740864,1.0],\"y\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"type\":\"scatter\"},{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(255, 255, 255, 0)\",\"width\":5},\"name\":\"AUC: 0.8433\",\"showlegend\":true,\"x\":[0.0,0.0016611295681063123,0.018272425249169437,0.02159468438538206,0.023255813953488372,0.026578073089700997,0.029900332225913623,0.03488372093023256,0.03820598006644518,0.03986710963455149,0.044850498338870434,0.05149501661129568,0.054817275747508304,0.059800664451827246,0.06312292358803986,0.07142857142857142,0.07475083056478406,0.08139534883720931,0.08637873754152824,0.11129568106312292,0.11295681063122924,0.11794019933554817,0.1212624584717608,0.12458471760797342,0.12790697674418605,0.12790697674418605,0.12956810631229235,0.13953488372093023,0.13953488372093023,0.14950166112956811,0.15614617940199335,0.16279069767441862,0.1777408637873754,0.17940199335548174,0.18272425249169436,0.1893687707641196,0.19435215946843853,0.2026578073089701,0.2026578073089701,0.20764119601328904,0.21262458471760798,0.22757475083056478,0.23588039867109634,0.23754152823920266,0.24086378737541528,0.24584717607973422,0.25083056478405313,0.2541528239202658,0.2574750830564784,0.26578073089701,0.2691029900332226,0.28903654485049834,0.2956810631229236,0.31727574750830567,0.3289036544850498,0.3488372093023256,0.3521594684385382,0.35714285714285715,0.36046511627906974,0.3903654485049834,0.39368770764119604,0.41362126245847175,0.4169435215946844,0.48006644518272423,0.4833887043189369,0.5033222591362126,0.5066445182724253,0.5083056478405316,0.5116279069767442,0.6112956810631229,0.6146179401993356,0.6295681063122923,0.6345514950166113,0.6478405315614618,0.6511627906976745,0.7192691029900332,0.7242524916943521,0.7308970099667774,0.7342192691029901,0.739202657807309,0.7425249169435216,0.7475083056478405,0.7508305647840532,0.7641196013289037,0.7691029900332226,0.7724252491694352,0.7840531561461794,0.7873754152823921,0.7906976744186046,0.7940199335548173,0.8039867109634552,0.8073089700996677,0.8372093023255814,0.840531561461794,0.8438538205980066,0.8471760797342193,0.8521594684385382,0.8554817275747508,0.8687707641196013,0.872093023255814,0.8887043189368771,0.8953488372093024,0.9385382059800664,0.9418604651162791,0.946843853820598,0.9501661129568106,0.9601328903654485,0.9634551495016611,0.9667774086378738,0.9700996677740864,1.0],\"y\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"type\":\"scatter\"},{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(255, 255, 255, 0)\",\"width\":0},\"name\":\"(95% CI: 0.5647-1.0000)\",\"showlegend\":true,\"x\":[0.0,0.0016611295681063123,0.018272425249169437,0.02159468438538206,0.023255813953488372,0.026578073089700997,0.029900332225913623,0.03488372093023256,0.03820598006644518,0.03986710963455149,0.044850498338870434,0.05149501661129568,0.054817275747508304,0.059800664451827246,0.06312292358803986,0.07142857142857142,0.07475083056478406,0.08139534883720931,0.08637873754152824,0.11129568106312292,0.11295681063122924,0.11794019933554817,0.1212624584717608,0.12458471760797342,0.12790697674418605,0.12790697674418605,0.12956810631229235,0.13953488372093023,0.13953488372093023,0.14950166112956811,0.15614617940199335,0.16279069767441862,0.1777408637873754,0.17940199335548174,0.18272425249169436,0.1893687707641196,0.19435215946843853,0.2026578073089701,0.2026578073089701,0.20764119601328904,0.21262458471760798,0.22757475083056478,0.23588039867109634,0.23754152823920266,0.24086378737541528,0.24584717607973422,0.25083056478405313,0.2541528239202658,0.2574750830564784,0.26578073089701,0.2691029900332226,0.28903654485049834,0.2956810631229236,0.31727574750830567,0.3289036544850498,0.3488372093023256,0.3521594684385382,0.35714285714285715,0.36046511627906974,0.3903654485049834,0.39368770764119604,0.41362126245847175,0.4169435215946844,0.48006644518272423,0.4833887043189369,0.5033222591362126,0.5066445182724253,0.5083056478405316,0.5116279069767442,0.6112956810631229,0.6146179401993356,0.6295681063122923,0.6345514950166113,0.6478405315614618,0.6511627906976745,0.7192691029900332,0.7242524916943521,0.7308970099667774,0.7342192691029901,0.739202657807309,0.7425249169435216,0.7475083056478405,0.7508305647840532,0.7641196013289037,0.7691029900332226,0.7724252491694352,0.7840531561461794,0.7873754152823921,0.7906976744186046,0.7940199335548173,0.8039867109634552,0.8073089700996677,0.8372093023255814,0.840531561461794,0.8438538205980066,0.8471760797342193,0.8521594684385382,0.8554817275747508,0.8687707641196013,0.872093023255814,0.8887043189368771,0.8953488372093024,0.9385382059800664,0.9418604651162791,0.946843853820598,0.9501661129568106,0.9601328903654485,0.9634551495016611,0.9667774086378738,0.9700996677740864,1.0],\"y\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.3333333333333333,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"title\":{\"x\":1},\"legend\":{\"yanchor\":\"bottom\",\"xanchor\":\"right\",\"x\":0.95,\"y\":0.01},\"xaxis\":{\"title\":{\"text\":\"\\u003cb\\u003e1-Specificity\\u003c\\u002fb\\u003e\"},\"range\":[0,1],\"gridcolor\":\"rgba(5, 5, 5, 0.5)\",\"constrain\":\"domain\",\"linecolor\":\"black\"},\"yaxis\":{\"title\":{\"text\":\"\\u003cb\\u003eRecall\\u003c\\u002fb\\u003e\"},\"range\":[0,1],\"gridcolor\":\"rgba(5, 5, 5, 0.5)\",\"scaleanchor\":\"x\",\"scaleratio\":1,\"linecolor\":\"black\"},\"width\":600,\"height\":600,\"font\":{\"family\":\"Times New Roman\",\"size\":22,\"color\":\"Black\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('123ae061-3934-4f3a-9c41-e5cea1d2aa66');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "white=test.drop(X_test[X_test['NEWRACE2_White'] == 0].index)\n",
        "#elsee=elsee.sample(95, random_state=25)\n",
        "white_predictors=white.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "white_target=white['UDPYOPI_1 - Yes']\n",
        "black=test.drop(X_test[X_test['NEWRACE2_Black'] == 0].index)\n",
        "\n",
        "#pop=pop.sample(95, random_state=25)\n",
        "black_predictors=black.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "black_target=black['UDPYOPI_1 - Yes']\n",
        "white_prob=network.predict(white_predictors)\n",
        "black_prob=network.predict(black_predictors)\n",
        "plot_roc_curve2(white_target, white_prob, black_target, black_prob, 'White', 'Black')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "b38eb0d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b38eb0d3",
        "outputId": "9f1048eb-cee7-42a6-8d29-67226be98113"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TtestResult(statistic=60.34627355022379, pvalue=0.0, df=1000)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "# White vs. Black\n",
        "df=[]\n",
        "for i in range_with_floats(0.0, 100.0, 0.1):\n",
        "        y_pred_white = (white_prob >= i*0.01).astype(bool)\n",
        "        cm_g1 = confusion_matrix(white_target, y_pred_white)\n",
        "        specificity_g1 = cm_g1[0,0]/(cm_g1[0,0]+cm_g1[0,1])\n",
        "        sensitivity_g1 = cm_g1[1,1]/(cm_g1[1,0]+cm_g1[1,1])\n",
        "\n",
        "        y_pred_black = (black_prob >= i*0.01).astype(bool)\n",
        "        cm_g2 = confusion_matrix(black_target, y_pred_black)\n",
        "        specificity_g2 = cm_g2[0,0]/(cm_g2[0,0]+cm_g2[0,1])\n",
        "        sensitivity_g2 = cm_g2[1,1]/(cm_g2[1,0]+cm_g2[1,1])\n",
        "\n",
        "        difference=abs(specificity_g1-specificity_g2)+abs(sensitivity_g1-sensitivity_g2)\n",
        "\n",
        "        df.append({'difference':difference, 'threshold':i})\n",
        "\n",
        "df = pd.DataFrame(df)\n",
        "diff=np.array(df['difference'])\n",
        "\n",
        "stats.ttest_1samp(diff, popmean=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "86418e2a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86418e2a",
        "outputId": "3058eef5-58ac-42a7-e61b-31fe51c34cc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.7320370651678566 sensitivity: 1.0 accuracy_g1: 0.7355903149775016 accuracy_g2: 0.7355371900826446 specificity_g1: 0.7339370418283743 specificity_g2: 0.7342192691029901 sensitivity_g1: 1.0 sensitivity_g2: 1.0 difference: 0.00028222727461579833 threshold: 8.099999999999987\n",
            "accuracy: 0.9746316269178186 sensitivity: 0.5121951219512195 accuracy_g1: 0.9721448467966574 accuracy_g2: 0.9851239669421488 specificity_g1: 0.9745579991375592 specificity_g2: 0.9900332225913622 sensitivity_g1: 0.5862068965517241 sensitivity_g2: 0.0 difference: 0.601682120005527 threshold: 50.0\n"
          ]
        }
      ],
      "source": [
        "# White vs. black\n",
        "\n",
        "df=[]\n",
        "\n",
        "\n",
        "for i in range_with_floats(0.0, 100.0, 0.1):\n",
        "    y_pred = (prob >= i*0.01).astype(bool)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    acc=(cm[0,0]+cm[1,1])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])\n",
        "    sen=cm[1,1]/(cm[1,0]+cm[1,1])\n",
        "    if sen>=0.5 and  acc>=0.5:\n",
        "        y_pred_white = (white_prob >= i*0.01).astype(bool)\n",
        "        cm_g1 = confusion_matrix(white_target, y_pred_white)\n",
        "        specificity_g1 = cm_g1[0,0]/(cm_g1[0,0]+cm_g1[0,1])\n",
        "        sensitivity_g1 = cm_g1[1,1]/(cm_g1[1,0]+cm_g1[1,1])\n",
        "        accuracy_g1=(cm_g1[0,0]+cm_g1[1,1])/(cm_g1[0,0]+cm_g1[0,1]+cm_g1[1,0]+cm_g1[1,1])\n",
        "        y_pred_black = (black_prob >= i*0.01).astype(bool)\n",
        "        cm_g2 = confusion_matrix(black_target, y_pred_black)\n",
        "        specificity_g2 = cm_g2[0,0]/(cm_g2[0,0]+cm_g2[0,1])\n",
        "        sensitivity_g2 = cm_g2[1,1]/(cm_g2[1,0]+cm_g2[1,1])\n",
        "        accuracy_g2=(cm_g2[0,0]+cm_g2[1,1])/(cm_g2[0,0]+cm_g2[0,1]+cm_g2[1,0]+cm_g2[1,1])\n",
        "        difference=abs(specificity_g1-specificity_g2)+abs(sensitivity_g1-sensitivity_g2)\n",
        "\n",
        "        df.append({'accuracy':acc, 'sensitivity':sen, 'accuracy_g1':accuracy_g1, 'accuracy_g2':accuracy_g2, 'specificity_g1':specificity_g1, 'specificity_g2':specificity_g2,'sensitivity_g1':sensitivity_g1,'sensitivity_g2':sensitivity_g2, 'difference':difference, 'threshold':i})\n",
        "\n",
        "df = pd.DataFrame(df)\n",
        "min_diff = df.iloc[df['difference'].idxmin()]\n",
        "print('accuracy:', min_diff[0], 'sensitivity:', min_diff[1], 'accuracy_g1:', min_diff[2], 'accuracy_g2:', min_diff[3], 'specificity_g1:', min_diff[4], 'specificity_g2:', min_diff[5], 'sensitivity_g1:', min_diff[6], 'sensitivity_g2:', min_diff[7], 'difference:', min_diff[8], 'threshold:', min_diff[9])\n",
        "\n",
        "y_pred = (prob >= 50*0.01).astype(bool)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "acc=(cm[0,0]+cm[1,1])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])\n",
        "sen=cm[1,1]/(cm[1,0]+cm[1,1])\n",
        "\n",
        "y_pred_white = (white_prob >= 50*0.01).astype(bool)\n",
        "cm_g1 = confusion_matrix(white_target, y_pred_white)\n",
        "specificity_g1 = cm_g1[0,0]/(cm_g1[0,0]+cm_g1[0,1])\n",
        "sensitivity_g1 = cm_g1[1,1]/(cm_g1[1,0]+cm_g1[1,1])\n",
        "accuracy_g1=(cm_g1[0,0]+cm_g1[1,1])/(cm_g1[0,0]+cm_g1[0,1]+cm_g1[1,0]+cm_g1[1,1])\n",
        "\n",
        "y_pred_black = (black_prob >= 50*0.01).astype(bool)\n",
        "cm_g2 = confusion_matrix(black_target, y_pred_black)\n",
        "specificity_g2 = cm_g2[0,0]/(cm_g2[0,0]+cm_g2[0,1])\n",
        "sensitivity_g2 = cm_g2[1,1]/(cm_g2[1,0]+cm_g2[1,1])\n",
        "accuracy_g2=(cm_g2[0,0]+cm_g2[1,1])/(cm_g2[0,0]+cm_g2[0,1]+cm_g2[1,0]+cm_g2[1,1])\n",
        "difference=abs(specificity_g1-specificity_g2)+abs(sensitivity_g1-sensitivity_g2)\n",
        "\n",
        "print('accuracy:', acc, 'sensitivity:', sen, 'accuracy_g1:', accuracy_g1, 'accuracy_g2:', accuracy_g2, 'specificity_g1:', specificity_g1, 'specificity_g2:', specificity_g2, 'sensitivity_g1:', sensitivity_g1, 'sensitivity_g2:', sensitivity_g2, 'difference:', difference, 'threshold:', 50.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "c7652fcb",
      "metadata": {
        "id": "c7652fcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "outputId": "68acadc9-cfb2-4ca9-d110-5002f1d1fb67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69/69 [==============================] - 0s 6ms/step\n",
            "138/138 [==============================] - 1s 5ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"1f5d6426-73eb-4871-aab9-87d3c2623607\" class=\"plotly-graph-div\" style=\"height:600px; width:600px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1f5d6426-73eb-4871-aab9-87d3c2623607\")) {                    Plotly.newPlot(                        \"1f5d6426-73eb-4871-aab9-87d3c2623607\",                        [{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(250, 50, 50, 1.0)\",\"width\":5},\"name\":\"\\u003cb\\u003eIncome less than $20,000\\u003c\\u002fb\\u003e\",\"showlegend\":true,\"x\":[0.0,0.0009220839096357768,0.0018441678192715537,0.002305209774089442,0.003227293683725219,0.004149377593360996,0.004149377593360996,0.004610419548178884,0.006454587367450438,0.007837713231904103,0.009220839096357769,0.010142923005993546,0.011065006915629323,0.011065006915629323,0.011526048870447211,0.012448132780082987,0.013831258644536652,0.015675426463808206,0.016136468418626097,0.016136468418626097,0.01705855232826187,0.01751959428307976,0.01751959428307976,0.019363762102351315,0.0198248040571692,0.02074688796680498,0.02120792992162287,0.023052097740894423,0.025357307514983864,0.02627939142461964,0.026740433379437527,0.027662517289073305,0.028123559243891195,0.029045643153526972,0.030428769017980636,0.03135085292761641,0.03227293683725219,0.03319502074688797,0.033656062701705854,0.034578146611341634,0.03734439834024896,0.03872752420470263,0.0396496081143384,0.04057169202397418,0.04057169202397418,0.04149377593360996,0.042876901798063624,0.0437989857076994,0.04472106961733518,0.04564315352697095,0.046104195481788846,0.04702627939142462,0.047487321346242506,0.04933148916551406,0.05071461502996773,0.052097740894421395,0.05486399262332872,0.0557860765329645,0.056708160442600276,0.058091286307053944,0.05901337021668972,0.06085753803596127,0.06224066390041494,0.06316274781005071,0.06731212540341171,0.06823420931304748,0.06823420931304748,0.06915629322268327,0.07053941908713693,0.07376671277086215,0.07376671277086215,0.07468879668049792,0.07745504840940526,0.07883817427385892,0.08068234209313048,0.08298755186721991,0.08390963577685569,0.08529276164130936,0.08713692946058091,0.0880590133702167,0.08852005532503458,0.08990318118948824,0.09313047487321346,0.09405255878284924,0.09774089442139235,0.0995850622406639,0.10096818810511757,0.10419548178884279,0.10557860765329645,0.10650069156293222,0.10742277547256801,0.1111111111111111,0.11203319502074689,0.11249423697556478,0.11387736284001844,0.11479944674965421,0.11802674043337943,0.11894882434301521,0.11940986629783311,0.12079299216228677,0.12217611802674043,0.12309820193637622,0.1235592438911941,0.12448132780082988,0.12540341171046565,0.1267865375749193,0.1272475795297372,0.12909174734900877,0.13001383125864455,0.13093591516828032,0.13370216689718764,0.13785154449054865,0.1392346703550023,0.14107883817427386,0.14153988012909174,0.14246196403872752,0.1433840479483633,0.14476717381281698,0.14522821576763487,0.14615029967727064,0.1470723835869064,0.14845550945136007,0.15029967727063162,0.15029967727063162,0.1507607192254495,0.15168280313508528,0.15352697095435686,0.1553711387736284,0.15629322268326418,0.15721530659289995,0.1585984324573536,0.1590594744121715,0.15998155832180727,0.15998155832180727,0.16090364223144307,0.16136468418626096,0.16413093591516828,0.16597510373443983,0.1668971876440756,0.1715076071922545,0.17242969110189027,0.1751959428307976,0.17842323651452283,0.1793453204241586,0.1798063623789765,0.18118948824343015,0.18211157215306592,0.1839557399723375,0.18441678192715538,0.1904103273397879,0.1917934532042416,0.19271553711387737,0.19363762102351315,0.19455970493314892,0.19640387275242047,0.19732595666205624,0.1991701244813278,0.1996311664361457,0.20055325034578148,0.20101429230059936,0.2033195020746888,0.20470262793914246,0.20562471184877823,0.20608575380359612,0.2070078377132319,0.20931304748732135,0.21346242508068233,0.2194559704933149,0.21991701244813278,0.22130013831258644,0.22268326417704012,0.2236053480866759,0.22498847395112956,0.22591055786076533,0.23328722913785155,0.2346703550023052,0.23559243891194098,0.23605348086675887,0.23697556477639464,0.23743660673121253,0.23835869064084833,0.23881973259566622,0.239741816505302,0.2425080682342093,0.2429691101890272,0.24389119409866297,0.2475795297372061,0.24850161364684187,0.24988473951129553,0.2512678653757492,0.25311203319502074,0.25587828492392806,0.25864453665283543,0.2591055786076533,0.2600276625172891,0.2627939142461964,0.2637159981558322,0.26509912402028585,0.2660212079299216,0.2669432918395574,0.26878745965882894,0.2701705855232826,0.27708621484555096,0.2793914246196404,0.28031350852927617,0.28169663439372983,0.2826187183033656,0.28400184416781926,0.2858460119870908,0.2863070539419087,0.28815122176118024,0.2918395573997234,0.29322268326417705,0.2950668510834486,0.2959889349930844,0.30013831258644535,0.30106039649608113,0.3019824804057169,0.3029045643153527,0.30336560627017056,0.30428769017980634,0.30567081604426005,0.3070539419087137,0.30889810972798526,0.30982019363762103,0.3112033195020747,0.3144306131857999,0.31627478100507145,0.3171968649147072,0.318118948824343,0.31904103273397877,0.31996311664361454,0.32226832641770403,0.3231904103273398,0.3236514522821577,0.32457353619179347,0.3278008298755187,0.32872291378515445,0.3301060396496081,0.3310281235592439,0.33195020746887965,0.33241124942369754,0.3333333333333333,0.3365606270170586,0.3384047948363301,0.34024896265560167,0.34117104656523745,0.34163208852005533,0.3453204241585984,0.34716459197787,0.34854771784232363,0.35361917934532044,0.3545412632549562,0.35730751498386354,0.3591516828031351,0.3651452282157676,0.3660673121254034,0.3674504379898571,0.3683725218994929,0.36929460580912865,0.3711387736284002,0.3715998155832181,0.37252189949285386,0.37574919317657907,0.37667127708621484,0.37943752881512216,0.38035961272475793,0.3812816966343937,0.3822037805440295,0.3835869064084832,0.38450899031811897,0.38589211618257263,0.3877362840018442,0.3909635776855694,0.39511295527893037,0.39603503918856614,0.3978792070078377,0.3988012909174735,0.3992623328722914,0.4001844167819272,0.40110650069156295,0.4020285846011987,0.4024896265560166,0.40387275242047027,0.40479483633010604,0.4066390041493776,0.40802213001383125,0.4107883817427386,0.41171046565237435,0.4135546334716459,0.41724296911018904,0.4181650530198248,0.4190871369294606,0.42000922083909636,0.42139234670355,0.4223144306131858,0.42415859843245735,0.4250806823420931,0.4283079760258183,0.4292300599354541,0.4306131857999078,0.4315352697095436,0.4319963116643615,0.43337943752881514,0.4352236053480867,0.43614568925772246,0.43660673121254034,0.4375288151221761,0.43937298294144767,0.44029506685108344,0.4416781927155371,0.4426002766251729,0.4476717381281697,0.44951590594744123,0.450437989857077,0.4532042415859843,0.4541263254956201,0.45643153526970953,0.4573536191793453,0.4582757030889811,0.45919778699861685,0.46426924850161366,0.467035500230521,0.46795758414015676,0.46887966804979253,0.47118487782388196,0.47210696173351774,0.47763946519133244,0.4785615491009682,0.48132780082987553,0.4827109266943292,0.4831719686491471,0.48409405255878285,0.4854771784232365,0.4863992623328723,0.4942369755647764,0.4951590594744122,0.4956201014292301,0.49654218533886585,0.49700322729368374,0.4983863531581374,0.49930843706777317,0.5011526048870447,0.5057630244352236,0.5066851083448594,0.5117565698478561,0.5136007376671277,0.5140617796219455,0.5149838635315813,0.5154449054863992,0.5163669893960351,0.5255878284923928,0.5265099124020286,0.5269709543568465,0.5278930382664823,0.5334255417242969,0.5343476256339327,0.5348086675887506,0.5361917934532042,0.53711387736284,0.5389580451821115,0.5398801290917473,0.541263254956201,0.5431074227754725,0.545412632549562,0.5467957584140156,0.5509451360073767,0.5527893038266483,0.5560165975103735,0.5569386814200092,0.5606270170585523,0.562010142923006,0.5629322268326418,0.5647763946519133,0.566159520516367,0.5675426463808206,0.5680036883356385,0.5698478561549101,0.57860765329645,0.5795297372060858,0.5799907791609037,0.582757030889811,0.5832180728446289,0.5841401567542647,0.5878284923928078,0.5896726602120793,0.5905947441217151,0.591055786076533,0.5919778699861687,0.5942830797602582,0.595205163669894,0.5965882895343476,0.5975103734439834,0.598893499308437,0.6002766251728907,0.6016597510373444,0.6025818349469801,0.6039649608114338,0.6058091286307054,0.607192254495159,0.6090364223144306,0.6094974642692486,0.6104195481788843,0.611802674043338,0.6127247579529738,0.6131857999077917,0.6141078838174274,0.6164130935915169,0.6173351775011526,0.6182572614107884,0.6191793453204242,0.6196403872752421,0.6205624711848778,0.6210235131396957,0.6219455970493315,0.6307053941908713,0.6325495620101429,0.6353158137390502,0.636237897648686,0.6371599815583218,0.6380820654679575,0.6394651913324112,0.640848317196865,0.6417704011065007,0.6422314430613186,0.6440756108805902,0.6454587367450438,0.6482249884739512,0.6491470723835869,0.6500691562932227,0.6509912402028585,0.65283540802213,0.6537574919317658,0.6546795758414016,0.6556016597510373,0.6565237436606731,0.6574458275703089,0.6579068695251268,0.6588289534347626,0.661134163208852,0.6620562471184878,0.6629783310281235,0.6643614568925772,0.6666666666666666,0.6680497925311203,0.6689718764407561,0.669432918395574,0.6708160442600276,0.6712770862148455,0.6726602120792993,0.6749654218533887,0.6758875057630245,0.6795758414015676,0.6804979253112033,0.6864914707238359,0.6874135546334716,0.6915629322268326,0.6924850161364684,0.6970954356846473,0.6984785615491009,0.7044721069617336,0.7058552328261872,0.7072383586906409,0.7081604426002767,0.7095435684647303,0.7118487782388198,0.7127708621484555,0.7146150299677271,0.7155371138773629,0.7159981558321807,0.7169202397418165,0.7183033656062702,0.719225449515906,0.7201475334255417,0.7210696173351775,0.7238358690640848,0.7247579529737206,0.7261410788381742,0.7275242047026279,0.7284462886122637,0.7293683725218995,0.7302904564315352,0.7307514983863531,0.7316735822959889,0.7325956662056247,0.7353619179345321,0.7367450437989858,0.7376671277086215,0.7381281696634394,0.7390502535730752,0.7395112955278931,0.7404333794375288,0.7413554633471646,0.7427385892116183,0.7445827570308898,0.7450437989857077,0.7464269248501614,0.7501152604887045,0.751959428307976,0.7588750576302443,0.7607192254495159,0.7611802674043338,0.7625633932687874,0.7634854771784232,0.764407561088059,0.7657906869525127,0.76855693868142,0.7694790225910558,0.7704011065006916,0.772706316274781,0.7736284001844168,0.7754725680036884,0.7763946519133241,0.7773167358229599,0.7791609036422315,0.7842323651452282,0.785154449054864,0.7860765329644998,0.7869986168741355,0.7874596588289534,0.7883817427385892,0.789303826648225,0.7902259105578607,0.7920700783771323,0.792992162286768,0.7939142461964038,0.7948363301060396,0.7952973720608575,0.7962194559704933,0.797602581834947,0.7989857076994007,0.8003688335638544,0.8012909174734901,0.8022130013831259,0.8031350852927617,0.8040571692023974,0.805901337021669,0.8063623789764869,0.8072844628861227,0.8082065467957584,0.8091286307053942,0.81005071461503,0.8118948824343015,0.8123559243891194,0.8132780082987552,0.8137390502535731,0.8155832180728446,0.817888427846934,0.8188105117565698,0.8192715537113877,0.8201936376210235,0.8215767634854771,0.8229598893499308,0.8248040571692024,0.8257261410788381,0.826187183033656,0.8271092669432918,0.8298755186721992,0.8312586445366529,0.8321807284462887,0.8335638543107423,0.834946980175196,0.8354080221300139,0.8363301060396496,0.8404794836330106,0.8414015675426464,0.8427846934071,0.8446288612263716,0.846934071000461,0.8478561549100968,0.8533886583679114,0.8543107422775472,0.8556938681420009,0.8570769940064545,0.8589211618257261,0.8616874135546335,0.8626094974642693,0.8635315813739051,0.8644536652835408,0.8653757491931766,0.8667588750576303,0.8672199170124482,0.8686030428769018,0.8695251267865376,0.871830336560627,0.8727524204702628,0.8732134624250807,0.8750576302443522,0.8792070078377132,0.8810511756569848,0.8852005532503457,0.8861226371599815,0.8875057630244352,0.888427846934071,0.8939603503918857,0.8958045182111573,0.8962655601659751,0.8971876440756109,0.9013370216689719,0.9031811894882434,0.9041032733978792,0.905025357307515,0.9059474412171508,0.9077916090364223,0.913324112494237,0.9147072383586906,0.9151682803135085,0.9160903642231443,0.9174734900875979,0.9188566159520516,0.9202397418165053,0.9230059935454127,0.9239280774550485,0.9266943291839558,0.9276164130935916,0.9280774550484094,0.929921622867681,0.9303826648224989,0.9317657906869525,0.9345320424158599,0.9354541263254956,0.9372982941447672,0.9391424619640387,0.9400645458736745,0.9409866297833103,0.941908713692946,0.9423697556477639,0.9432918395573997,0.9455970493314891,0.9469801751959428,0.9525126786537574,0.9534347625633933,0.9635776855693868,0.9644997694790226,0.9681881051175657,0.9691101890272015,0.9727985246657446,0.9737206085753803,0.9755647763946519,0.9764868603042877,0.9797141539880129,0.9806362378976486,0.9838635315813739,0.9847856154910097,0.9852466574458276,0.9861687413554634,0.9884739511295528,0.9898570769940065,0.9926233287229138,0.9935454126325496,1.0],\"y\":[0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.3,0.3,0.3,0.3,0.3,0.3,0.4,0.4,0.4,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.7,0.7,0.7,0.7,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"type\":\"scatter\"},{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(255, 255, 255, 0)\",\"width\":5},\"name\":\"AUC: 0.9454\",\"showlegend\":true,\"x\":[0.0,0.0009220839096357768,0.0018441678192715537,0.002305209774089442,0.003227293683725219,0.004149377593360996,0.004149377593360996,0.004610419548178884,0.006454587367450438,0.007837713231904103,0.009220839096357769,0.010142923005993546,0.011065006915629323,0.011065006915629323,0.011526048870447211,0.012448132780082987,0.013831258644536652,0.015675426463808206,0.016136468418626097,0.016136468418626097,0.01705855232826187,0.01751959428307976,0.01751959428307976,0.019363762102351315,0.0198248040571692,0.02074688796680498,0.02120792992162287,0.023052097740894423,0.025357307514983864,0.02627939142461964,0.026740433379437527,0.027662517289073305,0.028123559243891195,0.029045643153526972,0.030428769017980636,0.03135085292761641,0.03227293683725219,0.03319502074688797,0.033656062701705854,0.034578146611341634,0.03734439834024896,0.03872752420470263,0.0396496081143384,0.04057169202397418,0.04057169202397418,0.04149377593360996,0.042876901798063624,0.0437989857076994,0.04472106961733518,0.04564315352697095,0.046104195481788846,0.04702627939142462,0.047487321346242506,0.04933148916551406,0.05071461502996773,0.052097740894421395,0.05486399262332872,0.0557860765329645,0.056708160442600276,0.058091286307053944,0.05901337021668972,0.06085753803596127,0.06224066390041494,0.06316274781005071,0.06731212540341171,0.06823420931304748,0.06823420931304748,0.06915629322268327,0.07053941908713693,0.07376671277086215,0.07376671277086215,0.07468879668049792,0.07745504840940526,0.07883817427385892,0.08068234209313048,0.08298755186721991,0.08390963577685569,0.08529276164130936,0.08713692946058091,0.0880590133702167,0.08852005532503458,0.08990318118948824,0.09313047487321346,0.09405255878284924,0.09774089442139235,0.0995850622406639,0.10096818810511757,0.10419548178884279,0.10557860765329645,0.10650069156293222,0.10742277547256801,0.1111111111111111,0.11203319502074689,0.11249423697556478,0.11387736284001844,0.11479944674965421,0.11802674043337943,0.11894882434301521,0.11940986629783311,0.12079299216228677,0.12217611802674043,0.12309820193637622,0.1235592438911941,0.12448132780082988,0.12540341171046565,0.1267865375749193,0.1272475795297372,0.12909174734900877,0.13001383125864455,0.13093591516828032,0.13370216689718764,0.13785154449054865,0.1392346703550023,0.14107883817427386,0.14153988012909174,0.14246196403872752,0.1433840479483633,0.14476717381281698,0.14522821576763487,0.14615029967727064,0.1470723835869064,0.14845550945136007,0.15029967727063162,0.15029967727063162,0.1507607192254495,0.15168280313508528,0.15352697095435686,0.1553711387736284,0.15629322268326418,0.15721530659289995,0.1585984324573536,0.1590594744121715,0.15998155832180727,0.15998155832180727,0.16090364223144307,0.16136468418626096,0.16413093591516828,0.16597510373443983,0.1668971876440756,0.1715076071922545,0.17242969110189027,0.1751959428307976,0.17842323651452283,0.1793453204241586,0.1798063623789765,0.18118948824343015,0.18211157215306592,0.1839557399723375,0.18441678192715538,0.1904103273397879,0.1917934532042416,0.19271553711387737,0.19363762102351315,0.19455970493314892,0.19640387275242047,0.19732595666205624,0.1991701244813278,0.1996311664361457,0.20055325034578148,0.20101429230059936,0.2033195020746888,0.20470262793914246,0.20562471184877823,0.20608575380359612,0.2070078377132319,0.20931304748732135,0.21346242508068233,0.2194559704933149,0.21991701244813278,0.22130013831258644,0.22268326417704012,0.2236053480866759,0.22498847395112956,0.22591055786076533,0.23328722913785155,0.2346703550023052,0.23559243891194098,0.23605348086675887,0.23697556477639464,0.23743660673121253,0.23835869064084833,0.23881973259566622,0.239741816505302,0.2425080682342093,0.2429691101890272,0.24389119409866297,0.2475795297372061,0.24850161364684187,0.24988473951129553,0.2512678653757492,0.25311203319502074,0.25587828492392806,0.25864453665283543,0.2591055786076533,0.2600276625172891,0.2627939142461964,0.2637159981558322,0.26509912402028585,0.2660212079299216,0.2669432918395574,0.26878745965882894,0.2701705855232826,0.27708621484555096,0.2793914246196404,0.28031350852927617,0.28169663439372983,0.2826187183033656,0.28400184416781926,0.2858460119870908,0.2863070539419087,0.28815122176118024,0.2918395573997234,0.29322268326417705,0.2950668510834486,0.2959889349930844,0.30013831258644535,0.30106039649608113,0.3019824804057169,0.3029045643153527,0.30336560627017056,0.30428769017980634,0.30567081604426005,0.3070539419087137,0.30889810972798526,0.30982019363762103,0.3112033195020747,0.3144306131857999,0.31627478100507145,0.3171968649147072,0.318118948824343,0.31904103273397877,0.31996311664361454,0.32226832641770403,0.3231904103273398,0.3236514522821577,0.32457353619179347,0.3278008298755187,0.32872291378515445,0.3301060396496081,0.3310281235592439,0.33195020746887965,0.33241124942369754,0.3333333333333333,0.3365606270170586,0.3384047948363301,0.34024896265560167,0.34117104656523745,0.34163208852005533,0.3453204241585984,0.34716459197787,0.34854771784232363,0.35361917934532044,0.3545412632549562,0.35730751498386354,0.3591516828031351,0.3651452282157676,0.3660673121254034,0.3674504379898571,0.3683725218994929,0.36929460580912865,0.3711387736284002,0.3715998155832181,0.37252189949285386,0.37574919317657907,0.37667127708621484,0.37943752881512216,0.38035961272475793,0.3812816966343937,0.3822037805440295,0.3835869064084832,0.38450899031811897,0.38589211618257263,0.3877362840018442,0.3909635776855694,0.39511295527893037,0.39603503918856614,0.3978792070078377,0.3988012909174735,0.3992623328722914,0.4001844167819272,0.40110650069156295,0.4020285846011987,0.4024896265560166,0.40387275242047027,0.40479483633010604,0.4066390041493776,0.40802213001383125,0.4107883817427386,0.41171046565237435,0.4135546334716459,0.41724296911018904,0.4181650530198248,0.4190871369294606,0.42000922083909636,0.42139234670355,0.4223144306131858,0.42415859843245735,0.4250806823420931,0.4283079760258183,0.4292300599354541,0.4306131857999078,0.4315352697095436,0.4319963116643615,0.43337943752881514,0.4352236053480867,0.43614568925772246,0.43660673121254034,0.4375288151221761,0.43937298294144767,0.44029506685108344,0.4416781927155371,0.4426002766251729,0.4476717381281697,0.44951590594744123,0.450437989857077,0.4532042415859843,0.4541263254956201,0.45643153526970953,0.4573536191793453,0.4582757030889811,0.45919778699861685,0.46426924850161366,0.467035500230521,0.46795758414015676,0.46887966804979253,0.47118487782388196,0.47210696173351774,0.47763946519133244,0.4785615491009682,0.48132780082987553,0.4827109266943292,0.4831719686491471,0.48409405255878285,0.4854771784232365,0.4863992623328723,0.4942369755647764,0.4951590594744122,0.4956201014292301,0.49654218533886585,0.49700322729368374,0.4983863531581374,0.49930843706777317,0.5011526048870447,0.5057630244352236,0.5066851083448594,0.5117565698478561,0.5136007376671277,0.5140617796219455,0.5149838635315813,0.5154449054863992,0.5163669893960351,0.5255878284923928,0.5265099124020286,0.5269709543568465,0.5278930382664823,0.5334255417242969,0.5343476256339327,0.5348086675887506,0.5361917934532042,0.53711387736284,0.5389580451821115,0.5398801290917473,0.541263254956201,0.5431074227754725,0.545412632549562,0.5467957584140156,0.5509451360073767,0.5527893038266483,0.5560165975103735,0.5569386814200092,0.5606270170585523,0.562010142923006,0.5629322268326418,0.5647763946519133,0.566159520516367,0.5675426463808206,0.5680036883356385,0.5698478561549101,0.57860765329645,0.5795297372060858,0.5799907791609037,0.582757030889811,0.5832180728446289,0.5841401567542647,0.5878284923928078,0.5896726602120793,0.5905947441217151,0.591055786076533,0.5919778699861687,0.5942830797602582,0.595205163669894,0.5965882895343476,0.5975103734439834,0.598893499308437,0.6002766251728907,0.6016597510373444,0.6025818349469801,0.6039649608114338,0.6058091286307054,0.607192254495159,0.6090364223144306,0.6094974642692486,0.6104195481788843,0.611802674043338,0.6127247579529738,0.6131857999077917,0.6141078838174274,0.6164130935915169,0.6173351775011526,0.6182572614107884,0.6191793453204242,0.6196403872752421,0.6205624711848778,0.6210235131396957,0.6219455970493315,0.6307053941908713,0.6325495620101429,0.6353158137390502,0.636237897648686,0.6371599815583218,0.6380820654679575,0.6394651913324112,0.640848317196865,0.6417704011065007,0.6422314430613186,0.6440756108805902,0.6454587367450438,0.6482249884739512,0.6491470723835869,0.6500691562932227,0.6509912402028585,0.65283540802213,0.6537574919317658,0.6546795758414016,0.6556016597510373,0.6565237436606731,0.6574458275703089,0.6579068695251268,0.6588289534347626,0.661134163208852,0.6620562471184878,0.6629783310281235,0.6643614568925772,0.6666666666666666,0.6680497925311203,0.6689718764407561,0.669432918395574,0.6708160442600276,0.6712770862148455,0.6726602120792993,0.6749654218533887,0.6758875057630245,0.6795758414015676,0.6804979253112033,0.6864914707238359,0.6874135546334716,0.6915629322268326,0.6924850161364684,0.6970954356846473,0.6984785615491009,0.7044721069617336,0.7058552328261872,0.7072383586906409,0.7081604426002767,0.7095435684647303,0.7118487782388198,0.7127708621484555,0.7146150299677271,0.7155371138773629,0.7159981558321807,0.7169202397418165,0.7183033656062702,0.719225449515906,0.7201475334255417,0.7210696173351775,0.7238358690640848,0.7247579529737206,0.7261410788381742,0.7275242047026279,0.7284462886122637,0.7293683725218995,0.7302904564315352,0.7307514983863531,0.7316735822959889,0.7325956662056247,0.7353619179345321,0.7367450437989858,0.7376671277086215,0.7381281696634394,0.7390502535730752,0.7395112955278931,0.7404333794375288,0.7413554633471646,0.7427385892116183,0.7445827570308898,0.7450437989857077,0.7464269248501614,0.7501152604887045,0.751959428307976,0.7588750576302443,0.7607192254495159,0.7611802674043338,0.7625633932687874,0.7634854771784232,0.764407561088059,0.7657906869525127,0.76855693868142,0.7694790225910558,0.7704011065006916,0.772706316274781,0.7736284001844168,0.7754725680036884,0.7763946519133241,0.7773167358229599,0.7791609036422315,0.7842323651452282,0.785154449054864,0.7860765329644998,0.7869986168741355,0.7874596588289534,0.7883817427385892,0.789303826648225,0.7902259105578607,0.7920700783771323,0.792992162286768,0.7939142461964038,0.7948363301060396,0.7952973720608575,0.7962194559704933,0.797602581834947,0.7989857076994007,0.8003688335638544,0.8012909174734901,0.8022130013831259,0.8031350852927617,0.8040571692023974,0.805901337021669,0.8063623789764869,0.8072844628861227,0.8082065467957584,0.8091286307053942,0.81005071461503,0.8118948824343015,0.8123559243891194,0.8132780082987552,0.8137390502535731,0.8155832180728446,0.817888427846934,0.8188105117565698,0.8192715537113877,0.8201936376210235,0.8215767634854771,0.8229598893499308,0.8248040571692024,0.8257261410788381,0.826187183033656,0.8271092669432918,0.8298755186721992,0.8312586445366529,0.8321807284462887,0.8335638543107423,0.834946980175196,0.8354080221300139,0.8363301060396496,0.8404794836330106,0.8414015675426464,0.8427846934071,0.8446288612263716,0.846934071000461,0.8478561549100968,0.8533886583679114,0.8543107422775472,0.8556938681420009,0.8570769940064545,0.8589211618257261,0.8616874135546335,0.8626094974642693,0.8635315813739051,0.8644536652835408,0.8653757491931766,0.8667588750576303,0.8672199170124482,0.8686030428769018,0.8695251267865376,0.871830336560627,0.8727524204702628,0.8732134624250807,0.8750576302443522,0.8792070078377132,0.8810511756569848,0.8852005532503457,0.8861226371599815,0.8875057630244352,0.888427846934071,0.8939603503918857,0.8958045182111573,0.8962655601659751,0.8971876440756109,0.9013370216689719,0.9031811894882434,0.9041032733978792,0.905025357307515,0.9059474412171508,0.9077916090364223,0.913324112494237,0.9147072383586906,0.9151682803135085,0.9160903642231443,0.9174734900875979,0.9188566159520516,0.9202397418165053,0.9230059935454127,0.9239280774550485,0.9266943291839558,0.9276164130935916,0.9280774550484094,0.929921622867681,0.9303826648224989,0.9317657906869525,0.9345320424158599,0.9354541263254956,0.9372982941447672,0.9391424619640387,0.9400645458736745,0.9409866297833103,0.941908713692946,0.9423697556477639,0.9432918395573997,0.9455970493314891,0.9469801751959428,0.9525126786537574,0.9534347625633933,0.9635776855693868,0.9644997694790226,0.9681881051175657,0.9691101890272015,0.9727985246657446,0.9737206085753803,0.9755647763946519,0.9764868603042877,0.9797141539880129,0.9806362378976486,0.9838635315813739,0.9847856154910097,0.9852466574458276,0.9861687413554634,0.9884739511295528,0.9898570769940065,0.9926233287229138,0.9935454126325496,1.0],\"y\":[0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.3,0.3,0.3,0.3,0.3,0.3,0.4,0.4,0.4,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.7,0.7,0.7,0.7,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"type\":\"scatter\"},{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(255, 255, 255, 0)\",\"width\":0},\"name\":\"(95% CI: 0.8472-1.0000)\",\"showlegend\":true,\"x\":[0.0,0.0009220839096357768,0.0018441678192715537,0.002305209774089442,0.003227293683725219,0.004149377593360996,0.004149377593360996,0.004610419548178884,0.006454587367450438,0.007837713231904103,0.009220839096357769,0.010142923005993546,0.011065006915629323,0.011065006915629323,0.011526048870447211,0.012448132780082987,0.013831258644536652,0.015675426463808206,0.016136468418626097,0.016136468418626097,0.01705855232826187,0.01751959428307976,0.01751959428307976,0.019363762102351315,0.0198248040571692,0.02074688796680498,0.02120792992162287,0.023052097740894423,0.025357307514983864,0.02627939142461964,0.026740433379437527,0.027662517289073305,0.028123559243891195,0.029045643153526972,0.030428769017980636,0.03135085292761641,0.03227293683725219,0.03319502074688797,0.033656062701705854,0.034578146611341634,0.03734439834024896,0.03872752420470263,0.0396496081143384,0.04057169202397418,0.04057169202397418,0.04149377593360996,0.042876901798063624,0.0437989857076994,0.04472106961733518,0.04564315352697095,0.046104195481788846,0.04702627939142462,0.047487321346242506,0.04933148916551406,0.05071461502996773,0.052097740894421395,0.05486399262332872,0.0557860765329645,0.056708160442600276,0.058091286307053944,0.05901337021668972,0.06085753803596127,0.06224066390041494,0.06316274781005071,0.06731212540341171,0.06823420931304748,0.06823420931304748,0.06915629322268327,0.07053941908713693,0.07376671277086215,0.07376671277086215,0.07468879668049792,0.07745504840940526,0.07883817427385892,0.08068234209313048,0.08298755186721991,0.08390963577685569,0.08529276164130936,0.08713692946058091,0.0880590133702167,0.08852005532503458,0.08990318118948824,0.09313047487321346,0.09405255878284924,0.09774089442139235,0.0995850622406639,0.10096818810511757,0.10419548178884279,0.10557860765329645,0.10650069156293222,0.10742277547256801,0.1111111111111111,0.11203319502074689,0.11249423697556478,0.11387736284001844,0.11479944674965421,0.11802674043337943,0.11894882434301521,0.11940986629783311,0.12079299216228677,0.12217611802674043,0.12309820193637622,0.1235592438911941,0.12448132780082988,0.12540341171046565,0.1267865375749193,0.1272475795297372,0.12909174734900877,0.13001383125864455,0.13093591516828032,0.13370216689718764,0.13785154449054865,0.1392346703550023,0.14107883817427386,0.14153988012909174,0.14246196403872752,0.1433840479483633,0.14476717381281698,0.14522821576763487,0.14615029967727064,0.1470723835869064,0.14845550945136007,0.15029967727063162,0.15029967727063162,0.1507607192254495,0.15168280313508528,0.15352697095435686,0.1553711387736284,0.15629322268326418,0.15721530659289995,0.1585984324573536,0.1590594744121715,0.15998155832180727,0.15998155832180727,0.16090364223144307,0.16136468418626096,0.16413093591516828,0.16597510373443983,0.1668971876440756,0.1715076071922545,0.17242969110189027,0.1751959428307976,0.17842323651452283,0.1793453204241586,0.1798063623789765,0.18118948824343015,0.18211157215306592,0.1839557399723375,0.18441678192715538,0.1904103273397879,0.1917934532042416,0.19271553711387737,0.19363762102351315,0.19455970493314892,0.19640387275242047,0.19732595666205624,0.1991701244813278,0.1996311664361457,0.20055325034578148,0.20101429230059936,0.2033195020746888,0.20470262793914246,0.20562471184877823,0.20608575380359612,0.2070078377132319,0.20931304748732135,0.21346242508068233,0.2194559704933149,0.21991701244813278,0.22130013831258644,0.22268326417704012,0.2236053480866759,0.22498847395112956,0.22591055786076533,0.23328722913785155,0.2346703550023052,0.23559243891194098,0.23605348086675887,0.23697556477639464,0.23743660673121253,0.23835869064084833,0.23881973259566622,0.239741816505302,0.2425080682342093,0.2429691101890272,0.24389119409866297,0.2475795297372061,0.24850161364684187,0.24988473951129553,0.2512678653757492,0.25311203319502074,0.25587828492392806,0.25864453665283543,0.2591055786076533,0.2600276625172891,0.2627939142461964,0.2637159981558322,0.26509912402028585,0.2660212079299216,0.2669432918395574,0.26878745965882894,0.2701705855232826,0.27708621484555096,0.2793914246196404,0.28031350852927617,0.28169663439372983,0.2826187183033656,0.28400184416781926,0.2858460119870908,0.2863070539419087,0.28815122176118024,0.2918395573997234,0.29322268326417705,0.2950668510834486,0.2959889349930844,0.30013831258644535,0.30106039649608113,0.3019824804057169,0.3029045643153527,0.30336560627017056,0.30428769017980634,0.30567081604426005,0.3070539419087137,0.30889810972798526,0.30982019363762103,0.3112033195020747,0.3144306131857999,0.31627478100507145,0.3171968649147072,0.318118948824343,0.31904103273397877,0.31996311664361454,0.32226832641770403,0.3231904103273398,0.3236514522821577,0.32457353619179347,0.3278008298755187,0.32872291378515445,0.3301060396496081,0.3310281235592439,0.33195020746887965,0.33241124942369754,0.3333333333333333,0.3365606270170586,0.3384047948363301,0.34024896265560167,0.34117104656523745,0.34163208852005533,0.3453204241585984,0.34716459197787,0.34854771784232363,0.35361917934532044,0.3545412632549562,0.35730751498386354,0.3591516828031351,0.3651452282157676,0.3660673121254034,0.3674504379898571,0.3683725218994929,0.36929460580912865,0.3711387736284002,0.3715998155832181,0.37252189949285386,0.37574919317657907,0.37667127708621484,0.37943752881512216,0.38035961272475793,0.3812816966343937,0.3822037805440295,0.3835869064084832,0.38450899031811897,0.38589211618257263,0.3877362840018442,0.3909635776855694,0.39511295527893037,0.39603503918856614,0.3978792070078377,0.3988012909174735,0.3992623328722914,0.4001844167819272,0.40110650069156295,0.4020285846011987,0.4024896265560166,0.40387275242047027,0.40479483633010604,0.4066390041493776,0.40802213001383125,0.4107883817427386,0.41171046565237435,0.4135546334716459,0.41724296911018904,0.4181650530198248,0.4190871369294606,0.42000922083909636,0.42139234670355,0.4223144306131858,0.42415859843245735,0.4250806823420931,0.4283079760258183,0.4292300599354541,0.4306131857999078,0.4315352697095436,0.4319963116643615,0.43337943752881514,0.4352236053480867,0.43614568925772246,0.43660673121254034,0.4375288151221761,0.43937298294144767,0.44029506685108344,0.4416781927155371,0.4426002766251729,0.4476717381281697,0.44951590594744123,0.450437989857077,0.4532042415859843,0.4541263254956201,0.45643153526970953,0.4573536191793453,0.4582757030889811,0.45919778699861685,0.46426924850161366,0.467035500230521,0.46795758414015676,0.46887966804979253,0.47118487782388196,0.47210696173351774,0.47763946519133244,0.4785615491009682,0.48132780082987553,0.4827109266943292,0.4831719686491471,0.48409405255878285,0.4854771784232365,0.4863992623328723,0.4942369755647764,0.4951590594744122,0.4956201014292301,0.49654218533886585,0.49700322729368374,0.4983863531581374,0.49930843706777317,0.5011526048870447,0.5057630244352236,0.5066851083448594,0.5117565698478561,0.5136007376671277,0.5140617796219455,0.5149838635315813,0.5154449054863992,0.5163669893960351,0.5255878284923928,0.5265099124020286,0.5269709543568465,0.5278930382664823,0.5334255417242969,0.5343476256339327,0.5348086675887506,0.5361917934532042,0.53711387736284,0.5389580451821115,0.5398801290917473,0.541263254956201,0.5431074227754725,0.545412632549562,0.5467957584140156,0.5509451360073767,0.5527893038266483,0.5560165975103735,0.5569386814200092,0.5606270170585523,0.562010142923006,0.5629322268326418,0.5647763946519133,0.566159520516367,0.5675426463808206,0.5680036883356385,0.5698478561549101,0.57860765329645,0.5795297372060858,0.5799907791609037,0.582757030889811,0.5832180728446289,0.5841401567542647,0.5878284923928078,0.5896726602120793,0.5905947441217151,0.591055786076533,0.5919778699861687,0.5942830797602582,0.595205163669894,0.5965882895343476,0.5975103734439834,0.598893499308437,0.6002766251728907,0.6016597510373444,0.6025818349469801,0.6039649608114338,0.6058091286307054,0.607192254495159,0.6090364223144306,0.6094974642692486,0.6104195481788843,0.611802674043338,0.6127247579529738,0.6131857999077917,0.6141078838174274,0.6164130935915169,0.6173351775011526,0.6182572614107884,0.6191793453204242,0.6196403872752421,0.6205624711848778,0.6210235131396957,0.6219455970493315,0.6307053941908713,0.6325495620101429,0.6353158137390502,0.636237897648686,0.6371599815583218,0.6380820654679575,0.6394651913324112,0.640848317196865,0.6417704011065007,0.6422314430613186,0.6440756108805902,0.6454587367450438,0.6482249884739512,0.6491470723835869,0.6500691562932227,0.6509912402028585,0.65283540802213,0.6537574919317658,0.6546795758414016,0.6556016597510373,0.6565237436606731,0.6574458275703089,0.6579068695251268,0.6588289534347626,0.661134163208852,0.6620562471184878,0.6629783310281235,0.6643614568925772,0.6666666666666666,0.6680497925311203,0.6689718764407561,0.669432918395574,0.6708160442600276,0.6712770862148455,0.6726602120792993,0.6749654218533887,0.6758875057630245,0.6795758414015676,0.6804979253112033,0.6864914707238359,0.6874135546334716,0.6915629322268326,0.6924850161364684,0.6970954356846473,0.6984785615491009,0.7044721069617336,0.7058552328261872,0.7072383586906409,0.7081604426002767,0.7095435684647303,0.7118487782388198,0.7127708621484555,0.7146150299677271,0.7155371138773629,0.7159981558321807,0.7169202397418165,0.7183033656062702,0.719225449515906,0.7201475334255417,0.7210696173351775,0.7238358690640848,0.7247579529737206,0.7261410788381742,0.7275242047026279,0.7284462886122637,0.7293683725218995,0.7302904564315352,0.7307514983863531,0.7316735822959889,0.7325956662056247,0.7353619179345321,0.7367450437989858,0.7376671277086215,0.7381281696634394,0.7390502535730752,0.7395112955278931,0.7404333794375288,0.7413554633471646,0.7427385892116183,0.7445827570308898,0.7450437989857077,0.7464269248501614,0.7501152604887045,0.751959428307976,0.7588750576302443,0.7607192254495159,0.7611802674043338,0.7625633932687874,0.7634854771784232,0.764407561088059,0.7657906869525127,0.76855693868142,0.7694790225910558,0.7704011065006916,0.772706316274781,0.7736284001844168,0.7754725680036884,0.7763946519133241,0.7773167358229599,0.7791609036422315,0.7842323651452282,0.785154449054864,0.7860765329644998,0.7869986168741355,0.7874596588289534,0.7883817427385892,0.789303826648225,0.7902259105578607,0.7920700783771323,0.792992162286768,0.7939142461964038,0.7948363301060396,0.7952973720608575,0.7962194559704933,0.797602581834947,0.7989857076994007,0.8003688335638544,0.8012909174734901,0.8022130013831259,0.8031350852927617,0.8040571692023974,0.805901337021669,0.8063623789764869,0.8072844628861227,0.8082065467957584,0.8091286307053942,0.81005071461503,0.8118948824343015,0.8123559243891194,0.8132780082987552,0.8137390502535731,0.8155832180728446,0.817888427846934,0.8188105117565698,0.8192715537113877,0.8201936376210235,0.8215767634854771,0.8229598893499308,0.8248040571692024,0.8257261410788381,0.826187183033656,0.8271092669432918,0.8298755186721992,0.8312586445366529,0.8321807284462887,0.8335638543107423,0.834946980175196,0.8354080221300139,0.8363301060396496,0.8404794836330106,0.8414015675426464,0.8427846934071,0.8446288612263716,0.846934071000461,0.8478561549100968,0.8533886583679114,0.8543107422775472,0.8556938681420009,0.8570769940064545,0.8589211618257261,0.8616874135546335,0.8626094974642693,0.8635315813739051,0.8644536652835408,0.8653757491931766,0.8667588750576303,0.8672199170124482,0.8686030428769018,0.8695251267865376,0.871830336560627,0.8727524204702628,0.8732134624250807,0.8750576302443522,0.8792070078377132,0.8810511756569848,0.8852005532503457,0.8861226371599815,0.8875057630244352,0.888427846934071,0.8939603503918857,0.8958045182111573,0.8962655601659751,0.8971876440756109,0.9013370216689719,0.9031811894882434,0.9041032733978792,0.905025357307515,0.9059474412171508,0.9077916090364223,0.913324112494237,0.9147072383586906,0.9151682803135085,0.9160903642231443,0.9174734900875979,0.9188566159520516,0.9202397418165053,0.9230059935454127,0.9239280774550485,0.9266943291839558,0.9276164130935916,0.9280774550484094,0.929921622867681,0.9303826648224989,0.9317657906869525,0.9345320424158599,0.9354541263254956,0.9372982941447672,0.9391424619640387,0.9400645458736745,0.9409866297833103,0.941908713692946,0.9423697556477639,0.9432918395573997,0.9455970493314891,0.9469801751959428,0.9525126786537574,0.9534347625633933,0.9635776855693868,0.9644997694790226,0.9681881051175657,0.9691101890272015,0.9727985246657446,0.9737206085753803,0.9755647763946519,0.9764868603042877,0.9797141539880129,0.9806362378976486,0.9838635315813739,0.9847856154910097,0.9852466574458276,0.9861687413554634,0.9884739511295528,0.9898570769940065,0.9926233287229138,0.9935454126325496,1.0],\"y\":[0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.3,0.3,0.3,0.3,0.3,0.3,0.4,0.4,0.4,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.7,0.7,0.7,0.7,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.8,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.9,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"type\":\"scatter\"},{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(50, 50, 250, 1.0)\",\"width\":5},\"name\":\"\\u003cb\\u003eOther\\u003c\\u002fb\\u003e\",\"showlegend\":true,\"x\":[0.0,0.000228675966155957,0.000228675966155957,0.000914703864623828,0.000914703864623828,0.001829407729247656,0.001829407729247656,0.004116167390807226,0.004116167390807226,0.005030871255431054,0.005488223187742968,0.00846101074777041,0.00846101074777041,0.008689686713926366,0.008689686713926366,0.009375714612394238,0.010290418477018065,0.010519094443174023,0.010519094443174023,0.01372055796935742,0.014177909901669335,0.015778641664761034,0.015778641664761034,0.018522753258632518,0.018522753258632518,0.019666133089412303,0.019666133089412303,0.01989480905556826,0.01989480905556826,0.020352160987880175,0.020809512920192088,0.021266864852504,0.02378230048021953,0.024239652412531443,0.027898467871026754,0.02835581980333867,0.029270523667962497,0.02995655156643037,0.030413903498742283,0.03384404299108164,0.03430139492339355,0.03544477475417333,0.03544477475417333,0.03796021038188886,0.03841756231420078,0.03841756231420078,0.039332266178824606,0.03978961811113652,0.04024697004344843,0.04070432197576035,0.04093299794191631,0.04139034987422822,0.041619025840384176,0.041619025840384176,0.046421221129659275,0.046878573061971185,0.04710724902812714,0.04756460096043906,0.049165332723530755,0.04962268465584267,0.05008003658815458,0.05008003658815458,0.05190944431740224,0.05236679624971415,0.05282414818202607,0.053281500114337986,0.05419620397896181,0.05465355591127372,0.05511090784358564,0.055568259775897556,0.05716899153898925,0.05716899153898925,0.06311456665904414,0.06357191859135605,0.06380059455751201,0.06425794648982391,0.06494397438829179,0.0654013263206037,0.06631603018522753,0.06677338211753944,0.06951749371141093,0.07043219757603476,0.07134690144065858,0.0718042533729705,0.07226160530528242,0.07294763320375029,0.0734049851360622,0.07363366110221815,0.07592042076377772,0.0766064486622456,0.07797850445918134,0.07866453235764921,0.07912188428996113,0.07957923622227304,0.08049394008689686,0.0814086439515207,0.085067459410016,0.08735421907157558,0.08781157100388749,0.08849759890235537,0.08895495083466727,0.08918362680082323,0.09261376629316259,0.09329979419163045,0.0962725817516579,0.09672993368396982,0.09718728561628173,0.09764463754859365,0.09993139721015322,0.10038874914246512,0.10130345300708896,0.10198948090555683,0.10244683283786873,0.10290418477018065,0.10359021266864853,0.10404756460096044,0.10541962039789618,0.10793505602561171,0.10930711182254745,0.10976446375485936,0.11022181568717128,0.11090784358563915,0.11136519551795106,0.11273725131488681,0.11319460324719872,0.11685341870569403,0.11891150240109764,0.11891150240109764,0.12028355819803338,0.12211296592728105,0.122341641893437,0.12279899382574891,0.12348502172421678,0.1239423736565287,0.1266864852504002,0.1271438371827121,0.12805854104733594,0.12805854104733594,0.12851589297964783,0.1287445689458038,0.12920192087811572,0.13171735650583125,0.13217470843814316,0.13377544020123486,0.13423279213354677,0.1346901440658587,0.13514749599817058,0.13880631145666592,0.13926366338897783,0.1399496912874457,0.1404070432197576,0.14109307111822547,0.14177909901669333,0.1420077749828493,0.143608506745941,0.1472673222044363,0.14909672993368397,0.1500114337983078,0.15092613766293161,0.15229819345986736,0.15435627715527098,0.15458495312142695,0.15504230505373887,0.15755774068145437,0.15961582437685798,0.1600731763091699,0.1605305282414818,0.16098788017379373,0.16144523210610565,0.1621312600045735,0.16418934369997712,0.16464669563228904,0.1664761033615367,0.16693345529384862,0.16716213126000457,0.16853418705694032,0.17219300251543562,0.17265035444774754,0.17470843814315115,0.17516579007546307,0.17653784587239882,0.17653784587239882,0.17676652183855476,0.17722387377086668,0.17951063343242626,0.17951063343242626,0.18431282872170135,0.18431282872170135,0.18522753258632518,0.18591356048479304,0.18637091241710496,0.1872856162817288,0.1877429682140407,0.18797164418019666,0.18842899611250857,0.1888863480448205,0.1893436999771324,0.19048707980791219,0.1909444317402241,0.19940544248799452,0.19986279442030644,0.20009147038646238,0.20100617425108622,0.20192087811571005,0.20237823004802194,0.2037502858449577,0.20466498970958152,0.20626572147267322,0.20695174937114108,0.20923850903270066,0.20992453693116853,0.21061056482963642,0.21106791676194833,0.21152526869426022,0.21198262062657214,0.21404070432197575,0.21472673222044364,0.21769951978047108,0.21815687171278297,0.2197576034758747,0.2202149554081866,0.2250171506974617,0.22547450262977362,0.2270752343928653,0.22776126229133317,0.22798993825748914,0.228675966155957,0.22959067002058084,0.23004802195289276,0.2302766979190487,0.23073404985136062,0.2323347816144523,0.2330208095129202,0.23324948547907615,0.23416418934369998,0.23530756917447976,0.23576492110679168,0.23690830093757145,0.23736565286988337,0.23759432883603934,0.23805168076835126,0.23919506059913104,0.23965241253144295,0.2398810884975989,0.2398810884975989,0.244683283786874,0.2451406357191859,0.25040018294077293,0.25131488680539676,0.2520009147038646,0.25245826663617654,0.25497370226389204,0.2558884061285159,0.2574891378916076,0.2579464898239195,0.2581751657900755,0.25908986965469927,0.2595472215870112,0.2600045735193231,0.26091927738394693,0.2613766293162589,0.2654927967070661,0.265950148639378,0.26617882460553394,0.2666361765378459,0.2696089640978733,0.27029499199634116,0.27486851131946033,0.2753258632517722,0.276469243082552,0.27692659501486394,0.2771552709810199,0.27761262291333183,0.2798993825748914,0.2808140864395152,0.28287217013491883,0.28355819803338667,0.2851589297964784,0.2856162817287903,0.28973244911959756,0.29018980105190945,0.2913331808826892,0.29179053281500117,0.2938486165104048,0.2945346444088726,0.2959067002058084,0.2963640521381203,0.3048250628858907,0.3052824148182026,0.30596844271667045,0.3064257946489824,0.3148868053967528,0.31534415732906473,0.31603018522753257,0.3164875371598445,0.3176309169906243,0.3180882689229362,0.31900297278756,0.31946032471987196,0.3212897324491196,0.3217470843814315,0.32197576034758746,0.3224331122798994,0.32403384404299107,0.324491195975303,0.3288360393322662,0.3292933912645781,0.32997941916304596,0.33043677109535785,0.3313514749599817,0.33180882689229363,0.33844042991081635,0.33958380974159613,0.33981248570775213,0.340269837640064,0.3425565973016236,0.3430139492339355,0.3436999771324034,0.3441573290647153,0.3469014406585868,0.34781614452321064,0.34850217242167847,0.3489595243539904,0.3494168762863023,0.34987422821861425,0.35033158015092614,0.350788932083238,0.3533043677109536,0.35376171964326547,0.35513377544020125,0.35559112737251314,0.356277155270981,0.3567345072032929,0.3585639149325406,0.35902126686485253,0.3592499428310085,0.35970729476332036,0.3622227303910359,0.3626800823233478,0.3633661102218157,0.3638234621541276,0.3690830093757146,0.3699977132403384,0.3702263892064944,0.3706837411388063,0.372513148868054,0.37297050080036587,0.37479990852961353,0.3752572604619255,0.38005945575120054,0.3807454836496684,0.38097415961582437,0.3814315115481363,0.38806311456665904,0.388520466498971,0.38874914246512693,0.3892064943974388,0.3905785501943746,0.3910359021266865,0.3919506059913103,0.3924079579236222,0.3930939858220901,0.393780013720558,0.3956094214498056,0.39606677338211754,0.3962954493482735,0.39675280128058543,0.39743882917905327,0.3978961811113652,0.40064029270523666,0.4015549965698605,0.4024697004344843,0.40292705236679627,0.4068145437914475,0.4077292476560713,0.4164189343699977,0.4168762863023096,0.4171049622684656,0.4180196661330894,0.4196203978961811,0.420306425794649,0.42122112965927283,0.4216784815915847,0.42213583352389666,0.42259318545620855,0.4239652412531443,0.42465126915161217,0.42533729705008005,0.42579464898239194,0.42716670477932767,0.4276240567116396,0.4280814086439515,0.42853876057626344,0.4287674365424194,0.4292247884747313,0.43105419620397895,0.4315115481362909,0.4328836039332266,0.43334095586553856,0.4335696318316945,0.4340269837640064,0.4356277155270981,0.43654241939172195,0.4372284472901898,0.4376857992225017,0.4392865309855934,0.43974388291790534,0.44248799451177684,0.4434026983764006,0.4440887262748685,0.44454607820718045,0.44751886576720784,0.4479762176995198,0.4511776812257032,0.4516350331580151,0.4525497370226389,0.45300708895495084,0.4539217928195747,0.45437914475188657,0.45506517265035445,0.45552252458266634,0.4591813400411617,0.45963869197347357,0.46032471987194146,0.46078207180425335,0.46238280356734507,0.462840155499657,0.46352618339812485,0.4639835353304368,0.4653555911273725,0.4660416190258404,0.46832837868739996,0.46878573061971185,0.46901440658586785,0.46947175851817974,0.4706151383489595,0.47107249028127146,0.4713011662474274,0.4717585181797393,0.4731305739766751,0.4738166018751429,0.4770180654013263,0.47747541733363824,0.48021952892750974,0.4811342327921335,0.48227761262291335,0.48273496455522524,0.4857077521152527,0.4861651040475646,0.4866224559798765,0.4870798079121884,0.4877658358106563,0.4882231877429682,0.4916533272353076,0.49211067916761947,0.49805625428767436,0.4985136062199863,0.4994283100846101,0.499885662016922,0.5017150697461696,0.5021724216784816,0.5030871255431054,0.5035444774754173,0.5037731534415733,0.5042305053738853,0.5049165332723531,0.5056025611708209,0.5058312371369769,0.5062885890692889,0.5065172650354448,0.5069746169677567,0.5074319689000686,0.5078893208323805,0.5085753487308484,0.5090327006631603,0.5110907843585639,0.5115481362908758,0.5206951749371141,0.521152526869426,0.5229819345986737,0.5234392865309856,0.5259547221587011,0.526869426023325,0.5314429453464441,0.531900297278756,0.5337297050080037,0.5341870569403155,0.5355591127372513,0.5360164646695632,0.5385319002972787,0.5392179281957467,0.5396752801280585,0.5399039560942145,0.5403613080265264,0.5412760118911503,0.5417333638234622,0.5440201234850217,0.5447061513834895,0.5451635033158015,0.5458495312142694,0.5481362908758289,0.5485936428081408,0.5522524582666362,0.552709810198948,0.5561399496912874,0.5565973016235993,0.5568259775897553,0.5572833295220673,0.5602561170820947,0.5607134690144066,0.5613994969128745,0.5618568488451864,0.5630002286759661,0.5634575806082781,0.5664303681683055,0.5668877201006174,0.5671163960667733,0.5675737479990853,0.5691744797621769,0.5696318316944889,0.5707752115252687,0.5712325634575806,0.5723759432883604,0.5730619711868282,0.5735193231191402,0.5753487308483878,0.5758060827806998,0.5803796021038189,0.5808369540361308,0.5810656300022867,0.5815229819345987,0.5842670935284702,0.5847244454607821,0.5854104733592499,0.5860965012577178,0.5870112051223416,0.5876972330208096,0.5881545849531215,0.5911273725131488,0.5920420763777727,0.5931854562085525,0.5941001600731763,0.5945575120054882,0.595700891836268,0.5986736793962955,0.5995883832609192,0.6000457351932312,0.6005030871255431,0.6018751429224789,0.6023324948547908,0.6027898467871027,0.6032471987194146,0.6034758746855705,0.6039332266178825,0.6041619025840385,0.6046192545163503,0.6055339583809741,0.606448662245598,0.6069060141779099,0.6071346901440658,0.6080493940086897,0.6094214498056254,0.6098788017379373,0.611708209467185,0.612165561399497,0.6123942373656529,0.6130802652641207,0.6142236450949006,0.6146809970272125,0.617196432654928,0.6176537845872399,0.6183398124857078,0.6187971644180197,0.6201692202149555,0.6206265721472674,0.6235993597072947,0.6242853876057627,0.6258861193688543,0.6268008232334782,0.6281728790304139,0.6286302309627259,0.6290875828950377,0.6293162588611937,0.6297736107935056,0.6302309627258175,0.6306883146581295,0.6311456665904414,0.6316030185227532,0.6318316944889092,0.6327463983535331,0.6338897781843128,0.6343471301166247,0.6345758060827807,0.6350331580150926,0.6359478618797164,0.6364052138120283,0.6373199176766522,0.63800594557512,0.638691973473588,0.6398353533043677,0.6407500571689916,0.6412074091013035,0.6416647610336154,0.6423507889320832,0.6432654927967071,0.6439515206951749,0.6462382803567345,0.6469243082552024,0.6512691516121656,0.6517265035444775,0.6572147267322205,0.6576720786645324,0.6583581065630002,0.6588154584953121,0.6601875142922479,0.6606448662245598,0.6624742739538074,0.6629316258861193,0.6636176537845873,0.6640750057168991,0.6661330894123028,0.6665904413446146,0.6675051452092385,0.6684198490738623,0.6697919048707981,0.6704779327692659,0.6711639606677339,0.6725360164646695,0.6846558426709353,0.6851131946032472,0.686027898467871,0.6864852504001829,0.6869426023324948,0.6876286302309628,0.6887720100617425,0.6892293619940544,0.6896867139263664,0.6903727418248342,0.6908300937571461,0.691058769723302,0.69174479762177,0.6928881774525497,0.6933455293848616,0.6963183169448891,0.6976903727418249,0.6992911045049165,0.6997484564372285,0.7011205122341642,0.701577864166476,0.702263892064944,0.7024925680310999,0.7029499199634118,0.7031785959295678,0.7036359478618797,0.7040932997941917,0.7045506517265036,0.7050080036588154,0.7054653555911273,0.7066087354219072,0.707294763320375,0.707752115252687,0.7082094671849989,0.7102675508804025,0.7107249028127144,0.7141550423050538,0.7150697461696776,0.7164418019666133,0.7171278298650812,0.717813857763549,0.718271209695861,0.7194145895266407,0.7201006174251087,0.7210153212897324,0.7219300251543562,0.7223873770866682,0.7228447290189801,0.723530756917448,0.7239881088497598,0.7244454607820718,0.7249028127143837,0.7251314886805397,0.7260461925451634,0.7267322204436314,0.7276469243082552,0.7281042762405671,0.7285616281728791,0.7299336839698147,0.7303910359021267,0.7315344157329065,0.7319917676652183,0.734049851360622,0.734507203292934,0.7356505831237137,0.7361079350560256,0.7367939629544935,0.7372513148868054,0.7377086668191173,0.7381660187514292,0.7434255659730162,0.7438829179053281,0.7459410016007317,0.7463983535330436,0.7482277612622913,0.7486851131946033,0.7521152526869426,0.7525726046192546,0.7564600960439057,0.7569174479762177,0.7573747999085296,0.7580608278069975,0.7582895037731534,0.7587468557054654,0.7644637548593642,0.7649211067916762,0.7667505145209238,0.7676652183855477,0.7692659501486394,0.7701806540132632,0.7724674136748227,0.7729247656071347,0.7761262291333181,0.77658358106563,0.7772696089640979,0.7779556368625657,0.7784129887948776,0.7816144523210611,0.7823004802195289,0.7843585639149325,0.7850445918134004,0.7857306197118683,0.7864166476103361,0.7909901669334553,0.7914475188657673,0.7930482506288589,0.7935056025611709,0.7992225017150697,0.7996798536473817,0.8017379373427853,0.8021952892750972,0.8024239652412531,0.802881317173565,0.8058541047335925,0.8065401326320604,0.8069974845643723,0.8074548364966841,0.8079121884289961,0.808369540361308,0.8090555682597759,0.8097415961582438,0.8111136519551795,0.8122570317859593,0.8129430596844271,0.813400411616739,0.813857763549051,0.8147724674136748,0.8156871712782987,0.8170592270752344,0.8177452549737023,0.8182026069060142,0.8195746627029499,0.8200320146352619,0.8230048021952893,0.8234621541276012,0.824376857992225,0.8248342099245369,0.8262062657214727,0.8266636176537846,0.8273496455522524,0.8282643494168763,0.8303224331122799,0.8310084610107478,0.8314658129430597,0.8321518408415276,0.8367253601646467,0.8374113880631145,0.8396981477246741,0.840384175623142,0.840612851589298,0.8412988794877658,0.8424422593185457,0.8428996112508576,0.845643722844729,0.8461010747770409,0.8495312142693803,0.8504459181340042,0.8513606219986279,0.8518179739309398,0.8541047335924994,0.8545620855248114,0.8579922250171507,0.8584495769494626,0.8591356048479305,0.8600503087125543,0.8625657443402699,0.8630230962725818,0.867367939629545,0.8678252915618568,0.8694260233249486,0.8701120512234164,0.8710267550880403,0.8714841070203522,0.872398810884976,0.872856162817288,0.8735421907157558,0.8739995426480677,0.8758289503773153,0.8762863023096272,0.8774296821404071,0.877887034072719,0.8783443860050308,0.8788017379373427,0.8815458495312143,0.8820032014635262,0.8847473130573976,0.8852046649897096,0.8890921564143609,0.8895495083466728,0.8902355362451406,0.8918362680082323,0.8932083238051681,0.9002972787560027,0.9007546306883146,0.9032700663160302,0.904184770180654,0.9055568259775898,0.9060141779099017,0.9062428538760576,0.9067002058083695,0.909672993368397,0.9105876972330208,0.9110450491653327,0.9117310770638006,0.9126457809284244,0.9133318088268922,0.9135604847930483,0.9144751886576721,0.9151612165561399,0.9156185684884519,0.9183626800823234,0.9190487079807912,0.9217928195746627,0.9224788474731306,0.9227075234392865,0.9231648753715984,0.9243082552023782,0.9247656071346901,0.9286530985593414,0.9291104504916533,0.936428081408644,0.9368854333409559,0.9387148410702035,0.9391721930025154,0.9405442487994512,0.9410016007317631,0.9439743882917905,0.9444317402241025,0.9453464440887263,0.9460324719871942,0.9528927509718729,0.9533501029041848,0.9540361308026526,0.9549508346672765,0.9567802423965241,0.957466270294992,0.9586096501257718,0.9592956780242397,0.9595243539903956,0.9599817059227075,0.9613537617196433,0.9618111136519552,0.9634118454150469,0.9638691973473588,0.9640978733135147,0.9650125771781386,0.9663846329750743,0.9668419849073863,0.9707294763320375,0.9711868282643494,0.9716441801966613,0.9721015321289732,0.9727875600274412,0.973244911959753,0.9803338669105877,0.9810198948090556,0.9812485707752115,0.9817059227075234,0.9828493025383033,0.9833066544706152,0.9844500343013949,0.9849073862337069,0.9881088497598902,0.9885662016922021,0.994283100846101,0.9947404527784129,1.0],\"y\":[0.0,0.0,0.22580645161290322,0.22580645161290322,0.25806451612903225,0.25806451612903225,0.2903225806451613,0.2903225806451613,0.3225806451612903,0.3225806451612903,0.3225806451612903,0.3225806451612903,0.3548387096774194,0.3548387096774194,0.3870967741935484,0.3870967741935484,0.3870967741935484,0.3870967741935484,0.4838709677419355,0.4838709677419355,0.4838709677419355,0.4838709677419355,0.5161290322580645,0.5161290322580645,0.5483870967741935,0.5483870967741935,0.6129032258064516,0.6129032258064516,0.6451612903225806,0.6451612903225806,0.6451612903225806,0.6451612903225806,0.6451612903225806,0.6451612903225806,0.6451612903225806,0.6451612903225806,0.6451612903225806,0.6451612903225806,0.6451612903225806,0.6451612903225806,0.6451612903225806,0.6451612903225806,0.6774193548387096,0.6774193548387096,0.6774193548387096,0.7096774193548387,0.7096774193548387,0.7096774193548387,0.7096774193548387,0.7096774193548387,0.7096774193548387,0.7096774193548387,0.7096774193548387,0.7419354838709677,0.7419354838709677,0.7419354838709677,0.7419354838709677,0.7419354838709677,0.7419354838709677,0.7419354838709677,0.7419354838709677,0.7741935483870968,0.7741935483870968,0.7741935483870968,0.7741935483870968,0.7741935483870968,0.7741935483870968,0.7741935483870968,0.7741935483870968,0.7741935483870968,0.7741935483870968,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8387096774193549,0.8387096774193549,0.8387096774193549,0.8387096774193549,0.8387096774193549,0.8387096774193549,0.8387096774193549,0.8387096774193549,0.8387096774193549,0.8387096774193549,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.9032258064516129,0.9032258064516129,0.9032258064516129,0.9032258064516129,0.9354838709677419,0.9354838709677419,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"type\":\"scatter\"},{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(255, 255, 255, 0)\",\"width\":5},\"name\":\"AUC: 0.9548\",\"showlegend\":true,\"x\":[0.0,0.000228675966155957,0.000228675966155957,0.000914703864623828,0.000914703864623828,0.001829407729247656,0.001829407729247656,0.004116167390807226,0.004116167390807226,0.005030871255431054,0.005488223187742968,0.00846101074777041,0.00846101074777041,0.008689686713926366,0.008689686713926366,0.009375714612394238,0.010290418477018065,0.010519094443174023,0.010519094443174023,0.01372055796935742,0.014177909901669335,0.015778641664761034,0.015778641664761034,0.018522753258632518,0.018522753258632518,0.019666133089412303,0.019666133089412303,0.01989480905556826,0.01989480905556826,0.020352160987880175,0.020809512920192088,0.021266864852504,0.02378230048021953,0.024239652412531443,0.027898467871026754,0.02835581980333867,0.029270523667962497,0.02995655156643037,0.030413903498742283,0.03384404299108164,0.03430139492339355,0.03544477475417333,0.03544477475417333,0.03796021038188886,0.03841756231420078,0.03841756231420078,0.039332266178824606,0.03978961811113652,0.04024697004344843,0.04070432197576035,0.04093299794191631,0.04139034987422822,0.041619025840384176,0.041619025840384176,0.046421221129659275,0.046878573061971185,0.04710724902812714,0.04756460096043906,0.049165332723530755,0.04962268465584267,0.05008003658815458,0.05008003658815458,0.05190944431740224,0.05236679624971415,0.05282414818202607,0.053281500114337986,0.05419620397896181,0.05465355591127372,0.05511090784358564,0.055568259775897556,0.05716899153898925,0.05716899153898925,0.06311456665904414,0.06357191859135605,0.06380059455751201,0.06425794648982391,0.06494397438829179,0.0654013263206037,0.06631603018522753,0.06677338211753944,0.06951749371141093,0.07043219757603476,0.07134690144065858,0.0718042533729705,0.07226160530528242,0.07294763320375029,0.0734049851360622,0.07363366110221815,0.07592042076377772,0.0766064486622456,0.07797850445918134,0.07866453235764921,0.07912188428996113,0.07957923622227304,0.08049394008689686,0.0814086439515207,0.085067459410016,0.08735421907157558,0.08781157100388749,0.08849759890235537,0.08895495083466727,0.08918362680082323,0.09261376629316259,0.09329979419163045,0.0962725817516579,0.09672993368396982,0.09718728561628173,0.09764463754859365,0.09993139721015322,0.10038874914246512,0.10130345300708896,0.10198948090555683,0.10244683283786873,0.10290418477018065,0.10359021266864853,0.10404756460096044,0.10541962039789618,0.10793505602561171,0.10930711182254745,0.10976446375485936,0.11022181568717128,0.11090784358563915,0.11136519551795106,0.11273725131488681,0.11319460324719872,0.11685341870569403,0.11891150240109764,0.11891150240109764,0.12028355819803338,0.12211296592728105,0.122341641893437,0.12279899382574891,0.12348502172421678,0.1239423736565287,0.1266864852504002,0.1271438371827121,0.12805854104733594,0.12805854104733594,0.12851589297964783,0.1287445689458038,0.12920192087811572,0.13171735650583125,0.13217470843814316,0.13377544020123486,0.13423279213354677,0.1346901440658587,0.13514749599817058,0.13880631145666592,0.13926366338897783,0.1399496912874457,0.1404070432197576,0.14109307111822547,0.14177909901669333,0.1420077749828493,0.143608506745941,0.1472673222044363,0.14909672993368397,0.1500114337983078,0.15092613766293161,0.15229819345986736,0.15435627715527098,0.15458495312142695,0.15504230505373887,0.15755774068145437,0.15961582437685798,0.1600731763091699,0.1605305282414818,0.16098788017379373,0.16144523210610565,0.1621312600045735,0.16418934369997712,0.16464669563228904,0.1664761033615367,0.16693345529384862,0.16716213126000457,0.16853418705694032,0.17219300251543562,0.17265035444774754,0.17470843814315115,0.17516579007546307,0.17653784587239882,0.17653784587239882,0.17676652183855476,0.17722387377086668,0.17951063343242626,0.17951063343242626,0.18431282872170135,0.18431282872170135,0.18522753258632518,0.18591356048479304,0.18637091241710496,0.1872856162817288,0.1877429682140407,0.18797164418019666,0.18842899611250857,0.1888863480448205,0.1893436999771324,0.19048707980791219,0.1909444317402241,0.19940544248799452,0.19986279442030644,0.20009147038646238,0.20100617425108622,0.20192087811571005,0.20237823004802194,0.2037502858449577,0.20466498970958152,0.20626572147267322,0.20695174937114108,0.20923850903270066,0.20992453693116853,0.21061056482963642,0.21106791676194833,0.21152526869426022,0.21198262062657214,0.21404070432197575,0.21472673222044364,0.21769951978047108,0.21815687171278297,0.2197576034758747,0.2202149554081866,0.2250171506974617,0.22547450262977362,0.2270752343928653,0.22776126229133317,0.22798993825748914,0.228675966155957,0.22959067002058084,0.23004802195289276,0.2302766979190487,0.23073404985136062,0.2323347816144523,0.2330208095129202,0.23324948547907615,0.23416418934369998,0.23530756917447976,0.23576492110679168,0.23690830093757145,0.23736565286988337,0.23759432883603934,0.23805168076835126,0.23919506059913104,0.23965241253144295,0.2398810884975989,0.2398810884975989,0.244683283786874,0.2451406357191859,0.25040018294077293,0.25131488680539676,0.2520009147038646,0.25245826663617654,0.25497370226389204,0.2558884061285159,0.2574891378916076,0.2579464898239195,0.2581751657900755,0.25908986965469927,0.2595472215870112,0.2600045735193231,0.26091927738394693,0.2613766293162589,0.2654927967070661,0.265950148639378,0.26617882460553394,0.2666361765378459,0.2696089640978733,0.27029499199634116,0.27486851131946033,0.2753258632517722,0.276469243082552,0.27692659501486394,0.2771552709810199,0.27761262291333183,0.2798993825748914,0.2808140864395152,0.28287217013491883,0.28355819803338667,0.2851589297964784,0.2856162817287903,0.28973244911959756,0.29018980105190945,0.2913331808826892,0.29179053281500117,0.2938486165104048,0.2945346444088726,0.2959067002058084,0.2963640521381203,0.3048250628858907,0.3052824148182026,0.30596844271667045,0.3064257946489824,0.3148868053967528,0.31534415732906473,0.31603018522753257,0.3164875371598445,0.3176309169906243,0.3180882689229362,0.31900297278756,0.31946032471987196,0.3212897324491196,0.3217470843814315,0.32197576034758746,0.3224331122798994,0.32403384404299107,0.324491195975303,0.3288360393322662,0.3292933912645781,0.32997941916304596,0.33043677109535785,0.3313514749599817,0.33180882689229363,0.33844042991081635,0.33958380974159613,0.33981248570775213,0.340269837640064,0.3425565973016236,0.3430139492339355,0.3436999771324034,0.3441573290647153,0.3469014406585868,0.34781614452321064,0.34850217242167847,0.3489595243539904,0.3494168762863023,0.34987422821861425,0.35033158015092614,0.350788932083238,0.3533043677109536,0.35376171964326547,0.35513377544020125,0.35559112737251314,0.356277155270981,0.3567345072032929,0.3585639149325406,0.35902126686485253,0.3592499428310085,0.35970729476332036,0.3622227303910359,0.3626800823233478,0.3633661102218157,0.3638234621541276,0.3690830093757146,0.3699977132403384,0.3702263892064944,0.3706837411388063,0.372513148868054,0.37297050080036587,0.37479990852961353,0.3752572604619255,0.38005945575120054,0.3807454836496684,0.38097415961582437,0.3814315115481363,0.38806311456665904,0.388520466498971,0.38874914246512693,0.3892064943974388,0.3905785501943746,0.3910359021266865,0.3919506059913103,0.3924079579236222,0.3930939858220901,0.393780013720558,0.3956094214498056,0.39606677338211754,0.3962954493482735,0.39675280128058543,0.39743882917905327,0.3978961811113652,0.40064029270523666,0.4015549965698605,0.4024697004344843,0.40292705236679627,0.4068145437914475,0.4077292476560713,0.4164189343699977,0.4168762863023096,0.4171049622684656,0.4180196661330894,0.4196203978961811,0.420306425794649,0.42122112965927283,0.4216784815915847,0.42213583352389666,0.42259318545620855,0.4239652412531443,0.42465126915161217,0.42533729705008005,0.42579464898239194,0.42716670477932767,0.4276240567116396,0.4280814086439515,0.42853876057626344,0.4287674365424194,0.4292247884747313,0.43105419620397895,0.4315115481362909,0.4328836039332266,0.43334095586553856,0.4335696318316945,0.4340269837640064,0.4356277155270981,0.43654241939172195,0.4372284472901898,0.4376857992225017,0.4392865309855934,0.43974388291790534,0.44248799451177684,0.4434026983764006,0.4440887262748685,0.44454607820718045,0.44751886576720784,0.4479762176995198,0.4511776812257032,0.4516350331580151,0.4525497370226389,0.45300708895495084,0.4539217928195747,0.45437914475188657,0.45506517265035445,0.45552252458266634,0.4591813400411617,0.45963869197347357,0.46032471987194146,0.46078207180425335,0.46238280356734507,0.462840155499657,0.46352618339812485,0.4639835353304368,0.4653555911273725,0.4660416190258404,0.46832837868739996,0.46878573061971185,0.46901440658586785,0.46947175851817974,0.4706151383489595,0.47107249028127146,0.4713011662474274,0.4717585181797393,0.4731305739766751,0.4738166018751429,0.4770180654013263,0.47747541733363824,0.48021952892750974,0.4811342327921335,0.48227761262291335,0.48273496455522524,0.4857077521152527,0.4861651040475646,0.4866224559798765,0.4870798079121884,0.4877658358106563,0.4882231877429682,0.4916533272353076,0.49211067916761947,0.49805625428767436,0.4985136062199863,0.4994283100846101,0.499885662016922,0.5017150697461696,0.5021724216784816,0.5030871255431054,0.5035444774754173,0.5037731534415733,0.5042305053738853,0.5049165332723531,0.5056025611708209,0.5058312371369769,0.5062885890692889,0.5065172650354448,0.5069746169677567,0.5074319689000686,0.5078893208323805,0.5085753487308484,0.5090327006631603,0.5110907843585639,0.5115481362908758,0.5206951749371141,0.521152526869426,0.5229819345986737,0.5234392865309856,0.5259547221587011,0.526869426023325,0.5314429453464441,0.531900297278756,0.5337297050080037,0.5341870569403155,0.5355591127372513,0.5360164646695632,0.5385319002972787,0.5392179281957467,0.5396752801280585,0.5399039560942145,0.5403613080265264,0.5412760118911503,0.5417333638234622,0.5440201234850217,0.5447061513834895,0.5451635033158015,0.5458495312142694,0.5481362908758289,0.5485936428081408,0.5522524582666362,0.552709810198948,0.5561399496912874,0.5565973016235993,0.5568259775897553,0.5572833295220673,0.5602561170820947,0.5607134690144066,0.5613994969128745,0.5618568488451864,0.5630002286759661,0.5634575806082781,0.5664303681683055,0.5668877201006174,0.5671163960667733,0.5675737479990853,0.5691744797621769,0.5696318316944889,0.5707752115252687,0.5712325634575806,0.5723759432883604,0.5730619711868282,0.5735193231191402,0.5753487308483878,0.5758060827806998,0.5803796021038189,0.5808369540361308,0.5810656300022867,0.5815229819345987,0.5842670935284702,0.5847244454607821,0.5854104733592499,0.5860965012577178,0.5870112051223416,0.5876972330208096,0.5881545849531215,0.5911273725131488,0.5920420763777727,0.5931854562085525,0.5941001600731763,0.5945575120054882,0.595700891836268,0.5986736793962955,0.5995883832609192,0.6000457351932312,0.6005030871255431,0.6018751429224789,0.6023324948547908,0.6027898467871027,0.6032471987194146,0.6034758746855705,0.6039332266178825,0.6041619025840385,0.6046192545163503,0.6055339583809741,0.606448662245598,0.6069060141779099,0.6071346901440658,0.6080493940086897,0.6094214498056254,0.6098788017379373,0.611708209467185,0.612165561399497,0.6123942373656529,0.6130802652641207,0.6142236450949006,0.6146809970272125,0.617196432654928,0.6176537845872399,0.6183398124857078,0.6187971644180197,0.6201692202149555,0.6206265721472674,0.6235993597072947,0.6242853876057627,0.6258861193688543,0.6268008232334782,0.6281728790304139,0.6286302309627259,0.6290875828950377,0.6293162588611937,0.6297736107935056,0.6302309627258175,0.6306883146581295,0.6311456665904414,0.6316030185227532,0.6318316944889092,0.6327463983535331,0.6338897781843128,0.6343471301166247,0.6345758060827807,0.6350331580150926,0.6359478618797164,0.6364052138120283,0.6373199176766522,0.63800594557512,0.638691973473588,0.6398353533043677,0.6407500571689916,0.6412074091013035,0.6416647610336154,0.6423507889320832,0.6432654927967071,0.6439515206951749,0.6462382803567345,0.6469243082552024,0.6512691516121656,0.6517265035444775,0.6572147267322205,0.6576720786645324,0.6583581065630002,0.6588154584953121,0.6601875142922479,0.6606448662245598,0.6624742739538074,0.6629316258861193,0.6636176537845873,0.6640750057168991,0.6661330894123028,0.6665904413446146,0.6675051452092385,0.6684198490738623,0.6697919048707981,0.6704779327692659,0.6711639606677339,0.6725360164646695,0.6846558426709353,0.6851131946032472,0.686027898467871,0.6864852504001829,0.6869426023324948,0.6876286302309628,0.6887720100617425,0.6892293619940544,0.6896867139263664,0.6903727418248342,0.6908300937571461,0.691058769723302,0.69174479762177,0.6928881774525497,0.6933455293848616,0.6963183169448891,0.6976903727418249,0.6992911045049165,0.6997484564372285,0.7011205122341642,0.701577864166476,0.702263892064944,0.7024925680310999,0.7029499199634118,0.7031785959295678,0.7036359478618797,0.7040932997941917,0.7045506517265036,0.7050080036588154,0.7054653555911273,0.7066087354219072,0.707294763320375,0.707752115252687,0.7082094671849989,0.7102675508804025,0.7107249028127144,0.7141550423050538,0.7150697461696776,0.7164418019666133,0.7171278298650812,0.717813857763549,0.718271209695861,0.7194145895266407,0.7201006174251087,0.7210153212897324,0.7219300251543562,0.7223873770866682,0.7228447290189801,0.723530756917448,0.7239881088497598,0.7244454607820718,0.7249028127143837,0.7251314886805397,0.7260461925451634,0.7267322204436314,0.7276469243082552,0.7281042762405671,0.7285616281728791,0.7299336839698147,0.7303910359021267,0.7315344157329065,0.7319917676652183,0.734049851360622,0.734507203292934,0.7356505831237137,0.7361079350560256,0.7367939629544935,0.7372513148868054,0.7377086668191173,0.7381660187514292,0.7434255659730162,0.7438829179053281,0.7459410016007317,0.7463983535330436,0.7482277612622913,0.7486851131946033,0.7521152526869426,0.7525726046192546,0.7564600960439057,0.7569174479762177,0.7573747999085296,0.7580608278069975,0.7582895037731534,0.7587468557054654,0.7644637548593642,0.7649211067916762,0.7667505145209238,0.7676652183855477,0.7692659501486394,0.7701806540132632,0.7724674136748227,0.7729247656071347,0.7761262291333181,0.77658358106563,0.7772696089640979,0.7779556368625657,0.7784129887948776,0.7816144523210611,0.7823004802195289,0.7843585639149325,0.7850445918134004,0.7857306197118683,0.7864166476103361,0.7909901669334553,0.7914475188657673,0.7930482506288589,0.7935056025611709,0.7992225017150697,0.7996798536473817,0.8017379373427853,0.8021952892750972,0.8024239652412531,0.802881317173565,0.8058541047335925,0.8065401326320604,0.8069974845643723,0.8074548364966841,0.8079121884289961,0.808369540361308,0.8090555682597759,0.8097415961582438,0.8111136519551795,0.8122570317859593,0.8129430596844271,0.813400411616739,0.813857763549051,0.8147724674136748,0.8156871712782987,0.8170592270752344,0.8177452549737023,0.8182026069060142,0.8195746627029499,0.8200320146352619,0.8230048021952893,0.8234621541276012,0.824376857992225,0.8248342099245369,0.8262062657214727,0.8266636176537846,0.8273496455522524,0.8282643494168763,0.8303224331122799,0.8310084610107478,0.8314658129430597,0.8321518408415276,0.8367253601646467,0.8374113880631145,0.8396981477246741,0.840384175623142,0.840612851589298,0.8412988794877658,0.8424422593185457,0.8428996112508576,0.845643722844729,0.8461010747770409,0.8495312142693803,0.8504459181340042,0.8513606219986279,0.8518179739309398,0.8541047335924994,0.8545620855248114,0.8579922250171507,0.8584495769494626,0.8591356048479305,0.8600503087125543,0.8625657443402699,0.8630230962725818,0.867367939629545,0.8678252915618568,0.8694260233249486,0.8701120512234164,0.8710267550880403,0.8714841070203522,0.872398810884976,0.872856162817288,0.8735421907157558,0.8739995426480677,0.8758289503773153,0.8762863023096272,0.8774296821404071,0.877887034072719,0.8783443860050308,0.8788017379373427,0.8815458495312143,0.8820032014635262,0.8847473130573976,0.8852046649897096,0.8890921564143609,0.8895495083466728,0.8902355362451406,0.8918362680082323,0.8932083238051681,0.9002972787560027,0.9007546306883146,0.9032700663160302,0.904184770180654,0.9055568259775898,0.9060141779099017,0.9062428538760576,0.9067002058083695,0.909672993368397,0.9105876972330208,0.9110450491653327,0.9117310770638006,0.9126457809284244,0.9133318088268922,0.9135604847930483,0.9144751886576721,0.9151612165561399,0.9156185684884519,0.9183626800823234,0.9190487079807912,0.9217928195746627,0.9224788474731306,0.9227075234392865,0.9231648753715984,0.9243082552023782,0.9247656071346901,0.9286530985593414,0.9291104504916533,0.936428081408644,0.9368854333409559,0.9387148410702035,0.9391721930025154,0.9405442487994512,0.9410016007317631,0.9439743882917905,0.9444317402241025,0.9453464440887263,0.9460324719871942,0.9528927509718729,0.9533501029041848,0.9540361308026526,0.9549508346672765,0.9567802423965241,0.957466270294992,0.9586096501257718,0.9592956780242397,0.9595243539903956,0.9599817059227075,0.9613537617196433,0.9618111136519552,0.9634118454150469,0.9638691973473588,0.9640978733135147,0.9650125771781386,0.9663846329750743,0.9668419849073863,0.9707294763320375,0.9711868282643494,0.9716441801966613,0.9721015321289732,0.9727875600274412,0.973244911959753,0.9803338669105877,0.9810198948090556,0.9812485707752115,0.9817059227075234,0.9828493025383033,0.9833066544706152,0.9844500343013949,0.9849073862337069,0.9881088497598902,0.9885662016922021,0.994283100846101,0.9947404527784129,1.0],\"y\":[0.0,0.0,0.22580645161290322,0.22580645161290322,0.25806451612903225,0.25806451612903225,0.2903225806451613,0.2903225806451613,0.3225806451612903,0.3225806451612903,0.3225806451612903,0.3225806451612903,0.3548387096774194,0.3548387096774194,0.3870967741935484,0.3870967741935484,0.3870967741935484,0.3870967741935484,0.4838709677419355,0.4838709677419355,0.4838709677419355,0.4838709677419355,0.5161290322580645,0.5161290322580645,0.5483870967741935,0.5483870967741935,0.6129032258064516,0.6129032258064516,0.6451612903225806,0.6451612903225806,0.6451612903225806,0.6451612903225806,0.6451612903225806,0.6451612903225806,0.6451612903225806,0.6451612903225806,0.6451612903225806,0.6451612903225806,0.6451612903225806,0.6451612903225806,0.6451612903225806,0.6451612903225806,0.6774193548387096,0.6774193548387096,0.6774193548387096,0.7096774193548387,0.7096774193548387,0.7096774193548387,0.7096774193548387,0.7096774193548387,0.7096774193548387,0.7096774193548387,0.7096774193548387,0.7419354838709677,0.7419354838709677,0.7419354838709677,0.7419354838709677,0.7419354838709677,0.7419354838709677,0.7419354838709677,0.7419354838709677,0.7741935483870968,0.7741935483870968,0.7741935483870968,0.7741935483870968,0.7741935483870968,0.7741935483870968,0.7741935483870968,0.7741935483870968,0.7741935483870968,0.7741935483870968,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8387096774193549,0.8387096774193549,0.8387096774193549,0.8387096774193549,0.8387096774193549,0.8387096774193549,0.8387096774193549,0.8387096774193549,0.8387096774193549,0.8387096774193549,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.9032258064516129,0.9032258064516129,0.9032258064516129,0.9032258064516129,0.9354838709677419,0.9354838709677419,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"type\":\"scatter\"},{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(255, 255, 255, 0)\",\"width\":0},\"name\":\"(95% CI: 0.9037-1.0000)\",\"showlegend\":true,\"x\":[0.0,0.000228675966155957,0.000228675966155957,0.000914703864623828,0.000914703864623828,0.001829407729247656,0.001829407729247656,0.004116167390807226,0.004116167390807226,0.005030871255431054,0.005488223187742968,0.00846101074777041,0.00846101074777041,0.008689686713926366,0.008689686713926366,0.009375714612394238,0.010290418477018065,0.010519094443174023,0.010519094443174023,0.01372055796935742,0.014177909901669335,0.015778641664761034,0.015778641664761034,0.018522753258632518,0.018522753258632518,0.019666133089412303,0.019666133089412303,0.01989480905556826,0.01989480905556826,0.020352160987880175,0.020809512920192088,0.021266864852504,0.02378230048021953,0.024239652412531443,0.027898467871026754,0.02835581980333867,0.029270523667962497,0.02995655156643037,0.030413903498742283,0.03384404299108164,0.03430139492339355,0.03544477475417333,0.03544477475417333,0.03796021038188886,0.03841756231420078,0.03841756231420078,0.039332266178824606,0.03978961811113652,0.04024697004344843,0.04070432197576035,0.04093299794191631,0.04139034987422822,0.041619025840384176,0.041619025840384176,0.046421221129659275,0.046878573061971185,0.04710724902812714,0.04756460096043906,0.049165332723530755,0.04962268465584267,0.05008003658815458,0.05008003658815458,0.05190944431740224,0.05236679624971415,0.05282414818202607,0.053281500114337986,0.05419620397896181,0.05465355591127372,0.05511090784358564,0.055568259775897556,0.05716899153898925,0.05716899153898925,0.06311456665904414,0.06357191859135605,0.06380059455751201,0.06425794648982391,0.06494397438829179,0.0654013263206037,0.06631603018522753,0.06677338211753944,0.06951749371141093,0.07043219757603476,0.07134690144065858,0.0718042533729705,0.07226160530528242,0.07294763320375029,0.0734049851360622,0.07363366110221815,0.07592042076377772,0.0766064486622456,0.07797850445918134,0.07866453235764921,0.07912188428996113,0.07957923622227304,0.08049394008689686,0.0814086439515207,0.085067459410016,0.08735421907157558,0.08781157100388749,0.08849759890235537,0.08895495083466727,0.08918362680082323,0.09261376629316259,0.09329979419163045,0.0962725817516579,0.09672993368396982,0.09718728561628173,0.09764463754859365,0.09993139721015322,0.10038874914246512,0.10130345300708896,0.10198948090555683,0.10244683283786873,0.10290418477018065,0.10359021266864853,0.10404756460096044,0.10541962039789618,0.10793505602561171,0.10930711182254745,0.10976446375485936,0.11022181568717128,0.11090784358563915,0.11136519551795106,0.11273725131488681,0.11319460324719872,0.11685341870569403,0.11891150240109764,0.11891150240109764,0.12028355819803338,0.12211296592728105,0.122341641893437,0.12279899382574891,0.12348502172421678,0.1239423736565287,0.1266864852504002,0.1271438371827121,0.12805854104733594,0.12805854104733594,0.12851589297964783,0.1287445689458038,0.12920192087811572,0.13171735650583125,0.13217470843814316,0.13377544020123486,0.13423279213354677,0.1346901440658587,0.13514749599817058,0.13880631145666592,0.13926366338897783,0.1399496912874457,0.1404070432197576,0.14109307111822547,0.14177909901669333,0.1420077749828493,0.143608506745941,0.1472673222044363,0.14909672993368397,0.1500114337983078,0.15092613766293161,0.15229819345986736,0.15435627715527098,0.15458495312142695,0.15504230505373887,0.15755774068145437,0.15961582437685798,0.1600731763091699,0.1605305282414818,0.16098788017379373,0.16144523210610565,0.1621312600045735,0.16418934369997712,0.16464669563228904,0.1664761033615367,0.16693345529384862,0.16716213126000457,0.16853418705694032,0.17219300251543562,0.17265035444774754,0.17470843814315115,0.17516579007546307,0.17653784587239882,0.17653784587239882,0.17676652183855476,0.17722387377086668,0.17951063343242626,0.17951063343242626,0.18431282872170135,0.18431282872170135,0.18522753258632518,0.18591356048479304,0.18637091241710496,0.1872856162817288,0.1877429682140407,0.18797164418019666,0.18842899611250857,0.1888863480448205,0.1893436999771324,0.19048707980791219,0.1909444317402241,0.19940544248799452,0.19986279442030644,0.20009147038646238,0.20100617425108622,0.20192087811571005,0.20237823004802194,0.2037502858449577,0.20466498970958152,0.20626572147267322,0.20695174937114108,0.20923850903270066,0.20992453693116853,0.21061056482963642,0.21106791676194833,0.21152526869426022,0.21198262062657214,0.21404070432197575,0.21472673222044364,0.21769951978047108,0.21815687171278297,0.2197576034758747,0.2202149554081866,0.2250171506974617,0.22547450262977362,0.2270752343928653,0.22776126229133317,0.22798993825748914,0.228675966155957,0.22959067002058084,0.23004802195289276,0.2302766979190487,0.23073404985136062,0.2323347816144523,0.2330208095129202,0.23324948547907615,0.23416418934369998,0.23530756917447976,0.23576492110679168,0.23690830093757145,0.23736565286988337,0.23759432883603934,0.23805168076835126,0.23919506059913104,0.23965241253144295,0.2398810884975989,0.2398810884975989,0.244683283786874,0.2451406357191859,0.25040018294077293,0.25131488680539676,0.2520009147038646,0.25245826663617654,0.25497370226389204,0.2558884061285159,0.2574891378916076,0.2579464898239195,0.2581751657900755,0.25908986965469927,0.2595472215870112,0.2600045735193231,0.26091927738394693,0.2613766293162589,0.2654927967070661,0.265950148639378,0.26617882460553394,0.2666361765378459,0.2696089640978733,0.27029499199634116,0.27486851131946033,0.2753258632517722,0.276469243082552,0.27692659501486394,0.2771552709810199,0.27761262291333183,0.2798993825748914,0.2808140864395152,0.28287217013491883,0.28355819803338667,0.2851589297964784,0.2856162817287903,0.28973244911959756,0.29018980105190945,0.2913331808826892,0.29179053281500117,0.2938486165104048,0.2945346444088726,0.2959067002058084,0.2963640521381203,0.3048250628858907,0.3052824148182026,0.30596844271667045,0.3064257946489824,0.3148868053967528,0.31534415732906473,0.31603018522753257,0.3164875371598445,0.3176309169906243,0.3180882689229362,0.31900297278756,0.31946032471987196,0.3212897324491196,0.3217470843814315,0.32197576034758746,0.3224331122798994,0.32403384404299107,0.324491195975303,0.3288360393322662,0.3292933912645781,0.32997941916304596,0.33043677109535785,0.3313514749599817,0.33180882689229363,0.33844042991081635,0.33958380974159613,0.33981248570775213,0.340269837640064,0.3425565973016236,0.3430139492339355,0.3436999771324034,0.3441573290647153,0.3469014406585868,0.34781614452321064,0.34850217242167847,0.3489595243539904,0.3494168762863023,0.34987422821861425,0.35033158015092614,0.350788932083238,0.3533043677109536,0.35376171964326547,0.35513377544020125,0.35559112737251314,0.356277155270981,0.3567345072032929,0.3585639149325406,0.35902126686485253,0.3592499428310085,0.35970729476332036,0.3622227303910359,0.3626800823233478,0.3633661102218157,0.3638234621541276,0.3690830093757146,0.3699977132403384,0.3702263892064944,0.3706837411388063,0.372513148868054,0.37297050080036587,0.37479990852961353,0.3752572604619255,0.38005945575120054,0.3807454836496684,0.38097415961582437,0.3814315115481363,0.38806311456665904,0.388520466498971,0.38874914246512693,0.3892064943974388,0.3905785501943746,0.3910359021266865,0.3919506059913103,0.3924079579236222,0.3930939858220901,0.393780013720558,0.3956094214498056,0.39606677338211754,0.3962954493482735,0.39675280128058543,0.39743882917905327,0.3978961811113652,0.40064029270523666,0.4015549965698605,0.4024697004344843,0.40292705236679627,0.4068145437914475,0.4077292476560713,0.4164189343699977,0.4168762863023096,0.4171049622684656,0.4180196661330894,0.4196203978961811,0.420306425794649,0.42122112965927283,0.4216784815915847,0.42213583352389666,0.42259318545620855,0.4239652412531443,0.42465126915161217,0.42533729705008005,0.42579464898239194,0.42716670477932767,0.4276240567116396,0.4280814086439515,0.42853876057626344,0.4287674365424194,0.4292247884747313,0.43105419620397895,0.4315115481362909,0.4328836039332266,0.43334095586553856,0.4335696318316945,0.4340269837640064,0.4356277155270981,0.43654241939172195,0.4372284472901898,0.4376857992225017,0.4392865309855934,0.43974388291790534,0.44248799451177684,0.4434026983764006,0.4440887262748685,0.44454607820718045,0.44751886576720784,0.4479762176995198,0.4511776812257032,0.4516350331580151,0.4525497370226389,0.45300708895495084,0.4539217928195747,0.45437914475188657,0.45506517265035445,0.45552252458266634,0.4591813400411617,0.45963869197347357,0.46032471987194146,0.46078207180425335,0.46238280356734507,0.462840155499657,0.46352618339812485,0.4639835353304368,0.4653555911273725,0.4660416190258404,0.46832837868739996,0.46878573061971185,0.46901440658586785,0.46947175851817974,0.4706151383489595,0.47107249028127146,0.4713011662474274,0.4717585181797393,0.4731305739766751,0.4738166018751429,0.4770180654013263,0.47747541733363824,0.48021952892750974,0.4811342327921335,0.48227761262291335,0.48273496455522524,0.4857077521152527,0.4861651040475646,0.4866224559798765,0.4870798079121884,0.4877658358106563,0.4882231877429682,0.4916533272353076,0.49211067916761947,0.49805625428767436,0.4985136062199863,0.4994283100846101,0.499885662016922,0.5017150697461696,0.5021724216784816,0.5030871255431054,0.5035444774754173,0.5037731534415733,0.5042305053738853,0.5049165332723531,0.5056025611708209,0.5058312371369769,0.5062885890692889,0.5065172650354448,0.5069746169677567,0.5074319689000686,0.5078893208323805,0.5085753487308484,0.5090327006631603,0.5110907843585639,0.5115481362908758,0.5206951749371141,0.521152526869426,0.5229819345986737,0.5234392865309856,0.5259547221587011,0.526869426023325,0.5314429453464441,0.531900297278756,0.5337297050080037,0.5341870569403155,0.5355591127372513,0.5360164646695632,0.5385319002972787,0.5392179281957467,0.5396752801280585,0.5399039560942145,0.5403613080265264,0.5412760118911503,0.5417333638234622,0.5440201234850217,0.5447061513834895,0.5451635033158015,0.5458495312142694,0.5481362908758289,0.5485936428081408,0.5522524582666362,0.552709810198948,0.5561399496912874,0.5565973016235993,0.5568259775897553,0.5572833295220673,0.5602561170820947,0.5607134690144066,0.5613994969128745,0.5618568488451864,0.5630002286759661,0.5634575806082781,0.5664303681683055,0.5668877201006174,0.5671163960667733,0.5675737479990853,0.5691744797621769,0.5696318316944889,0.5707752115252687,0.5712325634575806,0.5723759432883604,0.5730619711868282,0.5735193231191402,0.5753487308483878,0.5758060827806998,0.5803796021038189,0.5808369540361308,0.5810656300022867,0.5815229819345987,0.5842670935284702,0.5847244454607821,0.5854104733592499,0.5860965012577178,0.5870112051223416,0.5876972330208096,0.5881545849531215,0.5911273725131488,0.5920420763777727,0.5931854562085525,0.5941001600731763,0.5945575120054882,0.595700891836268,0.5986736793962955,0.5995883832609192,0.6000457351932312,0.6005030871255431,0.6018751429224789,0.6023324948547908,0.6027898467871027,0.6032471987194146,0.6034758746855705,0.6039332266178825,0.6041619025840385,0.6046192545163503,0.6055339583809741,0.606448662245598,0.6069060141779099,0.6071346901440658,0.6080493940086897,0.6094214498056254,0.6098788017379373,0.611708209467185,0.612165561399497,0.6123942373656529,0.6130802652641207,0.6142236450949006,0.6146809970272125,0.617196432654928,0.6176537845872399,0.6183398124857078,0.6187971644180197,0.6201692202149555,0.6206265721472674,0.6235993597072947,0.6242853876057627,0.6258861193688543,0.6268008232334782,0.6281728790304139,0.6286302309627259,0.6290875828950377,0.6293162588611937,0.6297736107935056,0.6302309627258175,0.6306883146581295,0.6311456665904414,0.6316030185227532,0.6318316944889092,0.6327463983535331,0.6338897781843128,0.6343471301166247,0.6345758060827807,0.6350331580150926,0.6359478618797164,0.6364052138120283,0.6373199176766522,0.63800594557512,0.638691973473588,0.6398353533043677,0.6407500571689916,0.6412074091013035,0.6416647610336154,0.6423507889320832,0.6432654927967071,0.6439515206951749,0.6462382803567345,0.6469243082552024,0.6512691516121656,0.6517265035444775,0.6572147267322205,0.6576720786645324,0.6583581065630002,0.6588154584953121,0.6601875142922479,0.6606448662245598,0.6624742739538074,0.6629316258861193,0.6636176537845873,0.6640750057168991,0.6661330894123028,0.6665904413446146,0.6675051452092385,0.6684198490738623,0.6697919048707981,0.6704779327692659,0.6711639606677339,0.6725360164646695,0.6846558426709353,0.6851131946032472,0.686027898467871,0.6864852504001829,0.6869426023324948,0.6876286302309628,0.6887720100617425,0.6892293619940544,0.6896867139263664,0.6903727418248342,0.6908300937571461,0.691058769723302,0.69174479762177,0.6928881774525497,0.6933455293848616,0.6963183169448891,0.6976903727418249,0.6992911045049165,0.6997484564372285,0.7011205122341642,0.701577864166476,0.702263892064944,0.7024925680310999,0.7029499199634118,0.7031785959295678,0.7036359478618797,0.7040932997941917,0.7045506517265036,0.7050080036588154,0.7054653555911273,0.7066087354219072,0.707294763320375,0.707752115252687,0.7082094671849989,0.7102675508804025,0.7107249028127144,0.7141550423050538,0.7150697461696776,0.7164418019666133,0.7171278298650812,0.717813857763549,0.718271209695861,0.7194145895266407,0.7201006174251087,0.7210153212897324,0.7219300251543562,0.7223873770866682,0.7228447290189801,0.723530756917448,0.7239881088497598,0.7244454607820718,0.7249028127143837,0.7251314886805397,0.7260461925451634,0.7267322204436314,0.7276469243082552,0.7281042762405671,0.7285616281728791,0.7299336839698147,0.7303910359021267,0.7315344157329065,0.7319917676652183,0.734049851360622,0.734507203292934,0.7356505831237137,0.7361079350560256,0.7367939629544935,0.7372513148868054,0.7377086668191173,0.7381660187514292,0.7434255659730162,0.7438829179053281,0.7459410016007317,0.7463983535330436,0.7482277612622913,0.7486851131946033,0.7521152526869426,0.7525726046192546,0.7564600960439057,0.7569174479762177,0.7573747999085296,0.7580608278069975,0.7582895037731534,0.7587468557054654,0.7644637548593642,0.7649211067916762,0.7667505145209238,0.7676652183855477,0.7692659501486394,0.7701806540132632,0.7724674136748227,0.7729247656071347,0.7761262291333181,0.77658358106563,0.7772696089640979,0.7779556368625657,0.7784129887948776,0.7816144523210611,0.7823004802195289,0.7843585639149325,0.7850445918134004,0.7857306197118683,0.7864166476103361,0.7909901669334553,0.7914475188657673,0.7930482506288589,0.7935056025611709,0.7992225017150697,0.7996798536473817,0.8017379373427853,0.8021952892750972,0.8024239652412531,0.802881317173565,0.8058541047335925,0.8065401326320604,0.8069974845643723,0.8074548364966841,0.8079121884289961,0.808369540361308,0.8090555682597759,0.8097415961582438,0.8111136519551795,0.8122570317859593,0.8129430596844271,0.813400411616739,0.813857763549051,0.8147724674136748,0.8156871712782987,0.8170592270752344,0.8177452549737023,0.8182026069060142,0.8195746627029499,0.8200320146352619,0.8230048021952893,0.8234621541276012,0.824376857992225,0.8248342099245369,0.8262062657214727,0.8266636176537846,0.8273496455522524,0.8282643494168763,0.8303224331122799,0.8310084610107478,0.8314658129430597,0.8321518408415276,0.8367253601646467,0.8374113880631145,0.8396981477246741,0.840384175623142,0.840612851589298,0.8412988794877658,0.8424422593185457,0.8428996112508576,0.845643722844729,0.8461010747770409,0.8495312142693803,0.8504459181340042,0.8513606219986279,0.8518179739309398,0.8541047335924994,0.8545620855248114,0.8579922250171507,0.8584495769494626,0.8591356048479305,0.8600503087125543,0.8625657443402699,0.8630230962725818,0.867367939629545,0.8678252915618568,0.8694260233249486,0.8701120512234164,0.8710267550880403,0.8714841070203522,0.872398810884976,0.872856162817288,0.8735421907157558,0.8739995426480677,0.8758289503773153,0.8762863023096272,0.8774296821404071,0.877887034072719,0.8783443860050308,0.8788017379373427,0.8815458495312143,0.8820032014635262,0.8847473130573976,0.8852046649897096,0.8890921564143609,0.8895495083466728,0.8902355362451406,0.8918362680082323,0.8932083238051681,0.9002972787560027,0.9007546306883146,0.9032700663160302,0.904184770180654,0.9055568259775898,0.9060141779099017,0.9062428538760576,0.9067002058083695,0.909672993368397,0.9105876972330208,0.9110450491653327,0.9117310770638006,0.9126457809284244,0.9133318088268922,0.9135604847930483,0.9144751886576721,0.9151612165561399,0.9156185684884519,0.9183626800823234,0.9190487079807912,0.9217928195746627,0.9224788474731306,0.9227075234392865,0.9231648753715984,0.9243082552023782,0.9247656071346901,0.9286530985593414,0.9291104504916533,0.936428081408644,0.9368854333409559,0.9387148410702035,0.9391721930025154,0.9405442487994512,0.9410016007317631,0.9439743882917905,0.9444317402241025,0.9453464440887263,0.9460324719871942,0.9528927509718729,0.9533501029041848,0.9540361308026526,0.9549508346672765,0.9567802423965241,0.957466270294992,0.9586096501257718,0.9592956780242397,0.9595243539903956,0.9599817059227075,0.9613537617196433,0.9618111136519552,0.9634118454150469,0.9638691973473588,0.9640978733135147,0.9650125771781386,0.9663846329750743,0.9668419849073863,0.9707294763320375,0.9711868282643494,0.9716441801966613,0.9721015321289732,0.9727875600274412,0.973244911959753,0.9803338669105877,0.9810198948090556,0.9812485707752115,0.9817059227075234,0.9828493025383033,0.9833066544706152,0.9844500343013949,0.9849073862337069,0.9881088497598902,0.9885662016922021,0.994283100846101,0.9947404527784129,1.0],\"y\":[0.0,0.0,0.22580645161290322,0.22580645161290322,0.25806451612903225,0.25806451612903225,0.2903225806451613,0.2903225806451613,0.3225806451612903,0.3225806451612903,0.3225806451612903,0.3225806451612903,0.3548387096774194,0.3548387096774194,0.3870967741935484,0.3870967741935484,0.3870967741935484,0.3870967741935484,0.4838709677419355,0.4838709677419355,0.4838709677419355,0.4838709677419355,0.5161290322580645,0.5161290322580645,0.5483870967741935,0.5483870967741935,0.6129032258064516,0.6129032258064516,0.6451612903225806,0.6451612903225806,0.6451612903225806,0.6451612903225806,0.6451612903225806,0.6451612903225806,0.6451612903225806,0.6451612903225806,0.6451612903225806,0.6451612903225806,0.6451612903225806,0.6451612903225806,0.6451612903225806,0.6451612903225806,0.6774193548387096,0.6774193548387096,0.6774193548387096,0.7096774193548387,0.7096774193548387,0.7096774193548387,0.7096774193548387,0.7096774193548387,0.7096774193548387,0.7096774193548387,0.7096774193548387,0.7419354838709677,0.7419354838709677,0.7419354838709677,0.7419354838709677,0.7419354838709677,0.7419354838709677,0.7419354838709677,0.7419354838709677,0.7741935483870968,0.7741935483870968,0.7741935483870968,0.7741935483870968,0.7741935483870968,0.7741935483870968,0.7741935483870968,0.7741935483870968,0.7741935483870968,0.7741935483870968,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8064516129032258,0.8387096774193549,0.8387096774193549,0.8387096774193549,0.8387096774193549,0.8387096774193549,0.8387096774193549,0.8387096774193549,0.8387096774193549,0.8387096774193549,0.8387096774193549,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.8709677419354839,0.9032258064516129,0.9032258064516129,0.9032258064516129,0.9032258064516129,0.9354838709677419,0.9354838709677419,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,0.967741935483871,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"title\":{\"x\":1},\"legend\":{\"yanchor\":\"bottom\",\"xanchor\":\"right\",\"x\":0.95,\"y\":0.01},\"xaxis\":{\"title\":{\"text\":\"\\u003cb\\u003e1-Specificity\\u003c\\u002fb\\u003e\"},\"range\":[0,1],\"gridcolor\":\"rgba(5, 5, 5, 0.5)\",\"constrain\":\"domain\",\"linecolor\":\"black\"},\"yaxis\":{\"title\":{\"text\":\"\\u003cb\\u003eRecall\\u003c\\u002fb\\u003e\"},\"range\":[0,1],\"gridcolor\":\"rgba(5, 5, 5, 0.5)\",\"scaleanchor\":\"x\",\"scaleratio\":1,\"linecolor\":\"black\"},\"width\":600,\"height\":600,\"font\":{\"family\":\"Times New Roman\",\"size\":22,\"color\":\"Black\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1f5d6426-73eb-4871-aab9-87d3c2623607');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "income=test.drop(X_test[X_test['INCOME_1 - Less than $20,000'] == 0].index)\n",
        "#elsee=elsee.sample(95, random_state=25)\n",
        "income_predictors=income.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "income_target=income['UDPYOPI_1 - Yes']\n",
        "elsee=test.drop(X_test[X_test['INCOME_1 - Less than $20,000'] == 1].index)\n",
        "#pop=pop.sample(95, random_state=25)\n",
        "elsee_predictors=elsee.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "elsee_target=elsee['UDPYOPI_1 - Yes']\n",
        "income_prob=network.predict(income_predictors)\n",
        "elsee_prob=network.predict(elsee_predictors)\n",
        "plot_roc_curve2(income_target, income_prob, elsee_target, elsee_prob, 'Income less than $20,000', 'Other')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "c1d85496",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1d85496",
        "outputId": "40b490ff-600a-47ff-8add-d73d09e64b5a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TtestResult(statistic=44.56252994101343, pvalue=9.087225718005544e-240, df=1000)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "# income less than 20 vs. others\n",
        "df=[]\n",
        "for i in range_with_floats(0.0, 100.0, 0.1):\n",
        "        y_pred_income = (income_prob >= i*0.01).astype(bool)\n",
        "        cm_g1 = confusion_matrix(income_target, y_pred_income)\n",
        "        specificity_g1 = cm_g1[0,0]/(cm_g1[0,0]+cm_g1[0,1])\n",
        "        sensitivity_g1 = cm_g1[1,1]/(cm_g1[1,0]+cm_g1[1,1])\n",
        "\n",
        "        y_pred_elsee = (elsee_prob >= i*0.01).astype(bool)\n",
        "        cm_g2 = confusion_matrix(elsee_target, y_pred_elsee)\n",
        "        specificity_g2 = cm_g2[0,0]/(cm_g2[0,0]+cm_g2[0,1])\n",
        "        sensitivity_g2 = cm_g2[1,1]/(cm_g2[1,0]+cm_g2[1,1])\n",
        "\n",
        "        difference=abs(specificity_g1-specificity_g2)+abs(sensitivity_g1-sensitivity_g2)\n",
        "\n",
        "        df.append({'difference':difference, 'threshold':i})\n",
        "\n",
        "df = pd.DataFrame(df)\n",
        "diff=np.array(df['difference'])\n",
        "\n",
        "stats.ttest_1samp(diff, popmean=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "d0df9ea4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0df9ea4",
        "outputId": "8609fcfa-780d-4579-b88e-0ab203641b6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.9764545040255203 sensitivity: 0.5121951219512195 accuracy_g1: 0.9674162459843965 accuracy_g2: 0.9809264305177112 specificity_g1: 0.9695712309820194 specificity_g2: 0.9842213583352389 sensitivity_g1: 0.5 sensitivity_g2: 0.5161290322580645 difference: 0.03077915961128408 threshold: 52.60000000000048\n",
            "accuracy: 0.9746316269178186 sensitivity: 0.5121951219512195 accuracy_g1: 0.963285910968334 accuracy_g2: 0.9802452316076294 specificity_g1: 0.9654218533886584 specificity_g2: 0.9835353304367711 sensitivity_g1: 0.5 sensitivity_g2: 0.5161290322580645 difference: 0.03424250930617723 threshold: 50.0\n"
          ]
        }
      ],
      "source": [
        "# income less than 20 vs. others\n",
        "\n",
        "df=[]\n",
        "\n",
        "\n",
        "for i in range_with_floats(0.0, 100.0, 0.1):\n",
        "    y_pred = (prob >= i*0.01).astype(bool)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    acc=(cm[0,0]+cm[1,1])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])\n",
        "    sen=cm[1,1]/(cm[1,0]+cm[1,1])\n",
        "    if sen>=0.5 and  acc>=0.5:\n",
        "        y_pred_income = (income_prob >= i*0.01).astype(bool)\n",
        "        cm_g1 = confusion_matrix(income_target, y_pred_income)\n",
        "        specificity_g1 = cm_g1[0,0]/(cm_g1[0,0]+cm_g1[0,1])\n",
        "        sensitivity_g1 = cm_g1[1,1]/(cm_g1[1,0]+cm_g1[1,1])\n",
        "        accuracy_g1=(cm_g1[0,0]+cm_g1[1,1])/(cm_g1[0,0]+cm_g1[0,1]+cm_g1[1,0]+cm_g1[1,1])\n",
        "        y_pred_elsee = (elsee_prob >= i*0.01).astype(bool)\n",
        "        cm_g2 = confusion_matrix(elsee_target, y_pred_elsee)\n",
        "        specificity_g2 = cm_g2[0,0]/(cm_g2[0,0]+cm_g2[0,1])\n",
        "        sensitivity_g2 = cm_g2[1,1]/(cm_g2[1,0]+cm_g2[1,1])\n",
        "        accuracy_g2=(cm_g2[0,0]+cm_g2[1,1])/(cm_g2[0,0]+cm_g2[0,1]+cm_g2[1,0]+cm_g2[1,1])\n",
        "        difference=abs(specificity_g1-specificity_g2)+abs(sensitivity_g1-sensitivity_g2)\n",
        "\n",
        "        df.append({'accuracy':acc, 'sensitivity':sen, 'accuracy_g1':accuracy_g1, 'accuracy_g2':accuracy_g2, 'specificity_g1':specificity_g1, 'specificity_g2':specificity_g2,'sensitivity_g1':sensitivity_g1,'sensitivity_g2':sensitivity_g2, 'difference':difference, 'threshold':i})\n",
        "\n",
        "df = pd.DataFrame(df)\n",
        "min_diff = df.iloc[df['difference'].idxmin()]\n",
        "print('accuracy:', min_diff[0], 'sensitivity:', min_diff[1], 'accuracy_g1:', min_diff[2], 'accuracy_g2:', min_diff[3], 'specificity_g1:', min_diff[4], 'specificity_g2:', min_diff[5], 'sensitivity_g1:', min_diff[6], 'sensitivity_g2:', min_diff[7], 'difference:', min_diff[8], 'threshold:', min_diff[9])\n",
        "\n",
        "y_pred = (prob >= 50*0.01).astype(bool)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "acc=(cm[0,0]+cm[1,1])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])\n",
        "sen=cm[1,1]/(cm[1,0]+cm[1,1])\n",
        "\n",
        "y_pred_income = (income_prob >= 50*0.01).astype(bool)\n",
        "cm_g1 = confusion_matrix(income_target, y_pred_income)\n",
        "specificity_g1 = cm_g1[0,0]/(cm_g1[0,0]+cm_g1[0,1])\n",
        "sensitivity_g1 = cm_g1[1,1]/(cm_g1[1,0]+cm_g1[1,1])\n",
        "accuracy_g1=(cm_g1[0,0]+cm_g1[1,1])/(cm_g1[0,0]+cm_g1[0,1]+cm_g1[1,0]+cm_g1[1,1])\n",
        "\n",
        "y_pred_elsee = (elsee_prob >= 50*0.01).astype(bool)\n",
        "cm_g2 = confusion_matrix(elsee_target, y_pred_elsee)\n",
        "specificity_g2 = cm_g2[0,0]/(cm_g2[0,0]+cm_g2[0,1])\n",
        "sensitivity_g2 = cm_g2[1,1]/(cm_g2[1,0]+cm_g2[1,1])\n",
        "accuracy_g2=(cm_g2[0,0]+cm_g2[1,1])/(cm_g2[0,0]+cm_g2[0,1]+cm_g2[1,0]+cm_g2[1,1])\n",
        "difference=abs(specificity_g1-specificity_g2)+abs(sensitivity_g1-sensitivity_g2)\n",
        "\n",
        "print('accuracy:', acc, 'sensitivity:', sen, 'accuracy_g1:', accuracy_g1, 'accuracy_g2:', accuracy_g2, 'specificity_g1:', specificity_g1, 'specificity_g2:', specificity_g2, 'sensitivity_g1:', sensitivity_g1, 'sensitivity_g2:', sensitivity_g2, 'difference:', difference, 'threshold:', 50.0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "male1_test=test.drop(X_test[X_test['IRSEX_1 - Male'] == 0].index)\n",
        "female1_test=test.drop(X_test[X_test['IRSEX_1 - Male'] == 1].index)\n"
      ],
      "metadata": {
        "id": "U5-wzV5ntxsp"
      },
      "id": "U5-wzV5ntxsp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(male1_test))\n",
        "print(len(female1_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07lqPS-9tlxd",
        "outputId": "df17c603-3c7c-47a0-8c03-3c5c62115ecd"
      },
      "id": "07lqPS-9tlxd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3356\n",
            "3227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(male1))\n",
        "print(len(female1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "padwZMTWuSVf",
        "outputId": "ce8ddc72-08f9-46ff-da04-52a2e415ac9c"
      },
      "id": "padwZMTWuSVf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3356\n",
            "3227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g4BLswuxucQU"
      },
      "id": "g4BLswuxucQU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8961b176",
      "metadata": {
        "id": "8961b176"
      },
      "outputs": [],
      "source": [
        "train=pd.concat([X_train, y_train], axis=1)\n",
        "test=pd.concat([X_test, y_test], axis=1)\n",
        "female1=train.drop(X_train[X_train['IRSEX_1 - Male'] == 1].index)\n",
        "male1=train.drop(X_train[X_train['IRSEX_1 - Male'] == 0].index)\n",
        "male1_test=test.drop(X_test[X_test['IRSEX_1 - Male'] == 0].index)\n",
        "male1_test=male1_test.sample(3227, random_state=43)\n",
        "male_predictors_test=male1_test.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "male_target_test=male1_test['UDPYOPI_1 - Yes']\n",
        "female1_test=test.drop(X_test[X_test['IRSEX_1 - Male'] == 1].index)\n",
        "female1_test=female1_test.sample(3227, random_state=43)\n",
        "female_predictors_test=female1_test.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "female_target_test=female1_test['UDPYOPI_1 - Yes']\n",
        "data_test=pd.concat([male1_test, female1_test])\n",
        "X_for_test=data_test.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "y_for_test=data_test['UDPYOPI_1 - Yes']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0UHHJhXuqUEG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0UHHJhXuqUEG",
        "outputId": "f7c3b9db-340b-4d57-fc65-0c6abe338c7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "201/203 [============================>.] - ETA: 0s - loss: 0.8331 - accuracy: 0.4819\n",
            "Epoch 1: val_accuracy improved from -inf to 0.98280, saving model to model_50_gender.h5\n",
            "203/203 [==============================] - 6s 24ms/step - loss: 0.8301 - accuracy: 0.4818 - val_loss: 0.5174 - val_accuracy: 0.9828\n",
            "Epoch 2/20\n",
            "201/203 [============================>.] - ETA: 0s - loss: 0.6682 - accuracy: 0.6043\n",
            "Epoch 2: val_accuracy improved from 0.98280 to 0.99101, saving model to model_50_gender.h5\n",
            "203/203 [==============================] - 4s 17ms/step - loss: 0.6656 - accuracy: 0.6068 - val_loss: 0.4278 - val_accuracy: 0.9910\n",
            "Epoch 3/20\n",
            "199/203 [============================>.] - ETA: 0s - loss: 0.6713 - accuracy: 0.5919\n",
            "Epoch 3: val_accuracy did not improve from 0.99101\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.6647 - accuracy: 0.5983 - val_loss: 0.4277 - val_accuracy: 0.9904\n",
            "Epoch 4/20\n",
            "203/203 [==============================] - ETA: 0s - loss: 0.6416 - accuracy: 0.6539\n",
            "Epoch 4: val_accuracy did not improve from 0.99101\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.6416 - accuracy: 0.6539 - val_loss: 0.7518 - val_accuracy: 0.3068\n",
            "Epoch 5/20\n",
            "201/203 [============================>.] - ETA: 0s - loss: 0.6363 - accuracy: 0.6025\n",
            "Epoch 5: val_accuracy did not improve from 0.99101\n",
            "203/203 [==============================] - 5s 23ms/step - loss: 0.6396 - accuracy: 0.6048 - val_loss: 2.5993 - val_accuracy: 0.0776\n",
            "Epoch 6/20\n",
            "203/203 [==============================] - ETA: 0s - loss: 0.5943 - accuracy: 0.6897\n",
            "Epoch 6: val_accuracy did not improve from 0.99101\n",
            "203/203 [==============================] - 4s 18ms/step - loss: 0.5943 - accuracy: 0.6897 - val_loss: 0.8352 - val_accuracy: 0.3107\n",
            "Epoch 7/20\n",
            "201/203 [============================>.] - ETA: 0s - loss: 0.6615 - accuracy: 0.6301\n",
            "Epoch 7: val_accuracy did not improve from 0.99101\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.6593 - accuracy: 0.6313 - val_loss: 0.5273 - val_accuracy: 0.9769\n",
            "Epoch 8/20\n",
            "201/203 [============================>.] - ETA: 0s - loss: 0.5933 - accuracy: 0.6727\n",
            "Epoch 8: val_accuracy did not improve from 0.99101\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.5906 - accuracy: 0.6745 - val_loss: 0.2611 - val_accuracy: 0.9839\n",
            "Epoch 9/20\n",
            "201/203 [============================>.] - ETA: 0s - loss: 0.5808 - accuracy: 0.6929\n",
            "Epoch 9: val_accuracy did not improve from 0.99101\n",
            "203/203 [==============================] - 4s 22ms/step - loss: 0.5790 - accuracy: 0.6932 - val_loss: 0.3854 - val_accuracy: 0.9571\n",
            "Epoch 10/20\n",
            "202/203 [============================>.] - ETA: 0s - loss: 0.5542 - accuracy: 0.7234\n",
            "Epoch 10: val_accuracy did not improve from 0.99101\n",
            "203/203 [==============================] - 3s 16ms/step - loss: 0.5549 - accuracy: 0.7225 - val_loss: 1.1436 - val_accuracy: 0.0934\n",
            "Epoch 11/20\n",
            "200/203 [============================>.] - ETA: 0s - loss: 0.5410 - accuracy: 0.7602\n",
            "Epoch 11: val_accuracy did not improve from 0.99101\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.5471 - accuracy: 0.7626 - val_loss: 0.3983 - val_accuracy: 0.9672\n",
            "Epoch 12/20\n",
            "201/203 [============================>.] - ETA: 0s - loss: 0.5243 - accuracy: 0.7609\n",
            "Epoch 12: val_accuracy did not improve from 0.99101\n",
            "203/203 [==============================] - 3s 16ms/step - loss: 0.5220 - accuracy: 0.7621 - val_loss: 0.2541 - val_accuracy: 0.9701\n",
            "Epoch 13/20\n",
            "202/203 [============================>.] - ETA: 0s - loss: 0.5266 - accuracy: 0.7830\n",
            "Epoch 13: val_accuracy did not improve from 0.99101\n",
            "203/203 [==============================] - 4s 22ms/step - loss: 0.5261 - accuracy: 0.7833 - val_loss: 0.2882 - val_accuracy: 0.9543\n",
            "Epoch 14/20\n",
            "201/203 [============================>.] - ETA: 0s - loss: 0.4943 - accuracy: 0.7802\n",
            "Epoch 14: val_accuracy did not improve from 0.99101\n",
            "203/203 [==============================] - 5s 23ms/step - loss: 0.4980 - accuracy: 0.7803 - val_loss: 0.5815 - val_accuracy: 0.8127\n",
            "Epoch 15/20\n",
            "203/203 [==============================] - ETA: 0s - loss: 0.5061 - accuracy: 0.7811\n",
            "Epoch 15: val_accuracy did not improve from 0.99101\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.5061 - accuracy: 0.7811 - val_loss: 0.7361 - val_accuracy: 0.6033\n",
            "Epoch 16/20\n",
            "202/203 [============================>.] - ETA: 0s - loss: 0.4744 - accuracy: 0.7892\n",
            "Epoch 16: val_accuracy did not improve from 0.99101\n",
            "203/203 [==============================] - 4s 22ms/step - loss: 0.4739 - accuracy: 0.7894 - val_loss: 0.1617 - val_accuracy: 0.9707\n",
            "Epoch 17/20\n",
            "200/203 [============================>.] - ETA: 0s - loss: 0.4712 - accuracy: 0.7936\n",
            "Epoch 17: val_accuracy did not improve from 0.99101\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.4800 - accuracy: 0.7858 - val_loss: 0.8123 - val_accuracy: 0.5088\n",
            "Epoch 18/20\n",
            "201/203 [============================>.] - ETA: 0s - loss: 0.4823 - accuracy: 0.7708\n",
            "Epoch 18: val_accuracy did not improve from 0.99101\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.4813 - accuracy: 0.7717 - val_loss: 0.2624 - val_accuracy: 0.9414\n",
            "Epoch 19/20\n",
            "203/203 [==============================] - ETA: 0s - loss: 0.4714 - accuracy: 0.8062\n",
            "Epoch 19: val_accuracy did not improve from 0.99101\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.4714 - accuracy: 0.8062 - val_loss: 0.2112 - val_accuracy: 0.9543\n",
            "Epoch 20/20\n",
            "202/203 [============================>.] - ETA: 0s - loss: 0.4866 - accuracy: 0.7795\n",
            "Epoch 20: val_accuracy did not improve from 0.99101\n",
            "203/203 [==============================] - 4s 22ms/step - loss: 0.4864 - accuracy: 0.7795 - val_loss: 0.4968 - val_accuracy: 0.8489\n",
            "Epoch 1/20\n",
            "201/203 [============================>.] - ETA: 0s - loss: 0.8711 - accuracy: 0.5049\n",
            "Epoch 1: val_accuracy improved from -inf to 0.96669, saving model to model_625_gender.h5\n",
            "203/203 [==============================] - 22s 16ms/step - loss: 0.8676 - accuracy: 0.5072 - val_loss: 0.4432 - val_accuracy: 0.9667\n",
            "Epoch 2/20\n",
            "203/203 [==============================] - ETA: 0s - loss: 0.6396 - accuracy: 0.6565\n",
            "Epoch 2: val_accuracy improved from 0.96669 to 0.97010, saving model to model_625_gender.h5\n",
            "203/203 [==============================] - 4s 21ms/step - loss: 0.6396 - accuracy: 0.6565 - val_loss: 0.4618 - val_accuracy: 0.9701\n",
            "Epoch 3/20\n",
            "201/203 [============================>.] - ETA: 0s - loss: 0.6403 - accuracy: 0.6439\n",
            "Epoch 3: val_accuracy did not improve from 0.97010\n",
            "203/203 [==============================] - 4s 20ms/step - loss: 0.6386 - accuracy: 0.6430 - val_loss: 0.4423 - val_accuracy: 0.9507\n",
            "Epoch 4/20\n",
            "202/203 [============================>.] - ETA: 0s - loss: 0.5792 - accuracy: 0.7175\n",
            "Epoch 4: val_accuracy did not improve from 0.97010\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.5800 - accuracy: 0.7166 - val_loss: 1.3482 - val_accuracy: 0.0719\n",
            "Epoch 5/20\n",
            "201/203 [============================>.] - ETA: 0s - loss: 0.5962 - accuracy: 0.6863\n",
            "Epoch 5: val_accuracy did not improve from 0.97010\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.5974 - accuracy: 0.6881 - val_loss: 3.3480 - val_accuracy: 0.0707\n",
            "Epoch 6/20\n",
            "202/203 [============================>.] - ETA: 0s - loss: 0.5926 - accuracy: 0.6814\n",
            "Epoch 6: val_accuracy did not improve from 0.97010\n",
            "203/203 [==============================] - 5s 23ms/step - loss: 0.5925 - accuracy: 0.6806 - val_loss: 0.7041 - val_accuracy: 0.6103\n",
            "Epoch 7/20\n",
            "201/203 [============================>.] - ETA: 0s - loss: 0.5815 - accuracy: 0.7079\n",
            "Epoch 7: val_accuracy improved from 0.97010 to 0.98125, saving model to model_625_gender.h5\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.5791 - accuracy: 0.7097 - val_loss: 0.3109 - val_accuracy: 0.9813\n",
            "Epoch 8/20\n",
            "203/203 [==============================] - ETA: 0s - loss: 0.5599 - accuracy: 0.7490\n",
            "Epoch 8: val_accuracy did not improve from 0.98125\n",
            "203/203 [==============================] - 4s 18ms/step - loss: 0.5599 - accuracy: 0.7490 - val_loss: 1.3961 - val_accuracy: 0.0784\n",
            "Epoch 9/20\n",
            "202/203 [============================>.] - ETA: 0s - loss: 0.5306 - accuracy: 0.7343\n",
            "Epoch 9: val_accuracy did not improve from 0.98125\n",
            "203/203 [==============================] - 3s 16ms/step - loss: 0.5301 - accuracy: 0.7345 - val_loss: 0.1937 - val_accuracy: 0.9760\n",
            "Epoch 10/20\n",
            "200/203 [============================>.] - ETA: 0s - loss: 0.5558 - accuracy: 0.7241\n",
            "Epoch 10: val_accuracy did not improve from 0.98125\n",
            "203/203 [==============================] - 5s 23ms/step - loss: 0.5570 - accuracy: 0.7232 - val_loss: 0.4966 - val_accuracy: 0.8641\n",
            "Epoch 11/20\n",
            "202/203 [============================>.] - ETA: 0s - loss: 0.5118 - accuracy: 0.7560\n",
            "Epoch 11: val_accuracy did not improve from 0.98125\n",
            "203/203 [==============================] - 3s 14ms/step - loss: 0.5113 - accuracy: 0.7563 - val_loss: 0.2725 - val_accuracy: 0.9617\n",
            "Epoch 12/20\n",
            "199/203 [============================>.] - ETA: 0s - loss: 0.5166 - accuracy: 0.7721\n",
            "Epoch 12: val_accuracy did not improve from 0.98125\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.5122 - accuracy: 0.7736 - val_loss: 0.2661 - val_accuracy: 0.9579\n",
            "Epoch 13/20\n",
            "201/203 [============================>.] - ETA: 0s - loss: 0.5046 - accuracy: 0.7708\n",
            "Epoch 13: val_accuracy did not improve from 0.98125\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.5025 - accuracy: 0.7718 - val_loss: 0.2461 - val_accuracy: 0.9563\n",
            "Epoch 14/20\n",
            "200/203 [============================>.] - ETA: 0s - loss: 0.5026 - accuracy: 0.7691\n",
            "Epoch 14: val_accuracy did not improve from 0.98125\n",
            "203/203 [==============================] - 5s 22ms/step - loss: 0.5002 - accuracy: 0.7709 - val_loss: 0.3100 - val_accuracy: 0.9529\n",
            "Epoch 15/20\n",
            "200/203 [============================>.] - ETA: 0s - loss: 0.4985 - accuracy: 0.7938\n",
            "Epoch 15: val_accuracy did not improve from 0.98125\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.5014 - accuracy: 0.7915 - val_loss: 0.6635 - val_accuracy: 0.6878\n",
            "Epoch 16/20\n",
            "203/203 [==============================] - ETA: 0s - loss: 0.4070 - accuracy: 0.8239\n",
            "Epoch 16: val_accuracy did not improve from 0.98125\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.4070 - accuracy: 0.8239 - val_loss: 0.1437 - val_accuracy: 0.9647\n",
            "Epoch 17/20\n",
            "201/203 [============================>.] - ETA: 0s - loss: 0.4542 - accuracy: 0.8019\n",
            "Epoch 17: val_accuracy did not improve from 0.98125\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.4519 - accuracy: 0.8029 - val_loss: 0.1394 - val_accuracy: 0.9729\n",
            "Epoch 18/20\n",
            "203/203 [==============================] - ETA: 0s - loss: 0.4569 - accuracy: 0.8075\n",
            "Epoch 18: val_accuracy did not improve from 0.98125\n",
            "203/203 [==============================] - 4s 22ms/step - loss: 0.4569 - accuracy: 0.8075 - val_loss: 0.2323 - val_accuracy: 0.9509\n",
            "Epoch 19/20\n",
            "200/203 [============================>.] - ETA: 0s - loss: 0.4268 - accuracy: 0.8384\n",
            "Epoch 19: val_accuracy did not improve from 0.98125\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.4288 - accuracy: 0.8336 - val_loss: 0.2920 - val_accuracy: 0.9094\n",
            "Epoch 20/20\n",
            "199/203 [============================>.] - ETA: 0s - loss: 0.4148 - accuracy: 0.8386\n",
            "Epoch 20: val_accuracy did not improve from 0.98125\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.4156 - accuracy: 0.8395 - val_loss: 0.4601 - val_accuracy: 0.8427\n",
            "Epoch 1/20\n",
            "202/203 [============================>.] - ETA: 0s - loss: 0.7968 - accuracy: 0.5537\n",
            "Epoch 1: val_accuracy improved from -inf to 0.92098, saving model to model_75_gender.h5\n",
            "203/203 [==============================] - 4s 17ms/step - loss: 0.7962 - accuracy: 0.5536 - val_loss: 0.5676 - val_accuracy: 0.9210\n",
            "Epoch 2/20\n",
            "202/203 [============================>.] - ETA: 0s - loss: 0.6337 - accuracy: 0.6520\n",
            "Epoch 2: val_accuracy improved from 0.92098 to 0.97521, saving model to model_75_gender.h5\n",
            "203/203 [==============================] - 4s 22ms/step - loss: 0.6332 - accuracy: 0.6524 - val_loss: 0.3895 - val_accuracy: 0.9752\n",
            "Epoch 3/20\n",
            "200/203 [============================>.] - ETA: 0s - loss: 0.6311 - accuracy: 0.6569\n",
            "Epoch 3: val_accuracy did not improve from 0.97521\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.6372 - accuracy: 0.6592 - val_loss: 1.0644 - val_accuracy: 0.0685\n",
            "Epoch 4/20\n",
            "200/203 [============================>.] - ETA: 0s - loss: 0.5819 - accuracy: 0.6888\n",
            "Epoch 4: val_accuracy did not improve from 0.97521\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.5859 - accuracy: 0.6824 - val_loss: 0.5033 - val_accuracy: 0.8976\n",
            "Epoch 5/20\n",
            "200/203 [============================>.] - ETA: 0s - loss: 0.6183 - accuracy: 0.6422\n",
            "Epoch 5: val_accuracy did not improve from 0.97521\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.6176 - accuracy: 0.6461 - val_loss: 2.4494 - val_accuracy: 0.0697\n",
            "Epoch 6/20\n",
            "202/203 [============================>.] - ETA: 0s - loss: 0.5945 - accuracy: 0.6764\n",
            "Epoch 6: val_accuracy did not improve from 0.97521\n",
            "203/203 [==============================] - 4s 22ms/step - loss: 0.5944 - accuracy: 0.6757 - val_loss: 0.8047 - val_accuracy: 0.4038\n",
            "Epoch 7/20\n",
            "203/203 [==============================] - ETA: 0s - loss: 0.5925 - accuracy: 0.6721\n",
            "Epoch 7: val_accuracy did not improve from 0.97521\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.5925 - accuracy: 0.6721 - val_loss: 0.3455 - val_accuracy: 0.9732\n",
            "Epoch 8/20\n",
            "200/203 [============================>.] - ETA: 0s - loss: 0.5724 - accuracy: 0.7170\n",
            "Epoch 8: val_accuracy improved from 0.97521 to 0.98513, saving model to model_75_gender.h5\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.5671 - accuracy: 0.7202 - val_loss: 0.1781 - val_accuracy: 0.9851\n",
            "Epoch 9/20\n",
            "201/203 [============================>.] - ETA: 0s - loss: 0.5585 - accuracy: 0.7300\n",
            "Epoch 9: val_accuracy did not improve from 0.98513\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.5562 - accuracy: 0.7315 - val_loss: 0.3035 - val_accuracy: 0.9771\n",
            "Epoch 10/20\n",
            "201/203 [============================>.] - ETA: 0s - loss: 0.5055 - accuracy: 0.7524\n",
            "Epoch 10: val_accuracy did not improve from 0.98513\n",
            "203/203 [==============================] - 5s 24ms/step - loss: 0.5058 - accuracy: 0.7527 - val_loss: 0.5022 - val_accuracy: 0.8320\n",
            "Epoch 11/20\n",
            "201/203 [============================>.] - ETA: 0s - loss: 0.4830 - accuracy: 0.8043\n",
            "Epoch 11: val_accuracy did not improve from 0.98513\n",
            "203/203 [==============================] - 3s 16ms/step - loss: 0.4815 - accuracy: 0.8047 - val_loss: 0.3138 - val_accuracy: 0.9577\n",
            "Epoch 12/20\n",
            "199/203 [============================>.] - ETA: 0s - loss: 0.5356 - accuracy: 0.7582\n",
            "Epoch 12: val_accuracy did not improve from 0.98513\n",
            "203/203 [==============================] - 3s 16ms/step - loss: 0.5309 - accuracy: 0.7607 - val_loss: 0.2672 - val_accuracy: 0.9481\n",
            "Epoch 13/20\n",
            "202/203 [============================>.] - ETA: 0s - loss: 0.5481 - accuracy: 0.7493\n",
            "Epoch 13: val_accuracy did not improve from 0.98513\n",
            "203/203 [==============================] - 5s 24ms/step - loss: 0.5476 - accuracy: 0.7495 - val_loss: 0.2750 - val_accuracy: 0.9630\n",
            "Epoch 14/20\n",
            "199/203 [============================>.] - ETA: 0s - loss: 0.5338 - accuracy: 0.7679\n",
            "Epoch 14: val_accuracy did not improve from 0.98513\n",
            "203/203 [==============================] - 4s 20ms/step - loss: 0.5293 - accuracy: 0.7706 - val_loss: 0.2909 - val_accuracy: 0.9639\n",
            "Epoch 15/20\n",
            "199/203 [============================>.] - ETA: 0s - loss: 0.4865 - accuracy: 0.7666\n",
            "Epoch 15: val_accuracy did not improve from 0.98513\n",
            "203/203 [==============================] - 3s 14ms/step - loss: 0.4849 - accuracy: 0.7669 - val_loss: 0.6686 - val_accuracy: 0.6686\n",
            "Epoch 16/20\n",
            "202/203 [============================>.] - ETA: 0s - loss: 0.5057 - accuracy: 0.7770\n",
            "Epoch 16: val_accuracy did not improve from 0.98513\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.5052 - accuracy: 0.7772 - val_loss: 0.2586 - val_accuracy: 0.9611\n",
            "Epoch 17/20\n",
            "199/203 [============================>.] - ETA: 0s - loss: 0.5005 - accuracy: 0.7966\n",
            "Epoch 17: val_accuracy did not improve from 0.98513\n",
            "203/203 [==============================] - 3s 16ms/step - loss: 0.5138 - accuracy: 0.7903 - val_loss: 0.6610 - val_accuracy: 0.6971\n",
            "Epoch 18/20\n",
            "202/203 [============================>.] - ETA: 0s - loss: 0.4491 - accuracy: 0.8126\n",
            "Epoch 18: val_accuracy did not improve from 0.98513\n",
            "203/203 [==============================] - 4s 21ms/step - loss: 0.4487 - accuracy: 0.8127 - val_loss: 0.1976 - val_accuracy: 0.9586\n",
            "Epoch 19/20\n",
            "200/203 [============================>.] - ETA: 0s - loss: 0.4955 - accuracy: 0.7788\n",
            "Epoch 19: val_accuracy did not improve from 0.98513\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.4938 - accuracy: 0.7775 - val_loss: 0.4854 - val_accuracy: 0.9013\n",
            "Epoch 20/20\n",
            "199/203 [============================>.] - ETA: 0s - loss: 0.4521 - accuracy: 0.8076\n",
            "Epoch 20: val_accuracy did not improve from 0.98513\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.4510 - accuracy: 0.8083 - val_loss: 0.2354 - val_accuracy: 0.9405\n",
            "Epoch 1/20\n",
            "201/203 [============================>.] - ETA: 0s - loss: 0.7891 - accuracy: 0.5680\n",
            "Epoch 1: val_accuracy improved from -inf to 0.71785, saving model to model_875_gender.h5\n",
            "203/203 [==============================] - 4s 19ms/step - loss: 0.7891 - accuracy: 0.5649 - val_loss: 0.6646 - val_accuracy: 0.7178\n",
            "Epoch 2/20\n",
            "200/203 [============================>.] - ETA: 0s - loss: 0.6423 - accuracy: 0.6215\n",
            "Epoch 2: val_accuracy improved from 0.71785 to 0.98776, saving model to model_875_gender.h5\n",
            "203/203 [==============================] - 4s 19ms/step - loss: 0.6400 - accuracy: 0.6256 - val_loss: 0.3117 - val_accuracy: 0.9878\n",
            "Epoch 3/20\n",
            "202/203 [============================>.] - ETA: 0s - loss: 0.6167 - accuracy: 0.6694\n",
            "Epoch 3: val_accuracy did not improve from 0.98776\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.6168 - accuracy: 0.6686 - val_loss: 0.9378 - val_accuracy: 0.1035\n",
            "Epoch 4/20\n",
            "203/203 [==============================] - ETA: 0s - loss: 0.5832 - accuracy: 0.7010\n",
            "Epoch 4: val_accuracy did not improve from 0.98776\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.5832 - accuracy: 0.7010 - val_loss: 0.5026 - val_accuracy: 0.9050\n",
            "Epoch 5/20\n",
            "201/203 [============================>.] - ETA: 0s - loss: 0.5774 - accuracy: 0.7016\n",
            "Epoch 5: val_accuracy did not improve from 0.98776\n",
            "203/203 [==============================] - 4s 19ms/step - loss: 0.5795 - accuracy: 0.6978 - val_loss: 1.4422 - val_accuracy: 0.0779\n",
            "Epoch 6/20\n",
            "199/203 [============================>.] - ETA: 0s - loss: 0.5804 - accuracy: 0.7120\n",
            "Epoch 6: val_accuracy did not improve from 0.98776\n",
            "203/203 [==============================] - 4s 18ms/step - loss: 0.5818 - accuracy: 0.7152 - val_loss: 0.8258 - val_accuracy: 0.2687\n",
            "Epoch 7/20\n",
            "201/203 [============================>.] - ETA: 0s - loss: 0.6161 - accuracy: 0.6902\n",
            "Epoch 7: val_accuracy did not improve from 0.98776\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.6137 - accuracy: 0.6917 - val_loss: 0.3609 - val_accuracy: 0.9816\n",
            "Epoch 8/20\n",
            "202/203 [============================>.] - ETA: 0s - loss: 0.5274 - accuracy: 0.7477\n",
            "Epoch 8: val_accuracy did not improve from 0.98776\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.5270 - accuracy: 0.7479 - val_loss: 0.2930 - val_accuracy: 0.9619\n",
            "Epoch 9/20\n",
            "201/203 [============================>.] - ETA: 0s - loss: 0.5356 - accuracy: 0.7379\n",
            "Epoch 9: val_accuracy did not improve from 0.98776\n",
            "203/203 [==============================] - 4s 18ms/step - loss: 0.5341 - accuracy: 0.7383 - val_loss: 0.4623 - val_accuracy: 0.9394\n",
            "Epoch 10/20\n",
            "201/203 [============================>.] - ETA: 0s - loss: 0.4795 - accuracy: 0.7628\n",
            "Epoch 10: val_accuracy did not improve from 0.98776\n",
            "203/203 [==============================] - 4s 19ms/step - loss: 0.4803 - accuracy: 0.7591 - val_loss: 0.5390 - val_accuracy: 0.8351\n",
            "Epoch 11/20\n",
            "201/203 [============================>.] - ETA: 0s - loss: 0.4934 - accuracy: 0.7774\n",
            "Epoch 11: val_accuracy did not improve from 0.98776\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.4916 - accuracy: 0.7785 - val_loss: 0.3433 - val_accuracy: 0.9833\n",
            "Epoch 12/20\n",
            "199/203 [============================>.] - ETA: 0s - loss: 0.4944 - accuracy: 0.7637\n",
            "Epoch 12: val_accuracy did not improve from 0.98776\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.4920 - accuracy: 0.7610 - val_loss: 0.2330 - val_accuracy: 0.9552\n",
            "Epoch 13/20\n",
            "202/203 [============================>.] - ETA: 0s - loss: 0.4599 - accuracy: 0.7834\n",
            "Epoch 13: val_accuracy did not improve from 0.98776\n",
            "203/203 [==============================] - 4s 18ms/step - loss: 0.4598 - accuracy: 0.7834 - val_loss: 0.4621 - val_accuracy: 0.9202\n",
            "Epoch 14/20\n",
            "200/203 [============================>.] - ETA: 0s - loss: 0.4778 - accuracy: 0.7860\n",
            "Epoch 14: val_accuracy did not improve from 0.98776\n",
            "203/203 [==============================] - 4s 20ms/step - loss: 0.4760 - accuracy: 0.7875 - val_loss: 0.3342 - val_accuracy: 0.9529\n",
            "Epoch 15/20\n",
            "203/203 [==============================] - ETA: 0s - loss: 0.4577 - accuracy: 0.8088\n",
            "Epoch 15: val_accuracy did not improve from 0.98776\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.4577 - accuracy: 0.8088 - val_loss: 0.6278 - val_accuracy: 0.7020\n",
            "Epoch 16/20\n",
            "202/203 [============================>.] - ETA: 0s - loss: 0.4354 - accuracy: 0.8138\n",
            "Epoch 16: val_accuracy did not improve from 0.98776\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.4350 - accuracy: 0.8139 - val_loss: 0.1343 - val_accuracy: 0.9664\n",
            "Epoch 17/20\n",
            "201/203 [============================>.] - ETA: 0s - loss: 0.4939 - accuracy: 0.7941\n",
            "Epoch 17: val_accuracy did not improve from 0.98776\n",
            "203/203 [==============================] - 4s 20ms/step - loss: 0.4939 - accuracy: 0.7930 - val_loss: 0.3122 - val_accuracy: 0.9281\n",
            "Epoch 18/20\n",
            "202/203 [============================>.] - ETA: 0s - loss: 0.4448 - accuracy: 0.8049\n",
            "Epoch 18: val_accuracy did not improve from 0.98776\n",
            "203/203 [==============================] - 4s 19ms/step - loss: 0.4445 - accuracy: 0.8050 - val_loss: 0.2891 - val_accuracy: 0.9219\n",
            "Epoch 19/20\n",
            "202/203 [============================>.] - ETA: 0s - loss: 0.4149 - accuracy: 0.8283\n",
            "Epoch 19: val_accuracy did not improve from 0.98776\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.4145 - accuracy: 0.8284 - val_loss: 0.1796 - val_accuracy: 0.9563\n",
            "Epoch 20/20\n",
            "199/203 [============================>.] - ETA: 0s - loss: 0.3904 - accuracy: 0.8113\n",
            "Epoch 20: val_accuracy did not improve from 0.98776\n",
            "203/203 [==============================] - 3s 15ms/step - loss: 0.3898 - accuracy: 0.8122 - val_loss: 0.2004 - val_accuracy: 0.9369\n",
            "101/101 [==============================] - 0s 3ms/step\n",
            "101/101 [==============================] - 0s 3ms/step\n",
            "101/101 [==============================] - 0s 3ms/step\n",
            "101/101 [==============================] - 1s 5ms/step\n",
            "101/101 [==============================] - 1s 5ms/step\n",
            "101/101 [==============================] - 1s 6ms/step\n",
            "101/101 [==============================] - 1s 5ms/step\n",
            "101/101 [==============================] - 0s 3ms/step\n",
            "Male (50): 0.8211909434684792\n",
            "Female (50): 0.8285069444444445\n",
            "Male (62.5): 0.9076635871906563\n",
            "Female (37.5): 0.9495486111111111\n",
            "Male (75): 0.8495045713465128\n",
            "Female (25): 0.9036574074074073\n",
            "Male (87.5): 0.8437844047676033\n",
            "Female (12.5): 0.8648842592592592\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"5494de58-717a-40d2-9f9b-33110f56e9bd\" class=\"plotly-graph-div\" style=\"height:500px; width:500px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5494de58-717a-40d2-9f9b-33110f56e9bd\")) {                    Plotly.newPlot(                        \"5494de58-717a-40d2-9f9b-33110f56e9bd\",                        [{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(200, 20, 20, 1.0)\",\"width\":3},\"name\":\"\\u003cb\\u003eFemale\\u003c\\u002fb\\u003e\",\"showlegend\":true,\"x\":[50,62.5,75,87.5],\"y\":[0.8285069444444445,0.9495486111111111,0.9036574074074073,0.8648842592592592],\"type\":\"scatter\"},{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(20, 20, 200, 1)\",\"width\":3},\"name\":\"\\u003cb\\u003eMale\\u003c\\u002fb\\u003e\",\"showlegend\":true,\"x\":[50,62.5,75,87.5],\"y\":[0.8211909434684792,0.9076635871906563,0.8495045713465128,0.8437844047676033],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"title\":{\"x\":0.5},\"legend\":{\"yanchor\":\"bottom\",\"xanchor\":\"right\",\"x\":0.95,\"y\":0.01},\"xaxis\":{\"title\":{\"text\":\"\\u003cb\\u003ePercentage of males\\u003c\\u002fb\\u003e\"},\"range\":[40,100],\"gridcolor\":\"rgba(5, 5, 5, 0.5)\",\"constrain\":\"domain\",\"linecolor\":\"black\",\"dtick\":12.5},\"yaxis\":{\"title\":{\"text\":\"\\u003cb\\u003eAUC\\u003c\\u002fb\\u003e\"},\"range\":[0.7211909434684792,1.0495486111111112],\"gridcolor\":\"rgba(5, 5, 5, 0.5)\",\"scaleanchor\":\"x\",\"scaleratio\":170,\"linecolor\":\"black\"},\"width\":500,\"height\":500,\"font\":{\"family\":\"Times New Roman\",\"size\":18,\"color\":\"Black\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('5494de58-717a-40d2-9f9b-33110f56e9bd');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "male1_sample=male1.sample(12944, random_state=43)\n",
        "female1_sample=female1.sample(12944, random_state=43)\n",
        "male1_sample=male1_sample.sample(int(0.5*len(male1_sample)), random_state=43)\n",
        "female1_sample=female1_sample.sample(int(0.5*len(female1_sample)), random_state=43)\n",
        "data=pd.concat([male1_sample, female1_sample])\n",
        "X_sample=data.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "y_sample=data['UDPYOPI_1 - Yes']\n",
        "class_weights_sample = compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(y_sample),\n",
        "                                        y = y_sample\n",
        "                                    )\n",
        "sklearn_weights = dict(enumerate(class_weights_sample))\n",
        "class_weights_sample=sklearn_weights\n",
        "\n",
        "algorithm()\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath='model_50_gender.h5',\n",
        "                               monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "algorithm()\n",
        "callbacks = [checkpoint]\n",
        "number_of_features=44\n",
        "algorithm()\n",
        "network = models.Sequential()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=1000, activation=\"relu\", input_shape=(\n",
        "number_of_features,)))\n",
        "algorithm()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=1000, activation=\"relu\"))\n",
        "algorithm()\n",
        "# Add fully connected layer with a sigmoid activation function\n",
        "network.add(layers.Dense(units=1, activation=\"sigmoid\")) # No activation for regression\n",
        "# Compile neural network\n",
        "algorithm()\n",
        "network.compile(loss=\"binary_crossentropy\", # Cross-entropy # \"mse\" for regression\n",
        "optimizer=\"sgd\", # Root Mean Square Propagation\n",
        "metrics=[\"accuracy\"]) # Accuracy performance metric\n",
        "history = network.fit(X_sample, # Features\n",
        "y_sample, # Target vector\n",
        "epochs=20,\n",
        "verbose=1,\n",
        "callbacks=callbacks, # Print description after each epoch\n",
        "batch_size=64,\n",
        "class_weight=class_weights_sample,\n",
        "validation_data=(X_for_test, y_for_test))\n",
        "\n",
        "###################################################################\n",
        "\n",
        "male1_sample=male1.sample(12944, random_state=43)\n",
        "female1_sample=female1.sample(12944, random_state=43)\n",
        "male1_sample=male1_sample.sample(int(0.625*len(male1_sample)), random_state=43)\n",
        "female1_sample=female1_sample.sample(int(0.375*len(female1_sample)), random_state=43)\n",
        "data=pd.concat([male1_sample, female1_sample])\n",
        "\n",
        "X_sample=data.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "y_sample=data['UDPYOPI_1 - Yes']\n",
        "class_weights_sample = compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(y_sample),\n",
        "                                        y = y_sample\n",
        "                                    )\n",
        "sklearn_weights = dict(enumerate(class_weights_sample))\n",
        "class_weights_sample=sklearn_weights\n",
        "algorithm()\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath='model_625_gender.h5',\n",
        "                               monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "algorithm()\n",
        "callbacks = [checkpoint]\n",
        "number_of_features=44\n",
        "algorithm()\n",
        "network = models.Sequential()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=1000, activation=\"relu\", input_shape=(\n",
        "number_of_features,)))\n",
        "algorithm()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=1000, activation=\"relu\"))\n",
        "algorithm()\n",
        "# Add fully connected layer with a sigmoid activation function\n",
        "network.add(layers.Dense(units=1, activation=\"sigmoid\")) # No activation for regression\n",
        "# Compile neural network\n",
        "algorithm()\n",
        "network.compile(loss=\"binary_crossentropy\", # Cross-entropy # \"mse\" for regression\n",
        "optimizer=\"sgd\", # Root Mean Square Propagation\n",
        "metrics=[\"accuracy\"]) # Accuracy performance metric\n",
        "history = network.fit(X_sample, # Features\n",
        "y_sample, # Target vector\n",
        "epochs=20,\n",
        "verbose=1,\n",
        "callbacks=callbacks, # Print description after each epoch\n",
        "batch_size=64,\n",
        "class_weight=class_weights_sample,\n",
        "validation_data=(X_for_test, y_for_test))\n",
        "\n",
        "########################################################\n",
        "\n",
        "male1_sample=male1.sample(12944, random_state=43)\n",
        "female1_sample=female1.sample(12944, random_state=43)\n",
        "male1_sample=male1_sample.sample(int(0.75*len(male1_sample)), random_state=43)\n",
        "female1_sample=female1_sample.sample(int(0.25*len(female1_sample)), random_state=43)\n",
        "data=pd.concat([male1_sample, female1_sample])\n",
        "\n",
        "X_sample=data.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "y_sample=data['UDPYOPI_1 - Yes']\n",
        "class_weights_sample = compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(y_sample),\n",
        "                                        y = y_sample\n",
        "                                    )\n",
        "sklearn_weights = dict(enumerate(class_weights_sample))\n",
        "class_weights_sample=sklearn_weights\n",
        "\n",
        "algorithm()\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath='model_75_gender.h5',\n",
        "                               monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "algorithm()\n",
        "callbacks = [checkpoint]\n",
        "number_of_features=44\n",
        "algorithm()\n",
        "network = models.Sequential()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=1000, activation=\"relu\", input_shape=(\n",
        "number_of_features,)))\n",
        "algorithm()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=1000, activation=\"relu\"))\n",
        "algorithm()\n",
        "# Add fully connected layer with a sigmoid activation function\n",
        "network.add(layers.Dense(units=1, activation=\"sigmoid\")) # No activation for regression\n",
        "# Compile neural network\n",
        "algorithm()\n",
        "network.compile(loss=\"binary_crossentropy\", # Cross-entropy # \"mse\" for regression\n",
        "optimizer=\"sgd\", # Root Mean Square Propagation\n",
        "metrics=[\"accuracy\"]) # Accuracy performance metric\n",
        "history = network.fit(X_sample, # Features\n",
        "y_sample, # Target vector\n",
        "epochs=20,\n",
        "verbose=1,\n",
        "callbacks=callbacks, # Print description after each epoch\n",
        "batch_size=64,\n",
        "class_weight=class_weights_sample,\n",
        "validation_data=(X_for_test, y_for_test))\n",
        "\n",
        "######################################################\n",
        "\n",
        "male1_sample=male1.sample(12944, random_state=43)\n",
        "female1_sample=female1.sample(12944, random_state=43)\n",
        "male1_sample=male1_sample.sample(int(0.875*len(male1_sample)), random_state=43)\n",
        "female1_sample=female1_sample.sample(int(0.125*len(female1_sample)), random_state=43)\n",
        "data=pd.concat([male1_sample, female1_sample])\n",
        "\n",
        "X_sample=data.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "y_sample=data['UDPYOPI_1 - Yes']\n",
        "class_weights_sample = compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(y_sample),\n",
        "                                        y = y_sample\n",
        "                                    )\n",
        "sklearn_weights = dict(enumerate(class_weights_sample))\n",
        "class_weights_sample=sklearn_weights\n",
        "\n",
        "algorithm()\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath='model_875_gender.h5',\n",
        "                               monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "algorithm()\n",
        "callbacks = [checkpoint]\n",
        "number_of_features=44\n",
        "algorithm()\n",
        "network = models.Sequential()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=1000, activation=\"relu\", input_shape=(\n",
        "number_of_features,)))\n",
        "algorithm()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=1000, activation=\"relu\"))\n",
        "algorithm()\n",
        "# Add fully connected layer with a sigmoid activation function\n",
        "network.add(layers.Dense(units=1, activation=\"sigmoid\")) # No activation for regression\n",
        "# Compile neural network\n",
        "algorithm()\n",
        "network.compile(loss=\"binary_crossentropy\", # Cross-entropy # \"mse\" for regression\n",
        "optimizer=\"sgd\", # Root Mean Square Propagation\n",
        "metrics=[\"accuracy\"]) # Accuracy performance metric\n",
        "history = network.fit(X_sample, # Features\n",
        "y_sample, # Target vector\n",
        "epochs=20,\n",
        "verbose=1,\n",
        "callbacks=callbacks, # Print description after each epoch\n",
        "batch_size=64,\n",
        "class_weight=class_weights_sample,\n",
        "validation_data=(X_for_test, y_for_test))\n",
        "\n",
        "prob1_50=load_model('model_50_gender.h5').predict(male_predictors_test)\n",
        "prob2_50=load_model('model_50_gender.h5').predict(female_predictors_test)\n",
        "prob1_625=load_model('model_625_gender.h5').predict(male_predictors_test)\n",
        "prob2_625=load_model('model_625_gender.h5').predict(female_predictors_test)\n",
        "prob1_75=load_model('model_75_gender.h5').predict(male_predictors_test)\n",
        "prob2_75=load_model('model_75_gender.h5').predict(female_predictors_test)\n",
        "prob1_875=load_model('model_875_gender.h5').predict(male_predictors_test)\n",
        "prob2_875=load_model('model_875_gender.h5').predict(female_predictors_test)\n",
        "\n",
        "print('Male (50):', roc_auc_score(male_target_test, prob1_50))\n",
        "print('Female (50):', roc_auc_score(female_target_test, prob2_50))\n",
        "print('Male (62.5):', roc_auc_score(male_target_test, prob1_625))\n",
        "print('Female (37.5):', roc_auc_score(female_target_test, prob2_625))\n",
        "print('Male (75):', roc_auc_score(male_target_test, prob1_75))\n",
        "print('Female (25):', roc_auc_score(female_target_test, prob2_75))\n",
        "print('Male (87.5):', roc_auc_score(male_target_test, prob1_875))\n",
        "print('Female (12.5):', roc_auc_score(female_target_test, prob2_875))\n",
        "\n",
        "\n",
        "# x axis values\n",
        "x = [50, 62.5, 75, 87.5]\n",
        "# corresponding y axis values\n",
        "y = [roc_auc_score(female_target_test, prob2_50),roc_auc_score(female_target_test, prob2_625),\n",
        "     roc_auc_score(female_target_test, prob2_75),roc_auc_score(female_target_test, prob2_875)]\n",
        "z = [roc_auc_score(male_target_test, prob1_50),roc_auc_score(male_target_test, prob1_625),\n",
        "     roc_auc_score(male_target_test, prob1_75),roc_auc_score(male_target_test, prob1_875)]\n",
        "c_line_main1 = 'rgba(200, 20, 20, 1.0)'\n",
        "c_line_main2 = 'rgba(20, 20, 200, 1)'\n",
        "fig = go.Figure([\n",
        "\n",
        "    go.Scatter(\n",
        "        x          = x,\n",
        "        y          = y,\n",
        "        line       = dict(color=c_line_main1, width=3),\n",
        "        hoverinfo  = \"skip\",\n",
        "        showlegend = True,\n",
        "        name       = '<b>Female</b>'),\n",
        "    go.Scatter(\n",
        "        x          = x,\n",
        "        y          = z,\n",
        "        line       = dict(color=c_line_main2, width=3),\n",
        "        hoverinfo  = \"skip\",\n",
        "        showlegend = True,\n",
        "        name       = '<b>Male</b>')\n",
        "    ])\n",
        "fig.add_shape(\n",
        "        type ='line',\n",
        "        line =dict(dash='dash'),\n",
        "        x0=0, x1=1, y0=0, y1=1\n",
        "    )\n",
        "fig.update_layout(\n",
        "        template    = 'plotly_white',\n",
        "        title_x     = 0.5,\n",
        "        xaxis_title = \"<b>Percentage of males</b>\",\n",
        "        yaxis_title = \"<b>AUC</b>\",\n",
        "        width       = 500,\n",
        "        height      = 500,\n",
        "        legend      = dict(\n",
        "            yanchor=\"bottom\",\n",
        "            xanchor=\"right\",\n",
        "            x=0.95,\n",
        "            y=0.01,\n",
        "        )\n",
        "    )\n",
        "fig.update_layout(\n",
        "        font=dict(\n",
        "        family=\"Times New Roman\",\n",
        "        size=18,  # Set the font size here\n",
        "        color=\"Black\"\n",
        "        )\n",
        "    )\n",
        "fig.update_yaxes(\n",
        "        range       = [min(min(y), min(z))-0.1, max(max(y), max(z))+0.1],\n",
        "        gridcolor   = c_grid,\n",
        "        scaleanchor = \"x\",\n",
        "        scaleratio  = 170,\n",
        "        linecolor   = 'black')\n",
        "fig.update_xaxes(\n",
        "        range       = [40, 100],\n",
        "        gridcolor   = c_grid,\n",
        "        constrain   = 'domain',\n",
        "        linecolor   = 'black',dtick=12.5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "notmarried_test=test.drop(X_test[X_test['IRMARIT_4 - Never Been Married'] == 0].index)\n",
        "elsee_test=test.drop(X_test[X_test['IRMARIT_4 - Never Been Married'] == 1].index)\n",
        "print(len(notmarried_test))\n",
        "print(len(elsee_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEnMAgt-w9VU",
        "outputId": "342bfbf3-cd42-4129-8269-87dc708f464d"
      },
      "id": "iEnMAgt-w9VU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3334\n",
            "3249\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37b80c8b",
      "metadata": {
        "id": "37b80c8b"
      },
      "outputs": [],
      "source": [
        "notmarried=train.drop(X_train[X_train['IRMARIT_4 - Never Been Married'] == 0].index)\n",
        "elsee=train.drop(X_train[X_train['IRMARIT_4 - Never Been Married'] == 1].index)\n",
        "notmarried_test=test.drop(X_test[X_test['IRMARIT_4 - Never Been Married'] == 0].index)\n",
        "notmarried_test=notmarried_test.sample(3249, random_state=43)\n",
        "notmarried_predictors_test=notmarried_test.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "notmarried_target_test=notmarried_test['UDPYOPI_1 - Yes']\n",
        "elsee_test=test.drop(X_test[X_test['IRMARIT_4 - Never Been Married'] == 1].index)\n",
        "elsee_test=elsee_test.sample(3249, random_state=43)\n",
        "elsee_predictors_test=elsee_test.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "elsee_target_test=elsee_test['UDPYOPI_1 - Yes']\n",
        "data_test=pd.concat([notmarried_test, elsee_test])\n",
        "X_for_test=data_test.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "y_for_test=data_test['UDPYOPI_1 - Yes']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(notmarried))\n",
        "print(len(elsee))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b9kQzF3xT7F",
        "outputId": "8d1c8252-db73-4017-da54-874e9e7b2b0d"
      },
      "id": "1b9kQzF3xT7F",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13646\n",
            "12684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f4ea188",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9f4ea188",
        "outputId": "17ee5fdd-da16-43d3-8288-dcab9c39c0f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "196/199 [============================>.] - ETA: 0s - loss: 0.8383 - accuracy: 0.4471\n",
            "Epoch 1: val_accuracy improved from -inf to 0.07279, saving model to model_50_marit.h5\n",
            "199/199 [==============================] - 4s 16ms/step - loss: 0.8401 - accuracy: 0.4434 - val_loss: 0.9242 - val_accuracy: 0.0728\n",
            "Epoch 2/20\n",
            "197/199 [============================>.] - ETA: 0s - loss: 0.6548 - accuracy: 0.5563\n",
            "Epoch 2: val_accuracy improved from 0.07279 to 0.98261, saving model to model_50_marit.h5\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 0.6528 - accuracy: 0.5583 - val_loss: 0.4575 - val_accuracy: 0.9826\n",
            "Epoch 3/20\n",
            "198/199 [============================>.] - ETA: 0s - loss: 0.6376 - accuracy: 0.6063\n",
            "Epoch 3: val_accuracy did not improve from 0.98261\n",
            "199/199 [==============================] - 3s 17ms/step - loss: 0.6375 - accuracy: 0.6061 - val_loss: 0.6702 - val_accuracy: 0.6693\n",
            "Epoch 4/20\n",
            "196/199 [============================>.] - ETA: 0s - loss: 0.6378 - accuracy: 0.6175\n",
            "Epoch 4: val_accuracy did not improve from 0.98261\n",
            "199/199 [==============================] - 4s 21ms/step - loss: 0.6380 - accuracy: 0.6147 - val_loss: 0.6174 - val_accuracy: 0.8580\n",
            "Epoch 5/20\n",
            "199/199 [==============================] - ETA: 0s - loss: 0.6069 - accuracy: 0.6738\n",
            "Epoch 5: val_accuracy did not improve from 0.98261\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 0.6069 - accuracy: 0.6738 - val_loss: 0.3801 - val_accuracy: 0.9811\n",
            "Epoch 6/20\n",
            "196/199 [============================>.] - ETA: 0s - loss: 0.5909 - accuracy: 0.6901\n",
            "Epoch 6: val_accuracy did not improve from 0.98261\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 0.5906 - accuracy: 0.6927 - val_loss: 0.4310 - val_accuracy: 0.9412\n",
            "Epoch 7/20\n",
            "197/199 [============================>.] - ETA: 0s - loss: 0.5584 - accuracy: 0.7099\n",
            "Epoch 7: val_accuracy did not improve from 0.98261\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 0.5623 - accuracy: 0.7108 - val_loss: 0.5903 - val_accuracy: 0.7705\n",
            "Epoch 8/20\n",
            "198/199 [============================>.] - ETA: 0s - loss: 0.5682 - accuracy: 0.7204\n",
            "Epoch 8: val_accuracy did not improve from 0.98261\n",
            "199/199 [==============================] - 5s 23ms/step - loss: 0.5683 - accuracy: 0.7203 - val_loss: 1.2257 - val_accuracy: 0.1676\n",
            "Epoch 9/20\n",
            "196/199 [============================>.] - ETA: 0s - loss: 0.5924 - accuracy: 0.6745\n",
            "Epoch 9: val_accuracy did not improve from 0.98261\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 0.5959 - accuracy: 0.6749 - val_loss: 0.3710 - val_accuracy: 0.9703\n",
            "Epoch 10/20\n",
            "195/199 [============================>.] - ETA: 0s - loss: 0.5676 - accuracy: 0.7227\n",
            "Epoch 10: val_accuracy did not improve from 0.98261\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 0.5635 - accuracy: 0.7226 - val_loss: 0.3843 - val_accuracy: 0.9666\n",
            "Epoch 11/20\n",
            "196/199 [============================>.] - ETA: 0s - loss: 0.5418 - accuracy: 0.7380\n",
            "Epoch 11: val_accuracy did not improve from 0.98261\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 0.5402 - accuracy: 0.7401 - val_loss: 0.2924 - val_accuracy: 0.9626\n",
            "Epoch 12/20\n",
            "198/199 [============================>.] - ETA: 0s - loss: 0.5565 - accuracy: 0.7373\n",
            "Epoch 12: val_accuracy did not improve from 0.98261\n",
            "199/199 [==============================] - 4s 21ms/step - loss: 0.5563 - accuracy: 0.7371 - val_loss: 0.5812 - val_accuracy: 0.8041\n",
            "Epoch 13/20\n",
            "195/199 [============================>.] - ETA: 0s - loss: 0.5225 - accuracy: 0.7826\n",
            "Epoch 13: val_accuracy did not improve from 0.98261\n",
            "199/199 [==============================] - 3s 16ms/step - loss: 0.5188 - accuracy: 0.7822 - val_loss: 0.3697 - val_accuracy: 0.9575\n",
            "Epoch 14/20\n",
            "196/199 [============================>.] - ETA: 0s - loss: 0.5487 - accuracy: 0.7545\n",
            "Epoch 14: val_accuracy did not improve from 0.98261\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 0.5535 - accuracy: 0.7566 - val_loss: 0.2715 - val_accuracy: 0.9732\n",
            "Epoch 15/20\n",
            "197/199 [============================>.] - ETA: 0s - loss: 0.4927 - accuracy: 0.7905\n",
            "Epoch 15: val_accuracy did not improve from 0.98261\n",
            "199/199 [==============================] - 3s 16ms/step - loss: 0.4918 - accuracy: 0.7916 - val_loss: 0.3339 - val_accuracy: 0.9177\n",
            "Epoch 16/20\n",
            "196/199 [============================>.] - ETA: 0s - loss: 0.5115 - accuracy: 0.7816\n",
            "Epoch 16: val_accuracy did not improve from 0.98261\n",
            "199/199 [==============================] - 5s 23ms/step - loss: 0.5111 - accuracy: 0.7792 - val_loss: 0.3832 - val_accuracy: 0.9129\n",
            "Epoch 17/20\n",
            "197/199 [============================>.] - ETA: 0s - loss: 0.4919 - accuracy: 0.7674\n",
            "Epoch 17: val_accuracy did not improve from 0.98261\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 0.4931 - accuracy: 0.7675 - val_loss: 0.4900 - val_accuracy: 0.8323\n",
            "Epoch 18/20\n",
            "196/199 [============================>.] - ETA: 0s - loss: 0.4893 - accuracy: 0.7899\n",
            "Epoch 18: val_accuracy did not improve from 0.98261\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 0.4884 - accuracy: 0.7895 - val_loss: 0.3010 - val_accuracy: 0.9295\n",
            "Epoch 19/20\n",
            "199/199 [==============================] - ETA: 0s - loss: 0.5103 - accuracy: 0.7794\n",
            "Epoch 19: val_accuracy did not improve from 0.98261\n",
            "199/199 [==============================] - 4s 20ms/step - loss: 0.5103 - accuracy: 0.7794 - val_loss: 0.6285 - val_accuracy: 0.7148\n",
            "Epoch 20/20\n",
            "198/199 [============================>.] - ETA: 0s - loss: 0.4906 - accuracy: 0.7780\n",
            "Epoch 20: val_accuracy did not improve from 0.98261\n",
            "199/199 [==============================] - 6s 29ms/step - loss: 0.4904 - accuracy: 0.7781 - val_loss: 0.2729 - val_accuracy: 0.9498\n",
            "Epoch 1/20\n",
            "196/199 [============================>.] - ETA: 0s - loss: 0.8666 - accuracy: 0.4636\n",
            "Epoch 1: val_accuracy improved from -inf to 0.90135, saving model to model_625_marit.h5\n",
            "199/199 [==============================] - 4s 16ms/step - loss: 0.8646 - accuracy: 0.4662 - val_loss: 0.6008 - val_accuracy: 0.9014\n",
            "Epoch 2/20\n",
            "196/199 [============================>.] - ETA: 0s - loss: 0.6631 - accuracy: 0.5848\n",
            "Epoch 2: val_accuracy improved from 0.90135 to 0.97953, saving model to model_625_marit.h5\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 0.6587 - accuracy: 0.5889 - val_loss: 0.3895 - val_accuracy: 0.9795\n",
            "Epoch 3/20\n",
            "199/199 [==============================] - ETA: 0s - loss: 0.6683 - accuracy: 0.5855\n",
            "Epoch 3: val_accuracy improved from 0.97953 to 0.98015, saving model to model_625_marit.h5\n",
            "199/199 [==============================] - 4s 21ms/step - loss: 0.6683 - accuracy: 0.5855 - val_loss: 0.4494 - val_accuracy: 0.9801\n",
            "Epoch 4/20\n",
            "195/199 [============================>.] - ETA: 0s - loss: 0.6370 - accuracy: 0.6650\n",
            "Epoch 4: val_accuracy did not improve from 0.98015\n",
            "199/199 [==============================] - 3s 16ms/step - loss: 0.6397 - accuracy: 0.6562 - val_loss: 0.6669 - val_accuracy: 0.7045\n",
            "Epoch 5/20\n",
            "198/199 [============================>.] - ETA: 0s - loss: 0.6276 - accuracy: 0.6526\n",
            "Epoch 5: val_accuracy did not improve from 0.98015\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 0.6274 - accuracy: 0.6527 - val_loss: 0.6033 - val_accuracy: 0.8546\n",
            "Epoch 6/20\n",
            "195/199 [============================>.] - ETA: 0s - loss: 0.6073 - accuracy: 0.6683\n",
            "Epoch 6: val_accuracy did not improve from 0.98015\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 0.6127 - accuracy: 0.6678 - val_loss: 0.5710 - val_accuracy: 0.8506\n",
            "Epoch 7/20\n",
            "198/199 [============================>.] - ETA: 0s - loss: 0.5926 - accuracy: 0.6977\n",
            "Epoch 7: val_accuracy did not improve from 0.98015\n",
            "199/199 [==============================] - 4s 19ms/step - loss: 0.5924 - accuracy: 0.6974 - val_loss: 0.5411 - val_accuracy: 0.9004\n",
            "Epoch 8/20\n",
            "197/199 [============================>.] - ETA: 0s - loss: 0.5656 - accuracy: 0.7337\n",
            "Epoch 8: val_accuracy did not improve from 0.98015\n",
            "199/199 [==============================] - 4s 18ms/step - loss: 0.5683 - accuracy: 0.7346 - val_loss: 0.9352 - val_accuracy: 0.3383\n",
            "Epoch 9/20\n",
            "197/199 [============================>.] - ETA: 0s - loss: 0.5464 - accuracy: 0.7446\n",
            "Epoch 9: val_accuracy did not improve from 0.98015\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 0.5461 - accuracy: 0.7417 - val_loss: 0.4910 - val_accuracy: 0.9152\n",
            "Epoch 10/20\n",
            "196/199 [============================>.] - ETA: 0s - loss: 0.5506 - accuracy: 0.7634\n",
            "Epoch 10: val_accuracy did not improve from 0.98015\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 0.5466 - accuracy: 0.7655 - val_loss: 0.3190 - val_accuracy: 0.9795\n",
            "Epoch 11/20\n",
            "198/199 [============================>.] - ETA: 0s - loss: 0.5820 - accuracy: 0.7464\n",
            "Epoch 11: val_accuracy did not improve from 0.98015\n",
            "199/199 [==============================] - 4s 21ms/step - loss: 0.5819 - accuracy: 0.7461 - val_loss: 0.5846 - val_accuracy: 0.8176\n",
            "Epoch 12/20\n",
            "196/199 [============================>.] - ETA: 0s - loss: 0.5521 - accuracy: 0.7609\n",
            "Epoch 12: val_accuracy did not improve from 0.98015\n",
            "199/199 [==============================] - 4s 18ms/step - loss: 0.5552 - accuracy: 0.7591 - val_loss: 0.7027 - val_accuracy: 0.6294\n",
            "Epoch 13/20\n",
            "198/199 [============================>.] - ETA: 0s - loss: 0.5339 - accuracy: 0.7811\n",
            "Epoch 13: val_accuracy did not improve from 0.98015\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 0.5336 - accuracy: 0.7812 - val_loss: 0.2365 - val_accuracy: 0.9795\n",
            "Epoch 14/20\n",
            "197/199 [============================>.] - ETA: 0s - loss: 0.5277 - accuracy: 0.7900\n",
            "Epoch 14: val_accuracy did not improve from 0.98015\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 0.5298 - accuracy: 0.7910 - val_loss: 0.5335 - val_accuracy: 0.8307\n",
            "Epoch 15/20\n",
            "199/199 [==============================] - ETA: 0s - loss: 0.4950 - accuracy: 0.7935\n",
            "Epoch 15: val_accuracy did not improve from 0.98015\n",
            "199/199 [==============================] - 5s 23ms/step - loss: 0.4950 - accuracy: 0.7935 - val_loss: 0.1686 - val_accuracy: 0.9800\n",
            "Epoch 16/20\n",
            "195/199 [============================>.] - ETA: 0s - loss: 0.4614 - accuracy: 0.8275\n",
            "Epoch 16: val_accuracy did not improve from 0.98015\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 0.4635 - accuracy: 0.8218 - val_loss: 0.3825 - val_accuracy: 0.9246\n",
            "Epoch 17/20\n",
            "195/199 [============================>.] - ETA: 0s - loss: 0.5143 - accuracy: 0.7684\n",
            "Epoch 17: val_accuracy did not improve from 0.98015\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 0.5136 - accuracy: 0.7702 - val_loss: 0.4437 - val_accuracy: 0.8835\n",
            "Epoch 18/20\n",
            "198/199 [============================>.] - ETA: 0s - loss: 0.4617 - accuracy: 0.8104\n",
            "Epoch 18: val_accuracy did not improve from 0.98015\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 0.4615 - accuracy: 0.8105 - val_loss: 0.2153 - val_accuracy: 0.9774\n",
            "Epoch 19/20\n",
            "198/199 [============================>.] - ETA: 0s - loss: 0.4891 - accuracy: 0.8119\n",
            "Epoch 19: val_accuracy did not improve from 0.98015\n",
            "199/199 [==============================] - 4s 22ms/step - loss: 0.4889 - accuracy: 0.8119 - val_loss: 0.4430 - val_accuracy: 0.8883\n",
            "Epoch 20/20\n",
            "196/199 [============================>.] - ETA: 0s - loss: 0.4870 - accuracy: 0.7919\n",
            "Epoch 20: val_accuracy did not improve from 0.98015\n",
            "199/199 [==============================] - 3s 16ms/step - loss: 0.4833 - accuracy: 0.7935 - val_loss: 0.1676 - val_accuracy: 0.9720\n",
            "Epoch 1/20\n",
            "195/199 [============================>.] - ETA: 0s - loss: 0.8078 - accuracy: 0.5348\n",
            "Epoch 1: val_accuracy improved from -inf to 0.94475, saving model to model_75_marit.h5\n",
            "199/199 [==============================] - 4s 16ms/step - loss: 0.8037 - accuracy: 0.5407 - val_loss: 0.5344 - val_accuracy: 0.9448\n",
            "Epoch 2/20\n",
            "197/199 [============================>.] - ETA: 0s - loss: 0.6467 - accuracy: 0.6165\n",
            "Epoch 2: val_accuracy did not improve from 0.94475\n",
            "199/199 [==============================] - 5s 25ms/step - loss: 0.6533 - accuracy: 0.6180 - val_loss: 0.8609 - val_accuracy: 0.1545\n",
            "Epoch 3/20\n",
            "197/199 [============================>.] - ETA: 0s - loss: 0.6165 - accuracy: 0.6706\n",
            "Epoch 3: val_accuracy did not improve from 0.94475\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 0.6156 - accuracy: 0.6676 - val_loss: 0.6735 - val_accuracy: 0.6413\n",
            "Epoch 4/20\n",
            "197/199 [============================>.] - ETA: 0s - loss: 0.6224 - accuracy: 0.6856\n",
            "Epoch 4: val_accuracy did not improve from 0.94475\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 0.6212 - accuracy: 0.6830 - val_loss: 0.6068 - val_accuracy: 0.8167\n",
            "Epoch 5/20\n",
            "199/199 [==============================] - ETA: 0s - loss: 0.6030 - accuracy: 0.6925\n",
            "Epoch 5: val_accuracy improved from 0.94475 to 0.95045, saving model to model_75_marit.h5\n",
            "199/199 [==============================] - 4s 22ms/step - loss: 0.6030 - accuracy: 0.6925 - val_loss: 0.4271 - val_accuracy: 0.9504\n",
            "Epoch 6/20\n",
            "198/199 [============================>.] - ETA: 0s - loss: 0.5236 - accuracy: 0.7644\n",
            "Epoch 6: val_accuracy did not improve from 0.95045\n",
            "199/199 [==============================] - 6s 30ms/step - loss: 0.5234 - accuracy: 0.7643 - val_loss: 0.3336 - val_accuracy: 0.9406\n",
            "Epoch 7/20\n",
            "199/199 [==============================] - ETA: 0s - loss: 0.5391 - accuracy: 0.7603\n",
            "Epoch 7: val_accuracy did not improve from 0.95045\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 0.5391 - accuracy: 0.7603 - val_loss: 0.5015 - val_accuracy: 0.8490\n",
            "Epoch 8/20\n",
            "196/199 [============================>.] - ETA: 0s - loss: 0.5269 - accuracy: 0.7580\n",
            "Epoch 8: val_accuracy did not improve from 0.95045\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 0.5269 - accuracy: 0.7583 - val_loss: 0.6408 - val_accuracy: 0.7228\n",
            "Epoch 9/20\n",
            "198/199 [============================>.] - ETA: 0s - loss: 0.5750 - accuracy: 0.7431\n",
            "Epoch 9: val_accuracy did not improve from 0.95045\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 0.5750 - accuracy: 0.7431 - val_loss: 0.4504 - val_accuracy: 0.9118\n",
            "Epoch 10/20\n",
            "197/199 [============================>.] - ETA: 0s - loss: 0.5489 - accuracy: 0.7385\n",
            "Epoch 10: val_accuracy improved from 0.95045 to 0.97984, saving model to model_75_marit.h5\n",
            "199/199 [==============================] - 5s 23ms/step - loss: 0.5465 - accuracy: 0.7397 - val_loss: 0.2094 - val_accuracy: 0.9798\n",
            "Epoch 11/20\n",
            "197/199 [============================>.] - ETA: 0s - loss: 0.5140 - accuracy: 0.7505\n",
            "Epoch 11: val_accuracy did not improve from 0.97984\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 0.5125 - accuracy: 0.7513 - val_loss: 0.3129 - val_accuracy: 0.9484\n",
            "Epoch 12/20\n",
            "198/199 [============================>.] - ETA: 0s - loss: 0.5098 - accuracy: 0.7788\n",
            "Epoch 12: val_accuracy did not improve from 0.97984\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 0.5096 - accuracy: 0.7788 - val_loss: 0.4836 - val_accuracy: 0.8901\n",
            "Epoch 13/20\n",
            "195/199 [============================>.] - ETA: 0s - loss: 0.5202 - accuracy: 0.7612\n",
            "Epoch 13: val_accuracy did not improve from 0.97984\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 0.5153 - accuracy: 0.7642 - val_loss: 0.2580 - val_accuracy: 0.9604\n",
            "Epoch 14/20\n",
            "198/199 [============================>.] - ETA: 0s - loss: 0.4790 - accuracy: 0.7773\n",
            "Epoch 14: val_accuracy did not improve from 0.97984\n",
            "199/199 [==============================] - 4s 22ms/step - loss: 0.4787 - accuracy: 0.7774 - val_loss: 0.1520 - val_accuracy: 0.9703\n",
            "Epoch 15/20\n",
            "198/199 [============================>.] - ETA: 0s - loss: 0.4618 - accuracy: 0.8087\n",
            "Epoch 15: val_accuracy did not improve from 0.97984\n",
            "199/199 [==============================] - 3s 16ms/step - loss: 0.4616 - accuracy: 0.8088 - val_loss: 0.1608 - val_accuracy: 0.9660\n",
            "Epoch 16/20\n",
            "195/199 [============================>.] - ETA: 0s - loss: 0.4426 - accuracy: 0.8063\n",
            "Epoch 16: val_accuracy did not improve from 0.97984\n",
            "199/199 [==============================] - 3s 16ms/step - loss: 0.4461 - accuracy: 0.8000 - val_loss: 0.5245 - val_accuracy: 0.8213\n",
            "Epoch 17/20\n",
            "196/199 [============================>.] - ETA: 0s - loss: 0.4783 - accuracy: 0.7616\n",
            "Epoch 17: val_accuracy did not improve from 0.97984\n",
            "199/199 [==============================] - 3s 16ms/step - loss: 0.4792 - accuracy: 0.7615 - val_loss: 0.4595 - val_accuracy: 0.8638\n",
            "Epoch 18/20\n",
            "198/199 [============================>.] - ETA: 0s - loss: 0.5055 - accuracy: 0.7726\n",
            "Epoch 18: val_accuracy did not improve from 0.97984\n",
            "199/199 [==============================] - 4s 22ms/step - loss: 0.5054 - accuracy: 0.7727 - val_loss: 0.1816 - val_accuracy: 0.9717\n",
            "Epoch 19/20\n",
            "197/199 [============================>.] - ETA: 0s - loss: 0.4712 - accuracy: 0.8114\n",
            "Epoch 19: val_accuracy did not improve from 0.97984\n",
            "199/199 [==============================] - 3s 17ms/step - loss: 0.4702 - accuracy: 0.8111 - val_loss: 0.4400 - val_accuracy: 0.9090\n",
            "Epoch 20/20\n",
            "198/199 [============================>.] - ETA: 0s - loss: 0.4403 - accuracy: 0.8152\n",
            "Epoch 20: val_accuracy did not improve from 0.97984\n",
            "199/199 [==============================] - 3s 16ms/step - loss: 0.4401 - accuracy: 0.8153 - val_loss: 0.1601 - val_accuracy: 0.9609\n",
            "Epoch 1/20\n",
            "197/199 [============================>.] - ETA: 0s - loss: 0.8026 - accuracy: 0.5173\n",
            "Epoch 1: val_accuracy improved from -inf to 0.89566, saving model to model_875_marit.h5\n",
            "199/199 [==============================] - 5s 24ms/step - loss: 0.8033 - accuracy: 0.5194 - val_loss: 0.5549 - val_accuracy: 0.8957\n",
            "Epoch 2/20\n",
            "195/199 [============================>.] - ETA: 0s - loss: 0.6438 - accuracy: 0.6340\n",
            "Epoch 2: val_accuracy improved from 0.89566 to 0.97630, saving model to model_875_marit.h5\n",
            "199/199 [==============================] - 5s 23ms/step - loss: 0.6367 - accuracy: 0.6394 - val_loss: 0.2899 - val_accuracy: 0.9763\n",
            "Epoch 3/20\n",
            "196/199 [============================>.] - ETA: 0s - loss: 0.6038 - accuracy: 0.6909\n",
            "Epoch 3: val_accuracy did not improve from 0.97630\n",
            "199/199 [==============================] - 3s 16ms/step - loss: 0.6003 - accuracy: 0.6924 - val_loss: 0.3711 - val_accuracy: 0.9661\n",
            "Epoch 4/20\n",
            "195/199 [============================>.] - ETA: 0s - loss: 0.5783 - accuracy: 0.7305\n",
            "Epoch 4: val_accuracy did not improve from 0.97630\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 0.5798 - accuracy: 0.7211 - val_loss: 0.5944 - val_accuracy: 0.8143\n",
            "Epoch 5/20\n",
            "197/199 [============================>.] - ETA: 0s - loss: 0.5928 - accuracy: 0.7061\n",
            "Epoch 5: val_accuracy did not improve from 0.97630\n",
            "199/199 [==============================] - 3s 17ms/step - loss: 0.5913 - accuracy: 0.7066 - val_loss: 0.4534 - val_accuracy: 0.9278\n",
            "Epoch 6/20\n",
            "197/199 [============================>.] - ETA: 0s - loss: 0.5362 - accuracy: 0.7518\n",
            "Epoch 6: val_accuracy did not improve from 0.97630\n",
            "199/199 [==============================] - 4s 20ms/step - loss: 0.5367 - accuracy: 0.7530 - val_loss: 0.3255 - val_accuracy: 0.9443\n",
            "Epoch 7/20\n",
            "197/199 [============================>.] - ETA: 0s - loss: 0.5426 - accuracy: 0.7324\n",
            "Epoch 7: val_accuracy did not improve from 0.97630\n",
            "199/199 [==============================] - 3s 16ms/step - loss: 0.5446 - accuracy: 0.7333 - val_loss: 0.5494 - val_accuracy: 0.7969\n",
            "Epoch 8/20\n",
            "197/199 [============================>.] - ETA: 0s - loss: 0.5061 - accuracy: 0.7741\n",
            "Epoch 8: val_accuracy did not improve from 0.97630\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 0.5130 - accuracy: 0.7747 - val_loss: 1.8492 - val_accuracy: 0.0699\n",
            "Epoch 9/20\n",
            "198/199 [============================>.] - ETA: 0s - loss: 0.4717 - accuracy: 0.8080\n",
            "Epoch 9: val_accuracy did not improve from 0.97630\n",
            "199/199 [==============================] - 4s 18ms/step - loss: 0.4717 - accuracy: 0.8080 - val_loss: 0.4747 - val_accuracy: 0.8580\n",
            "Epoch 10/20\n",
            "199/199 [==============================] - ETA: 0s - loss: 0.5052 - accuracy: 0.7865\n",
            "Epoch 10: val_accuracy did not improve from 0.97630\n",
            "199/199 [==============================] - 4s 21ms/step - loss: 0.5052 - accuracy: 0.7865 - val_loss: 0.3210 - val_accuracy: 0.9524\n",
            "Epoch 11/20\n",
            "196/199 [============================>.] - ETA: 0s - loss: 0.4986 - accuracy: 0.7694\n",
            "Epoch 11: val_accuracy did not improve from 0.97630\n",
            "199/199 [==============================] - 3s 16ms/step - loss: 0.4967 - accuracy: 0.7709 - val_loss: 0.3789 - val_accuracy: 0.9389\n",
            "Epoch 12/20\n",
            "198/199 [============================>.] - ETA: 0s - loss: 0.5076 - accuracy: 0.7872\n",
            "Epoch 12: val_accuracy did not improve from 0.97630\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 0.5075 - accuracy: 0.7872 - val_loss: 0.5027 - val_accuracy: 0.8741\n",
            "Epoch 13/20\n",
            "197/199 [============================>.] - ETA: 0s - loss: 0.4738 - accuracy: 0.8112\n",
            "Epoch 13: val_accuracy did not improve from 0.97630\n",
            "199/199 [==============================] - 3s 17ms/step - loss: 0.4725 - accuracy: 0.8114 - val_loss: 0.2435 - val_accuracy: 0.9486\n",
            "Epoch 14/20\n",
            "198/199 [============================>.] - ETA: 0s - loss: 0.4982 - accuracy: 0.7959\n",
            "Epoch 14: val_accuracy did not improve from 0.97630\n",
            "199/199 [==============================] - 4s 21ms/step - loss: 0.4980 - accuracy: 0.7961 - val_loss: 0.2312 - val_accuracy: 0.9677\n",
            "Epoch 15/20\n",
            "199/199 [==============================] - ETA: 0s - loss: 0.4647 - accuracy: 0.8188\n",
            "Epoch 15: val_accuracy did not improve from 0.97630\n",
            "199/199 [==============================] - 3s 16ms/step - loss: 0.4647 - accuracy: 0.8188 - val_loss: 0.7736 - val_accuracy: 0.6114\n",
            "Epoch 16/20\n",
            "196/199 [============================>.] - ETA: 0s - loss: 0.4234 - accuracy: 0.8367\n",
            "Epoch 16: val_accuracy did not improve from 0.97630\n",
            "199/199 [==============================] - 3s 16ms/step - loss: 0.4257 - accuracy: 0.8312 - val_loss: 0.4509 - val_accuracy: 0.8832\n",
            "Epoch 17/20\n",
            "197/199 [============================>.] - ETA: 0s - loss: 0.4733 - accuracy: 0.8140\n",
            "Epoch 17: val_accuracy did not improve from 0.97630\n",
            "199/199 [==============================] - 4s 21ms/step - loss: 0.4750 - accuracy: 0.8144 - val_loss: 0.3893 - val_accuracy: 0.8861\n",
            "Epoch 18/20\n",
            "197/199 [============================>.] - ETA: 0s - loss: 0.4587 - accuracy: 0.8218\n",
            "Epoch 18: val_accuracy did not improve from 0.97630\n",
            "199/199 [==============================] - 4s 20ms/step - loss: 0.4566 - accuracy: 0.8226 - val_loss: 0.1440 - val_accuracy: 0.9760\n",
            "Epoch 19/20\n",
            "197/199 [============================>.] - ETA: 0s - loss: 0.4154 - accuracy: 0.8441\n",
            "Epoch 19: val_accuracy did not improve from 0.97630\n",
            "199/199 [==============================] - 3s 17ms/step - loss: 0.4148 - accuracy: 0.8437 - val_loss: 0.4539 - val_accuracy: 0.8989\n",
            "Epoch 20/20\n",
            "197/199 [============================>.] - ETA: 0s - loss: 0.4483 - accuracy: 0.8281\n",
            "Epoch 20: val_accuracy did not improve from 0.97630\n",
            "199/199 [==============================] - 3s 15ms/step - loss: 0.4463 - accuracy: 0.8286 - val_loss: 0.1520 - val_accuracy: 0.9698\n",
            "102/102 [==============================] - 0s 3ms/step\n",
            "102/102 [==============================] - 0s 3ms/step\n",
            "102/102 [==============================] - 1s 5ms/step\n",
            "102/102 [==============================] - 1s 5ms/step\n",
            "102/102 [==============================] - 1s 5ms/step\n",
            "102/102 [==============================] - 1s 4ms/step\n",
            "102/102 [==============================] - 0s 3ms/step\n",
            "102/102 [==============================] - 0s 3ms/step\n",
            "Not Married (50): 0.8994794700058242\n",
            "Else (50): 0.9202196382428941\n",
            "Not Married (62.5): 0.8772932440302854\n",
            "Else (37.5): 0.9115116279069768\n",
            "Not Married (75): 0.9033925451368667\n",
            "Else (25): 0.9235142118863049\n",
            "Not Married (87.5): 0.789640361094933\n",
            "Else (12.5): 0.8311369509043928\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"1bba9720-2355-44b0-bfcb-250d85d33019\" class=\"plotly-graph-div\" style=\"height:500px; width:600px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1bba9720-2355-44b0-bfcb-250d85d33019\")) {                    Plotly.newPlot(                        \"1bba9720-2355-44b0-bfcb-250d85d33019\",                        [{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(200, 20, 20, 1.0)\",\"width\":3},\"name\":\"\\u003cb\\u003eOthers\\u003c\\u002fb\\u003e\",\"showlegend\":true,\"x\":[50,62.5,75,87.5],\"y\":[0.9202196382428941,0.9115116279069768,0.9235142118863049,0.8311369509043928],\"type\":\"scatter\"},{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(20, 20, 200, 1)\",\"width\":3},\"name\":\"\\u003cb\\u003eNever been married\\u003c\\u002fb\\u003e\",\"showlegend\":true,\"x\":[50,62.5,75,87.5],\"y\":[0.8994794700058242,0.8772932440302854,0.9033925451368667,0.789640361094933],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"title\":{\"x\":0.5},\"legend\":{\"yanchor\":\"bottom\",\"xanchor\":\"right\",\"x\":0.95,\"y\":0.01},\"xaxis\":{\"title\":{\"text\":\"\\u003cb\\u003ePercentage of 'Never been married'\\u003c\\u002fb\\u003e\"},\"range\":[40,100],\"gridcolor\":\"rgba(5, 5, 5, 0.5)\",\"constrain\":\"domain\",\"linecolor\":\"black\",\"dtick\":12.5},\"yaxis\":{\"title\":{\"text\":\"\\u003cb\\u003eAUC\\u003c\\u002fb\\u003e\"},\"range\":[0.689640361094933,1.023514211886305],\"gridcolor\":\"rgba(5, 5, 5, 0.5)\",\"scaleanchor\":\"x\",\"scaleratio\":170,\"linecolor\":\"black\"},\"width\":600,\"height\":500,\"font\":{\"family\":\"Times New Roman\",\"size\":18,\"color\":\"Black\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1bba9720-2355-44b0-bfcb-250d85d33019');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "notmarried_sample=notmarried.sample(12680, random_state=43)\n",
        "elsee_sample=elsee.sample(12680, random_state=43)\n",
        "notmarried_sample=notmarried_sample.sample(int(0.5*len(notmarried_sample)), random_state=43)\n",
        "elsee_sample=elsee_sample.sample(int(0.5*len(elsee_sample)), random_state=43)\n",
        "data=pd.concat([notmarried_sample, elsee_sample])\n",
        "X_sample=data.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "y_sample=data['UDPYOPI_1 - Yes']\n",
        "class_weights_sample = compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(y_sample),\n",
        "                                        y = y_sample\n",
        "                                    )\n",
        "sklearn_weights = dict(enumerate(class_weights_sample))\n",
        "class_weights_sample=sklearn_weights\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "algorithm()\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath='model_50_marit.h5',\n",
        "                               monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "algorithm()\n",
        "callbacks = [checkpoint]\n",
        "number_of_features=44\n",
        "algorithm()\n",
        "network = models.Sequential()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=1000, activation=\"relu\", input_shape=(\n",
        "number_of_features,)))\n",
        "algorithm()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=1000, activation=\"relu\"))\n",
        "algorithm()\n",
        "# Add fully connected layer with a sigmoid activation function\n",
        "network.add(layers.Dense(units=1, activation=\"sigmoid\")) # No activation for regression\n",
        "# Compile neural network\n",
        "algorithm()\n",
        "network.compile(loss=\"binary_crossentropy\", # Cross-entropy # \"mse\" for regression\n",
        "optimizer=\"sgd\", # Root Mean Square Propagation\n",
        "metrics=[\"accuracy\"]) # Accuracy performance metric\n",
        "history = network.fit(X_sample, # Features\n",
        "y_sample, # Target vector\n",
        "epochs=20,\n",
        "verbose=1,\n",
        "callbacks=callbacks, # Print description after each epoch\n",
        "batch_size=64,\n",
        "class_weight=class_weights_sample,\n",
        "validation_data=(X_for_test, y_for_test))\n",
        "\n",
        "###################################################################\n",
        "\n",
        "notmarried_sample=notmarried.sample(12680, random_state=43)\n",
        "elsee_sample=elsee.sample(12680, random_state=43)\n",
        "notmarried_sample=notmarried_sample.sample(int(0.625*len(notmarried_sample)), random_state=43)\n",
        "elsee_sample=elsee_sample.sample(int(0.375*len(elsee_sample)), random_state=43)\n",
        "data=pd.concat([notmarried_sample, elsee_sample])\n",
        "\n",
        "X_sample=data.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "y_sample=data['UDPYOPI_1 - Yes']\n",
        "class_weights_sample = compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(y_sample),\n",
        "                                        y = y_sample\n",
        "                                    )\n",
        "sklearn_weights = dict(enumerate(class_weights_sample))\n",
        "class_weights_sample=sklearn_weights\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "algorithm()\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath='model_625_marit.h5',\n",
        "                               monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "algorithm()\n",
        "callbacks = [checkpoint]\n",
        "number_of_features=44\n",
        "algorithm()\n",
        "network = models.Sequential()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=1000, activation=\"relu\", input_shape=(\n",
        "number_of_features,)))\n",
        "algorithm()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=1000, activation=\"relu\"))\n",
        "algorithm()\n",
        "# Add fully connected layer with a sigmoid activation function\n",
        "network.add(layers.Dense(units=1, activation=\"sigmoid\")) # No activation for regression\n",
        "# Compile neural network\n",
        "algorithm()\n",
        "network.compile(loss=\"binary_crossentropy\", # Cross-entropy # \"mse\" for regression\n",
        "optimizer=\"sgd\", # Root Mean Square Propagation\n",
        "metrics=[\"accuracy\"]) # Accuracy performance metric\n",
        "history = network.fit(X_sample, # Features\n",
        "y_sample, # Target vector\n",
        "epochs=20,\n",
        "verbose=1,\n",
        "callbacks=callbacks, # Print description after each epoch\n",
        "batch_size=64,\n",
        "class_weight=class_weights_sample,\n",
        "validation_data=(X_for_test, y_for_test))\n",
        "\n",
        "##############################################################\n",
        "\n",
        "notmarried_sample=notmarried.sample(12680, random_state=43)\n",
        "elsee_sample=elsee.sample(12680, random_state=43)\n",
        "notmarried_sample=notmarried_sample.sample(int(0.75*len(notmarried_sample)), random_state=43)\n",
        "elsee_sample=elsee_sample.sample(int(0.25*len(elsee_sample)), random_state=43)\n",
        "data=pd.concat([notmarried_sample, elsee_sample])\n",
        "\n",
        "X_sample=data.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "y_sample=data['UDPYOPI_1 - Yes']\n",
        "class_weights_sample = compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(y_sample),\n",
        "                                        y = y_sample\n",
        "                                    )\n",
        "sklearn_weights = dict(enumerate(class_weights_sample))\n",
        "class_weights_sample=sklearn_weights\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "algorithm()\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath='model_75_marit.h5',\n",
        "                               monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "algorithm()\n",
        "callbacks = [checkpoint]\n",
        "number_of_features=44\n",
        "algorithm()\n",
        "network = models.Sequential()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=1000, activation=\"relu\", input_shape=(\n",
        "number_of_features,)))\n",
        "algorithm()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=1000, activation=\"relu\"))\n",
        "algorithm()\n",
        "# Add fully connected layer with a sigmoid activation function\n",
        "network.add(layers.Dense(units=1, activation=\"sigmoid\")) # No activation for regression\n",
        "# Compile neural network\n",
        "algorithm()\n",
        "network.compile(loss=\"binary_crossentropy\", # Cross-entropy # \"mse\" for regression\n",
        "optimizer=\"sgd\", # Root Mean Square Propagation\n",
        "metrics=[\"accuracy\"]) # Accuracy performance metric\n",
        "history = network.fit(X_sample, # Features\n",
        "y_sample, # Target vector\n",
        "epochs=20,\n",
        "verbose=1,\n",
        "callbacks=callbacks, # Print description after each epoch\n",
        "batch_size=64,\n",
        "class_weight=class_weights_sample,\n",
        "validation_data=(X_for_test, y_for_test))\n",
        "\n",
        "#########################################################################\n",
        "\n",
        "notmarried_sample=notmarried.sample(12680, random_state=43)\n",
        "elsee_sample=elsee.sample(12680, random_state=43)\n",
        "notmarried_sample=notmarried_sample.sample(int(0.875*len(notmarried_sample)), random_state=43)\n",
        "elsee_sample=elsee_sample.sample(int(0.125*len(elsee_sample)), random_state=43)\n",
        "data=pd.concat([notmarried_sample, elsee_sample])\n",
        "\n",
        "X_sample=data.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "y_sample=data['UDPYOPI_1 - Yes']\n",
        "class_weights_sample = compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(y_sample),\n",
        "                                        y = y_sample\n",
        "                                    )\n",
        "sklearn_weights = dict(enumerate(class_weights_sample))\n",
        "class_weights_sample=sklearn_weights\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "algorithm()\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath='model_875_marit.h5',\n",
        "                               monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "algorithm()\n",
        "callbacks = [checkpoint]\n",
        "number_of_features=44\n",
        "algorithm()\n",
        "network = models.Sequential()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=1000, activation=\"relu\", input_shape=(\n",
        "number_of_features,)))\n",
        "algorithm()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=1000, activation=\"relu\"))\n",
        "algorithm()\n",
        "# Add fully connected layer with a sigmoid activation function\n",
        "network.add(layers.Dense(units=1, activation=\"sigmoid\")) # No activation for regression\n",
        "# Compile neural network\n",
        "algorithm()\n",
        "network.compile(loss=\"binary_crossentropy\", # Cross-entropy # \"mse\" for regression\n",
        "optimizer=\"sgd\", # Root Mean Square Propagation\n",
        "metrics=[\"accuracy\"]) # Accuracy performance metric\n",
        "history = network.fit(X_sample, # Features\n",
        "y_sample, # Target vector\n",
        "epochs=20,\n",
        "verbose=1,\n",
        "callbacks=callbacks, # Print description after each epoch\n",
        "batch_size=64,\n",
        "class_weight=class_weights_sample,\n",
        "validation_data=(X_for_test, y_for_test))\n",
        "\n",
        "prob1_50=load_model('model_50_marit.h5').predict(notmarried_predictors_test)\n",
        "prob2_50=load_model('model_50_marit.h5').predict(elsee_predictors_test)\n",
        "prob1_625=load_model('model_625_marit.h5').predict(notmarried_predictors_test)\n",
        "prob2_625=load_model('model_625_marit.h5').predict(elsee_predictors_test)\n",
        "prob1_75=load_model('model_75_marit.h5').predict(notmarried_predictors_test)\n",
        "prob2_75=load_model('model_75_marit.h5').predict(elsee_predictors_test)\n",
        "prob1_875=load_model('model_875_marit.h5').predict(notmarried_predictors_test)\n",
        "prob2_875=load_model('model_875_marit.h5').predict(elsee_predictors_test)\n",
        "\n",
        "print('Not Married (50):', roc_auc_score(notmarried_target_test, prob1_50))\n",
        "print('Else (50):', roc_auc_score(elsee_target_test, prob2_50))\n",
        "print('Not Married (62.5):', roc_auc_score(notmarried_target_test, prob1_625))\n",
        "print('Else (37.5):', roc_auc_score(elsee_target_test, prob2_625))\n",
        "print('Not Married (75):', roc_auc_score(notmarried_target_test, prob1_75))\n",
        "print('Else (25):', roc_auc_score(elsee_target_test, prob2_75))\n",
        "print('Not Married (87.5):', roc_auc_score(notmarried_target_test, prob1_875))\n",
        "print('Else (12.5):', roc_auc_score(elsee_target_test, prob2_875))\n",
        "\n",
        "# x axis values\n",
        "x = [50, 62.5, 75, 87.5]\n",
        "# corresponding y axis values\n",
        "y = [roc_auc_score(elsee_target_test, prob2_50),roc_auc_score(elsee_target_test, prob2_625),\n",
        "     roc_auc_score(elsee_target_test, prob2_75),roc_auc_score(elsee_target_test, prob2_875)]\n",
        "z = [roc_auc_score(notmarried_target_test, prob1_50),roc_auc_score(notmarried_target_test, prob1_625),\n",
        "     roc_auc_score(notmarried_target_test, prob1_75),roc_auc_score(notmarried_target_test, prob1_875)]\n",
        "c_line_main1 = 'rgba(200, 20, 20, 1.0)'\n",
        "c_line_main2 = 'rgba(20, 20, 200, 1)'\n",
        "fig = go.Figure([\n",
        "\n",
        "    go.Scatter(\n",
        "        x          = x,\n",
        "        y          = y,\n",
        "        line       = dict(color=c_line_main1, width=3),\n",
        "        hoverinfo  = \"skip\",\n",
        "        showlegend = True,\n",
        "        name       = f'<b>Others</b>'),\n",
        "    go.Scatter(\n",
        "        x          = x,\n",
        "        y          = z,\n",
        "        line       = dict(color=c_line_main2, width=3),\n",
        "        hoverinfo  = \"skip\",\n",
        "        showlegend = True,\n",
        "        name       = f'<b>Never been married</b>')\n",
        "    ])\n",
        "fig.add_shape(\n",
        "        type ='line',\n",
        "        line =dict(dash='dash'),\n",
        "        x0=0, x1=1, y0=0, y1=1\n",
        "    )\n",
        "fig.update_layout(\n",
        "        template    = 'plotly_white',\n",
        "        title_x     = 0.5,\n",
        "        xaxis_title = \"<b>Percentage of 'Never been married'</b>\",\n",
        "        yaxis_title = \"<b>AUC</b>\",\n",
        "        width       = 600,\n",
        "        height      = 500,\n",
        "        legend      = dict(\n",
        "            yanchor=\"bottom\",\n",
        "            xanchor=\"right\",\n",
        "            x=0.95,\n",
        "            y=0.01,\n",
        "        )\n",
        "    )\n",
        "fig.update_layout(\n",
        "        font=dict(\n",
        "        family=\"Times New Roman\",\n",
        "        size=18,  # Set the font size here\n",
        "        color=\"Black\"\n",
        "        )\n",
        "    )\n",
        "fig.update_layout(\n",
        "        font=dict(\n",
        "        family=\"Times New Roman\",\n",
        "        size=18,  # Set the font size here\n",
        "        color=\"Black\"\n",
        "        )\n",
        "    )\n",
        "fig.update_yaxes(\n",
        "        range       = [min(min(y), min(z))-0.1, max(max(y), max(z))+0.1],\n",
        "        gridcolor   = c_grid,\n",
        "        scaleanchor = \"x\",\n",
        "        scaleratio  = 170,\n",
        "        linecolor   = 'black')\n",
        "fig.update_xaxes(\n",
        "        range       = [40, 100],\n",
        "        gridcolor   = c_grid,\n",
        "        constrain   = 'domain',\n",
        "        linecolor   = 'black',dtick=12.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3de5d96",
      "metadata": {
        "id": "b3de5d96"
      },
      "outputs": [],
      "source": [
        "work=train.drop(X_train[X_train['WRK35WKUS_1 - Yes'] == 0].index)\n",
        "elsee=train.drop(X_train[X_train['WRK35WKUS_1 - Yes'] == 1].index)\n",
        "work_test=test.drop(X_test[X_test['WRK35WKUS_1 - Yes'] == 0].index)\n",
        "work_test=work_test.sample(1584, random_state=43)\n",
        "work_predictors_test=work_test.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "work_target_test=work_test['UDPYOPI_1 - Yes']\n",
        "elsee_test=test.drop(X_test[X_test['WRK35WKUS_1 - Yes'] == 1].index)\n",
        "elsee_test=elsee_test.sample(1584, random_state=43)\n",
        "elsee_predictors_test=elsee_test.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "elsee_target_test=elsee_test['UDPYOPI_1 - Yes']\n",
        "data_test=pd.concat([work_test, elsee_test])\n",
        "X_for_test=data_test.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "y_for_test=data_test['UDPYOPI_1 - Yes']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(work))\n",
        "print(len(elsee))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDcnJZ7m2T1d",
        "outputId": "740bd383-0f6e-4441-f54c-057bd77edc0a"
      },
      "id": "PDcnJZ7m2T1d",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6290\n",
            "20040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7ec2270",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c7ec2270",
        "outputId": "e2ed7db7-3fde-4977-9a7e-649df8171dd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "95/99 [===========================>..] - ETA: 0s - loss: 0.9865 - accuracy: 0.5044\n",
            "Epoch 1: val_accuracy improved from -inf to 0.96843, saving model to model_50_work.h5\n",
            "99/99 [==============================] - 2s 18ms/step - loss: 0.9831 - accuracy: 0.5119 - val_loss: 0.4515 - val_accuracy: 0.9684\n",
            "Epoch 2/20\n",
            "95/99 [===========================>..] - ETA: 0s - loss: 0.7542 - accuracy: 0.5188\n",
            "Epoch 2: val_accuracy did not improve from 0.96843\n",
            "99/99 [==============================] - 1s 15ms/step - loss: 0.7568 - accuracy: 0.5057 - val_loss: 0.7411 - val_accuracy: 0.2045\n",
            "Epoch 3/20\n",
            "96/99 [============================>.] - ETA: 0s - loss: 0.6927 - accuracy: 0.4941\n",
            "Epoch 3: val_accuracy did not improve from 0.96843\n",
            "99/99 [==============================] - 1s 15ms/step - loss: 0.6954 - accuracy: 0.4841 - val_loss: 0.7079 - val_accuracy: 0.5543\n",
            "Epoch 4/20\n",
            "99/99 [==============================] - ETA: 0s - loss: 0.6780 - accuracy: 0.4987\n",
            "Epoch 4: val_accuracy did not improve from 0.96843\n",
            "99/99 [==============================] - 2s 16ms/step - loss: 0.6780 - accuracy: 0.4987 - val_loss: 0.5856 - val_accuracy: 0.9274\n",
            "Epoch 5/20\n",
            "99/99 [==============================] - ETA: 0s - loss: 0.6563 - accuracy: 0.5809\n",
            "Epoch 5: val_accuracy did not improve from 0.96843\n",
            "99/99 [==============================] - 2s 18ms/step - loss: 0.6563 - accuracy: 0.5809 - val_loss: 0.6515 - val_accuracy: 0.7150\n",
            "Epoch 6/20\n",
            "98/99 [============================>.] - ETA: 0s - loss: 0.6509 - accuracy: 0.6060\n",
            "Epoch 6: val_accuracy did not improve from 0.96843\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 0.6501 - accuracy: 0.6064 - val_loss: 0.5710 - val_accuracy: 0.8867\n",
            "Epoch 7/20\n",
            "96/99 [============================>.] - ETA: 0s - loss: 0.6094 - accuracy: 0.6229\n",
            "Epoch 7: val_accuracy did not improve from 0.96843\n",
            "99/99 [==============================] - 2s 19ms/step - loss: 0.6274 - accuracy: 0.6196 - val_loss: 0.6624 - val_accuracy: 0.6742\n",
            "Epoch 8/20\n",
            "95/99 [===========================>..] - ETA: 0s - loss: 0.6146 - accuracy: 0.6883\n",
            "Epoch 8: val_accuracy improved from 0.96843 to 0.98580, saving model to model_50_work.h5\n",
            "99/99 [==============================] - 2s 16ms/step - loss: 0.6022 - accuracy: 0.6950 - val_loss: 0.3285 - val_accuracy: 0.9858\n",
            "Epoch 9/20\n",
            "97/99 [============================>.] - ETA: 0s - loss: 0.6193 - accuracy: 0.6815\n",
            "Epoch 9: val_accuracy did not improve from 0.98580\n",
            "99/99 [==============================] - 2s 16ms/step - loss: 0.6194 - accuracy: 0.6743 - val_loss: 0.5811 - val_accuracy: 0.7951\n",
            "Epoch 10/20\n",
            "98/99 [============================>.] - ETA: 0s - loss: 0.6171 - accuracy: 0.6446\n",
            "Epoch 10: val_accuracy did not improve from 0.98580\n",
            "99/99 [==============================] - 2s 15ms/step - loss: 0.6160 - accuracy: 0.6455 - val_loss: 0.3286 - val_accuracy: 0.9842\n",
            "Epoch 11/20\n",
            "98/99 [============================>.] - ETA: 0s - loss: 0.6569 - accuracy: 0.6427\n",
            "Epoch 11: val_accuracy did not improve from 0.98580\n",
            "99/99 [==============================] - 2s 15ms/step - loss: 0.6559 - accuracy: 0.6433 - val_loss: 0.4461 - val_accuracy: 0.9729\n",
            "Epoch 12/20\n",
            "97/99 [============================>.] - ETA: 0s - loss: 0.6067 - accuracy: 0.6917\n",
            "Epoch 12: val_accuracy did not improve from 0.98580\n",
            "99/99 [==============================] - 2s 16ms/step - loss: 0.6018 - accuracy: 0.6953 - val_loss: 0.3791 - val_accuracy: 0.9773\n",
            "Epoch 13/20\n",
            "98/99 [============================>.] - ETA: 0s - loss: 0.5663 - accuracy: 0.7296\n",
            "Epoch 13: val_accuracy did not improve from 0.98580\n",
            "99/99 [==============================] - 2s 20ms/step - loss: 0.5701 - accuracy: 0.7303 - val_loss: 1.6103 - val_accuracy: 0.0527\n",
            "Epoch 14/20\n",
            "99/99 [==============================] - ETA: 0s - loss: 0.6316 - accuracy: 0.6913\n",
            "Epoch 14: val_accuracy did not improve from 0.98580\n",
            "99/99 [==============================] - 3s 25ms/step - loss: 0.6316 - accuracy: 0.6913 - val_loss: 0.3676 - val_accuracy: 0.9684\n",
            "Epoch 15/20\n",
            "99/99 [==============================] - ETA: 0s - loss: 0.5480 - accuracy: 0.7826\n",
            "Epoch 15: val_accuracy did not improve from 0.98580\n",
            "99/99 [==============================] - 2s 17ms/step - loss: 0.5480 - accuracy: 0.7826 - val_loss: 0.3078 - val_accuracy: 0.9779\n",
            "Epoch 16/20\n",
            "95/99 [===========================>..] - ETA: 0s - loss: 0.5318 - accuracy: 0.7860\n",
            "Epoch 16: val_accuracy did not improve from 0.98580\n",
            "99/99 [==============================] - 1s 15ms/step - loss: 0.5251 - accuracy: 0.7813 - val_loss: 0.3615 - val_accuracy: 0.9760\n",
            "Epoch 17/20\n",
            "96/99 [============================>.] - ETA: 0s - loss: 0.4957 - accuracy: 0.7520\n",
            "Epoch 17: val_accuracy did not improve from 0.98580\n",
            "99/99 [==============================] - 2s 16ms/step - loss: 0.5226 - accuracy: 0.7551 - val_loss: 4.0421 - val_accuracy: 0.0524\n",
            "Epoch 18/20\n",
            "96/99 [============================>.] - ETA: 0s - loss: 0.6432 - accuracy: 0.5864\n",
            "Epoch 18: val_accuracy improved from 0.98580 to 0.99053, saving model to model_50_work.h5\n",
            "99/99 [==============================] - 2s 16ms/step - loss: 0.6345 - accuracy: 0.5957 - val_loss: 0.2523 - val_accuracy: 0.9905\n",
            "Epoch 19/20\n",
            "98/99 [============================>.] - ETA: 0s - loss: 0.5864 - accuracy: 0.7352\n",
            "Epoch 19: val_accuracy did not improve from 0.99053\n",
            "99/99 [==============================] - 2s 16ms/step - loss: 0.5858 - accuracy: 0.7349 - val_loss: 0.5632 - val_accuracy: 0.8157\n",
            "Epoch 20/20\n",
            "97/99 [============================>.] - ETA: 0s - loss: 0.5588 - accuracy: 0.7310\n",
            "Epoch 20: val_accuracy did not improve from 0.99053\n",
            "99/99 [==============================] - 2s 17ms/step - loss: 0.5601 - accuracy: 0.7233 - val_loss: 0.5780 - val_accuracy: 0.7923\n",
            "Epoch 1/20\n",
            "98/99 [============================>.] - ETA: 0s - loss: 0.9351 - accuracy: 0.5078\n",
            "Epoch 1: val_accuracy improved from -inf to 0.98643, saving model to model_625_work.h5\n",
            "99/99 [==============================] - 3s 29ms/step - loss: 0.9334 - accuracy: 0.5091 - val_loss: 0.4405 - val_accuracy: 0.9864\n",
            "Epoch 2/20\n",
            "96/99 [============================>.] - ETA: 0s - loss: 0.6899 - accuracy: 0.5817\n",
            "Epoch 2: val_accuracy did not improve from 0.98643\n",
            "99/99 [==============================] - 2s 19ms/step - loss: 0.6903 - accuracy: 0.5903 - val_loss: 0.5155 - val_accuracy: 0.9776\n",
            "Epoch 3/20\n",
            "98/99 [============================>.] - ETA: 0s - loss: 0.6633 - accuracy: 0.6296\n",
            "Epoch 3: val_accuracy did not improve from 0.98643\n",
            "99/99 [==============================] - 2s 15ms/step - loss: 0.6627 - accuracy: 0.6282 - val_loss: 0.6333 - val_accuracy: 0.7724\n",
            "Epoch 4/20\n",
            "99/99 [==============================] - ETA: 0s - loss: 0.6346 - accuracy: 0.5854\n",
            "Epoch 4: val_accuracy did not improve from 0.98643\n",
            "99/99 [==============================] - 2s 15ms/step - loss: 0.6346 - accuracy: 0.5854 - val_loss: 0.2310 - val_accuracy: 0.9858\n",
            "Epoch 5/20\n",
            "99/99 [==============================] - ETA: 0s - loss: 0.6223 - accuracy: 0.6764\n",
            "Epoch 5: val_accuracy did not improve from 0.98643\n",
            "99/99 [==============================] - 2s 15ms/step - loss: 0.6223 - accuracy: 0.6764 - val_loss: 0.5578 - val_accuracy: 0.8116\n",
            "Epoch 6/20\n",
            "98/99 [============================>.] - ETA: 0s - loss: 0.6688 - accuracy: 0.5931\n",
            "Epoch 6: val_accuracy did not improve from 0.98643\n",
            "99/99 [==============================] - 2s 16ms/step - loss: 0.6679 - accuracy: 0.5934 - val_loss: 0.5264 - val_accuracy: 0.9028\n",
            "Epoch 7/20\n",
            "98/99 [============================>.] - ETA: 0s - loss: 0.6535 - accuracy: 0.6395\n",
            "Epoch 7: val_accuracy did not improve from 0.98643\n",
            "99/99 [==============================] - 2s 15ms/step - loss: 0.6535 - accuracy: 0.6379 - val_loss: 0.8942 - val_accuracy: 0.1395\n",
            "Epoch 8/20\n",
            "98/99 [============================>.] - ETA: 0s - loss: 0.6522 - accuracy: 0.6277\n",
            "Epoch 8: val_accuracy did not improve from 0.98643\n",
            "99/99 [==============================] - 2s 22ms/step - loss: 0.6517 - accuracy: 0.6263 - val_loss: 0.7122 - val_accuracy: 0.5597\n",
            "Epoch 9/20\n",
            "97/99 [============================>.] - ETA: 0s - loss: 0.5675 - accuracy: 0.7062\n",
            "Epoch 9: val_accuracy did not improve from 0.98643\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 0.5632 - accuracy: 0.7088 - val_loss: 0.3120 - val_accuracy: 0.9776\n",
            "Epoch 10/20\n",
            "96/99 [============================>.] - ETA: 0s - loss: 0.7003 - accuracy: 0.5832\n",
            "Epoch 10: val_accuracy did not improve from 0.98643\n",
            "99/99 [==============================] - 2s 16ms/step - loss: 0.6965 - accuracy: 0.5903 - val_loss: 0.4084 - val_accuracy: 0.9807\n",
            "Epoch 11/20\n",
            "96/99 [============================>.] - ETA: 0s - loss: 0.6367 - accuracy: 0.6470\n",
            "Epoch 11: val_accuracy did not improve from 0.98643\n",
            "99/99 [==============================] - 2s 16ms/step - loss: 0.6534 - accuracy: 0.6422 - val_loss: 0.8109 - val_accuracy: 0.2803\n",
            "Epoch 12/20\n",
            "97/99 [============================>.] - ETA: 0s - loss: 0.5856 - accuracy: 0.6946\n",
            "Epoch 12: val_accuracy did not improve from 0.98643\n",
            "99/99 [==============================] - 2s 16ms/step - loss: 0.5922 - accuracy: 0.6983 - val_loss: 6.3682 - val_accuracy: 0.0451\n",
            "Epoch 13/20\n",
            "99/99 [==============================] - ETA: 0s - loss: 0.7575 - accuracy: 0.4601\n",
            "Epoch 13: val_accuracy improved from 0.98643 to 0.98864, saving model to model_625_work.h5\n",
            "99/99 [==============================] - 2s 16ms/step - loss: 0.7575 - accuracy: 0.4601 - val_loss: 0.3706 - val_accuracy: 0.9886\n",
            "Epoch 14/20\n",
            "99/99 [==============================] - ETA: 0s - loss: 0.6100 - accuracy: 0.6433\n",
            "Epoch 14: val_accuracy did not improve from 0.98864\n",
            "99/99 [==============================] - 2s 16ms/step - loss: 0.6100 - accuracy: 0.6433 - val_loss: 0.4146 - val_accuracy: 0.9735\n",
            "Epoch 15/20\n",
            "95/99 [===========================>..] - ETA: 0s - loss: 0.5842 - accuracy: 0.6658\n",
            "Epoch 15: val_accuracy did not improve from 0.98864\n",
            "99/99 [==============================] - 2s 16ms/step - loss: 0.5793 - accuracy: 0.6624 - val_loss: 0.3485 - val_accuracy: 0.9779\n",
            "Epoch 16/20\n",
            "99/99 [==============================] - ETA: 0s - loss: 0.5705 - accuracy: 0.6888\n",
            "Epoch 16: val_accuracy did not improve from 0.98864\n",
            "99/99 [==============================] - 2s 22ms/step - loss: 0.5705 - accuracy: 0.6888 - val_loss: 0.5058 - val_accuracy: 0.8924\n",
            "Epoch 17/20\n",
            "99/99 [==============================] - ETA: 0s - loss: 0.5835 - accuracy: 0.6891\n",
            "Epoch 17: val_accuracy did not improve from 0.98864\n",
            "99/99 [==============================] - 3s 28ms/step - loss: 0.5835 - accuracy: 0.6891 - val_loss: 0.9312 - val_accuracy: 0.2206\n",
            "Epoch 18/20\n",
            "96/99 [============================>.] - ETA: 0s - loss: 0.5829 - accuracy: 0.6509\n",
            "Epoch 18: val_accuracy did not improve from 0.98864\n",
            "99/99 [==============================] - 2s 16ms/step - loss: 0.5878 - accuracy: 0.6574 - val_loss: 0.3801 - val_accuracy: 0.9628\n",
            "Epoch 19/20\n",
            "97/99 [============================>.] - ETA: 0s - loss: 0.5514 - accuracy: 0.7254\n",
            "Epoch 19: val_accuracy did not improve from 0.98864\n",
            "99/99 [==============================] - 2s 17ms/step - loss: 0.5459 - accuracy: 0.7288 - val_loss: 0.2277 - val_accuracy: 0.9855\n",
            "Epoch 20/20\n",
            "97/99 [============================>.] - ETA: 0s - loss: 0.5694 - accuracy: 0.7463\n",
            "Epoch 20: val_accuracy did not improve from 0.98864\n",
            "99/99 [==============================] - 2s 16ms/step - loss: 0.5669 - accuracy: 0.7436 - val_loss: 0.3855 - val_accuracy: 0.9246\n",
            "Epoch 1/20\n",
            "98/99 [============================>.] - ETA: 0s - loss: 0.9613 - accuracy: 0.5285\n",
            "Epoch 1: val_accuracy improved from -inf to 0.11332, saving model to model_75_work.h5\n",
            "99/99 [==============================] - 4s 32ms/step - loss: 0.9601 - accuracy: 0.5272 - val_loss: 0.7620 - val_accuracy: 0.1133\n",
            "Epoch 2/20\n",
            "96/99 [============================>.] - ETA: 0s - loss: 0.6952 - accuracy: 0.5381\n",
            "Epoch 2: val_accuracy improved from 0.11332 to 0.68813, saving model to model_75_work.h5\n",
            "99/99 [==============================] - 2s 17ms/step - loss: 0.6947 - accuracy: 0.5344 - val_loss: 0.6591 - val_accuracy: 0.6881\n",
            "Epoch 3/20\n",
            "97/99 [============================>.] - ETA: 0s - loss: 0.6648 - accuracy: 0.6036\n",
            "Epoch 3: val_accuracy did not improve from 0.68813\n",
            "99/99 [==============================] - 1s 15ms/step - loss: 0.6628 - accuracy: 0.5961 - val_loss: 0.6875 - val_accuracy: 0.6016\n",
            "Epoch 4/20\n",
            "97/99 [============================>.] - ETA: 0s - loss: 0.6364 - accuracy: 0.6485\n",
            "Epoch 4: val_accuracy improved from 0.68813 to 0.69381, saving model to model_75_work.h5\n",
            "99/99 [==============================] - 2s 16ms/step - loss: 0.6374 - accuracy: 0.6403 - val_loss: 0.6292 - val_accuracy: 0.6938\n",
            "Epoch 5/20\n",
            "98/99 [============================>.] - ETA: 0s - loss: 0.5599 - accuracy: 0.7282\n",
            "Epoch 5: val_accuracy improved from 0.69381 to 0.74432, saving model to model_75_work.h5\n",
            "99/99 [==============================] - 2s 16ms/step - loss: 0.5597 - accuracy: 0.7265 - val_loss: 0.5709 - val_accuracy: 0.7443\n",
            "Epoch 6/20\n",
            "97/99 [============================>.] - ETA: 0s - loss: 0.6841 - accuracy: 0.6356\n",
            "Epoch 6: val_accuracy did not improve from 0.74432\n",
            "99/99 [==============================] - 2s 15ms/step - loss: 0.6826 - accuracy: 0.6282 - val_loss: 0.6570 - val_accuracy: 0.6588\n",
            "Epoch 7/20\n",
            "96/99 [============================>.] - ETA: 0s - loss: 0.5617 - accuracy: 0.7243\n",
            "Epoch 7: val_accuracy did not improve from 0.74432\n",
            "99/99 [==============================] - 2s 15ms/step - loss: 0.6023 - accuracy: 0.7176 - val_loss: 1.1092 - val_accuracy: 0.0306\n",
            "Epoch 8/20\n",
            "98/99 [============================>.] - ETA: 0s - loss: 0.6341 - accuracy: 0.6472\n",
            "Epoch 8: val_accuracy improved from 0.74432 to 0.93750, saving model to model_75_work.h5\n",
            "99/99 [==============================] - 2s 24ms/step - loss: 0.6331 - accuracy: 0.6477 - val_loss: 0.4539 - val_accuracy: 0.9375\n",
            "Epoch 9/20\n",
            "98/99 [============================>.] - ETA: 0s - loss: 0.5873 - accuracy: 0.6849\n",
            "Epoch 9: val_accuracy improved from 0.93750 to 0.97538, saving model to model_75_work.h5\n",
            "99/99 [==============================] - 2s 24ms/step - loss: 0.5862 - accuracy: 0.6858 - val_loss: 0.2680 - val_accuracy: 0.9754\n",
            "Epoch 10/20\n",
            "95/99 [===========================>..] - ETA: 0s - loss: 0.5776 - accuracy: 0.7082\n",
            "Epoch 10: val_accuracy did not improve from 0.97538\n",
            "99/99 [==============================] - 2s 16ms/step - loss: 0.5716 - accuracy: 0.7069 - val_loss: 0.3627 - val_accuracy: 0.9615\n",
            "Epoch 11/20\n",
            "95/99 [===========================>..] - ETA: 0s - loss: 0.5736 - accuracy: 0.6975\n",
            "Epoch 11: val_accuracy did not improve from 0.97538\n",
            "99/99 [==============================] - 2s 15ms/step - loss: 0.5827 - accuracy: 0.6962 - val_loss: 0.4868 - val_accuracy: 0.8718\n",
            "Epoch 12/20\n",
            "98/99 [============================>.] - ETA: 0s - loss: 0.5774 - accuracy: 0.7164\n",
            "Epoch 12: val_accuracy did not improve from 0.97538\n",
            "99/99 [==============================] - 2s 16ms/step - loss: 0.5762 - accuracy: 0.7171 - val_loss: 0.2683 - val_accuracy: 0.9719\n",
            "Epoch 13/20\n",
            "98/99 [============================>.] - ETA: 0s - loss: 0.5409 - accuracy: 0.7412\n",
            "Epoch 13: val_accuracy did not improve from 0.97538\n",
            "99/99 [==============================] - 2s 20ms/step - loss: 0.5397 - accuracy: 0.7419 - val_loss: 0.2093 - val_accuracy: 0.9751\n",
            "Epoch 14/20\n",
            "98/99 [============================>.] - ETA: 0s - loss: 0.5615 - accuracy: 0.7050\n",
            "Epoch 14: val_accuracy did not improve from 0.97538\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 0.5606 - accuracy: 0.7056 - val_loss: 0.2486 - val_accuracy: 0.9662\n",
            "Epoch 15/20\n",
            "98/99 [============================>.] - ETA: 0s - loss: 0.5407 - accuracy: 0.7357\n",
            "Epoch 15: val_accuracy did not improve from 0.97538\n",
            "99/99 [==============================] - 2s 21ms/step - loss: 0.5397 - accuracy: 0.7363 - val_loss: 0.2187 - val_accuracy: 0.9735\n",
            "Epoch 16/20\n",
            "98/99 [============================>.] - ETA: 0s - loss: 0.5767 - accuracy: 0.7199\n",
            "Epoch 16: val_accuracy did not improve from 0.97538\n",
            "99/99 [==============================] - 2s 24ms/step - loss: 0.5755 - accuracy: 0.7206 - val_loss: 0.2470 - val_accuracy: 0.9754\n",
            "Epoch 17/20\n",
            "96/99 [============================>.] - ETA: 0s - loss: 0.5310 - accuracy: 0.7547\n",
            "Epoch 17: val_accuracy did not improve from 0.97538\n",
            "99/99 [==============================] - 1s 15ms/step - loss: 0.5509 - accuracy: 0.7392 - val_loss: 1.2987 - val_accuracy: 0.0467\n",
            "Epoch 18/20\n",
            "95/99 [===========================>..] - ETA: 0s - loss: 0.5654 - accuracy: 0.7079\n",
            "Epoch 18: val_accuracy did not improve from 0.97538\n",
            "99/99 [==============================] - 2s 16ms/step - loss: 0.5656 - accuracy: 0.7152 - val_loss: 0.3417 - val_accuracy: 0.9479\n",
            "Epoch 19/20\n",
            "97/99 [============================>.] - ETA: 0s - loss: 0.5735 - accuracy: 0.7514\n",
            "Epoch 19: val_accuracy improved from 0.97538 to 0.99179, saving model to model_75_work.h5\n",
            "99/99 [==============================] - 2s 16ms/step - loss: 0.5684 - accuracy: 0.7546 - val_loss: 0.3171 - val_accuracy: 0.9918\n",
            "Epoch 20/20\n",
            "98/99 [============================>.] - ETA: 0s - loss: 0.6133 - accuracy: 0.6832\n",
            "Epoch 20: val_accuracy did not improve from 0.99179\n",
            "99/99 [==============================] - 2s 16ms/step - loss: 0.6126 - accuracy: 0.6835 - val_loss: 0.5625 - val_accuracy: 0.8368\n",
            "Epoch 1/20\n",
            "98/99 [============================>.] - ETA: 0s - loss: 0.9611 - accuracy: 0.5402\n",
            "Epoch 1: val_accuracy improved from -inf to 0.94697, saving model to model_875_work.h5\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 0.9594 - accuracy: 0.5410 - val_loss: 0.5181 - val_accuracy: 0.9470\n",
            "Epoch 2/20\n",
            "96/99 [============================>.] - ETA: 0s - loss: 0.6979 - accuracy: 0.5513\n",
            "Epoch 2: val_accuracy did not improve from 0.94697\n",
            "99/99 [==============================] - 2s 17ms/step - loss: 0.6965 - accuracy: 0.5604 - val_loss: 0.5555 - val_accuracy: 0.9350\n",
            "Epoch 3/20\n",
            "96/99 [============================>.] - ETA: 0s - loss: 0.6525 - accuracy: 0.6600\n",
            "Epoch 3: val_accuracy did not improve from 0.94697\n",
            "99/99 [==============================] - 2s 16ms/step - loss: 0.6548 - accuracy: 0.6454 - val_loss: 0.6093 - val_accuracy: 0.8128\n",
            "Epoch 4/20\n",
            "97/99 [============================>.] - ETA: 0s - loss: 0.6424 - accuracy: 0.6535\n",
            "Epoch 4: val_accuracy did not improve from 0.94697\n",
            "99/99 [==============================] - 2s 15ms/step - loss: 0.6369 - accuracy: 0.6573 - val_loss: 0.3338 - val_accuracy: 0.9454\n",
            "Epoch 5/20\n",
            "99/99 [==============================] - ETA: 0s - loss: 0.6280 - accuracy: 0.6221\n",
            "Epoch 5: val_accuracy did not improve from 0.94697\n",
            "99/99 [==============================] - 2s 17ms/step - loss: 0.6280 - accuracy: 0.6221 - val_loss: 0.6376 - val_accuracy: 0.7137\n",
            "Epoch 6/20\n",
            "98/99 [============================>.] - ETA: 0s - loss: 0.6226 - accuracy: 0.6298\n",
            "Epoch 6: val_accuracy did not improve from 0.94697\n",
            "99/99 [==============================] - 2s 16ms/step - loss: 0.6220 - accuracy: 0.6288 - val_loss: 0.5592 - val_accuracy: 0.7910\n",
            "Epoch 7/20\n",
            "99/99 [==============================] - ETA: 0s - loss: 0.5845 - accuracy: 0.6900\n",
            "Epoch 7: val_accuracy did not improve from 0.94697\n",
            "99/99 [==============================] - 2s 15ms/step - loss: 0.5845 - accuracy: 0.6900 - val_loss: 0.6540 - val_accuracy: 0.6638\n",
            "Epoch 8/20\n",
            "97/99 [============================>.] - ETA: 0s - loss: 0.6098 - accuracy: 0.6743\n",
            "Epoch 8: val_accuracy improved from 0.94697 to 0.95802, saving model to model_875_work.h5\n",
            "99/99 [==============================] - 2s 23ms/step - loss: 0.6041 - accuracy: 0.6781 - val_loss: 0.2851 - val_accuracy: 0.9580\n",
            "Epoch 9/20\n",
            "95/99 [===========================>..] - ETA: 0s - loss: 0.6777 - accuracy: 0.5788\n",
            "Epoch 9: val_accuracy improved from 0.95802 to 0.96843, saving model to model_875_work.h5\n",
            "99/99 [==============================] - 2s 22ms/step - loss: 0.6660 - accuracy: 0.5914 - val_loss: 0.3852 - val_accuracy: 0.9684\n",
            "Epoch 10/20\n",
            "98/99 [============================>.] - ETA: 0s - loss: 0.6317 - accuracy: 0.6661\n",
            "Epoch 10: val_accuracy did not improve from 0.96843\n",
            "99/99 [==============================] - 2s 15ms/step - loss: 0.6308 - accuracy: 0.6668 - val_loss: 0.4067 - val_accuracy: 0.9574\n",
            "Epoch 11/20\n",
            "98/99 [============================>.] - ETA: 0s - loss: 0.6112 - accuracy: 0.6834\n",
            "Epoch 11: val_accuracy did not improve from 0.96843\n",
            "99/99 [==============================] - 2s 16ms/step - loss: 0.6104 - accuracy: 0.6837 - val_loss: 0.5047 - val_accuracy: 0.9151\n",
            "Epoch 12/20\n",
            "98/99 [============================>.] - ETA: 0s - loss: 0.5325 - accuracy: 0.7419\n",
            "Epoch 12: val_accuracy improved from 0.96843 to 0.97128, saving model to model_875_work.h5\n",
            "99/99 [==============================] - 2s 16ms/step - loss: 0.5314 - accuracy: 0.7425 - val_loss: 0.2371 - val_accuracy: 0.9713\n",
            "Epoch 13/20\n",
            "96/99 [============================>.] - ETA: 0s - loss: 0.6018 - accuracy: 0.7078\n",
            "Epoch 13: val_accuracy did not improve from 0.97128\n",
            "99/99 [==============================] - 2s 16ms/step - loss: 0.6025 - accuracy: 0.7102 - val_loss: 0.5844 - val_accuracy: 0.8441\n",
            "Epoch 14/20\n",
            "96/99 [============================>.] - ETA: 0s - loss: 0.5364 - accuracy: 0.7446\n",
            "Epoch 14: val_accuracy did not improve from 0.97128\n",
            "99/99 [==============================] - 2s 15ms/step - loss: 0.5298 - accuracy: 0.7490 - val_loss: 0.2359 - val_accuracy: 0.9665\n",
            "Epoch 15/20\n",
            "98/99 [============================>.] - ETA: 0s - loss: 0.4921 - accuracy: 0.7385\n",
            "Epoch 15: val_accuracy did not improve from 0.97128\n",
            "99/99 [==============================] - 2s 15ms/step - loss: 0.4911 - accuracy: 0.7392 - val_loss: 0.1898 - val_accuracy: 0.9703\n",
            "Epoch 16/20\n",
            "98/99 [============================>.] - ETA: 0s - loss: 0.5239 - accuracy: 0.7513\n",
            "Epoch 16: val_accuracy improved from 0.97128 to 0.97254, saving model to model_875_work.h5\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 0.5228 - accuracy: 0.7519 - val_loss: 0.2056 - val_accuracy: 0.9725\n",
            "Epoch 17/20\n",
            "98/99 [============================>.] - ETA: 0s - loss: 0.5551 - accuracy: 0.7224\n",
            "Epoch 17: val_accuracy did not improve from 0.97254\n",
            "99/99 [==============================] - 2s 20ms/step - loss: 0.5547 - accuracy: 0.7215 - val_loss: 0.6176 - val_accuracy: 0.7926\n",
            "Epoch 18/20\n",
            "95/99 [===========================>..] - ETA: 0s - loss: 0.5649 - accuracy: 0.7112\n",
            "Epoch 18: val_accuracy did not improve from 0.97254\n",
            "99/99 [==============================] - 2s 16ms/step - loss: 0.5643 - accuracy: 0.7166 - val_loss: 0.3433 - val_accuracy: 0.9384\n",
            "Epoch 19/20\n",
            "95/99 [===========================>..] - ETA: 0s - loss: 0.5216 - accuracy: 0.7508\n",
            "Epoch 19: val_accuracy did not improve from 0.97254\n",
            "99/99 [==============================] - 2s 17ms/step - loss: 0.5324 - accuracy: 0.7551 - val_loss: 1.1342 - val_accuracy: 0.0455\n",
            "Epoch 20/20\n",
            "99/99 [==============================] - ETA: 0s - loss: 0.5359 - accuracy: 0.7268\n",
            "Epoch 20: val_accuracy did not improve from 0.97254\n",
            "99/99 [==============================] - 2s 16ms/step - loss: 0.5359 - accuracy: 0.7268 - val_loss: 0.3416 - val_accuracy: 0.9328\n",
            "50/50 [==============================] - 0s 3ms/step\n",
            "50/50 [==============================] - 0s 3ms/step\n",
            "50/50 [==============================] - 0s 3ms/step\n",
            "50/50 [==============================] - 0s 3ms/step\n",
            "50/50 [==============================] - 0s 3ms/step\n",
            "50/50 [==============================] - 0s 3ms/step\n",
            "50/50 [==============================] - 0s 3ms/step\n",
            "50/50 [==============================] - 0s 3ms/step\n",
            "Working More Than 35 Hours (50): 0.9469488536155202\n",
            "Else (50): 0.8609911054637865\n",
            "Working More Than 35 Hours (62.5): 0.9130158730158731\n",
            "Else (37.5): 0.7727445997458704\n",
            "Working More Than 35 Hours (75): 0.8722398589065257\n",
            "Else (25): 0.667725540025413\n",
            "Working More Than 35 Hours (87.5): 0.926278659611993\n",
            "Else (12.5): 0.8275095298602286\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"23b646ab-ee0f-4408-9ebc-cecb312dfb10\" class=\"plotly-graph-div\" style=\"height:500px; width:600px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"23b646ab-ee0f-4408-9ebc-cecb312dfb10\")) {                    Plotly.newPlot(                        \"23b646ab-ee0f-4408-9ebc-cecb312dfb10\",                        [{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(200, 20, 20, 1.0)\",\"width\":3},\"name\":\"\\u003cb\\u003eOthers\\u003c\\u002fb\\u003e\",\"showlegend\":true,\"x\":[50,62.5,75,87.5],\"y\":[0.8609911054637865,0.7727445997458704,0.667725540025413,0.8275095298602286],\"type\":\"scatter\"},{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(20, 20, 200, 1)\",\"width\":3},\"name\":\"\\u003cb\\u003eWorking 35 hours or more\\u003c\\u002fb\\u003e\",\"showlegend\":true,\"x\":[50,62.5,75,87.5],\"y\":[0.9469488536155202,0.9130158730158731,0.8722398589065257,0.926278659611993],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"title\":{\"x\":0.3},\"legend\":{\"yanchor\":\"bottom\",\"xanchor\":\"right\",\"x\":0.95,\"y\":0.01},\"xaxis\":{\"title\":{\"text\":\"\\u003cb\\u003ePercentage of 'Working 35 hours or more'\\u003c\\u002fb\\u003e\"},\"range\":[40,100],\"gridcolor\":\"rgba(5, 5, 5, 0.5)\",\"constrain\":\"domain\",\"linecolor\":\"black\",\"dtick\":12.5},\"yaxis\":{\"title\":{\"text\":\"\\u003cb\\u003eAUC\\u003c\\u002fb\\u003e\"},\"range\":[0.567725540025413,1.0469488536155203],\"gridcolor\":\"rgba(5, 5, 5, 0.5)\",\"scaleanchor\":\"x\",\"scaleratio\":190,\"linecolor\":\"black\"},\"width\":600,\"height\":500,\"font\":{\"family\":\"Times New Roman\",\"size\":18,\"color\":\"Black\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('23b646ab-ee0f-4408-9ebc-cecb312dfb10');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "work_sample=work.sample(6288, random_state=43)\n",
        "elsee_sample=elsee.sample(6288, random_state=43)\n",
        "work_sample=work_sample.sample(int(0.5*len(work_sample)), random_state=43)\n",
        "elsee_sample=elsee_sample.sample(int(0.5*len(elsee_sample)), random_state=43)\n",
        "data=pd.concat([work_sample, elsee_sample])\n",
        "X_sample=data.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "y_sample=data['UDPYOPI_1 - Yes']\n",
        "class_weights_sample = compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(y_sample),\n",
        "                                        y = y_sample\n",
        "                                    )\n",
        "sklearn_weights = dict(enumerate(class_weights_sample))\n",
        "class_weights_sample=sklearn_weights\n",
        "\n",
        "algorithm()\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath='model_50_work.h5',\n",
        "                               monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "algorithm()\n",
        "callbacks = [checkpoint]\n",
        "number_of_features=44\n",
        "algorithm()\n",
        "network = models.Sequential()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=1000, activation=\"relu\", input_shape=(\n",
        "number_of_features,)))\n",
        "algorithm()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=1000, activation=\"relu\"))\n",
        "algorithm()\n",
        "# Add fully connected layer with a sigmoid activation function\n",
        "network.add(layers.Dense(units=1, activation=\"sigmoid\")) # No activation for regression\n",
        "# Compile neural network\n",
        "algorithm()\n",
        "network.compile(loss=\"binary_crossentropy\", # Cross-entropy # \"mse\" for regression\n",
        "optimizer=\"sgd\", # Root Mean Square Propagation\n",
        "metrics=[\"accuracy\"]) # Accuracy performance metric\n",
        "history = network.fit(X_sample, # Features\n",
        "y_sample, # Target vector\n",
        "epochs=20,\n",
        "verbose=1,\n",
        "callbacks=callbacks, # Print description after each epoch\n",
        "batch_size=64,\n",
        "class_weight=class_weights_sample,\n",
        "validation_data=(X_for_test, y_for_test))\n",
        "\n",
        "######################################################################\n",
        "\n",
        "work_sample=work.sample(6288, random_state=43)\n",
        "elsee_sample=elsee.sample(6288, random_state=43)\n",
        "work_sample=work_sample.sample(int(0.625*len(work_sample)), random_state=43)\n",
        "elsee_sample=elsee_sample.sample(int(0.375*len(elsee_sample)), random_state=43)\n",
        "data=pd.concat([work_sample, elsee_sample])\n",
        "\n",
        "X_sample=data.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "y_sample=data['UDPYOPI_1 - Yes']\n",
        "class_weights_sample = compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(y_sample),\n",
        "                                        y = y_sample\n",
        "                                    )\n",
        "sklearn_weights = dict(enumerate(class_weights_sample))\n",
        "class_weights_sample=sklearn_weights\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "algorithm()\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath='model_625_work.h5',\n",
        "                               monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "algorithm()\n",
        "callbacks = [checkpoint]\n",
        "number_of_features=44\n",
        "algorithm()\n",
        "network = models.Sequential()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=1000, activation=\"relu\", input_shape=(\n",
        "number_of_features,)))\n",
        "algorithm()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=1000, activation=\"relu\"))\n",
        "algorithm()\n",
        "# Add fully connected layer with a sigmoid activation function\n",
        "network.add(layers.Dense(units=1, activation=\"sigmoid\")) # No activation for regression\n",
        "# Compile neural network\n",
        "algorithm()\n",
        "network.compile(loss=\"binary_crossentropy\", # Cross-entropy # \"mse\" for regression\n",
        "optimizer=\"sgd\", # Root Mean Square Propagation\n",
        "metrics=[\"accuracy\"]) # Accuracy performance metric\n",
        "history = network.fit(X_sample, # Features\n",
        "y_sample, # Target vector\n",
        "epochs=20,\n",
        "verbose=1,\n",
        "callbacks=callbacks, # Print description after each epoch\n",
        "batch_size=64,\n",
        "class_weight=class_weights_sample,\n",
        "validation_data=(X_for_test, y_for_test))\n",
        "\n",
        "##################################################################################\n",
        "\n",
        "work_sample=work.sample(6288, random_state=43)\n",
        "elsee_sample=elsee.sample(6288, random_state=43)\n",
        "work_sample=work_sample.sample(int(0.75*len(work_sample)), random_state=43)\n",
        "elsee_sample=elsee_sample.sample(int(0.25*len(elsee_sample)), random_state=43)\n",
        "data=pd.concat([work_sample, elsee_sample])\n",
        "\n",
        "X_sample=data.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "y_sample=data['UDPYOPI_1 - Yes']\n",
        "class_weights_sample = compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(y_sample),\n",
        "                                        y = y_sample\n",
        "                                    )\n",
        "sklearn_weights = dict(enumerate(class_weights_sample))\n",
        "class_weights_sample=sklearn_weights\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "algorithm()\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath='model_75_work.h5',\n",
        "                               monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "algorithm()\n",
        "callbacks = [checkpoint]\n",
        "number_of_features=44\n",
        "algorithm()\n",
        "network = models.Sequential()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=1000, activation=\"relu\", input_shape=(\n",
        "number_of_features,)))\n",
        "algorithm()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=1000, activation=\"relu\"))\n",
        "algorithm()\n",
        "# Add fully connected layer with a sigmoid activation function\n",
        "network.add(layers.Dense(units=1, activation=\"sigmoid\")) # No activation for regression\n",
        "# Compile neural network\n",
        "algorithm()\n",
        "network.compile(loss=\"binary_crossentropy\", # Cross-entropy # \"mse\" for regression\n",
        "optimizer=\"sgd\", # Root Mean Square Propagation\n",
        "metrics=[\"accuracy\"]) # Accuracy performance metric\n",
        "history = network.fit(X_sample, # Features\n",
        "y_sample, # Target vector\n",
        "epochs=20,\n",
        "verbose=1,\n",
        "callbacks=callbacks, # Print description after each epoch\n",
        "batch_size=64,\n",
        "class_weight=class_weights_sample,\n",
        "validation_data=(X_for_test, y_for_test))\n",
        "\n",
        "######################################################################\n",
        "\n",
        "work_sample=work.sample(6288, random_state=43)\n",
        "elsee_sample=elsee.sample(6288, random_state=43)\n",
        "work_sample=work_sample.sample(int(0.875*len(work_sample)), random_state=43)\n",
        "elsee_sample=elsee_sample.sample(int(0.125*len(elsee_sample)), random_state=43)\n",
        "data=pd.concat([work_sample, elsee_sample])\n",
        "\n",
        "X_sample=data.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "y_sample=data['UDPYOPI_1 - Yes']\n",
        "class_weights_sample = compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(y_sample),\n",
        "                                        y = y_sample\n",
        "                                    )\n",
        "sklearn_weights = dict(enumerate(class_weights_sample))\n",
        "class_weights_sample=sklearn_weights\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "algorithm()\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath='model_875_work.h5',\n",
        "                               monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "algorithm()\n",
        "callbacks = [checkpoint]\n",
        "number_of_features=44\n",
        "algorithm()\n",
        "network = models.Sequential()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=1000, activation=\"relu\", input_shape=(\n",
        "number_of_features,)))\n",
        "algorithm()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "network.add(layers.Dense(units=1000, activation=\"relu\"))\n",
        "algorithm()\n",
        "# Add fully connected layer with a sigmoid activation function\n",
        "network.add(layers.Dense(units=1, activation=\"sigmoid\")) # No activation for regression\n",
        "# Compile neural network\n",
        "algorithm()\n",
        "network.compile(loss=\"binary_crossentropy\", # Cross-entropy # \"mse\" for regression\n",
        "optimizer=\"sgd\", # Root Mean Square Propagation\n",
        "metrics=[\"accuracy\"]) # Accuracy performance metric\n",
        "history = network.fit(X_sample, # Features\n",
        "y_sample, # Target vector\n",
        "epochs=20,\n",
        "verbose=1,\n",
        "callbacks=callbacks, # Print description after each epoch\n",
        "batch_size=64,\n",
        "class_weight=class_weights_sample,\n",
        "validation_data=(X_for_test, y_for_test))\n",
        "\n",
        "prob1_50=load_model('model_50_work.h5').predict(work_predictors_test)\n",
        "prob2_50=load_model('model_50_work.h5').predict(elsee_predictors_test)\n",
        "prob1_625=load_model('model_625_work.h5').predict(work_predictors_test)\n",
        "prob2_625=load_model('model_625_work.h5').predict(elsee_predictors_test)\n",
        "prob1_75=load_model('model_75_work.h5').predict(work_predictors_test)\n",
        "prob2_75=load_model('model_75_work.h5').predict(elsee_predictors_test)\n",
        "prob1_875=load_model('model_875_work.h5').predict(work_predictors_test)\n",
        "prob2_875=load_model('model_875_work.h5').predict(elsee_predictors_test)\n",
        "\n",
        "print('Working More Than 35 Hours (50):', roc_auc_score(work_target_test, prob1_50))\n",
        "print('Else (50):', roc_auc_score(elsee_target_test, prob2_50))\n",
        "print('Working More Than 35 Hours (62.5):', roc_auc_score(work_target_test, prob1_625))\n",
        "print('Else (37.5):', roc_auc_score(elsee_target_test, prob2_625))\n",
        "print('Working More Than 35 Hours (75):', roc_auc_score(work_target_test, prob1_75))\n",
        "print('Else (25):', roc_auc_score(elsee_target_test, prob2_75))\n",
        "print('Working More Than 35 Hours (87.5):', roc_auc_score(work_target_test, prob1_875))\n",
        "print('Else (12.5):', roc_auc_score(elsee_target_test, prob2_875))\n",
        "\n",
        "# x axis values\n",
        "x = [50, 62.5, 75, 87.5]\n",
        "# corresponding y axis values\n",
        "y = [roc_auc_score(elsee_target_test, prob2_50),roc_auc_score(elsee_target_test, prob2_625),\n",
        "     roc_auc_score(elsee_target_test, prob2_75),roc_auc_score(elsee_target_test, prob2_875)]\n",
        "z = [roc_auc_score(work_target_test, prob1_50),roc_auc_score(work_target_test, prob1_625),\n",
        "     roc_auc_score(work_target_test, prob1_75),roc_auc_score(work_target_test, prob1_875)]\n",
        "c_line_main1 = 'rgba(200, 20, 20, 1.0)'\n",
        "c_line_main2 = 'rgba(20, 20, 200, 1)'\n",
        "fig = go.Figure([\n",
        "\n",
        "    go.Scatter(\n",
        "        x          = x,\n",
        "        y          = y,\n",
        "        line       = dict(color=c_line_main1, width=3),\n",
        "        hoverinfo  = \"skip\",\n",
        "        showlegend = True,\n",
        "        name       = f'<b>Others</b>'),\n",
        "    go.Scatter(\n",
        "        x          = x,\n",
        "        y          = z,\n",
        "        line       = dict(color=c_line_main2, width=3),\n",
        "        hoverinfo  = \"skip\",\n",
        "        showlegend = True,\n",
        "        name       = f'<b>Working 35 hours or more</b>')\n",
        "    ])\n",
        "fig.add_shape(\n",
        "        type ='line',\n",
        "        line =dict(dash='dash'),\n",
        "        x0=0, x1=1, y0=0, y1=1\n",
        "    )\n",
        "fig.update_layout(\n",
        "        template    = 'plotly_white',\n",
        "        title_x     = 0.3,\n",
        "        xaxis_title = \"<b>Percentage of 'Working 35 hours or more'</b>\",\n",
        "        yaxis_title = \"<b>AUC</b>\",\n",
        "        width       = 600,\n",
        "        height      = 500,\n",
        "        legend      = dict(\n",
        "            yanchor=\"bottom\",\n",
        "            xanchor=\"right\",\n",
        "            x=0.95,\n",
        "            y=0.01,\n",
        "        )\n",
        "    )\n",
        "fig.update_layout(\n",
        "        font=dict(\n",
        "        family=\"Times New Roman\",\n",
        "        size=18,  # Set the font size here\n",
        "        color=\"Black\"\n",
        "        )\n",
        "    )\n",
        "fig.update_yaxes(\n",
        "        range       = [min(min(y), min(z))-0.1, max(max(y), max(z))+0.1],\n",
        "        gridcolor   = c_grid,\n",
        "        scaleanchor = \"x\",\n",
        "        scaleratio  = 190,\n",
        "        linecolor   = 'black')\n",
        "fig.update_xaxes(\n",
        "        range       = [40, 100],\n",
        "        gridcolor   = c_grid,\n",
        "        constrain   = 'domain',\n",
        "        linecolor   = 'black',dtick=12.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3d66663",
      "metadata": {
        "id": "b3d66663"
      },
      "outputs": [],
      "source": [
        "white=train.drop(X_train[X_train['NEWRACE2_White'] == 0].index)\n",
        "black=train.drop(X_train[X_train['NEWRACE2_Black'] == 0].index)\n",
        "\n",
        "white_test=test.drop(X_test[X_test['NEWRACE2_White'] == 0].index)\n",
        "white_test=white_test.sample(605, random_state=43)\n",
        "white_predictors_test=white_test.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "white_target_test=white_test['UDPYOPI_1 - Yes']\n",
        "\n",
        "black_test=test.drop(X_test[X_test['NEWRACE2_Black'] == 0].index)\n",
        "black_test=black_test.sample(605, random_state=43)\n",
        "black_predictors_test=black_test.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "black_target_test=black_test['UDPYOPI_1 - Yes']\n",
        "data_test=pd.concat([white_test, black_test])\n",
        "X_for_test=data_test.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "y_for_test=data_test['UDPYOPI_1 - Yes']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "white_test=test.drop(X_test[X_test['NEWRACE2_White'] == 0].index)\n",
        "black_test=test.drop(X_test[X_test['NEWRACE2_Black'] == 0].index)\n",
        "print(len(white_test))\n",
        "print(len(black_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woepIKQD3orZ",
        "outputId": "813039d3-1a81-4c83-fdcc-08d404f57b02"
      },
      "id": "woepIKQD3orZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4667\n",
            "605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "white=train.drop(X_train[X_train['NEWRACE2_White'] == 0].index)\n",
        "black=train.drop(X_train[X_train['NEWRACE2_Black'] == 0].index)\n",
        "print(len(white))\n",
        "print(len(black))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgDhL8pv3x7-",
        "outputId": "ea6a1a09-1033-4f26-a20b-13c5184d673c"
      },
      "id": "JgDhL8pv3x7-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18746\n",
            "2454\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fb21ad6",
      "metadata": {
        "id": "4fb21ad6",
        "outputId": "82586838-4817-4c96-dff1-0248592393f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "38/39 [============================>.] - ETA: 0s - loss: 1.8153 - accuracy: 0.3766\n",
            "Epoch 1: val_accuracy improved from -inf to 0.87355, saving model to model_50_black.h5\n",
            "39/39 [==============================] - 2s 35ms/step - loss: 1.8048 - accuracy: 0.3791 - val_loss: 0.2980 - val_accuracy: 0.8736\n",
            "Epoch 2/20\n",
            "37/39 [===========================>..] - ETA: 0s - loss: 0.7991 - accuracy: 0.4092\n",
            "Epoch 2: val_accuracy did not improve from 0.87355\n",
            "39/39 [==============================] - 1s 25ms/step - loss: 0.7882 - accuracy: 0.3958 - val_loss: 0.6323 - val_accuracy: 0.8612\n",
            "Epoch 3/20\n",
            "36/39 [==========================>...] - ETA: 0s - loss: 0.7076 - accuracy: 0.3355\n",
            "Epoch 3: val_accuracy improved from 0.87355 to 0.98099, saving model to model_50_black.h5\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6762 - accuracy: 0.3734 - val_loss: 0.3092 - val_accuracy: 0.9810\n",
            "Epoch 4/20\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.7276 - accuracy: 0.4502\n",
            "Epoch 4: val_accuracy did not improve from 0.98099\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.7276 - accuracy: 0.4502 - val_loss: 0.8048 - val_accuracy: 0.1116\n",
            "Epoch 5/20\n",
            "38/39 [============================>.] - ETA: 0s - loss: 0.6821 - accuracy: 0.4334\n",
            "Epoch 5: val_accuracy did not improve from 0.98099\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6808 - accuracy: 0.4306 - val_loss: 0.7923 - val_accuracy: 0.1223\n",
            "Epoch 6/20\n",
            "35/39 [=========================>....] - ETA: 0s - loss: 0.6904 - accuracy: 0.4473\n",
            "Epoch 6: val_accuracy improved from 0.98099 to 0.99256, saving model to model_50_black.h5\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6544 - accuracy: 0.4943 - val_loss: 0.4451 - val_accuracy: 0.9926\n",
            "Epoch 7/20\n",
            "38/39 [============================>.] - ETA: 0s - loss: 0.6410 - accuracy: 0.5654\n",
            "Epoch 7: val_accuracy did not improve from 0.99256\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6380 - accuracy: 0.5682 - val_loss: 0.3548 - val_accuracy: 0.9926\n",
            "Epoch 8/20\n",
            "36/39 [==========================>...] - ETA: 0s - loss: 0.6776 - accuracy: 0.5964\n",
            "Epoch 8: val_accuracy did not improve from 0.99256\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.6894 - accuracy: 0.5682 - val_loss: 0.8780 - val_accuracy: 0.1273\n",
            "Epoch 9/20\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.6645 - accuracy: 0.5335\n",
            "Epoch 9: val_accuracy did not improve from 0.99256\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6645 - accuracy: 0.5335 - val_loss: 0.9848 - val_accuracy: 0.1264\n",
            "Epoch 10/20\n",
            "38/39 [============================>.] - ETA: 0s - loss: 0.6495 - accuracy: 0.4696\n",
            "Epoch 10: val_accuracy did not improve from 0.99256\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.6471 - accuracy: 0.4726 - val_loss: 0.5114 - val_accuracy: 0.9860\n",
            "Epoch 11/20\n",
            "37/39 [===========================>..] - ETA: 0s - loss: 0.6588 - accuracy: 0.6520\n",
            "Epoch 11: val_accuracy did not improve from 0.99256\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6579 - accuracy: 0.6344 - val_loss: 0.8562 - val_accuracy: 0.1331\n",
            "Epoch 12/20\n",
            "35/39 [=========================>....] - ETA: 0s - loss: 0.6039 - accuracy: 0.5531\n",
            "Epoch 12: val_accuracy did not improve from 0.99256\n",
            "39/39 [==============================] - 1s 17ms/step - loss: 0.6251 - accuracy: 0.5400 - val_loss: 0.7459 - val_accuracy: 0.3711\n",
            "Epoch 13/20\n",
            "35/39 [=========================>....] - ETA: 0s - loss: 0.6410 - accuracy: 0.5884\n",
            "Epoch 13: val_accuracy did not improve from 0.99256\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.6484 - accuracy: 0.5711 - val_loss: 0.6639 - val_accuracy: 0.6479\n",
            "Epoch 14/20\n",
            "38/39 [============================>.] - ETA: 0s - loss: 0.6243 - accuracy: 0.5271\n",
            "Epoch 14: val_accuracy did not improve from 0.99256\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6215 - accuracy: 0.5302 - val_loss: 0.3917 - val_accuracy: 0.9926\n",
            "Epoch 15/20\n",
            "38/39 [============================>.] - ETA: 0s - loss: 0.5747 - accuracy: 0.6386\n",
            "Epoch 15: val_accuracy did not improve from 0.99256\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.5732 - accuracy: 0.6377 - val_loss: 0.5408 - val_accuracy: 0.9281\n",
            "Epoch 16/20\n",
            "37/39 [===========================>..] - ETA: 0s - loss: 0.6833 - accuracy: 0.5448\n",
            "Epoch 16: val_accuracy did not improve from 0.99256\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.6742 - accuracy: 0.5339 - val_loss: 0.6199 - val_accuracy: 0.7901\n",
            "Epoch 17/20\n",
            "38/39 [============================>.] - ETA: 0s - loss: 0.6318 - accuracy: 0.5847\n",
            "Epoch 17: val_accuracy did not improve from 0.99256\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6309 - accuracy: 0.5809 - val_loss: 0.6983 - val_accuracy: 0.5058\n",
            "Epoch 18/20\n",
            "37/39 [===========================>..] - ETA: 0s - loss: 0.6307 - accuracy: 0.5642\n",
            "Epoch 18: val_accuracy did not improve from 0.99256\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.6199 - accuracy: 0.5707 - val_loss: 0.4586 - val_accuracy: 0.9851\n",
            "Epoch 19/20\n",
            "37/39 [===========================>..] - ETA: 0s - loss: 0.6703 - accuracy: 0.5351\n",
            "Epoch 19: val_accuracy did not improve from 0.99256\n",
            "39/39 [==============================] - 1s 24ms/step - loss: 0.6604 - accuracy: 0.5319 - val_loss: 0.5284 - val_accuracy: 0.9421\n",
            "Epoch 20/20\n",
            "37/39 [===========================>..] - ETA: 0s - loss: 0.5805 - accuracy: 0.7386\n",
            "Epoch 20: val_accuracy did not improve from 0.99256\n",
            "39/39 [==============================] - 1s 25ms/step - loss: 0.6658 - accuracy: 0.7410 - val_loss: 2.1674 - val_accuracy: 0.1264\n",
            "Epoch 1/20\n",
            "38/39 [============================>.] - ETA: 0s - loss: 1.5270 - accuracy: 0.4350\n",
            "Epoch 1: val_accuracy improved from -inf to 0.98099, saving model to model_625_black.h5\n",
            "39/39 [==============================] - 1s 21ms/step - loss: 1.5178 - accuracy: 0.4387 - val_loss: 0.2370 - val_accuracy: 0.9810\n",
            "Epoch 2/20\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.7865 - accuracy: 0.5118\n",
            "Epoch 2: val_accuracy did not improve from 0.98099\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.7865 - accuracy: 0.5118 - val_loss: 2.6376 - val_accuracy: 0.0074\n",
            "Epoch 3/20\n",
            "37/39 [===========================>..] - ETA: 0s - loss: 0.7184 - accuracy: 0.3003\n",
            "Epoch 3: val_accuracy improved from 0.98099 to 0.99256, saving model to model_625_black.h5\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.7014 - accuracy: 0.3231 - val_loss: 0.3468 - val_accuracy: 0.9926\n",
            "Epoch 4/20\n",
            "35/39 [=========================>....] - ETA: 0s - loss: 0.7167 - accuracy: 0.6366\n",
            "Epoch 4: val_accuracy did not improve from 0.99256\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.6927 - accuracy: 0.5919 - val_loss: 0.6834 - val_accuracy: 0.6264\n",
            "Epoch 5/20\n",
            "35/39 [=========================>....] - ETA: 0s - loss: 0.6699 - accuracy: 0.3531\n",
            "Epoch 5: val_accuracy did not improve from 0.99256\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.6806 - accuracy: 0.4024 - val_loss: 0.6669 - val_accuracy: 0.7620\n",
            "Epoch 6/20\n",
            "38/39 [============================>.] - ETA: 0s - loss: 0.6834 - accuracy: 0.5720\n",
            "Epoch 6: val_accuracy did not improve from 0.99256\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.6815 - accuracy: 0.5686 - val_loss: 0.7221 - val_accuracy: 0.2306\n",
            "Epoch 7/20\n",
            "38/39 [============================>.] - ETA: 0s - loss: 0.6350 - accuracy: 0.4996\n",
            "Epoch 7: val_accuracy did not improve from 0.99256\n",
            "39/39 [==============================] - 1s 24ms/step - loss: 0.6326 - accuracy: 0.5029 - val_loss: 0.4824 - val_accuracy: 0.9926\n",
            "Epoch 8/20\n",
            "37/39 [===========================>..] - ETA: 0s - loss: 0.7157 - accuracy: 0.4523\n",
            "Epoch 8: val_accuracy did not improve from 0.99256\n",
            "39/39 [==============================] - 1s 24ms/step - loss: 0.7040 - accuracy: 0.4453 - val_loss: 0.6467 - val_accuracy: 0.8471\n",
            "Epoch 9/20\n",
            "37/39 [===========================>..] - ETA: 0s - loss: 0.6644 - accuracy: 0.6639\n",
            "Epoch 9: val_accuracy did not improve from 0.99256\n",
            "39/39 [==============================] - 1s 25ms/step - loss: 0.6592 - accuracy: 0.6467 - val_loss: 0.8398 - val_accuracy: 0.1264\n",
            "Epoch 10/20\n",
            "38/39 [============================>.] - ETA: 0s - loss: 0.6705 - accuracy: 0.3359\n",
            "Epoch 10: val_accuracy did not improve from 0.99256\n",
            "39/39 [==============================] - 1s 23ms/step - loss: 0.6684 - accuracy: 0.3358 - val_loss: 0.6537 - val_accuracy: 0.7198\n",
            "Epoch 11/20\n",
            "38/39 [============================>.] - ETA: 0s - loss: 0.6728 - accuracy: 0.5506\n",
            "Epoch 11: val_accuracy did not improve from 0.99256\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.6717 - accuracy: 0.5474 - val_loss: 0.8017 - val_accuracy: 0.1331\n",
            "Epoch 12/20\n",
            "35/39 [=========================>....] - ETA: 0s - loss: 0.6717 - accuracy: 0.4808\n",
            "Epoch 12: val_accuracy did not improve from 0.99256\n",
            "39/39 [==============================] - 1s 17ms/step - loss: 0.6719 - accuracy: 0.4538 - val_loss: 0.7934 - val_accuracy: 0.1331\n",
            "Epoch 13/20\n",
            "35/39 [=========================>....] - ETA: 0s - loss: 0.6525 - accuracy: 0.3906\n",
            "Epoch 13: val_accuracy did not improve from 0.99256\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.6744 - accuracy: 0.4420 - val_loss: 1.0618 - val_accuracy: 0.1264\n",
            "Epoch 14/20\n",
            "35/39 [=========================>....] - ETA: 0s - loss: 0.7095 - accuracy: 0.4004\n",
            "Epoch 14: val_accuracy did not improve from 0.99256\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.6839 - accuracy: 0.3824 - val_loss: 0.5970 - val_accuracy: 0.9736\n",
            "Epoch 15/20\n",
            "36/39 [==========================>...] - ETA: 0s - loss: 0.6784 - accuracy: 0.5273\n",
            "Epoch 15: val_accuracy did not improve from 0.99256\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.6702 - accuracy: 0.5049 - val_loss: 0.8329 - val_accuracy: 0.1273\n",
            "Epoch 16/20\n",
            "36/39 [==========================>...] - ETA: 0s - loss: 0.6465 - accuracy: 0.5091\n",
            "Epoch 16: val_accuracy did not improve from 0.99256\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6561 - accuracy: 0.4951 - val_loss: 0.8732 - val_accuracy: 0.1273\n",
            "Epoch 17/20\n",
            "38/39 [============================>.] - ETA: 0s - loss: 0.6472 - accuracy: 0.4918\n",
            "Epoch 17: val_accuracy did not improve from 0.99256\n",
            "39/39 [==============================] - 1s 17ms/step - loss: 0.6464 - accuracy: 0.4890 - val_loss: 0.8599 - val_accuracy: 0.1306\n",
            "Epoch 18/20\n",
            "35/39 [=========================>....] - ETA: 0s - loss: 0.7191 - accuracy: 0.2848\n",
            "Epoch 18: val_accuracy did not improve from 0.99256\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.6842 - accuracy: 0.3227 - val_loss: 0.5467 - val_accuracy: 0.9909\n",
            "Epoch 19/20\n",
            "35/39 [=========================>....] - ETA: 0s - loss: 0.6636 - accuracy: 0.6246\n",
            "Epoch 19: val_accuracy did not improve from 0.99256\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.6486 - accuracy: 0.5813 - val_loss: 0.7055 - val_accuracy: 0.3686\n",
            "Epoch 20/20\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.6366 - accuracy: 0.5408\n",
            "Epoch 20: val_accuracy did not improve from 0.99256\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.6366 - accuracy: 0.5408 - val_loss: 0.7537 - val_accuracy: 0.2380\n",
            "Epoch 1/20\n",
            "35/39 [=========================>....] - ETA: 0s - loss: 1.7019 - accuracy: 0.3304\n",
            "Epoch 1: val_accuracy improved from -inf to 0.98182, saving model to model_75_black.h5\n",
            "39/39 [==============================] - 1s 23ms/step - loss: 1.5715 - accuracy: 0.3844 - val_loss: 0.2524 - val_accuracy: 0.9818\n",
            "Epoch 2/20\n",
            "38/39 [============================>.] - ETA: 0s - loss: 0.7958 - accuracy: 0.4243\n",
            "Epoch 2: val_accuracy did not improve from 0.98182\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.7931 - accuracy: 0.4220 - val_loss: 0.6932 - val_accuracy: 0.5835\n",
            "Epoch 3/20\n",
            "37/39 [===========================>..] - ETA: 0s - loss: 0.6782 - accuracy: 0.4177\n",
            "Epoch 3: val_accuracy did not improve from 0.98182\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6979 - accuracy: 0.4301 - val_loss: 0.6752 - val_accuracy: 0.8273\n",
            "Epoch 4/20\n",
            "35/39 [=========================>....] - ETA: 0s - loss: 0.7161 - accuracy: 0.4915\n",
            "Epoch 4: val_accuracy improved from 0.98182 to 0.99008, saving model to model_75_black.h5\n",
            "39/39 [==============================] - 1s 18ms/step - loss: 0.6814 - accuracy: 0.5319 - val_loss: 0.5076 - val_accuracy: 0.9901\n",
            "Epoch 5/20\n",
            "36/39 [==========================>...] - ETA: 0s - loss: 0.6696 - accuracy: 0.5291\n",
            "Epoch 5: val_accuracy did not improve from 0.99008\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6809 - accuracy: 0.5564 - val_loss: 0.5971 - val_accuracy: 0.9843\n",
            "Epoch 6/20\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.6705 - accuracy: 0.4559\n",
            "Epoch 6: val_accuracy did not improve from 0.99008\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6705 - accuracy: 0.4559 - val_loss: 0.4299 - val_accuracy: 0.9901\n",
            "Epoch 7/20\n",
            "35/39 [=========================>....] - ETA: 0s - loss: 0.7376 - accuracy: 0.5710\n",
            "Epoch 7: val_accuracy did not improve from 0.99008\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.7025 - accuracy: 0.5866 - val_loss: 0.5383 - val_accuracy: 0.9893\n",
            "Epoch 8/20\n",
            "36/39 [==========================>...] - ETA: 0s - loss: 0.6939 - accuracy: 0.5148\n",
            "Epoch 8: val_accuracy did not improve from 0.99008\n",
            "39/39 [==============================] - 1s 18ms/step - loss: 0.6713 - accuracy: 0.5388 - val_loss: 0.5228 - val_accuracy: 0.9893\n",
            "Epoch 9/20\n",
            "38/39 [============================>.] - ETA: 0s - loss: 0.6436 - accuracy: 0.7109\n",
            "Epoch 9: val_accuracy did not improve from 0.99008\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.6420 - accuracy: 0.7079 - val_loss: 0.6998 - val_accuracy: 0.4421\n",
            "Epoch 10/20\n",
            "36/39 [==========================>...] - ETA: 0s - loss: 0.6573 - accuracy: 0.7270\n",
            "Epoch 10: val_accuracy did not improve from 0.99008\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6759 - accuracy: 0.6936 - val_loss: 0.9806 - val_accuracy: 0.1240\n",
            "Epoch 11/20\n",
            "38/39 [============================>.] - ETA: 0s - loss: 0.6514 - accuracy: 0.4243\n",
            "Epoch 11: val_accuracy did not improve from 0.99008\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6494 - accuracy: 0.4232 - val_loss: 0.6031 - val_accuracy: 0.9537\n",
            "Epoch 12/20\n",
            "36/39 [==========================>...] - ETA: 0s - loss: 0.6388 - accuracy: 0.6667\n",
            "Epoch 12: val_accuracy did not improve from 0.99008\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6645 - accuracy: 0.6409 - val_loss: 0.8240 - val_accuracy: 0.1240\n",
            "Epoch 13/20\n",
            "36/39 [==========================>...] - ETA: 0s - loss: 0.6007 - accuracy: 0.5026\n",
            "Epoch 13: val_accuracy did not improve from 0.99008\n",
            "39/39 [==============================] - 1s 23ms/step - loss: 0.6433 - accuracy: 0.5225 - val_loss: 1.8198 - val_accuracy: 0.1240\n",
            "Epoch 14/20\n",
            "36/39 [==========================>...] - ETA: 0s - loss: 0.6114 - accuracy: 0.6341\n",
            "Epoch 14: val_accuracy did not improve from 0.99008\n",
            "39/39 [==============================] - 1s 25ms/step - loss: 0.6671 - accuracy: 0.6123 - val_loss: 1.0487 - val_accuracy: 0.1240\n",
            "Epoch 15/20\n",
            "37/39 [===========================>..] - ETA: 0s - loss: 0.6243 - accuracy: 0.5093\n",
            "Epoch 15: val_accuracy did not improve from 0.99008\n",
            "39/39 [==============================] - 1s 25ms/step - loss: 0.6463 - accuracy: 0.5163 - val_loss: 0.7838 - val_accuracy: 0.1364\n",
            "Epoch 16/20\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.6133 - accuracy: 0.6270\n",
            "Epoch 16: val_accuracy did not improve from 0.99008\n",
            "39/39 [==============================] - 1s 23ms/step - loss: 0.6133 - accuracy: 0.6270 - val_loss: 0.8736 - val_accuracy: 0.1256\n",
            "Epoch 17/20\n",
            "35/39 [=========================>....] - ETA: 0s - loss: 0.5845 - accuracy: 0.5750\n",
            "Epoch 17: val_accuracy did not improve from 0.99008\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.6119 - accuracy: 0.6017 - val_loss: 0.7172 - val_accuracy: 0.4083\n",
            "Epoch 18/20\n",
            "37/39 [===========================>..] - ETA: 0s - loss: 0.6071 - accuracy: 0.6698\n",
            "Epoch 18: val_accuracy did not improve from 0.99008\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6119 - accuracy: 0.6548 - val_loss: 0.8207 - val_accuracy: 0.1455\n",
            "Epoch 19/20\n",
            "37/39 [===========================>..] - ETA: 0s - loss: 0.6062 - accuracy: 0.6292\n",
            "Epoch 19: val_accuracy did not improve from 0.99008\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6197 - accuracy: 0.6152 - val_loss: 0.9493 - val_accuracy: 0.1240\n",
            "Epoch 20/20\n",
            "37/39 [===========================>..] - ETA: 0s - loss: 0.5283 - accuracy: 0.5549\n",
            "Epoch 20: val_accuracy did not improve from 0.99008\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6346 - accuracy: 0.5633 - val_loss: 0.8988 - val_accuracy: 0.1248\n",
            "Epoch 1/20\n",
            "39/39 [==============================] - ETA: 0s - loss: 1.5071 - accuracy: 0.3386\n",
            "Epoch 1: val_accuracy improved from -inf to 0.94793, saving model to model_875_black.h5\n",
            "39/39 [==============================] - 2s 31ms/step - loss: 1.5071 - accuracy: 0.3386 - val_loss: 0.4523 - val_accuracy: 0.9479\n",
            "Epoch 2/20\n",
            "37/39 [===========================>..] - ETA: 0s - loss: 0.7459 - accuracy: 0.5072\n",
            "Epoch 2: val_accuracy improved from 0.94793 to 0.96860, saving model to model_875_black.h5\n",
            "39/39 [==============================] - 1s 27ms/step - loss: 0.7308 - accuracy: 0.5225 - val_loss: 0.4393 - val_accuracy: 0.9686\n",
            "Epoch 3/20\n",
            "38/39 [============================>.] - ETA: 0s - loss: 0.7336 - accuracy: 0.6131\n",
            "Epoch 3: val_accuracy did not improve from 0.96860\n",
            "39/39 [==============================] - 1s 26ms/step - loss: 0.7569 - accuracy: 0.6107 - val_loss: 2.8631 - val_accuracy: 0.0074\n",
            "Epoch 4/20\n",
            "37/39 [===========================>..] - ETA: 0s - loss: 0.8503 - accuracy: 0.2454\n",
            "Epoch 4: val_accuracy did not improve from 0.96860\n",
            "39/39 [==============================] - 1s 25ms/step - loss: 0.8594 - accuracy: 0.2390 - val_loss: 0.9201 - val_accuracy: 0.0074\n",
            "Epoch 5/20\n",
            "37/39 [===========================>..] - ETA: 0s - loss: 0.6934 - accuracy: 0.2859\n",
            "Epoch 5: val_accuracy did not improve from 0.96860\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.7002 - accuracy: 0.2770 - val_loss: 0.7712 - val_accuracy: 0.0083\n",
            "Epoch 6/20\n",
            "38/39 [============================>.] - ETA: 0s - loss: 0.6887 - accuracy: 0.3845\n",
            "Epoch 6: val_accuracy did not improve from 0.96860\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.6863 - accuracy: 0.3873 - val_loss: 0.6095 - val_accuracy: 0.9364\n",
            "Epoch 7/20\n",
            "37/39 [===========================>..] - ETA: 0s - loss: 0.6867 - accuracy: 0.5376\n",
            "Epoch 7: val_accuracy did not improve from 0.96860\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6752 - accuracy: 0.5462 - val_loss: 0.5965 - val_accuracy: 0.9612\n",
            "Epoch 8/20\n",
            "36/39 [==========================>...] - ETA: 0s - loss: 0.6850 - accuracy: 0.4922\n",
            "Epoch 8: val_accuracy improved from 0.96860 to 0.96942, saving model to model_875_black.h5\n",
            "39/39 [==============================] - 1s 17ms/step - loss: 0.6631 - accuracy: 0.5159 - val_loss: 0.5324 - val_accuracy: 0.9694\n",
            "Epoch 9/20\n",
            "38/39 [============================>.] - ETA: 0s - loss: 0.6811 - accuracy: 0.6225\n",
            "Epoch 9: val_accuracy did not improve from 0.96942\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.6792 - accuracy: 0.6197 - val_loss: 0.7302 - val_accuracy: 0.2289\n",
            "Epoch 10/20\n",
            "37/39 [===========================>..] - ETA: 0s - loss: 0.6710 - accuracy: 0.5089\n",
            "Epoch 10: val_accuracy improved from 0.96942 to 0.98099, saving model to model_875_black.h5\n",
            "39/39 [==============================] - 1s 17ms/step - loss: 0.6571 - accuracy: 0.5249 - val_loss: 0.4446 - val_accuracy: 0.9810\n",
            "Epoch 11/20\n",
            "38/39 [============================>.] - ETA: 0s - loss: 0.6771 - accuracy: 0.5892\n",
            "Epoch 11: val_accuracy did not improve from 0.98099\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.6746 - accuracy: 0.5915 - val_loss: 0.5494 - val_accuracy: 0.9785\n",
            "Epoch 12/20\n",
            "37/39 [===========================>..] - ETA: 0s - loss: 0.6058 - accuracy: 0.6546\n",
            "Epoch 12: val_accuracy did not improve from 0.98099\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6517 - accuracy: 0.6577 - val_loss: 0.8001 - val_accuracy: 0.1165\n",
            "Epoch 13/20\n",
            "37/39 [===========================>..] - ETA: 0s - loss: 0.6388 - accuracy: 0.6039\n",
            "Epoch 13: val_accuracy did not improve from 0.98099\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6274 - accuracy: 0.6152 - val_loss: 0.5013 - val_accuracy: 0.9810\n",
            "Epoch 14/20\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.6542 - accuracy: 0.7079\n",
            "Epoch 14: val_accuracy did not improve from 0.98099\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6542 - accuracy: 0.7079 - val_loss: 0.8090 - val_accuracy: 0.1421\n",
            "Epoch 15/20\n",
            "36/39 [==========================>...] - ETA: 0s - loss: 0.6655 - accuracy: 0.5747\n",
            "Epoch 15: val_accuracy improved from 0.98099 to 0.98595, saving model to model_875_black.h5\n",
            "39/39 [==============================] - 1s 18ms/step - loss: 0.6433 - accuracy: 0.5980 - val_loss: 0.4999 - val_accuracy: 0.9860\n",
            "Epoch 16/20\n",
            "38/39 [============================>.] - ETA: 0s - loss: 0.6438 - accuracy: 0.6970\n",
            "Epoch 16: val_accuracy did not improve from 0.98595\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6710 - accuracy: 0.6985 - val_loss: 2.1937 - val_accuracy: 0.1149\n",
            "Epoch 17/20\n",
            "37/39 [===========================>..] - ETA: 0s - loss: 0.7412 - accuracy: 0.3991\n",
            "Epoch 17: val_accuracy did not improve from 0.98595\n",
            "39/39 [==============================] - 1s 17ms/step - loss: 0.7376 - accuracy: 0.3926 - val_loss: 0.9846 - val_accuracy: 0.1182\n",
            "Epoch 18/20\n",
            "35/39 [=========================>....] - ETA: 0s - loss: 0.6754 - accuracy: 0.3629\n",
            "Epoch 18: val_accuracy improved from 0.98595 to 0.98678, saving model to model_875_black.h5\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.6745 - accuracy: 0.3922 - val_loss: 0.5552 - val_accuracy: 0.9868\n",
            "Epoch 19/20\n",
            "37/39 [===========================>..] - ETA: 0s - loss: 0.6740 - accuracy: 0.5870\n",
            "Epoch 19: val_accuracy did not improve from 0.98678\n",
            "39/39 [==============================] - 1s 15ms/step - loss: 0.6617 - accuracy: 0.5993 - val_loss: 0.5513 - val_accuracy: 0.9868\n",
            "Epoch 20/20\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.6252 - accuracy: 0.7704\n",
            "Epoch 20: val_accuracy did not improve from 0.98678\n",
            "39/39 [==============================] - 1s 19ms/step - loss: 0.6252 - accuracy: 0.7704 - val_loss: 0.5627 - val_accuracy: 0.9810\n",
            "19/19 [==============================] - 0s 6ms/step\n",
            "19/19 [==============================] - 0s 6ms/step\n",
            "19/19 [==============================] - 0s 6ms/step\n",
            "19/19 [==============================] - 0s 5ms/step\n",
            "19/19 [==============================] - 0s 6ms/step\n",
            "19/19 [==============================] - 0s 6ms/step\n",
            "19/19 [==============================] - 0s 4ms/step\n",
            "19/19 [==============================] - 0s 4ms/step\n",
            "Black (50): 0.5398671096345514\n",
            "White (50): 0.8439065108514191\n",
            "Black (62.5): 0.48006644518272423\n",
            "White (37.5): 0.7178631051752923\n",
            "Black (75): 0.6445182724252491\n",
            "White (25): 0.8177518085698385\n",
            "Black (87.5): 0.9080841638981174\n",
            "White (12.5): 0.805230940456316\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"9734c83e-1e83-4101-8f12-e52c8ca94b12\" class=\"plotly-graph-div\" style=\"height:800px; width:600px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9734c83e-1e83-4101-8f12-e52c8ca94b12\")) {                    Plotly.newPlot(                        \"9734c83e-1e83-4101-8f12-e52c8ca94b12\",                        [{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(200, 20, 20, 1.0)\",\"width\":3},\"name\":\"\\u003cb\\u003eBlack\\u003c\\u002fb\\u003e\",\"showlegend\":true,\"x\":[50,62.5,75,87.5],\"y\":[0.5398671096345514,0.48006644518272423,0.6445182724252491,0.9080841638981174],\"type\":\"scatter\"},{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(20, 20, 200, 1)\",\"width\":3},\"name\":\"\\u003cb\\u003eWhite\\u003c\\u002fb\\u003e\",\"showlegend\":true,\"x\":[50,62.5,75,87.5],\"y\":[0.8439065108514191,0.7178631051752923,0.8177518085698385,0.805230940456316],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"title\":{\"x\":0.3},\"legend\":{\"yanchor\":\"bottom\",\"xanchor\":\"right\",\"x\":0.95,\"y\":0.01},\"xaxis\":{\"title\":{\"text\":\"\\u003cb\\u003ePercentage of black race\\u003c\\u002fb\\u003e\"},\"range\":[40,100],\"gridcolor\":\"rgba(5, 5, 5, 0.5)\",\"constrain\":\"domain\",\"linecolor\":\"black\",\"dtick\":12.5},\"yaxis\":{\"title\":{\"text\":\"\\u003cb\\u003eAUC\\u003c\\u002fb\\u003e\"},\"range\":[0.38006644518272426,1.0080841638981175],\"gridcolor\":\"rgba(5, 5, 5, 0.5)\",\"scaleanchor\":\"x\",\"scaleratio\":190,\"linecolor\":\"black\"},\"width\":600,\"height\":800,\"font\":{\"family\":\"Times New Roman\",\"size\":18,\"color\":\"Black\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9734c83e-1e83-4101-8f12-e52c8ca94b12');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "white_sample=white.sample(2448, random_state=43)\n",
        "black_sample=black.sample(2448, random_state=43)\n",
        "white_sample=white_sample.sample(int(0.5*len(white_sample)), random_state=43)\n",
        "black_sample=black_sample.sample(int(0.5*len(black_sample)), random_state=43)\n",
        "data=pd.concat([white_sample, black_sample])\n",
        "X_sample=data.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "y_sample=data['UDPYOPI_1 - Yes']\n",
        "class_weights_sample = compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(y_sample),\n",
        "                                        y = y_sample\n",
        "                                    )\n",
        "sklearn_weights = dict(enumerate(class_weights_sample))\n",
        "class_weights_sample=sklearn_weights\n",
        "\n",
        "algorithm()\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath='model_50_black.h5',\n",
        "                               monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "algorithm()\n",
        "callbacks = [checkpoint]\n",
        "number_of_features=44\n",
        "algorithm()\n",
        "netwhite = models.Sequential()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "netwhite.add(layers.Dense(units=1000, activation=\"relu\", input_shape=(\n",
        "number_of_features,)))\n",
        "algorithm()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "netwhite.add(layers.Dense(units=1000, activation=\"relu\"))\n",
        "algorithm()\n",
        "# Add fully connected layer with a sigmoid activation function\n",
        "netwhite.add(layers.Dense(units=1, activation=\"sigmoid\")) # No activation for regression\n",
        "# Compile neural netwhite\n",
        "algorithm()\n",
        "netwhite.compile(loss=\"binary_crossentropy\", # Cross-entropy # \"mse\" for regression\n",
        "optimizer=\"sgd\", # Root Mean Square Propagation\n",
        "metrics=[\"accuracy\"]) # Accuracy performance metric\n",
        "history = netwhite.fit(X_sample, # Features\n",
        "y_sample, # Target vector\n",
        "epochs=20,\n",
        "verbose=1,\n",
        "callbacks=callbacks, # Print description after each epoch\n",
        "batch_size=64,\n",
        "class_weight=class_weights_sample,\n",
        "validation_data=(X_for_test, y_for_test))\n",
        "\n",
        "######################################################################\n",
        "\n",
        "white_sample=white.sample(2448, random_state=43)\n",
        "black_sample=black.sample(2448, random_state=43)\n",
        "white_sample=white_sample.sample(int(0.375*len(white_sample)), random_state=43)\n",
        "black_sample=black_sample.sample(int(0.625*len(black_sample)), random_state=43)\n",
        "data=pd.concat([white_sample, black_sample])\n",
        "\n",
        "X_sample=data.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "y_sample=data['UDPYOPI_1 - Yes']\n",
        "class_weights_sample = compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(y_sample),\n",
        "                                        y = y_sample\n",
        "                                    )\n",
        "sklearn_weights = dict(enumerate(class_weights_sample))\n",
        "class_weights_sample=sklearn_weights\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "algorithm()\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath='model_625_black.h5',\n",
        "                               monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "algorithm()\n",
        "callbacks = [checkpoint]\n",
        "number_of_features=44\n",
        "algorithm()\n",
        "netwhite = models.Sequential()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "netwhite.add(layers.Dense(units=1000, activation=\"relu\", input_shape=(\n",
        "number_of_features,)))\n",
        "algorithm()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "netwhite.add(layers.Dense(units=1000, activation=\"relu\"))\n",
        "algorithm()\n",
        "# Add fully connected layer with a sigmoid activation function\n",
        "netwhite.add(layers.Dense(units=1, activation=\"sigmoid\")) # No activation for regression\n",
        "# Compile neural netwhite\n",
        "algorithm()\n",
        "netwhite.compile(loss=\"binary_crossentropy\", # Cross-entropy # \"mse\" for regression\n",
        "optimizer=\"sgd\", # Root Mean Square Propagation\n",
        "metrics=[\"accuracy\"]) # Accuracy performance metric\n",
        "history = netwhite.fit(X_sample, # Features\n",
        "y_sample, # Target vector\n",
        "epochs=20,\n",
        "verbose=1,\n",
        "callbacks=callbacks, # Print description after each epoch\n",
        "batch_size=64,\n",
        "class_weight=class_weights_sample,\n",
        "validation_data=(X_for_test, y_for_test))\n",
        "\n",
        "##################################################################################\n",
        "\n",
        "white_sample=white.sample(2448, random_state=43)\n",
        "black_sample=black.sample(2448, random_state=43)\n",
        "white_sample=white_sample.sample(int(0.25*len(white_sample)), random_state=43)\n",
        "black_sample=black_sample.sample(int(0.75*len(black_sample)), random_state=43)\n",
        "data=pd.concat([white_sample, black_sample])\n",
        "\n",
        "X_sample=data.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "y_sample=data['UDPYOPI_1 - Yes']\n",
        "class_weights_sample = compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(y_sample),\n",
        "                                        y = y_sample\n",
        "                                    )\n",
        "sklearn_weights = dict(enumerate(class_weights_sample))\n",
        "class_weights_sample=sklearn_weights\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "algorithm()\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath='model_75_black.h5',\n",
        "                               monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "algorithm()\n",
        "callbacks = [checkpoint]\n",
        "number_of_features=44\n",
        "algorithm()\n",
        "netwhite = models.Sequential()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "netwhite.add(layers.Dense(units=1000, activation=\"relu\", input_shape=(\n",
        "number_of_features,)))\n",
        "algorithm()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "netwhite.add(layers.Dense(units=1000, activation=\"relu\"))\n",
        "algorithm()\n",
        "# Add fully connected layer with a sigmoid activation function\n",
        "netwhite.add(layers.Dense(units=1, activation=\"sigmoid\")) # No activation for regression\n",
        "# Compile neural netwhite\n",
        "algorithm()\n",
        "netwhite.compile(loss=\"binary_crossentropy\", # Cross-entropy # \"mse\" for regression\n",
        "optimizer=\"sgd\", # Root Mean Square Propagation\n",
        "metrics=[\"accuracy\"]) # Accuracy performance metric\n",
        "history = netwhite.fit(X_sample, # Features\n",
        "y_sample, # Target vector\n",
        "epochs=20,\n",
        "verbose=1,\n",
        "callbacks=callbacks, # Print description after each epoch\n",
        "batch_size=64,\n",
        "class_weight=class_weights_sample,\n",
        "validation_data=(X_for_test, y_for_test))\n",
        "\n",
        "######################################################################\n",
        "\n",
        "white_sample=white.sample(2448, random_state=43)\n",
        "black_sample=black.sample(2448, random_state=43)\n",
        "white_sample=white_sample.sample(int(0.125*len(white_sample)), random_state=43)\n",
        "black_sample=black_sample.sample(int(0.875*len(black_sample)), random_state=43)\n",
        "data=pd.concat([white_sample, black_sample])\n",
        "\n",
        "X_sample=data.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "y_sample=data['UDPYOPI_1 - Yes']\n",
        "class_weights_sample = compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(y_sample),\n",
        "                                        y = y_sample\n",
        "                                    )\n",
        "sklearn_weights = dict(enumerate(class_weights_sample))\n",
        "class_weights_sample=sklearn_weights\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "algorithm()\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath='model_875_black.h5',\n",
        "                               monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "algorithm()\n",
        "callbacks = [checkpoint]\n",
        "number_of_features=44\n",
        "algorithm()\n",
        "netwhite = models.Sequential()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "netwhite.add(layers.Dense(units=1000, activation=\"relu\", input_shape=(\n",
        "number_of_features,)))\n",
        "algorithm()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "netwhite.add(layers.Dense(units=1000, activation=\"relu\"))\n",
        "algorithm()\n",
        "# Add fully connected layer with a sigmoid activation function\n",
        "netwhite.add(layers.Dense(units=1, activation=\"sigmoid\")) # No activation for regression\n",
        "# Compile neural netwhite\n",
        "algorithm()\n",
        "netwhite.compile(loss=\"binary_crossentropy\", # Cross-entropy # \"mse\" for regression\n",
        "optimizer=\"sgd\", # Root Mean Square Propagation\n",
        "metrics=[\"accuracy\"]) # Accuracy performance metric\n",
        "history = netwhite.fit(X_sample, # Features\n",
        "y_sample, # Target vector\n",
        "epochs=20,\n",
        "verbose=1,\n",
        "callbacks=callbacks, # Print description after each epoch\n",
        "batch_size=64,\n",
        "class_weight=class_weights_sample,\n",
        "validation_data=(X_for_test, y_for_test))\n",
        "\n",
        "prob2_50=load_model('model_50_black.h5').predict(white_predictors_test)\n",
        "prob1_50=load_model('model_50_black.h5').predict(black_predictors_test)\n",
        "prob2_625=load_model('model_625_black.h5').predict(white_predictors_test)\n",
        "prob1_625=load_model('model_625_black.h5').predict(black_predictors_test)\n",
        "prob2_75=load_model('model_75_black.h5').predict(white_predictors_test)\n",
        "prob1_75=load_model('model_75_black.h5').predict(black_predictors_test)\n",
        "prob2_875=load_model('model_875_black.h5').predict(white_predictors_test)\n",
        "prob1_875=load_model('model_875_black.h5').predict(black_predictors_test)\n",
        "\n",
        "print('Black (50):', roc_auc_score(black_target_test, prob1_50))\n",
        "print('White (50):', roc_auc_score(white_target_test, prob2_50))\n",
        "print('Black (62.5):', roc_auc_score(black_target_test, prob1_625))\n",
        "print('White (37.5):', roc_auc_score(white_target_test, prob2_625))\n",
        "print('Black (75):', roc_auc_score(black_target_test, prob1_75))\n",
        "print('White (25):', roc_auc_score(white_target_test, prob2_75))\n",
        "print('Black (87.5):', roc_auc_score(black_target_test, prob1_875))\n",
        "print('White (12.5):', roc_auc_score(white_target_test, prob2_875))\n",
        "\n",
        "# x axis values\n",
        "x = [50, 62.5, 75, 87.5]\n",
        "# corresponding y axis values\n",
        "y = [roc_auc_score(black_target_test, prob1_50),roc_auc_score(black_target_test, prob1_625),\n",
        "     roc_auc_score(black_target_test, prob1_75),roc_auc_score(black_target_test, prob1_875)]\n",
        "z = [roc_auc_score(white_target_test, prob2_50),roc_auc_score(white_target_test, prob2_625),\n",
        "     roc_auc_score(white_target_test, prob2_75),roc_auc_score(white_target_test, prob2_875)]\n",
        "c_line_main1 = 'rgba(200, 20, 20, 1.0)'\n",
        "c_line_main2 = 'rgba(20, 20, 200, 1)'\n",
        "fig = go.Figure([\n",
        "\n",
        "    go.Scatter(\n",
        "        x          = x,\n",
        "        y          = y,\n",
        "        line       = dict(color=c_line_main1, width=3),\n",
        "        hoverinfo  = \"skip\",\n",
        "        showlegend = True,\n",
        "        name       = f'<b>Black</b>'),\n",
        "    go.Scatter(\n",
        "        x          = x,\n",
        "        y          = z,\n",
        "        line       = dict(color=c_line_main2, width=3),\n",
        "        hoverinfo  = \"skip\",\n",
        "        showlegend = True,\n",
        "        name       = f'<b>White</b>')\n",
        "    ])\n",
        "fig.add_shape(\n",
        "        type ='line',\n",
        "        line =dict(dash='dash'),\n",
        "        x0=0, x1=1, y0=0, y1=1\n",
        "    )\n",
        "fig.update_layout(\n",
        "        template    = 'plotly_white',\n",
        "        title_x     = 0.3,\n",
        "        xaxis_title = \"<b>Percentage of black race</b>\",\n",
        "        yaxis_title = \"<b>AUC</b>\",\n",
        "        width       = 600,\n",
        "        height      = 800,\n",
        "        legend      = dict(\n",
        "            yanchor=\"bottom\",\n",
        "            xanchor=\"right\",\n",
        "            x=0.95,\n",
        "            y=0.01,\n",
        "        )\n",
        "    )\n",
        "fig.update_layout(\n",
        "        font=dict(\n",
        "        family=\"Times New Roman\",\n",
        "        size=18,  # Set the font size here\n",
        "        color=\"Black\"\n",
        "        )\n",
        "    )\n",
        "fig.update_yaxes(\n",
        "        range       = [min(min(y), min(z))-0.1, max(max(y), max(z))+0.1],\n",
        "        gridcolor   = c_grid,\n",
        "        scaleanchor = \"x\",\n",
        "        scaleratio  = 190,\n",
        "        linecolor   = 'black')\n",
        "fig.update_xaxes(\n",
        "        range       = [40, 100],\n",
        "        gridcolor   = c_grid,\n",
        "        constrain   = 'domain',\n",
        "        linecolor   = 'black',dtick=12.5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97bd0cb2",
      "metadata": {
        "id": "97bd0cb2",
        "outputId": "54e71c06-2a6f-4c92-ec37-5f1fba6408a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"0a44b9c2-18bb-4b1d-8d54-1743aed1e2cf\" class=\"plotly-graph-div\" style=\"height:500px; width:600px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0a44b9c2-18bb-4b1d-8d54-1743aed1e2cf\")) {                    Plotly.newPlot(                        \"0a44b9c2-18bb-4b1d-8d54-1743aed1e2cf\",                        [{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(200, 20, 20, 1.0)\",\"width\":3},\"name\":\"\\u003cb\\u003eBlack race\\u003c\\u002fb\\u003e\",\"showlegend\":true,\"x\":[50,62.5,75,87.5],\"y\":[0.5398671096345514,0.48006644518272423,0.6445182724252491,0.9080841638981174],\"type\":\"scatter\"},{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(20, 20, 200, 1)\",\"width\":3},\"name\":\"\\u003cb\\u003eWhite race\\u003c\\u002fb\\u003e\",\"showlegend\":true,\"x\":[50,62.5,75,87.5],\"y\":[0.8439065108514191,0.7178631051752923,0.8177518085698385,0.805230940456316],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"title\":{\"x\":0.3},\"legend\":{\"yanchor\":\"bottom\",\"xanchor\":\"right\",\"x\":0.95,\"y\":0.01},\"xaxis\":{\"title\":{\"text\":\"\\u003cb\\u003ePercentage of black race\\u003c\\u002fb\\u003e\"},\"range\":[40,100],\"gridcolor\":\"rgba(5, 5, 5, 0.5)\",\"constrain\":\"domain\",\"linecolor\":\"black\",\"dtick\":12.5},\"yaxis\":{\"title\":{\"text\":\"\\u003cb\\u003eAUC\\u003c\\u002fb\\u003e\"},\"range\":[0.38006644518272426,1.0080841638981175],\"gridcolor\":\"rgba(5, 5, 5, 0.5)\",\"scaleanchor\":\"x\",\"scaleratio\":110,\"linecolor\":\"black\"},\"width\":600,\"height\":500,\"font\":{\"family\":\"Times New Roman\",\"size\":18,\"color\":\"Black\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('0a44b9c2-18bb-4b1d-8d54-1743aed1e2cf');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "x = [50, 62.5, 75, 87.5]\n",
        "# corresponding y axis values\n",
        "y = [roc_auc_score(black_target_test, prob1_50),roc_auc_score(black_target_test, prob1_625),\n",
        "     roc_auc_score(black_target_test, prob1_75),roc_auc_score(black_target_test, prob1_875)]\n",
        "z = [roc_auc_score(white_target_test, prob2_50),roc_auc_score(white_target_test, prob2_625),\n",
        "     roc_auc_score(white_target_test, prob2_75),roc_auc_score(white_target_test, prob2_875)]\n",
        "c_line_main1 = 'rgba(200, 20, 20, 1.0)'\n",
        "c_line_main2 = 'rgba(20, 20, 200, 1)'\n",
        "fig = go.Figure([\n",
        "\n",
        "    go.Scatter(\n",
        "        x          = x,\n",
        "        y          = y,\n",
        "        line       = dict(color=c_line_main1, width=3),\n",
        "        hoverinfo  = \"skip\",\n",
        "        showlegend = True,\n",
        "        name       = f'<b>Black race</b>'),\n",
        "    go.Scatter(\n",
        "        x          = x,\n",
        "        y          = z,\n",
        "        line       = dict(color=c_line_main2, width=3),\n",
        "        hoverinfo  = \"skip\",\n",
        "        showlegend = True,\n",
        "        name       = f'<b>White race</b>')\n",
        "    ])\n",
        "fig.add_shape(\n",
        "        type ='line',\n",
        "        line =dict(dash='dash'),\n",
        "        x0=0, x1=1, y0=0, y1=1\n",
        "    )\n",
        "fig.update_layout(\n",
        "        template    = 'plotly_white',\n",
        "        title_x     = 0.3,\n",
        "        xaxis_title = \"<b>Percentage of black race</b>\",\n",
        "        yaxis_title = \"<b>AUC</b>\",\n",
        "        width       = 600,\n",
        "        height      = 500,\n",
        "        legend      = dict(\n",
        "            yanchor=\"bottom\",\n",
        "            xanchor=\"right\",\n",
        "            x=0.95,\n",
        "            y=0.01,\n",
        "        )\n",
        "    )\n",
        "fig.update_layout(\n",
        "        font=dict(\n",
        "        family=\"Times New Roman\",\n",
        "        size=18,  # Set the font size here\n",
        "        color=\"Black\"\n",
        "        )\n",
        "    )\n",
        "fig.update_yaxes(\n",
        "        range       = [min(min(y), min(z))-0.1, max(max(y), max(z))+0.1],\n",
        "        gridcolor   = c_grid,\n",
        "        scaleanchor = \"x\",\n",
        "        scaleratio  = 110,\n",
        "        linecolor   = 'black')\n",
        "fig.update_xaxes(\n",
        "        range       = [40, 100],\n",
        "        gridcolor   = c_grid,\n",
        "        constrain   = 'domain',\n",
        "        linecolor   = 'black',dtick=12.5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b9980a6",
      "metadata": {
        "id": "8b9980a6"
      },
      "outputs": [],
      "source": [
        "income=train.drop(X_train[X_train['INCOME_1 - Less than $20,000'] == 0].index)\n",
        "elsee=train.drop(X_train[X_train['INCOME_1 - Less than $20,000'] == 1].index)\n",
        "income_test=test.drop(X_test[X_test['INCOME_1 - Less than $20,000'] == 0].index)\n",
        "income_test=income_test.sample(2179, random_state=43)\n",
        "income_predictors_test=income_test.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "income_target_test=income_test['UDPYOPI_1 - Yes']\n",
        "elsee_test=test.drop(X_test[X_test['INCOME_1 - Less than $20,000'] == 1].index)\n",
        "elsee_test=elsee_test.sample(2179, random_state=43)\n",
        "elsee_predictors_test=elsee_test.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "elsee_target_test=elsee_test['UDPYOPI_1 - Yes']\n",
        "data_test=pd.concat([income_test, elsee_test])\n",
        "X_for_test=data_test.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "y_for_test=data_test['UDPYOPI_1 - Yes']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "income_test=test.drop(X_test[X_test['INCOME_1 - Less than $20,000'] == 0].index)\n",
        "elsee_test=test.drop(X_test[X_test['INCOME_1 - Less than $20,000'] == 1].index)\n",
        "print(len(income_test))\n",
        "print(len(elsee_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1yehLAg4U6R",
        "outputId": "b4cac557-9c23-41db-e17e-5adec9a43a9f"
      },
      "id": "L1yehLAg4U6R",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2179\n",
            "4404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "income=train.drop(X_train[X_train['INCOME_1 - Less than $20,000'] == 0].index)\n",
        "elsee=train.drop(X_train[X_train['INCOME_1 - Less than $20,000'] == 1].index)\n",
        "print(len(income))\n",
        "print(len(elsee))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcugpfpV4PUU",
        "outputId": "e6eda310-7520-48dd-af68-953f59a963d8"
      },
      "id": "OcugpfpV4PUU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8588\n",
            "17742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fe9f652",
      "metadata": {
        "id": "7fe9f652",
        "outputId": "da9dcbc3-2286-46f8-b0a8-075226ec7bf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "133/135 [============================>.] - ETA: 0s - loss: 0.9332 - accuracy: 0.4852\n",
            "Epoch 1: val_accuracy improved from -inf to 0.94837, saving model to model_50_income.h5\n",
            "135/135 [==============================] - 3s 17ms/step - loss: 0.9283 - accuracy: 0.4845 - val_loss: 0.5341 - val_accuracy: 0.9484\n",
            "Epoch 2/20\n",
            "131/135 [============================>.] - ETA: 0s - loss: 0.6631 - accuracy: 0.5998\n",
            "Epoch 2: val_accuracy improved from 0.94837 to 0.96076, saving model to model_50_income.h5\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.6541 - accuracy: 0.6072 - val_loss: 0.4055 - val_accuracy: 0.9608\n",
            "Epoch 3/20\n",
            "131/135 [============================>.] - ETA: 0s - loss: 0.6825 - accuracy: 0.5477\n",
            "Epoch 3: val_accuracy did not improve from 0.96076\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.6894 - accuracy: 0.5565 - val_loss: 0.6925 - val_accuracy: 0.6361\n",
            "Epoch 4/20\n",
            "135/135 [==============================] - ETA: 0s - loss: 0.6649 - accuracy: 0.6165\n",
            "Epoch 4: val_accuracy did not improve from 0.96076\n",
            "135/135 [==============================] - 2s 16ms/step - loss: 0.6649 - accuracy: 0.6165 - val_loss: 0.6871 - val_accuracy: 0.6985\n",
            "Epoch 5/20\n",
            "133/135 [============================>.] - ETA: 0s - loss: 0.6479 - accuracy: 0.6380\n",
            "Epoch 5: val_accuracy did not improve from 0.96076\n",
            "135/135 [==============================] - 3s 25ms/step - loss: 0.6452 - accuracy: 0.6393 - val_loss: 0.5218 - val_accuracy: 0.9534\n",
            "Epoch 6/20\n",
            "135/135 [==============================] - ETA: 0s - loss: 0.5941 - accuracy: 0.6579\n",
            "Epoch 6: val_accuracy improved from 0.96076 to 0.98577, saving model to model_50_income.h5\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.5941 - accuracy: 0.6579 - val_loss: 0.1920 - val_accuracy: 0.9858\n",
            "Epoch 7/20\n",
            "133/135 [============================>.] - ETA: 0s - loss: 0.6125 - accuracy: 0.6964\n",
            "Epoch 7: val_accuracy did not improve from 0.98577\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.6087 - accuracy: 0.6989 - val_loss: 0.2749 - val_accuracy: 0.9849\n",
            "Epoch 8/20\n",
            "133/135 [============================>.] - ETA: 0s - loss: 0.5924 - accuracy: 0.6917\n",
            "Epoch 8: val_accuracy did not improve from 0.98577\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.6039 - accuracy: 0.6942 - val_loss: 13.0471 - val_accuracy: 0.0055\n",
            "Epoch 9/20\n",
            "134/135 [============================>.] - ETA: 0s - loss: 0.9241 - accuracy: 0.4963\n",
            "Epoch 9: val_accuracy did not improve from 0.98577\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.9236 - accuracy: 0.4958 - val_loss: 0.6614 - val_accuracy: 0.9270\n",
            "Epoch 10/20\n",
            "134/135 [============================>.] - ETA: 0s - loss: 0.6908 - accuracy: 0.5279\n",
            "Epoch 10: val_accuracy did not improve from 0.98577\n",
            "135/135 [==============================] - 2s 17ms/step - loss: 0.6906 - accuracy: 0.5274 - val_loss: 0.8112 - val_accuracy: 0.0734\n",
            "Epoch 11/20\n",
            "135/135 [==============================] - ETA: 0s - loss: 0.6565 - accuracy: 0.5183\n",
            "Epoch 11: val_accuracy did not improve from 0.98577\n",
            "135/135 [==============================] - 3s 25ms/step - loss: 0.6565 - accuracy: 0.5183 - val_loss: 0.5370 - val_accuracy: 0.9812\n",
            "Epoch 12/20\n",
            "131/135 [============================>.] - ETA: 0s - loss: 0.6413 - accuracy: 0.5892\n",
            "Epoch 12: val_accuracy did not improve from 0.98577\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.6418 - accuracy: 0.5828 - val_loss: 0.7286 - val_accuracy: 0.3924\n",
            "Epoch 13/20\n",
            "134/135 [============================>.] - ETA: 0s - loss: 0.6293 - accuracy: 0.6196\n",
            "Epoch 13: val_accuracy improved from 0.98577 to 0.98715, saving model to model_50_income.h5\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.6289 - accuracy: 0.6200 - val_loss: 0.3466 - val_accuracy: 0.9872\n",
            "Epoch 14/20\n",
            "132/135 [============================>.] - ETA: 0s - loss: 0.6218 - accuracy: 0.6693\n",
            "Epoch 14: val_accuracy did not improve from 0.98715\n",
            "135/135 [==============================] - 3s 19ms/step - loss: 0.6274 - accuracy: 0.6643 - val_loss: 0.8058 - val_accuracy: 0.1969\n",
            "Epoch 15/20\n",
            "135/135 [==============================] - ETA: 0s - loss: 0.6036 - accuracy: 0.6815\n",
            "Epoch 15: val_accuracy did not improve from 0.98715\n",
            "135/135 [==============================] - 3s 24ms/step - loss: 0.6036 - accuracy: 0.6815 - val_loss: 0.8769 - val_accuracy: 0.0996\n",
            "Epoch 16/20\n",
            "133/135 [============================>.] - ETA: 0s - loss: 0.5794 - accuracy: 0.6856\n",
            "Epoch 16: val_accuracy improved from 0.98715 to 0.98807, saving model to model_50_income.h5\n",
            "135/135 [==============================] - 3s 24ms/step - loss: 0.5756 - accuracy: 0.6883 - val_loss: 0.2220 - val_accuracy: 0.9881\n",
            "Epoch 17/20\n",
            "131/135 [============================>.] - ETA: 0s - loss: 0.5786 - accuracy: 0.7291\n",
            "Epoch 17: val_accuracy did not improve from 0.98807\n",
            "135/135 [==============================] - 2s 17ms/step - loss: 0.5820 - accuracy: 0.7146 - val_loss: 0.6801 - val_accuracy: 0.6696\n",
            "Epoch 18/20\n",
            "132/135 [============================>.] - ETA: 0s - loss: 0.5837 - accuracy: 0.7249\n",
            "Epoch 18: val_accuracy did not improve from 0.98807\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.5829 - accuracy: 0.7166 - val_loss: 0.4453 - val_accuracy: 0.9275\n",
            "Epoch 19/20\n",
            "132/135 [============================>.] - ETA: 0s - loss: 0.5381 - accuracy: 0.7480\n",
            "Epoch 19: val_accuracy did not improve from 0.98807\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.5386 - accuracy: 0.7399 - val_loss: 0.5213 - val_accuracy: 0.8720\n",
            "Epoch 20/20\n",
            "135/135 [==============================] - ETA: 0s - loss: 0.5303 - accuracy: 0.7353\n",
            "Epoch 20: val_accuracy did not improve from 0.98807\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.5303 - accuracy: 0.7353 - val_loss: 0.3834 - val_accuracy: 0.9394\n",
            "Epoch 1/20\n",
            "133/135 [============================>.] - ETA: 0s - loss: 0.9129 - accuracy: 0.4867\n",
            "Epoch 1: val_accuracy improved from -inf to 0.03580, saving model to model_625_income.h5\n",
            "135/135 [==============================] - 3s 17ms/step - loss: 0.9132 - accuracy: 0.4832 - val_loss: 0.9048 - val_accuracy: 0.0358\n",
            "Epoch 2/20\n",
            "133/135 [============================>.] - ETA: 0s - loss: 0.6777 - accuracy: 0.4947\n",
            "Epoch 2: val_accuracy improved from 0.03580 to 0.98807, saving model to model_625_income.h5\n",
            "135/135 [==============================] - 3s 24ms/step - loss: 0.6738 - accuracy: 0.4988 - val_loss: 0.3374 - val_accuracy: 0.9881\n",
            "Epoch 3/20\n",
            "131/135 [============================>.] - ETA: 0s - loss: 0.6559 - accuracy: 0.6087\n",
            "Epoch 3: val_accuracy did not improve from 0.98807\n",
            "135/135 [==============================] - 2s 16ms/step - loss: 0.6539 - accuracy: 0.6081 - val_loss: 0.6332 - val_accuracy: 0.8442\n",
            "Epoch 4/20\n",
            "131/135 [============================>.] - ETA: 0s - loss: 0.6369 - accuracy: 0.6266\n",
            "Epoch 4: val_accuracy did not improve from 0.98807\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.6449 - accuracy: 0.6265 - val_loss: 0.6981 - val_accuracy: 0.5750\n",
            "Epoch 5/20\n",
            "132/135 [============================>.] - ETA: 0s - loss: 0.6333 - accuracy: 0.6444\n",
            "Epoch 5: val_accuracy did not improve from 0.98807\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.6381 - accuracy: 0.6496 - val_loss: 0.4364 - val_accuracy: 0.9718\n",
            "Epoch 6/20\n",
            "133/135 [============================>.] - ETA: 0s - loss: 0.6380 - accuracy: 0.6279\n",
            "Epoch 6: val_accuracy improved from 0.98807 to 0.99036, saving model to model_625_income.h5\n",
            "135/135 [==============================] - 2s 16ms/step - loss: 0.6341 - accuracy: 0.6309 - val_loss: 0.2840 - val_accuracy: 0.9904\n",
            "Epoch 7/20\n",
            "134/135 [============================>.] - ETA: 0s - loss: 0.6384 - accuracy: 0.6608\n",
            "Epoch 7: val_accuracy did not improve from 0.99036\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.6381 - accuracy: 0.6610 - val_loss: 0.4071 - val_accuracy: 0.9736\n",
            "Epoch 8/20\n",
            "135/135 [==============================] - ETA: 0s - loss: 0.6010 - accuracy: 0.6897\n",
            "Epoch 8: val_accuracy did not improve from 0.99036\n",
            "135/135 [==============================] - 3s 24ms/step - loss: 0.6010 - accuracy: 0.6897 - val_loss: 5.6346 - val_accuracy: 0.0796\n",
            "Epoch 9/20\n",
            "131/135 [============================>.] - ETA: 0s - loss: 0.6709 - accuracy: 0.5842\n",
            "Epoch 9: val_accuracy did not improve from 0.99036\n",
            "135/135 [==============================] - 2s 17ms/step - loss: 0.6712 - accuracy: 0.5913 - val_loss: 0.5277 - val_accuracy: 0.9291\n",
            "Epoch 10/20\n",
            "133/135 [============================>.] - ETA: 0s - loss: 0.6728 - accuracy: 0.5804\n",
            "Epoch 10: val_accuracy did not improve from 0.99036\n",
            "135/135 [==============================] - 2s 14ms/step - loss: 0.6699 - accuracy: 0.5815 - val_loss: 0.4551 - val_accuracy: 0.9734\n",
            "Epoch 11/20\n",
            "133/135 [============================>.] - ETA: 0s - loss: 0.6014 - accuracy: 0.6551\n",
            "Epoch 11: val_accuracy did not improve from 0.99036\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.6058 - accuracy: 0.6567 - val_loss: 1.0509 - val_accuracy: 0.0856\n",
            "Epoch 12/20\n",
            "132/135 [============================>.] - ETA: 0s - loss: 0.5888 - accuracy: 0.6795\n",
            "Epoch 12: val_accuracy did not improve from 0.99036\n",
            "135/135 [==============================] - 2s 14ms/step - loss: 0.5832 - accuracy: 0.6832 - val_loss: 0.2678 - val_accuracy: 0.9784\n",
            "Epoch 13/20\n",
            "134/135 [============================>.] - ETA: 0s - loss: 0.5748 - accuracy: 0.6861\n",
            "Epoch 13: val_accuracy did not improve from 0.99036\n",
            "135/135 [==============================] - 2s 14ms/step - loss: 0.5744 - accuracy: 0.6864 - val_loss: 0.2555 - val_accuracy: 0.9876\n",
            "Epoch 14/20\n",
            "132/135 [============================>.] - ETA: 0s - loss: 0.5684 - accuracy: 0.7025\n",
            "Epoch 14: val_accuracy did not improve from 0.99036\n",
            "135/135 [==============================] - 3s 22ms/step - loss: 0.5691 - accuracy: 0.7048 - val_loss: 0.5017 - val_accuracy: 0.8954\n",
            "Epoch 15/20\n",
            "135/135 [==============================] - ETA: 0s - loss: 0.5746 - accuracy: 0.7390\n",
            "Epoch 15: val_accuracy did not improve from 0.99036\n",
            "135/135 [==============================] - 3s 19ms/step - loss: 0.5746 - accuracy: 0.7390 - val_loss: 0.4824 - val_accuracy: 0.9222\n",
            "Epoch 16/20\n",
            "133/135 [============================>.] - ETA: 0s - loss: 0.5538 - accuracy: 0.7298\n",
            "Epoch 16: val_accuracy did not improve from 0.99036\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.5545 - accuracy: 0.7315 - val_loss: 8.7250 - val_accuracy: 0.0819\n",
            "Epoch 17/20\n",
            "133/135 [============================>.] - ETA: 0s - loss: 0.6546 - accuracy: 0.6553\n",
            "Epoch 17: val_accuracy did not improve from 0.99036\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.6509 - accuracy: 0.6580 - val_loss: 0.2893 - val_accuracy: 0.9789\n",
            "Epoch 18/20\n",
            "134/135 [============================>.] - ETA: 0s - loss: 0.5418 - accuracy: 0.7403\n",
            "Epoch 18: val_accuracy did not improve from 0.99036\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.5414 - accuracy: 0.7404 - val_loss: 0.2070 - val_accuracy: 0.9782\n",
            "Epoch 19/20\n",
            "131/135 [============================>.] - ETA: 0s - loss: 0.5859 - accuracy: 0.7085\n",
            "Epoch 19: val_accuracy did not improve from 0.99036\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.5855 - accuracy: 0.7139 - val_loss: 0.6795 - val_accuracy: 0.6221\n",
            "Epoch 20/20\n",
            "132/135 [============================>.] - ETA: 0s - loss: 0.5283 - accuracy: 0.7408\n",
            "Epoch 20: val_accuracy did not improve from 0.99036\n",
            "135/135 [==============================] - 3s 19ms/step - loss: 0.5261 - accuracy: 0.7418 - val_loss: 1.4416 - val_accuracy: 0.0856\n",
            "Epoch 1/20\n",
            "132/135 [============================>.] - ETA: 0s - loss: 0.9282 - accuracy: 0.4968\n",
            "Epoch 1: val_accuracy improved from -inf to 0.34741, saving model to model_75_income.h5\n",
            "135/135 [==============================] - 3s 16ms/step - loss: 0.9215 - accuracy: 0.4896 - val_loss: 0.7117 - val_accuracy: 0.3474\n",
            "Epoch 2/20\n",
            "133/135 [============================>.] - ETA: 0s - loss: 0.6863 - accuracy: 0.5341\n",
            "Epoch 2: val_accuracy improved from 0.34741 to 0.98967, saving model to model_75_income.h5\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.6829 - accuracy: 0.5379 - val_loss: 0.4751 - val_accuracy: 0.9897\n",
            "Epoch 3/20\n",
            "131/135 [============================>.] - ETA: 0s - loss: 0.6595 - accuracy: 0.6137\n",
            "Epoch 3: val_accuracy did not improve from 0.98967\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.6581 - accuracy: 0.6188 - val_loss: 0.6407 - val_accuracy: 0.8614\n",
            "Epoch 4/20\n",
            "131/135 [============================>.] - ETA: 0s - loss: 0.6512 - accuracy: 0.6059\n",
            "Epoch 4: val_accuracy did not improve from 0.98967\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.6531 - accuracy: 0.6101 - val_loss: 0.5538 - val_accuracy: 0.9660\n",
            "Epoch 5/20\n",
            "134/135 [============================>.] - ETA: 0s - loss: 0.6304 - accuracy: 0.6678\n",
            "Epoch 5: val_accuracy improved from 0.98967 to 0.98990, saving model to model_75_income.h5\n",
            "135/135 [==============================] - 3s 19ms/step - loss: 0.6300 - accuracy: 0.6681 - val_loss: 0.3314 - val_accuracy: 0.9899\n",
            "Epoch 6/20\n",
            "135/135 [==============================] - ETA: 0s - loss: 0.6440 - accuracy: 0.6467\n",
            "Epoch 6: val_accuracy did not improve from 0.98990\n",
            "135/135 [==============================] - 3s 21ms/step - loss: 0.6440 - accuracy: 0.6467 - val_loss: 0.4656 - val_accuracy: 0.9718\n",
            "Epoch 7/20\n",
            "135/135 [==============================] - ETA: 0s - loss: 0.6512 - accuracy: 0.6153\n",
            "Epoch 7: val_accuracy did not improve from 0.98990\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.6512 - accuracy: 0.6153 - val_loss: 3.6079 - val_accuracy: 0.0794\n",
            "Epoch 8/20\n",
            "133/135 [============================>.] - ETA: 0s - loss: 0.6530 - accuracy: 0.6228\n",
            "Epoch 8: val_accuracy did not improve from 0.98990\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.6601 - accuracy: 0.6184 - val_loss: 5.3703 - val_accuracy: 0.0773\n",
            "Epoch 9/20\n",
            "131/135 [============================>.] - ETA: 0s - loss: 0.7183 - accuracy: 0.5336\n",
            "Epoch 9: val_accuracy did not improve from 0.98990\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.7131 - accuracy: 0.5388 - val_loss: 0.4345 - val_accuracy: 0.9819\n",
            "Epoch 10/20\n",
            "131/135 [============================>.] - ETA: 0s - loss: 0.6744 - accuracy: 0.5899\n",
            "Epoch 10: val_accuracy did not improve from 0.98990\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.6713 - accuracy: 0.5819 - val_loss: 0.5677 - val_accuracy: 0.9346\n",
            "Epoch 11/20\n",
            "133/135 [============================>.] - ETA: 0s - loss: 0.6001 - accuracy: 0.6611\n",
            "Epoch 11: val_accuracy did not improve from 0.98990\n",
            "135/135 [==============================] - 3s 20ms/step - loss: 0.6069 - accuracy: 0.6629 - val_loss: 1.0367 - val_accuracy: 0.0833\n",
            "Epoch 12/20\n",
            "133/135 [============================>.] - ETA: 0s - loss: 0.5972 - accuracy: 0.6157\n",
            "Epoch 12: val_accuracy did not improve from 0.98990\n",
            "135/135 [==============================] - 3s 22ms/step - loss: 0.5945 - accuracy: 0.6179 - val_loss: 0.3685 - val_accuracy: 0.9768\n",
            "Epoch 13/20\n",
            "133/135 [============================>.] - ETA: 0s - loss: 0.5578 - accuracy: 0.7153\n",
            "Epoch 13: val_accuracy did not improve from 0.98990\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.5600 - accuracy: 0.7155 - val_loss: 0.6045 - val_accuracy: 0.8155\n",
            "Epoch 14/20\n",
            "132/135 [============================>.] - ETA: 0s - loss: 0.6146 - accuracy: 0.6542\n",
            "Epoch 14: val_accuracy did not improve from 0.98990\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.6156 - accuracy: 0.6558 - val_loss: 0.5927 - val_accuracy: 0.8511\n",
            "Epoch 15/20\n",
            "132/135 [============================>.] - ETA: 0s - loss: 0.5807 - accuracy: 0.7010\n",
            "Epoch 15: val_accuracy did not improve from 0.98990\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.5800 - accuracy: 0.7025 - val_loss: 0.5141 - val_accuracy: 0.9041\n",
            "Epoch 16/20\n",
            "133/135 [============================>.] - ETA: 0s - loss: 0.5839 - accuracy: 0.7236\n",
            "Epoch 16: val_accuracy did not improve from 0.98990\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.5850 - accuracy: 0.7239 - val_loss: 6.2480 - val_accuracy: 0.0826\n",
            "Epoch 17/20\n",
            "133/135 [============================>.] - ETA: 0s - loss: 0.6506 - accuracy: 0.6594\n",
            "Epoch 17: val_accuracy did not improve from 0.98990\n",
            "135/135 [==============================] - 3s 19ms/step - loss: 0.6589 - accuracy: 0.6617 - val_loss: 0.4597 - val_accuracy: 0.9566\n",
            "Epoch 18/20\n",
            "133/135 [============================>.] - ETA: 0s - loss: 0.5405 - accuracy: 0.7619\n",
            "Epoch 18: val_accuracy did not improve from 0.98990\n",
            "135/135 [==============================] - 3s 25ms/step - loss: 0.5382 - accuracy: 0.7626 - val_loss: 0.2818 - val_accuracy: 0.9734\n",
            "Epoch 19/20\n",
            "135/135 [==============================] - ETA: 0s - loss: 0.5792 - accuracy: 0.6993\n",
            "Epoch 19: val_accuracy did not improve from 0.98990\n",
            "135/135 [==============================] - 4s 26ms/step - loss: 0.5792 - accuracy: 0.6993 - val_loss: 0.8775 - val_accuracy: 0.2458\n",
            "Epoch 20/20\n",
            "131/135 [============================>.] - ETA: 0s - loss: 0.5364 - accuracy: 0.7444\n",
            "Epoch 20: val_accuracy did not improve from 0.98990\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.5325 - accuracy: 0.7428 - val_loss: 0.3904 - val_accuracy: 0.9578\n",
            "Epoch 1/20\n",
            "131/135 [============================>.] - ETA: 0s - loss: 0.8828 - accuracy: 0.5052\n",
            "Epoch 1: val_accuracy improved from -inf to 0.32079, saving model to model_875_income.h5\n",
            "135/135 [==============================] - 3s 17ms/step - loss: 0.8806 - accuracy: 0.5010 - val_loss: 0.7204 - val_accuracy: 0.3208\n",
            "Epoch 2/20\n",
            "134/135 [============================>.] - ETA: 0s - loss: 0.6938 - accuracy: 0.5128\n",
            "Epoch 2: val_accuracy improved from 0.32079 to 0.99128, saving model to model_875_income.h5\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.6934 - accuracy: 0.5132 - val_loss: 0.4429 - val_accuracy: 0.9913\n",
            "Epoch 3/20\n",
            "132/135 [============================>.] - ETA: 0s - loss: 0.6730 - accuracy: 0.5690\n",
            "Epoch 3: val_accuracy did not improve from 0.99128\n",
            "135/135 [==============================] - 3s 25ms/step - loss: 0.6731 - accuracy: 0.5726 - val_loss: 0.6607 - val_accuracy: 0.7816\n",
            "Epoch 4/20\n",
            "132/135 [============================>.] - ETA: 0s - loss: 0.6331 - accuracy: 0.6183\n",
            "Epoch 4: val_accuracy did not improve from 0.99128\n",
            "135/135 [==============================] - 2s 17ms/step - loss: 0.6410 - accuracy: 0.6166 - val_loss: 0.6033 - val_accuracy: 0.8825\n",
            "Epoch 5/20\n",
            "132/135 [============================>.] - ETA: 0s - loss: 0.6287 - accuracy: 0.6297\n",
            "Epoch 5: val_accuracy did not improve from 0.99128\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.6322 - accuracy: 0.6213 - val_loss: 4.4218 - val_accuracy: 0.0824\n",
            "Epoch 6/20\n",
            "134/135 [============================>.] - ETA: 0s - loss: 0.6920 - accuracy: 0.5075\n",
            "Epoch 6: val_accuracy did not improve from 0.99128\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.6916 - accuracy: 0.5079 - val_loss: 0.3715 - val_accuracy: 0.9911\n",
            "Epoch 7/20\n",
            "132/135 [============================>.] - ETA: 0s - loss: 0.6479 - accuracy: 0.6123\n",
            "Epoch 7: val_accuracy did not improve from 0.99128\n",
            "135/135 [==============================] - 2s 16ms/step - loss: 0.6430 - accuracy: 0.6129 - val_loss: 0.4553 - val_accuracy: 0.9766\n",
            "Epoch 8/20\n",
            "131/135 [============================>.] - ETA: 0s - loss: 0.6210 - accuracy: 0.6486\n",
            "Epoch 8: val_accuracy did not improve from 0.99128\n",
            "135/135 [==============================] - 2s 18ms/step - loss: 0.6262 - accuracy: 0.6490 - val_loss: 5.2182 - val_accuracy: 0.0831\n",
            "Epoch 9/20\n",
            "134/135 [============================>.] - ETA: 0s - loss: 0.6958 - accuracy: 0.5149\n",
            "Epoch 9: val_accuracy did not improve from 0.99128\n",
            "135/135 [==============================] - 3s 24ms/step - loss: 0.6954 - accuracy: 0.5153 - val_loss: 0.3852 - val_accuracy: 0.9874\n",
            "Epoch 10/20\n",
            "132/135 [============================>.] - ETA: 0s - loss: 0.6427 - accuracy: 0.6594\n",
            "Epoch 10: val_accuracy did not improve from 0.99128\n",
            "135/135 [==============================] - 2s 16ms/step - loss: 0.6415 - accuracy: 0.6561 - val_loss: 0.5260 - val_accuracy: 0.9314\n",
            "Epoch 11/20\n",
            "133/135 [============================>.] - ETA: 0s - loss: 0.5702 - accuracy: 0.6848\n",
            "Epoch 11: val_accuracy did not improve from 0.99128\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.5838 - accuracy: 0.6865 - val_loss: 1.0303 - val_accuracy: 0.0890\n",
            "Epoch 12/20\n",
            "134/135 [============================>.] - ETA: 0s - loss: 0.5546 - accuracy: 0.7087\n",
            "Epoch 12: val_accuracy did not improve from 0.99128\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.5543 - accuracy: 0.7090 - val_loss: 0.3475 - val_accuracy: 0.9617\n",
            "Epoch 13/20\n",
            "131/135 [============================>.] - ETA: 0s - loss: 0.5535 - accuracy: 0.7024\n",
            "Epoch 13: val_accuracy did not improve from 0.99128\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.5437 - accuracy: 0.7090 - val_loss: 0.2067 - val_accuracy: 0.9901\n",
            "Epoch 14/20\n",
            "132/135 [============================>.] - ETA: 0s - loss: 0.5742 - accuracy: 0.6909\n",
            "Epoch 14: val_accuracy did not improve from 0.99128\n",
            "135/135 [==============================] - 2s 18ms/step - loss: 0.5756 - accuracy: 0.6904 - val_loss: 0.5404 - val_accuracy: 0.8589\n",
            "Epoch 15/20\n",
            "135/135 [==============================] - ETA: 0s - loss: 0.5630 - accuracy: 0.7239\n",
            "Epoch 15: val_accuracy did not improve from 0.99128\n",
            "135/135 [==============================] - 3s 24ms/step - loss: 0.5630 - accuracy: 0.7239 - val_loss: 0.5939 - val_accuracy: 0.7981\n",
            "Epoch 16/20\n",
            "133/135 [============================>.] - ETA: 0s - loss: 0.5505 - accuracy: 0.7223\n",
            "Epoch 16: val_accuracy did not improve from 0.99128\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.5569 - accuracy: 0.7245 - val_loss: 14.8360 - val_accuracy: 0.0831\n",
            "Epoch 17/20\n",
            "131/135 [============================>.] - ETA: 0s - loss: 0.8208 - accuracy: 0.5871\n",
            "Epoch 17: val_accuracy improved from 0.99128 to 0.99358, saving model to model_875_income.h5\n",
            "135/135 [==============================] - 2s 15ms/step - loss: 0.8072 - accuracy: 0.5953 - val_loss: 0.3103 - val_accuracy: 0.9936\n",
            "Epoch 18/20\n",
            "131/135 [============================>.] - ETA: 0s - loss: 0.6431 - accuracy: 0.6360\n",
            "Epoch 18: val_accuracy did not improve from 0.99358\n",
            "135/135 [==============================] - 2s 16ms/step - loss: 0.6410 - accuracy: 0.6356 - val_loss: 0.5474 - val_accuracy: 0.9369\n",
            "Epoch 19/20\n",
            "134/135 [============================>.] - ETA: 0s - loss: 0.5779 - accuracy: 0.7401\n",
            "Epoch 19: val_accuracy did not improve from 0.99358\n",
            "135/135 [==============================] - 2s 16ms/step - loss: 0.5780 - accuracy: 0.7394 - val_loss: 0.8218 - val_accuracy: 0.3040\n",
            "Epoch 20/20\n",
            "135/135 [==============================] - ETA: 0s - loss: 0.5435 - accuracy: 0.7336\n",
            "Epoch 20: val_accuracy did not improve from 0.99358\n",
            "135/135 [==============================] - 3s 19ms/step - loss: 0.5435 - accuracy: 0.7336 - val_loss: 0.3378 - val_accuracy: 0.9640\n",
            "69/69 [==============================] - 0s 5ms/step\n",
            "69/69 [==============================] - 0s 5ms/step\n",
            "69/69 [==============================] - 0s 5ms/step\n",
            "69/69 [==============================] - 0s 3ms/step\n",
            "69/69 [==============================] - 0s 3ms/step\n",
            "69/69 [==============================] - 0s 3ms/step\n",
            "69/69 [==============================] - 0s 3ms/step\n",
            "69/69 [==============================] - 0s 3ms/step\n",
            "Income less than $20,000 (50): 0.7918856615952051\n",
            "Else (50): 0.833817222038931\n",
            "Income less than $20,000 (62.5): 0.8112955278930382\n",
            "Else (37.5): 0.859881227317717\n",
            "Income less than $20,000 (75): 0.8256800368833563\n",
            "Else (25): 0.9071923457604751\n",
            "Income less than $20,000 (87.5): 0.9244813278008298\n",
            "Else (12.5): 0.9415044539755856\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"97828eef-4d06-44b6-99e8-3a68cb82c267\" class=\"plotly-graph-div\" style=\"height:500px; width:600px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"97828eef-4d06-44b6-99e8-3a68cb82c267\")) {                    Plotly.newPlot(                        \"97828eef-4d06-44b6-99e8-3a68cb82c267\",                        [{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(200, 20, 20, 1.0)\",\"width\":3},\"name\":\"\\u003cb\\u003eOther\\u003c\\u002fb\\u003e\",\"showlegend\":true,\"x\":[50,62.5,75,87.5],\"y\":[0.833817222038931,0.859881227317717,0.9071923457604751,0.9415044539755856],\"type\":\"scatter\"},{\"hoverinfo\":\"skip\",\"line\":{\"color\":\"rgba(20, 20, 200, 1)\",\"width\":3},\"name\":\"\\u003cb\\u003eIncome less than $20,000\\u003c\\u002fb\\u003e\",\"showlegend\":true,\"x\":[50,62.5,75,87.5],\"y\":[0.7918856615952051,0.8112955278930382,0.8256800368833563,0.9244813278008298],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"title\":{\"x\":0.3},\"legend\":{\"yanchor\":\"bottom\",\"xanchor\":\"right\",\"x\":0.95,\"y\":0.01},\"xaxis\":{\"title\":{\"text\":\"\\u003cb\\u003ePercentage of 'Income less than $20,000'\\u003c\\u002fb\\u003e\"},\"range\":[40,100],\"gridcolor\":\"rgba(5, 5, 5, 0.5)\",\"constrain\":\"domain\",\"linecolor\":\"black\",\"dtick\":12.5},\"yaxis\":{\"title\":{\"text\":\"\\u003cb\\u003eAUC\\u003c\\u002fb\\u003e\"},\"range\":[0.6918856615952051,1.0415044539755856],\"gridcolor\":\"rgba(5, 5, 5, 0.5)\",\"scaleanchor\":\"x\",\"scaleratio\":190,\"linecolor\":\"black\"},\"width\":600,\"height\":500,\"font\":{\"family\":\"Times New Roman\",\"size\":18,\"color\":\"Black\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('97828eef-4d06-44b6-99e8-3a68cb82c267');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "income_sample=income.sample(8584, random_state=43)\n",
        "elsee_sample=elsee.sample(8584, random_state=43)\n",
        "income_sample=income_sample.sample(int(0.5*len(income_sample)), random_state=43)\n",
        "elsee_sample=elsee_sample.sample(int(0.5*len(elsee_sample)), random_state=43)\n",
        "data=pd.concat([income_sample, elsee_sample])\n",
        "X_sample=data.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "y_sample=data['UDPYOPI_1 - Yes']\n",
        "class_weights_sample = compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(y_sample),\n",
        "                                        y = y_sample\n",
        "                                    )\n",
        "sklearn_weights = dict(enumerate(class_weights_sample))\n",
        "class_weights_sample=sklearn_weights\n",
        "\n",
        "algorithm()\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath='model_50_income.h5',\n",
        "                               monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "algorithm()\n",
        "callbacks = [checkpoint]\n",
        "number_of_features=44\n",
        "algorithm()\n",
        "netincome = models.Sequential()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "netincome.add(layers.Dense(units=1000, activation=\"relu\", input_shape=(\n",
        "number_of_features,)))\n",
        "algorithm()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "netincome.add(layers.Dense(units=1000, activation=\"relu\"))\n",
        "algorithm()\n",
        "# Add fully connected layer with a sigmoid activation function\n",
        "netincome.add(layers.Dense(units=1, activation=\"sigmoid\")) # No activation for regression\n",
        "# Compile neural netincome\n",
        "algorithm()\n",
        "netincome.compile(loss=\"binary_crossentropy\", # Cross-entropy # \"mse\" for regression\n",
        "optimizer=\"sgd\", # Root Mean Square Propagation\n",
        "metrics=[\"accuracy\"]) # Accuracy performance metric\n",
        "history = netincome.fit(X_sample, # Features\n",
        "y_sample, # Target vector\n",
        "epochs=20,\n",
        "verbose=1,\n",
        "callbacks=callbacks, # Print description after each epoch\n",
        "batch_size=64,\n",
        "class_weight=class_weights_sample,\n",
        "validation_data=(X_for_test, y_for_test))\n",
        "\n",
        "######################################################################\n",
        "\n",
        "income_sample=income.sample(8584, random_state=43)\n",
        "elsee_sample=elsee.sample(8584, random_state=43)\n",
        "income_sample=income_sample.sample(int(0.625*len(income_sample)), random_state=43)\n",
        "elsee_sample=elsee_sample.sample(int(0.375*len(elsee_sample)), random_state=43)\n",
        "data=pd.concat([income_sample, elsee_sample])\n",
        "\n",
        "X_sample=data.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "y_sample=data['UDPYOPI_1 - Yes']\n",
        "class_weights_sample = compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(y_sample),\n",
        "                                        y = y_sample\n",
        "                                    )\n",
        "sklearn_weights = dict(enumerate(class_weights_sample))\n",
        "class_weights_sample=sklearn_weights\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "algorithm()\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath='model_625_income.h5',\n",
        "                               monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "algorithm()\n",
        "callbacks = [checkpoint]\n",
        "number_of_features=44\n",
        "algorithm()\n",
        "netincome = models.Sequential()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "netincome.add(layers.Dense(units=1000, activation=\"relu\", input_shape=(\n",
        "number_of_features,)))\n",
        "algorithm()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "netincome.add(layers.Dense(units=1000, activation=\"relu\"))\n",
        "algorithm()\n",
        "# Add fully connected layer with a sigmoid activation function\n",
        "netincome.add(layers.Dense(units=1, activation=\"sigmoid\")) # No activation for regression\n",
        "# Compile neural netincome\n",
        "algorithm()\n",
        "netincome.compile(loss=\"binary_crossentropy\", # Cross-entropy # \"mse\" for regression\n",
        "optimizer=\"sgd\", # Root Mean Square Propagation\n",
        "metrics=[\"accuracy\"]) # Accuracy performance metric\n",
        "history = netincome.fit(X_sample, # Features\n",
        "y_sample, # Target vector\n",
        "epochs=20,\n",
        "verbose=1,\n",
        "callbacks=callbacks, # Print description after each epoch\n",
        "batch_size=64,\n",
        "class_weight=class_weights_sample,\n",
        "validation_data=(X_for_test, y_for_test))\n",
        "\n",
        "##################################################################################\n",
        "\n",
        "income_sample=income.sample(8584, random_state=43)\n",
        "elsee_sample=elsee.sample(8584, random_state=43)\n",
        "income_sample=income_sample.sample(int(0.75*len(income_sample)), random_state=43)\n",
        "elsee_sample=elsee_sample.sample(int(0.25*len(elsee_sample)), random_state=43)\n",
        "data=pd.concat([income_sample, elsee_sample])\n",
        "\n",
        "X_sample=data.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "y_sample=data['UDPYOPI_1 - Yes']\n",
        "class_weights_sample = compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(y_sample),\n",
        "                                        y = y_sample\n",
        "                                    )\n",
        "sklearn_weights = dict(enumerate(class_weights_sample))\n",
        "class_weights_sample=sklearn_weights\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "algorithm()\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath='model_75_income.h5',\n",
        "                               monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "algorithm()\n",
        "callbacks = [checkpoint]\n",
        "number_of_features=44\n",
        "algorithm()\n",
        "netincome = models.Sequential()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "netincome.add(layers.Dense(units=1000, activation=\"relu\", input_shape=(\n",
        "number_of_features,)))\n",
        "algorithm()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "netincome.add(layers.Dense(units=1000, activation=\"relu\"))\n",
        "algorithm()\n",
        "# Add fully connected layer with a sigmoid activation function\n",
        "netincome.add(layers.Dense(units=1, activation=\"sigmoid\")) # No activation for regression\n",
        "# Compile neural netincome\n",
        "algorithm()\n",
        "netincome.compile(loss=\"binary_crossentropy\", # Cross-entropy # \"mse\" for regression\n",
        "optimizer=\"sgd\", # Root Mean Square Propagation\n",
        "metrics=[\"accuracy\"]) # Accuracy performance metric\n",
        "history = netincome.fit(X_sample, # Features\n",
        "y_sample, # Target vector\n",
        "epochs=20,\n",
        "verbose=1,\n",
        "callbacks=callbacks, # Print description after each epoch\n",
        "batch_size=64,\n",
        "class_weight=class_weights_sample,\n",
        "validation_data=(X_for_test, y_for_test))\n",
        "\n",
        "######################################################################\n",
        "\n",
        "income_sample=income.sample(8584, random_state=43)\n",
        "elsee_sample=elsee.sample(8584, random_state=43)\n",
        "income_sample=income_sample.sample(int(0.875*len(income_sample)), random_state=43)\n",
        "elsee_sample=elsee_sample.sample(int(0.125*len(elsee_sample)), random_state=43)\n",
        "data=pd.concat([income_sample, elsee_sample])\n",
        "\n",
        "X_sample=data.drop(['UDPYOPI_1 - Yes'], axis=1)\n",
        "y_sample=data['UDPYOPI_1 - Yes']\n",
        "class_weights_sample = compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(y_sample),\n",
        "                                        y = y_sample\n",
        "                                    )\n",
        "sklearn_weights = dict(enumerate(class_weights_sample))\n",
        "class_weights_sample=sklearn_weights\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "algorithm()\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath='model_875_income.h5',\n",
        "                               monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "algorithm()\n",
        "callbacks = [checkpoint]\n",
        "number_of_features=44\n",
        "algorithm()\n",
        "netincome = models.Sequential()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "netincome.add(layers.Dense(units=1000, activation=\"relu\", input_shape=(\n",
        "number_of_features,)))\n",
        "algorithm()\n",
        "# Add fully connected layer with a ReLU activation function\n",
        "netincome.add(layers.Dense(units=1000, activation=\"relu\"))\n",
        "algorithm()\n",
        "# Add fully connected layer with a sigmoid activation function\n",
        "netincome.add(layers.Dense(units=1, activation=\"sigmoid\")) # No activation for regression\n",
        "# Compile neural netincome\n",
        "algorithm()\n",
        "netincome.compile(loss=\"binary_crossentropy\", # Cross-entropy # \"mse\" for regression\n",
        "optimizer=\"sgd\", # Root Mean Square Propagation\n",
        "metrics=[\"accuracy\"]) # Accuracy performance metric\n",
        "history = netincome.fit(X_sample, # Features\n",
        "y_sample, # Target vector\n",
        "epochs=20,\n",
        "verbose=1,\n",
        "callbacks=callbacks, # Print description after each epoch\n",
        "batch_size=64,\n",
        "class_weight=class_weights_sample,\n",
        "validation_data=(X_for_test, y_for_test))\n",
        "\n",
        "prob1_50=load_model('model_50_income.h5').predict(income_predictors_test)\n",
        "prob2_50=load_model('model_50_income.h5').predict(elsee_predictors_test)\n",
        "prob1_625=load_model('model_625_income.h5').predict(income_predictors_test)\n",
        "prob2_625=load_model('model_625_income.h5').predict(elsee_predictors_test)\n",
        "prob1_75=load_model('model_75_income.h5').predict(income_predictors_test)\n",
        "prob2_75=load_model('model_75_income.h5').predict(elsee_predictors_test)\n",
        "prob1_875=load_model('model_875_income.h5').predict(income_predictors_test)\n",
        "prob2_875=load_model('model_875_income.h5').predict(elsee_predictors_test)\n",
        "\n",
        "print('Income less than $20,000 (50):', roc_auc_score(income_target_test, prob1_50))\n",
        "print('Else (50):', roc_auc_score(elsee_target_test, prob2_50))\n",
        "print('Income less than $20,000 (62.5):', roc_auc_score(income_target_test, prob1_625))\n",
        "print('Else (37.5):', roc_auc_score(elsee_target_test, prob2_625))\n",
        "print('Income less than $20,000 (75):', roc_auc_score(income_target_test, prob1_75))\n",
        "print('Else (25):', roc_auc_score(elsee_target_test, prob2_75))\n",
        "print('Income less than $20,000 (87.5):', roc_auc_score(income_target_test, prob1_875))\n",
        "print('Else (12.5):', roc_auc_score(elsee_target_test, prob2_875))\n",
        "\n",
        "# x axis values\n",
        "x = [50, 62.5, 75, 87.5]\n",
        "# corresponding y axis values\n",
        "y = [roc_auc_score(elsee_target_test, prob2_50),roc_auc_score(elsee_target_test, prob2_625),\n",
        "     roc_auc_score(elsee_target_test, prob2_75),roc_auc_score(elsee_target_test, prob2_875)]\n",
        "z = [roc_auc_score(income_target_test, prob1_50),roc_auc_score(income_target_test, prob1_625),\n",
        "     roc_auc_score(income_target_test, prob1_75),roc_auc_score(income_target_test, prob1_875)]\n",
        "c_line_main1 = 'rgba(200, 20, 20, 1.0)'\n",
        "c_line_main2 = 'rgba(20, 20, 200, 1)'\n",
        "fig = go.Figure([\n",
        "\n",
        "    go.Scatter(\n",
        "        x          = x,\n",
        "        y          = y,\n",
        "        line       = dict(color=c_line_main1, width=3),\n",
        "        hoverinfo  = \"skip\",\n",
        "        showlegend = True,\n",
        "        name       = f'<b>Other</b>'),\n",
        "    go.Scatter(\n",
        "        x          = x,\n",
        "        y          = z,\n",
        "        line       = dict(color=c_line_main2, width=3),\n",
        "        hoverinfo  = \"skip\",\n",
        "        showlegend = True,\n",
        "        name       = f'<b>Income less than $20,000</b>')\n",
        "    ])\n",
        "fig.add_shape(\n",
        "        type ='line',\n",
        "        line =dict(dash='dash'),\n",
        "        x0=0, x1=1, y0=0, y1=1\n",
        "    )\n",
        "fig.update_layout(\n",
        "        template    = 'plotly_white',\n",
        "        title_x     = 0.3,\n",
        "        xaxis_title = \"<b>Percentage of 'Income less than $20,000'</b>\",\n",
        "        yaxis_title = \"<b>AUC</b>\",\n",
        "        width       = 600,\n",
        "        height      = 500,\n",
        "        legend      = dict(\n",
        "            yanchor=\"bottom\",\n",
        "            xanchor=\"right\",\n",
        "            x=0.95,\n",
        "            y=0.01,\n",
        "        )\n",
        "    )\n",
        "fig.update_layout(\n",
        "        font=dict(\n",
        "        family=\"Times New Roman\",\n",
        "        size=18,  # Set the font size here\n",
        "        color=\"Black\"\n",
        "        )\n",
        "    )\n",
        "fig.update_yaxes(\n",
        "        range       = [min(min(y), min(z))-0.1, max(max(y), max(z))+0.1],\n",
        "        gridcolor   = c_grid,\n",
        "        scaleanchor = \"x\",\n",
        "        scaleratio  = 190,\n",
        "        linecolor   = 'black')\n",
        "fig.update_xaxes(\n",
        "        range       = [40, 100],\n",
        "        gridcolor   = c_grid,\n",
        "        constrain   = 'domain',\n",
        "        linecolor   = 'black',dtick=12.5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "820d1057",
      "metadata": {
        "id": "820d1057"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b81ae104",
      "metadata": {
        "id": "b81ae104"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46a346d4",
      "metadata": {
        "id": "46a346d4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7645381",
      "metadata": {
        "id": "a7645381"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d323e66",
      "metadata": {
        "id": "0d323e66"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02ca45b5",
      "metadata": {
        "id": "02ca45b5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b16e559",
      "metadata": {
        "id": "9b16e559"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "5d43390a",
      "metadata": {
        "id": "5d43390a",
        "outputId": "39beeb7a-3ed0-4842-ea3f-17fc52cb79b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "206/206 [==============================] - 1s 4ms/step\n",
            "206/206 [==============================] - 1s 3ms/step\n",
            "206/206 [==============================] - 1s 3ms/step\n",
            "206/206 [==============================] - 1s 3ms/step\n",
            "206/206 [==============================] - 1s 3ms/step\n"
          ]
        }
      ],
      "source": [
        "# Classifying Using All the Classifiers\n",
        "network = load_model('best_model_sgd.h5')\n",
        "preds_gender = (network.predict(X_test) >= 52.10*0.01).astype(int)\n",
        "preds_marital = (network.predict(X_test) >= 5.80*0.01).astype(int)\n",
        "preds_work = (network.predict(X_test) >= 12.50*0.01).astype(int)\n",
        "preds_race = (network.predict(X_test) >= 8.10*0.01).astype(int)\n",
        "preds_income = (network.predict(X_test) >= 52.60*0.01).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "89944fb1",
      "metadata": {
        "id": "89944fb1"
      },
      "outputs": [],
      "source": [
        "values=[]\n",
        "preds=[]\n",
        "def most_frequent(List):\n",
        "    return max(set(List), key = List.count)\n",
        "for i in range(len(X_test)):\n",
        "    values.append(preds_gender[i][0])\n",
        "    values.append(preds_marital[i][0])\n",
        "    values.append(preds_work[i][0])\n",
        "    values.append(preds_race[i][0])\n",
        "    values.append(preds_income[i][0])\n",
        "    preds.append(most_frequent(values))\n",
        "    values=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "07828165",
      "metadata": {
        "id": "07828165",
        "outputId": "314cb59b-110e-4b2c-8a6b-f6af93342fd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "conf_matrix = confusion_matrix(y_test, preds)\n",
        "fig, ax = plot_confusion_matrix(conf_mat=conf_matrix, figsize=(3, 3), cmap=plt.cm.Blues)\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.ylabel('True Label', fontsize=12)\n",
        "accuracy=(conf_matrix[0,0]+conf_matrix[1,1])/(conf_matrix[0,0]+conf_matrix[1,1]+conf_matrix[0,1]+conf_matrix[1,0])\n",
        "sensitivity=conf_matrix[1,1]/(conf_matrix[1,0]+conf_matrix[1,1])\n",
        "precision=conf_matrix[1,1]/(conf_matrix[0,1]+conf_matrix[1,1])\n",
        "f1_score=2*precision*sensitivity/(precision+sensitivity)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "6ab8906b",
      "metadata": {
        "id": "6ab8906b"
      },
      "outputs": [],
      "source": [
        "preds_1=[preds_gender, preds_marital, preds_work, preds_race, preds_income]\n",
        "preds_1=np.array(preds_1)\n",
        "w_gender=2.03/(2.03+13.02+19.91+60.17+3.42)\n",
        "w_marital=13.02/(2.03+13.02+19.91+60.17+3.42)\n",
        "w_work=19.91/(2.03+13.02+19.91+60.17+3.42)\n",
        "w_race=60.17/(2.03+13.02+19.91+60.17+3.42)\n",
        "w_income=3.42/(2.03+13.02+19.91+60.17+3.42)\n",
        "wts=[w_gender, w_marital, w_work, w_race, w_income]\n",
        "wted_preds1 = np.tensordot(preds_1, wts, axes=((0),(0)))\n",
        "preds = (wted_preds1 >= 50*0.01).astype(bool)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "95ea5d79",
      "metadata": {
        "id": "95ea5d79",
        "outputId": "f73f8b21-d545-4bf0-ed93-133d0f8d99c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "conf_matrix = confusion_matrix(y_test, preds)\n",
        "fig, ax = plot_confusion_matrix(conf_mat=conf_matrix, figsize=(3, 3), cmap=plt.cm.Blues)\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.ylabel('True Label', fontsize=12)\n",
        "accuracy=(conf_matrix[0,0]+conf_matrix[1,1])/(conf_matrix[0,0]+conf_matrix[1,1]+conf_matrix[0,1]+conf_matrix[1,0])\n",
        "sensitivity=conf_matrix[1,1]/(conf_matrix[1,0]+conf_matrix[1,1])\n",
        "precision=conf_matrix[1,1]/(conf_matrix[0,1]+conf_matrix[1,1])\n",
        "f1_score=2*precision*sensitivity/(precision+sensitivity)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}